{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Masbaisis_indices_280619.xlsx to Masbasis_indices_280619.xlsx  \n",
    "Rename Masbasis_2606_2019_color_and_othe_indecies  to Masbasis_260619_color_and_othe_indecies  \n",
    "Rename/manually change the date format of Masbasis 2021 data from YYMMDD to DDMMYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:29.987023Z",
     "start_time": "2021-10-22T23:31:28.401754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "\n",
    "# Dictionaries\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To display df nicely in loops\n",
    "from IPython.display import display \n",
    "# display(df1.head()) \n",
    "# display(df2.head())\n",
    "\n",
    "# Display rows and columns Pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:30.002236Z",
     "start_time": "2021-10-22T23:31:29.988274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fahad\\\\MegaSync\\\\NMBU\\\\GitHub\\\\vPheno'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the current working directory\n",
    "os.getcwd()\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Username folder to make general path for multi PC use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:30.018837Z",
     "start_time": "2021-10-22T23:31:30.003234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fahad'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = str(os.getcwd()).split('\\\\')[2]\n",
    "username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo:  \n",
    "  \n",
    "2019 2020 data is fine  \n",
    "Cant use 2017 because of the blue band  \n",
    "Distt is not normal in 2018 robot  \n",
    "AREA UNDER THE CURVE in each season for 2018 2017  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:30.034080Z",
     "start_time": "2021-10-22T23:31:30.021115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019 Staur Graminor',\n",
       " '2019 Vollebekk Graminor',\n",
       " '2019 Vollebekk Masbasis',\n",
       " '2020 Staur Graminor',\n",
       " '2020 Staur Masbasis_bandsNA',\n",
       " '2020 Vollebekk Graminor',\n",
       " '2020 Vollebekk Masbasis',\n",
       " '2020 Vollebekk Robot',\n",
       " '2021 Vollebekk Masbasis_yieldNA']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'C:\\\\Users\\\\'+username+'\\\\MegaSync\\\\NMBU\\\\Master Thesis\\\\Data\\\\Feb2021'\n",
    "parent_path = './Data/'\n",
    "complete_df_path = parent_path+'1. complete_datasets/'\n",
    "\n",
    "# Create export_path folder if not exists already\n",
    "os.makedirs(complete_df_path, exist_ok=True)\n",
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Creating list of all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:30.052745Z",
     "start_time": "2021-10-22T23:31:30.035078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 files founnd in the directory\n"
     ]
    }
   ],
   "source": [
    "# Get the list of all files in directory tree at given path\n",
    "\n",
    "files_with_address = []\n",
    "files_list = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "    files_with_address += [os.path.join(dirpath, file) for file in filenames]\n",
    "    files_list.extend(filenames)\n",
    "    \n",
    "print(len(files_with_address), 'files founnd in the directory')\n",
    "# files_with_address\n",
    "# files_list\n",
    "files_with_address_bkp = copy(files_with_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Checking/control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Check for duplicate filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:30.067909Z",
     "start_time": "2021-10-22T23:31:30.054946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files are : 87\n",
      "Number of unique file names are: 87\n",
      "There is/are 0 duplicate file name/names.\n"
     ]
    }
   ],
   "source": [
    "print('Total number of files are :', len(files_list))\n",
    "\n",
    "print('Number of unique file names are:', len(set(files_list)))\n",
    "\n",
    "print('There is/are', len(files_list) - len(set(files_list)),'duplicate file name/names.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if there are multiple sheets in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:32.316384Z",
     "start_time": "2021-10-22T23:31:30.068906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following files have multiple sheets.\n",
      "3 19BMLFN3 - MASBASIS yield trial Staur 2019.xlsx in folder 2019 Staur Graminor\n",
      "4 19TvPhenores.xlsx in folder 2019 Vollebekk Graminor\n",
      "4 19BMLGI1 - MASBASIS yield trial Vollebekk 2019.xlsx in folder 2019 Vollebekk Masbasis\n",
      "3 Staur-Graminor-Masbasis_2020.xlsx in folder 2020 Staur Graminor\n",
      "2 20BMLFN3 - MASBASIS avlingsforsÃ¸k Staur 2020 lodging data.xlsx in folder 2020 Staur Masbasis_bandsNA\n",
      "2 Masbasis_2020_staur.xlsx in folder 2020 Staur Masbasis_bandsNA\n",
      "2 Staur_maturity_heading_yield_2020.xlsx in folder 2020 Staur Masbasis_bandsNA\n",
      "3 20BMLGI1_2020_tm.xlsx in folder 2020 Vollebekk Masbasis\n",
      "3 Masbasis_Mica_2020_all_dates_MEDIAN_DP.xlsx in folder 2020 Vollebekk Masbasis\n",
      "3 ROBOT_2020.xlsx in folder 2020 Vollebekk Robot\n"
     ]
    }
   ],
   "source": [
    "# Print number of sheets in all files\n",
    "print('The following files have multiple sheets.')\n",
    "\n",
    "list_multi_sheet = []\n",
    "for file in files_with_address:\n",
    "    \n",
    "    xl_file = pd.ExcelFile(file,engine='openpyxl')\n",
    "    number_of_sheets = len(xl_file.sheet_names)\n",
    "    if number_of_sheets > 1:\n",
    "        print(number_of_sheets, os.path.basename(file), 'in folder', os.path.basename(os.path.dirname(file))\n",
    ")\n",
    "        list_multi_sheet.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing files with multiple sheets from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:32.331574Z",
     "start_time": "2021-10-22T23:31:32.317611Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing files with multiple sheets from the list\n",
    "\n",
    "for i in list_multi_sheet:\n",
    "    files_with_address.remove(i)\n",
    "len(files_with_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing files without dates\n",
    "(with 2019 in name means they dont have date format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:32.341843Z",
     "start_time": "2021-10-22T23:31:32.333569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_Graminor_2019_median PLT918-2050 240719 070819 150819 210819 300819.xlsx in folder 2019 Staur Graminor\n",
      "Staur_Masbasis_2019 PLT101-866 240719 070819 150819 300819.xlsx in folder 2019 Staur Graminor\n",
      "2020TGraminor-Vollebekk-res.xlsx in folder 2020 Vollebekk Graminor\n"
     ]
    }
   ],
   "source": [
    "files_w_2019 = []\n",
    "for file in files_with_address:\n",
    "    file_name = os.path.basename(file)\n",
    "    if '2019' in file_name:\n",
    "        print(file_name, 'in folder', os.path.basename(os.path.dirname(file)))\n",
    "        files_w_2019.append(file)\n",
    "    if '2020' in file_name:\n",
    "        print(file_name, 'in folder', os.path.basename(os.path.dirname(file)))\n",
    "        files_w_2019.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:32.357937Z",
     "start_time": "2021-10-22T23:31:32.343974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\\\Users\\\\fahad\\MegaSync\\NMBU\\Master Thesis\\Data\\Feb2021\\2019 Staur Graminor\\Staur_Graminor_2019_median PLT918-2050 240719 070819 150819 210819 300819.xlsx\n",
      "C:\\\\Users\\\\fahad\\MegaSync\\NMBU\\Master Thesis\\Data\\Feb2021\\2019 Staur Graminor\\Staur_Masbasis_2019 PLT101-866 240719 070819 150819 300819.xlsx\n",
      "C:\\\\Users\\\\fahad\\MegaSync\\NMBU\\Master Thesis\\Data\\Feb2021\\2020 Vollebekk Graminor\\2020TGraminor-Vollebekk-res.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Removing from list\n",
    "for i in files_w_2019:\n",
    "    print(i)\n",
    "    files_with_address.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:32.377113Z",
     "start_time": "2021-10-22T23:31:32.359933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_with_address)\n",
    "# files_with_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking number of unique cultivars in the field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:32.397530Z",
     "start_time": "2021-10-22T23:31:32.379122Z"
    }
   },
   "outputs": [],
   "source": [
    "# plots_data = pd.read_excel(files_with_address[0],engine='openpyxl')\n",
    "# # Pandas converts 'NA' string to NaN. Need to change those to \n",
    "# # some string to get a count as NaNs are not counted as unique values\n",
    "\n",
    "# plots_data.Name.fillna('-', inplace=True)\n",
    "# plots_data.CodeName.fillna('-', inplace=True)\n",
    "\n",
    "# # Creating a new column as multiple plots were named 'NA' but the \n",
    "# # CodeName was different for each one of them\n",
    "# plots_data['NameCode'] = plots_data.Name+plots_data.CodeName\n",
    "\n",
    "# plots_data\n",
    "# len(plots_data.NameCode.unique())\n",
    "# plots_data.NameCode.value_counts()\n",
    "# # plots_data.NameCode.value_counts().sum()\n",
    "# # plots_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data files to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:37.918700Z",
     "start_time": "2021-10-22T23:31:32.398526Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_070819_mean_median_SP ===== (1328, 6)\n",
      "Staur_150819_mean_median_SP ===== (1328, 6)\n",
      "Staur_210819_mean_median_SP ===== (1328, 6)\n",
      "Staur_240719_mean_median_SP ===== (1328, 6)\n",
      "Staur_300819_mean_median_SP ===== (1328, 6)\n",
      "Graminor_250719 ===== (600, 6)\n",
      "Graminor_050719_plots_826,_837_deleted,_one_missing_row_deleted ===== (597, 6)\n",
      "Graminor_060619 ===== (600, 6)\n",
      "Graminor_070819_2 ===== (600, 6)\n",
      "Graminor_110619 ===== (600, 6)\n",
      "Graminor_150719 ===== (600, 6)\n",
      "Graminor_150819 ===== (600, 6)\n",
      "Graminor_280619_corrected ===== (600, 6)\n",
      "Graminor_eastwest_020719_NIR_half_missing ===== (600, 6)\n",
      "Graminor_eastwest_050819 ===== (600, 6)\n",
      "Graminor_east_110719 ===== (300, 6)\n",
      "Masbasis_050719_corrected ===== (528, 6)\n",
      "Masbasis_060619_Indices ===== (528, 6)\n",
      "Masbasis_070819_correct ===== (528, 6)\n",
      "Masbasis_150719 ===== (528, 6)\n",
      "Masbasis_220719_correct ===== (528, 6)\n",
      "Masbasis_260619_color_and_othe_indecies ===== (528, 6)\n",
      "Masbasis_290719 ===== (528, 6)\n",
      "Masbasis_indices_280619 ===== (528, 6)\n",
      "Staur_090720_M ===== (1722, 6)\n",
      "Staur_160720_Mica ===== (1722, 6)\n",
      "Staur_200620_Mica_index ===== (1722, 6)\n",
      "Staur_240720 ===== (1722, 6)\n",
      "Staur_250620_Mica_index ===== (1722, 6)\n",
      "Staur_310720 ===== (1722, 6)\n",
      "Graminor_eastwest_040720 ===== (800, 6)\n",
      "Graminor_eastwest_040820 ===== (793, 6)\n",
      "Graminor_eastwest_070720_correct ===== (800, 6)\n",
      "Graminor_eastwest_130720 ===== (800, 6)\n",
      "Graminor_eastwest_140820 ===== (800, 6)\n",
      "Graminor_eastwest_300720 ===== (787, 6)\n",
      "Graminor_east_010720 ===== (400, 6)\n",
      "Graminor_east_170720 ===== (400, 6)\n",
      "Graminor_east_180620 ===== (400, 6)\n",
      "Graminor_east_200720 ===== (400, 6)\n",
      "Graminor_Mica_eastcorrect_west_240620 ===== (757, 6)\n",
      "Masbasis_Mica_010720 ===== (688, 6)\n",
      "Masbasis_Mica_070820 ===== (688, 6)\n",
      "Masbasis_Mica_080720 ===== (688, 6)\n",
      "Masbasis_Mica_120820 ===== (688, 6)\n",
      "Masbasis_Mica_130720 ===== (688, 6)\n",
      "Masbasis_Mica_140820 ===== (688, 6)\n",
      "Masbasis_mica_170720 ===== (688, 6)\n",
      "Masbasis_mica_180620_several_missing_rows_deleted ===== (688, 6)\n",
      "Masbasis_Mica_220720 ===== (688, 6)\n",
      "Masbasis_mica_240620 ===== (688, 6)\n",
      "Masbasis_Mica_260620 ===== (688, 6)\n",
      "Masbasis_Mica_300720_duplicate_plots_deleted_1332,1329,1330,1331same_data ===== (688, 6)\n",
      "Robot_Mica_010720 ===== (96, 6)\n",
      "Robot_Mica_040820 ===== (96, 6)\n",
      "Robot_Mica_070720 ===== (96, 6)\n",
      "Robot_Mica_120820 ===== (96, 6)\n",
      "Robot_Mica_130720 ===== (96, 6)\n",
      "Robot_mica_180620 ===== (96, 6)\n",
      "Robot_Mica_200720 ===== (96, 6)\n",
      "Robot_Mica_220720 ===== (96, 6)\n",
      "Robot_Mica_230620 ===== (96, 6)\n",
      "Robot_Mica_240620 ===== (96, 6)\n",
      "Robot_Mica_250620 ===== (96, 6)\n",
      "Robot_Mica_270720 ===== (96, 6)\n",
      "Robot_Mica_290620 ===== (96, 6)\n",
      "Robot_Mica_300720 ===== (96, 6)\n",
      "Masbasis_mica_020621 ===== (696, 6)\n",
      "Masbasis_mica_090721_excel ===== (696, 6)\n",
      "Masbasis_mica_170621 ===== (696, 6)\n",
      "Masbasis_mica_220721 ===== (696, 6)\n",
      "Masbasis_mica_230621_excel ===== (696, 6)\n",
      "Masbasis_mica_240621_excel ===== (696, 6)\n",
      "Masbasis_mica_260721 ===== (696, 6)\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_df = []\n",
    "for data in files_with_address:\n",
    "    file_name = os.path.splitext(os.path.basename(data))[0]\n",
    "\n",
    "    # Replce all invalid characters in the name\n",
    "    file_name = file_name.replace(\"-\", \"_\")\n",
    "    file_name = file_name.replace(\" \", \"_\")\n",
    "    file_name = file_name.replace(\"(\", \"\")\n",
    "    file_name = file_name.replace(\")\", \"\")\n",
    "    df_name = file_name.replace(\".\", \"\")\n",
    "    # Test: Check if the same date is already present in the current dict key\n",
    "    if df_name in all_df:\n",
    "        print(f'A file with the same name {df_name} has already been imported. \\n Please check if there is duplication of data.')\n",
    "        raise NameError\n",
    "            \n",
    "    all_df.append(df_name)\n",
    "\n",
    "    locals()[df_name] = pd.read_excel(data, engine='openpyxl')\n",
    "    print(df_name, '=====', locals()[df_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:37.937326Z",
     "start_time": "2021-10-22T23:31:37.919092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imported 74\n"
     ]
    }
   ],
   "source": [
    "print(f'Total imported {len(all_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Control: Check which df have the data column heading we need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing column headings into df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.018396Z",
     "start_time": "2021-10-22T23:31:37.937326Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.1 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Staur_070819_mean_median_SP</th>\n",
       "      <th>Staur_150819_mean_median_SP</th>\n",
       "      <th>Staur_210819_mean_median_SP</th>\n",
       "      <th>Staur_240719_mean_median_SP</th>\n",
       "      <th>Staur_300819_mean_median_SP</th>\n",
       "      <th>Graminor_250719</th>\n",
       "      <th>Graminor_050719_plots_826,_837_deleted,_one_missing_row_deleted</th>\n",
       "      <th>Graminor_060619</th>\n",
       "      <th>Graminor_070819_2</th>\n",
       "      <th>Graminor_110619</th>\n",
       "      <th>Graminor_150719</th>\n",
       "      <th>Graminor_150819</th>\n",
       "      <th>Graminor_280619_corrected</th>\n",
       "      <th>Graminor_eastwest_020719_NIR_half_missing</th>\n",
       "      <th>Graminor_eastwest_050819</th>\n",
       "      <th>Graminor_east_110719</th>\n",
       "      <th>Masbasis_050719_corrected</th>\n",
       "      <th>Masbasis_060619_Indices</th>\n",
       "      <th>Masbasis_070819_correct</th>\n",
       "      <th>Masbasis_150719</th>\n",
       "      <th>Masbasis_220719_correct</th>\n",
       "      <th>Masbasis_260619_color_and_othe_indecies</th>\n",
       "      <th>Masbasis_290719</th>\n",
       "      <th>Masbasis_indices_280619</th>\n",
       "      <th>Staur_090720_M</th>\n",
       "      <th>Staur_160720_Mica</th>\n",
       "      <th>Staur_200620_Mica_index</th>\n",
       "      <th>Staur_240720</th>\n",
       "      <th>Staur_250620_Mica_index</th>\n",
       "      <th>Staur_310720</th>\n",
       "      <th>Graminor_eastwest_040720</th>\n",
       "      <th>Graminor_eastwest_040820</th>\n",
       "      <th>Graminor_eastwest_070720_correct</th>\n",
       "      <th>Graminor_eastwest_130720</th>\n",
       "      <th>Graminor_eastwest_140820</th>\n",
       "      <th>Graminor_eastwest_300720</th>\n",
       "      <th>Graminor_east_010720</th>\n",
       "      <th>Graminor_east_170720</th>\n",
       "      <th>Graminor_east_180620</th>\n",
       "      <th>Graminor_east_200720</th>\n",
       "      <th>Graminor_Mica_eastcorrect_west_240620</th>\n",
       "      <th>Masbasis_Mica_010720</th>\n",
       "      <th>Masbasis_Mica_070820</th>\n",
       "      <th>Masbasis_Mica_080720</th>\n",
       "      <th>Masbasis_Mica_120820</th>\n",
       "      <th>Masbasis_Mica_130720</th>\n",
       "      <th>Masbasis_Mica_140820</th>\n",
       "      <th>Masbasis_mica_170720</th>\n",
       "      <th>Masbasis_mica_180620_several_missing_rows_deleted</th>\n",
       "      <th>Masbasis_Mica_220720</th>\n",
       "      <th>Masbasis_mica_240620</th>\n",
       "      <th>Masbasis_Mica_260620</th>\n",
       "      <th>Masbasis_Mica_300720_duplicate_plots_deleted_1332,1329,1330,1331same_data</th>\n",
       "      <th>Robot_Mica_010720</th>\n",
       "      <th>Robot_Mica_040820</th>\n",
       "      <th>Robot_Mica_070720</th>\n",
       "      <th>Robot_Mica_120820</th>\n",
       "      <th>Robot_Mica_130720</th>\n",
       "      <th>Robot_mica_180620</th>\n",
       "      <th>Robot_Mica_200720</th>\n",
       "      <th>Robot_Mica_220720</th>\n",
       "      <th>Robot_Mica_230620</th>\n",
       "      <th>Robot_Mica_240620</th>\n",
       "      <th>Robot_Mica_250620</th>\n",
       "      <th>Robot_Mica_270720</th>\n",
       "      <th>Robot_Mica_290620</th>\n",
       "      <th>Robot_Mica_300720</th>\n",
       "      <th>Masbasis_mica_020621</th>\n",
       "      <th>Masbasis_mica_090721_excel</th>\n",
       "      <th>Masbasis_mica_170621</th>\n",
       "      <th>Masbasis_mica_220721</th>\n",
       "      <th>Masbasis_mica_230621_excel</th>\n",
       "      <th>Masbasis_mica_240621_excel</th>\n",
       "      <th>Masbasis_mica_260721</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "      <td>Plot_ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "      <td>Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>NIR</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "      <td>RedEdge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Staur_070819_mean_median_SP Staur_150819_mean_median_SP  \\\n",
       "0                     Plot_ID                     Plot_ID   \n",
       "1                        Blue                        Blue   \n",
       "2                       Green                       Green   \n",
       "3                         Red                         Red   \n",
       "4                     RedEdge                     RedEdge   \n",
       "5                         NIR                         NIR   \n",
       "\n",
       "  Staur_210819_mean_median_SP Staur_240719_mean_median_SP  \\\n",
       "0                     Plot_ID                     Plot_ID   \n",
       "1                        Blue                        Blue   \n",
       "2                       Green                       Green   \n",
       "3                         Red                         Red   \n",
       "4                     RedEdge                     RedEdge   \n",
       "5                         NIR                         NIR   \n",
       "\n",
       "  Staur_300819_mean_median_SP Graminor_250719  \\\n",
       "0                     Plot_ID         Plot_ID   \n",
       "1                        Blue            Blue   \n",
       "2                       Green           Green   \n",
       "3                         Red             Red   \n",
       "4                     RedEdge         RedEdge   \n",
       "5                         NIR             NIR   \n",
       "\n",
       "  Graminor_050719_plots_826,_837_deleted,_one_missing_row_deleted  \\\n",
       "0                                            Plot_ID                \n",
       "1                                               Blue                \n",
       "2                                              Green                \n",
       "3                                                Red                \n",
       "4                                            RedEdge                \n",
       "5                                                NIR                \n",
       "\n",
       "  Graminor_060619 Graminor_070819_2 Graminor_110619 Graminor_150719  \\\n",
       "0         Plot_ID           Plot_ID         Plot_ID         Plot_ID   \n",
       "1            Blue              Blue            Blue            Blue   \n",
       "2           Green             Green           Green           Green   \n",
       "3             NIR               NIR             NIR             Red   \n",
       "4             Red               Red             Red         RedEdge   \n",
       "5         RedEdge           RedEdge         RedEdge             NIR   \n",
       "\n",
       "  Graminor_150819 Graminor_280619_corrected  \\\n",
       "0         Plot_ID                   Plot_ID   \n",
       "1            Blue                      Blue   \n",
       "2           Green                     Green   \n",
       "3             Red                       NIR   \n",
       "4         RedEdge                       Red   \n",
       "5             NIR                   RedEdge   \n",
       "\n",
       "  Graminor_eastwest_020719_NIR_half_missing Graminor_eastwest_050819  \\\n",
       "0                                   Plot_ID                  Plot_ID   \n",
       "1                                      Blue                     Blue   \n",
       "2                                     Green                    Green   \n",
       "3                                       Red                      Red   \n",
       "4                                   RedEdge                  RedEdge   \n",
       "5                                       NIR                      NIR   \n",
       "\n",
       "  Graminor_east_110719 Masbasis_050719_corrected Masbasis_060619_Indices  \\\n",
       "0              Plot_ID                   Plot_ID                 Plot_ID   \n",
       "1                 Blue                      Blue                    Blue   \n",
       "2                Green                     Green                   Green   \n",
       "3                  NIR                       Red                     NIR   \n",
       "4                  Red                   RedEdge                     Red   \n",
       "5              RedEdge                       NIR                 RedEdge   \n",
       "\n",
       "  Masbasis_070819_correct Masbasis_150719 Masbasis_220719_correct  \\\n",
       "0                 Plot_ID         Plot_ID                 Plot_ID   \n",
       "1                    Blue            Blue                    Blue   \n",
       "2                   Green           Green                   Green   \n",
       "3                     Red             NIR                     Red   \n",
       "4                 RedEdge             Red                 RedEdge   \n",
       "5                     NIR         RedEdge                     NIR   \n",
       "\n",
       "  Masbasis_260619_color_and_othe_indecies Masbasis_290719  \\\n",
       "0                                 Plot_ID         Plot_ID   \n",
       "1                                    Blue            Blue   \n",
       "2                                   Green           Green   \n",
       "3                                     NIR             NIR   \n",
       "4                                     Red             Red   \n",
       "5                                 RedEdge         RedEdge   \n",
       "\n",
       "  Masbasis_indices_280619 Staur_090720_M Staur_160720_Mica  \\\n",
       "0                 Plot_ID        Plot_ID           Plot_ID   \n",
       "1                    Blue           Blue              Blue   \n",
       "2                   Green          Green             Green   \n",
       "3                     NIR            NIR               NIR   \n",
       "4                     Red            Red               Red   \n",
       "5                 RedEdge        RedEdge           RedEdge   \n",
       "\n",
       "  Staur_200620_Mica_index Staur_240720 Staur_250620_Mica_index Staur_310720  \\\n",
       "0                 Plot_ID      Plot_ID                 Plot_ID      Plot_ID   \n",
       "1                    Blue         Blue                    Blue         Blue   \n",
       "2                   Green        Green                   Green        Green   \n",
       "3                     NIR          NIR                     NIR          NIR   \n",
       "4                     Red          Red                     Red          Red   \n",
       "5                 RedEdge      RedEdge                 RedEdge      RedEdge   \n",
       "\n",
       "  Graminor_eastwest_040720 Graminor_eastwest_040820  \\\n",
       "0                  Plot_ID                  Plot_ID   \n",
       "1                     Blue                     Blue   \n",
       "2                    Green                    Green   \n",
       "3                      NIR                      NIR   \n",
       "4                      Red                      Red   \n",
       "5                  RedEdge                  RedEdge   \n",
       "\n",
       "  Graminor_eastwest_070720_correct Graminor_eastwest_130720  \\\n",
       "0                          Plot_ID                  Plot_ID   \n",
       "1                             Blue                     Blue   \n",
       "2                            Green                    Green   \n",
       "3                              NIR                      Red   \n",
       "4                              Red                  RedEdge   \n",
       "5                          RedEdge                      NIR   \n",
       "\n",
       "  Graminor_eastwest_140820 Graminor_eastwest_300720 Graminor_east_010720  \\\n",
       "0                  Plot_ID                  Plot_ID              Plot_ID   \n",
       "1                     Blue                     Blue                 Blue   \n",
       "2                    Green                    Green                Green   \n",
       "3                      NIR                      NIR                  NIR   \n",
       "4                      Red                      Red                  Red   \n",
       "5                  RedEdge                  RedEdge              RedEdge   \n",
       "\n",
       "  Graminor_east_170720 Graminor_east_180620 Graminor_east_200720  \\\n",
       "0              Plot_ID              Plot_ID              Plot_ID   \n",
       "1                 Blue                 Blue                 Blue   \n",
       "2                Green                Green                Green   \n",
       "3                  NIR                  NIR                  Red   \n",
       "4                  Red                  Red              RedEdge   \n",
       "5              RedEdge              RedEdge                  NIR   \n",
       "\n",
       "  Graminor_Mica_eastcorrect_west_240620 Masbasis_Mica_010720  \\\n",
       "0                               Plot_ID              Plot_ID   \n",
       "1                                  Blue                 Blue   \n",
       "2                                 Green                Green   \n",
       "3                                   NIR                  NIR   \n",
       "4                                   Red                  Red   \n",
       "5                               RedEdge              RedEdge   \n",
       "\n",
       "  Masbasis_Mica_070820 Masbasis_Mica_080720 Masbasis_Mica_120820  \\\n",
       "0              Plot_ID              Plot_ID              Plot_ID   \n",
       "1                 Blue                 Blue                 Blue   \n",
       "2                Green                Green                Green   \n",
       "3                  NIR                  Red                  NIR   \n",
       "4                  Red              RedEdge                  Red   \n",
       "5              RedEdge                  NIR              RedEdge   \n",
       "\n",
       "  Masbasis_Mica_130720 Masbasis_Mica_140820 Masbasis_mica_170720  \\\n",
       "0              Plot_ID              Plot_ID              Plot_ID   \n",
       "1                 Blue                 Blue                 Blue   \n",
       "2                Green                Green                Green   \n",
       "3                  Red                  NIR                  Red   \n",
       "4              RedEdge                  Red              RedEdge   \n",
       "5                  NIR              RedEdge                  NIR   \n",
       "\n",
       "  Masbasis_mica_180620_several_missing_rows_deleted Masbasis_Mica_220720  \\\n",
       "0                                           Plot_ID              Plot_ID   \n",
       "1                                              Blue                 Blue   \n",
       "2                                             Green                Green   \n",
       "3                                               Red                  NIR   \n",
       "4                                           RedEdge                  Red   \n",
       "5                                               NIR              RedEdge   \n",
       "\n",
       "  Masbasis_mica_240620 Masbasis_Mica_260620  \\\n",
       "0              Plot_ID              Plot_ID   \n",
       "1                 Blue                 Blue   \n",
       "2                Green                Green   \n",
       "3                  Red                  Red   \n",
       "4              RedEdge              RedEdge   \n",
       "5                  NIR                  NIR   \n",
       "\n",
       "  Masbasis_Mica_300720_duplicate_plots_deleted_1332,1329,1330,1331same_data  \\\n",
       "0                                            Plot_ID                          \n",
       "1                                               Blue                          \n",
       "2                                              Green                          \n",
       "3                                                NIR                          \n",
       "4                                                Red                          \n",
       "5                                            RedEdge                          \n",
       "\n",
       "  Robot_Mica_010720 Robot_Mica_040820 Robot_Mica_070720 Robot_Mica_120820  \\\n",
       "0           Plot_ID           Plot_ID           Plot_ID           Plot_ID   \n",
       "1              Blue              Blue              Blue              Blue   \n",
       "2             Green             Green             Green             Green   \n",
       "3               Red               NIR               Red               Red   \n",
       "4           RedEdge               Red           RedEdge           RedEdge   \n",
       "5               NIR           RedEdge               NIR               NIR   \n",
       "\n",
       "  Robot_Mica_130720 Robot_mica_180620 Robot_Mica_200720 Robot_Mica_220720  \\\n",
       "0           Plot_ID           Plot_ID           Plot_ID           Plot_ID   \n",
       "1              Blue              Blue              Blue              Blue   \n",
       "2             Green             Green             Green             Green   \n",
       "3               Red               NIR               NIR               NIR   \n",
       "4           RedEdge               Red               Red               Red   \n",
       "5               NIR           RedEdge           RedEdge           RedEdge   \n",
       "\n",
       "  Robot_Mica_230620 Robot_Mica_240620 Robot_Mica_250620 Robot_Mica_270720  \\\n",
       "0           Plot_ID           Plot_ID           Plot_ID           Plot_ID   \n",
       "1              Blue              Blue              Blue              Blue   \n",
       "2             Green             Green             Green             Green   \n",
       "3               NIR               NIR               NIR               NIR   \n",
       "4               Red               Red               Red               Red   \n",
       "5           RedEdge           RedEdge           RedEdge           RedEdge   \n",
       "\n",
       "  Robot_Mica_290620 Robot_Mica_300720 Masbasis_mica_020621  \\\n",
       "0           Plot_ID           Plot_ID              Plot_ID   \n",
       "1              Blue              Blue                 Blue   \n",
       "2             Green             Green                Green   \n",
       "3               NIR               NIR                  NIR   \n",
       "4               Red               Red                  Red   \n",
       "5           RedEdge           RedEdge              RedEdge   \n",
       "\n",
       "  Masbasis_mica_090721_excel Masbasis_mica_170621 Masbasis_mica_220721  \\\n",
       "0                    Plot_ID              Plot_ID              Plot_ID   \n",
       "1                       Blue                 Blue                 Blue   \n",
       "2                      Green                Green                Green   \n",
       "3                        NIR                  NIR                  NIR   \n",
       "4                        Red                  Red                  Red   \n",
       "5                    RedEdge              RedEdge              RedEdge   \n",
       "\n",
       "  Masbasis_mica_230621_excel Masbasis_mica_240621_excel Masbasis_mica_260721  \n",
       "0                    Plot_ID                    Plot_ID              Plot_ID  \n",
       "1                       Blue                       Blue                 Blue  \n",
       "2                      Green                      Green                Green  \n",
       "3                        NIR                        NIR                  NIR  \n",
       "4                        Red                        Red                  Red  \n",
       "5                    RedEdge                    RedEdge              RedEdge  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Finding max number of columns in all df\n",
    "\n",
    "len_columns = []\n",
    "for df in all_df:\n",
    "    cols_df = locals()[df].columns\n",
    "    len_columns.append(len(cols_df))\n",
    "max_cols_in_df = max(len_columns)\n",
    "\n",
    "# Now creating a empty df to collect all column headings\n",
    "columns_df = pd.DataFrame(data=range(0,max_cols_in_df), columns = ['ID'])\n",
    "columns_df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "for df in all_df:\n",
    "    cols_df = locals()[df].columns\n",
    "    columns_df[df] = pd.Series(cols_df)\n",
    "columns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert columns_df to dictoionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.048316Z",
     "start_time": "2021-10-22T23:31:38.019393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Function to convert df to dict while dropping nan in each column separately\n",
    "\n",
    "def comp_dropna(df1):\n",
    "    return {k: v.dropna().to_dict() for k,v in df1.items()}\n",
    "\n",
    "columns_dict = comp_dropna(columns_df)\n",
    "# columns_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing the names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T23:27:44.274887Z",
     "start_time": "2021-10-21T23:27:44.264024Z"
    }
   },
   "source": [
    "## Creating a dictionary with all dates for a certain field for a certain year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.064272Z",
     "start_time": "2021-10-22T23:31:38.050311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_df)\n",
    "# all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.106438Z",
     "start_time": "2021-10-22T23:31:38.065271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_070819 ********* Staur_070819_mean_median_SP\n",
      "Staur_150819 ********* Staur_150819_mean_median_SP\n",
      "Staur_210819 ********* Staur_210819_mean_median_SP\n",
      "Staur_240719 ********* Staur_240719_mean_median_SP\n",
      "Staur_300819 ********* Staur_300819_mean_median_SP\n",
      "Graminor_250719 ********* Graminor_250719\n",
      "Graminor_050719 ********* Graminor_050719_plots_826,_837_deleted,_one_missing_row_deleted\n",
      "Graminor_060619 ********* Graminor_060619\n",
      "Graminor_070819 ********* Graminor_070819_2\n",
      "Graminor_110619 ********* Graminor_110619\n",
      "Graminor_150719 ********* Graminor_150719\n",
      "Graminor_150819 ********* Graminor_150819\n",
      "Graminor_280619 ********* Graminor_280619_corrected\n",
      "Graminor_020719 ********* Graminor_eastwest_020719_NIR_half_missing\n",
      "Graminor_050819 ********* Graminor_eastwest_050819\n",
      "Graminor_110719 ********* Graminor_east_110719\n",
      "Masbasis_050719 ********* Masbasis_050719_corrected\n",
      "Masbasis_060619 ********* Masbasis_060619_Indices\n",
      "Masbasis_070819 ********* Masbasis_070819_correct\n",
      "Masbasis_150719 ********* Masbasis_150719\n",
      "Masbasis_220719 ********* Masbasis_220719_correct\n",
      "Masbasis_260619 ********* Masbasis_260619_color_and_othe_indecies\n",
      "Masbasis_290719 ********* Masbasis_290719\n",
      "Masbasis_280619 ********* Masbasis_indices_280619\n",
      "Staur_090720 ********* Staur_090720_M\n",
      "Staur_160720 ********* Staur_160720_Mica\n",
      "Staur_200620 ********* Staur_200620_Mica_index\n",
      "Staur_240720 ********* Staur_240720\n",
      "Staur_250620 ********* Staur_250620_Mica_index\n",
      "Staur_310720 ********* Staur_310720\n",
      "Graminor_040720 ********* Graminor_eastwest_040720\n",
      "Graminor_040820 ********* Graminor_eastwest_040820\n",
      "Graminor_070720 ********* Graminor_eastwest_070720_correct\n",
      "Graminor_130720 ********* Graminor_eastwest_130720\n",
      "Graminor_140820 ********* Graminor_eastwest_140820\n",
      "Graminor_300720 ********* Graminor_eastwest_300720\n",
      "Graminor_010720 ********* Graminor_east_010720\n",
      "Graminor_170720 ********* Graminor_east_170720\n",
      "Graminor_180620 ********* Graminor_east_180620\n",
      "Graminor_200720 ********* Graminor_east_200720\n",
      "Graminor_240620 ********* Graminor_Mica_eastcorrect_west_240620\n",
      "Masbasis_010720 ********* Masbasis_Mica_010720\n",
      "Masbasis_070820 ********* Masbasis_Mica_070820\n",
      "Masbasis_080720 ********* Masbasis_Mica_080720\n",
      "Masbasis_120820 ********* Masbasis_Mica_120820\n",
      "Masbasis_130720 ********* Masbasis_Mica_130720\n",
      "Masbasis_140820 ********* Masbasis_Mica_140820\n",
      "Masbasis_170720 ********* Masbasis_mica_170720\n",
      "Masbasis_180620 ********* Masbasis_mica_180620_several_missing_rows_deleted\n",
      "Masbasis_220720 ********* Masbasis_Mica_220720\n",
      "Masbasis_240620 ********* Masbasis_mica_240620\n",
      "Masbasis_260620 ********* Masbasis_Mica_260620\n",
      "Masbasis_300720 ********* Masbasis_Mica_300720_duplicate_plots_deleted_1332,1329,1330,1331same_data\n",
      "Robot_010720 ********* Robot_Mica_010720\n",
      "Robot_040820 ********* Robot_Mica_040820\n",
      "Robot_070720 ********* Robot_Mica_070720\n",
      "Robot_120820 ********* Robot_Mica_120820\n",
      "Robot_130720 ********* Robot_Mica_130720\n",
      "Robot_180620 ********* Robot_mica_180620\n",
      "Robot_200720 ********* Robot_Mica_200720\n",
      "Robot_220720 ********* Robot_Mica_220720\n",
      "Robot_230620 ********* Robot_Mica_230620\n",
      "Robot_240620 ********* Robot_Mica_240620\n",
      "Robot_250620 ********* Robot_Mica_250620\n",
      "Robot_270720 ********* Robot_Mica_270720\n",
      "Robot_290620 ********* Robot_Mica_290620\n",
      "Robot_300720 ********* Robot_Mica_300720\n",
      "Masbasis_020621 ********* Masbasis_mica_020621\n",
      "Masbasis_090721 ********* Masbasis_mica_090721_excel\n",
      "Masbasis_170621 ********* Masbasis_mica_170621\n",
      "Masbasis_220721 ********* Masbasis_mica_220721\n",
      "Masbasis_230621 ********* Masbasis_mica_230621_excel\n",
      "Masbasis_240621 ********* Masbasis_mica_240621_excel\n",
      "Masbasis_260721 ********* Masbasis_mica_260721\n",
      "field_year_dict created.\n",
      "{'Graminor_2019': ['250719',\n",
      "                   '050719',\n",
      "                   '060619',\n",
      "                   '070819',\n",
      "                   '110619',\n",
      "                   '150719',\n",
      "                   '150819',\n",
      "                   '280619',\n",
      "                   '020719',\n",
      "                   '050819',\n",
      "                   '110719'],\n",
      " 'Graminor_2020': ['040720',\n",
      "                   '040820',\n",
      "                   '070720',\n",
      "                   '130720',\n",
      "                   '140820',\n",
      "                   '300720',\n",
      "                   '010720',\n",
      "                   '170720',\n",
      "                   '180620',\n",
      "                   '200720',\n",
      "                   '240620'],\n",
      " 'Masbasis_2019': ['050719',\n",
      "                   '060619',\n",
      "                   '070819',\n",
      "                   '150719',\n",
      "                   '220719',\n",
      "                   '260619',\n",
      "                   '290719',\n",
      "                   '280619'],\n",
      " 'Masbasis_2020': ['010720',\n",
      "                   '070820',\n",
      "                   '080720',\n",
      "                   '120820',\n",
      "                   '130720',\n",
      "                   '140820',\n",
      "                   '170720',\n",
      "                   '180620',\n",
      "                   '220720',\n",
      "                   '240620',\n",
      "                   '260620',\n",
      "                   '300720'],\n",
      " 'Masbasis_2021': ['020621',\n",
      "                   '090721',\n",
      "                   '170621',\n",
      "                   '220721',\n",
      "                   '230621',\n",
      "                   '240621',\n",
      "                   '260721'],\n",
      " 'Robot_2020': ['010720',\n",
      "                '040820',\n",
      "                '070720',\n",
      "                '120820',\n",
      "                '130720',\n",
      "                '180620',\n",
      "                '200720',\n",
      "                '220720',\n",
      "                '230620',\n",
      "                '240620',\n",
      "                '250620',\n",
      "                '270720',\n",
      "                '290620',\n",
      "                '300720'],\n",
      " 'Staur_2019': ['070819', '150819', '210819', '240719', '300819'],\n",
      " 'Staur_2020': ['090720', '160720', '200620', '240720', '250620', '310720']}\n",
      "Wall time: 23.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "elements_to_strip = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_-().\"\n",
    "\n",
    "all_df_std = []\n",
    "\n",
    "field_year_dict = {}\n",
    "\n",
    "# A reference dict to keep record of the names of files before they got renamed \n",
    "renamed_to_from = {}\n",
    "\n",
    "for df in all_df:\n",
    "    \n",
    "    # Getting date from the df name\n",
    "    date1 = copy(df)\n",
    "\n",
    "    for x in range(3):\n",
    "        date1 = date1.rstrip(elements_to_strip)\n",
    "        date1 = date1.lstrip(elements_to_strip)\n",
    "        for c in range(3):\n",
    "            date1 = date1.rstrip(elements_to_strip)\n",
    "            date1 = date1.lstrip(elements_to_strip)\n",
    "        date1 = date1.split('_')[0]\n",
    "    \n",
    "    field_name = df.split('_')[0]\n",
    "    field_name = field_name.split('-')[0]\n",
    "\n",
    "    new_df_name = field_name +'_'+date1\n",
    "    \n",
    "    # Drop all columns except the std columns \n",
    "    locals()[new_df_name] = locals()[df].copy()\n",
    "    \n",
    "    all_df_std.append(new_df_name)\n",
    "    \n",
    "    # Creating a dict with all dates for a certain field for a certain year\n",
    "    dict_key = field_name+'_20'+date1[-2:]\n",
    "    \n",
    "    # If the Field name is present in dict then add the date to that key\n",
    "    # Otherwise, create new key for current field and add the date to it\n",
    "    if dict_key in field_year_dict:\n",
    "        # Test: Check if the same date is already present in the current dict key\n",
    "        if date1 in field_year_dict[dict_key]:\n",
    "            print(f'Duplicate Data file Error: {date1} is already present in {dict_key}\\n Current df {df}\\n Conflict with {renamed_to_from[new_df_name]}')\n",
    "            raise NameError\n",
    "        field_year_dict[dict_key].append(date1)\n",
    "    else:\n",
    "        field_year_dict[dict_key] = [date1]\n",
    "    \n",
    "    # Adding new and old names to a dict for record\n",
    "    renamed_to_from[new_df_name] = df\n",
    "    print( new_df_name, '*********', df)\n",
    "#     print(date1)\n",
    "print('field_year_dict created.')\n",
    "\n",
    "# pprint(field_year_dict)\n",
    "# all_df_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Check if there are duplicate datasets/names in all_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.121141Z",
     "start_time": "2021-10-22T23:31:38.107436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate dataset found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if len(all_df_std) > len(set(all_df_std)):\n",
    "    duplicates = len(all_df_std) - len(set(all_df_std))\n",
    "    if duplicates>1:\n",
    "        verb, plural='are', 's'\n",
    "    else:\n",
    "        verb, plural='is', ''\n",
    "    print(f'Error:\\nThere {verb} {duplicates} duplicate name{plural} in the datasets out of total {len(all_df_std)}.\\n \\\n",
    "    Make sure no dataset has been lost because of data being separated in east/west fields on the same date')\n",
    "    # Printing the names of the duplicate datasets, if any\n",
    "    find_duplicates=[]\n",
    "    for i in all_df_std:\n",
    "        if i not in find_duplicates:\n",
    "            find_duplicates.append(i)\n",
    "        else:\n",
    "            print(f'Duplicate dataset named \\'{i}\\',\\n')\n",
    "    raise NameError\n",
    "    \n",
    "else:\n",
    "    print('No duplicate dataset found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging the dates in field_year_dict in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.136250Z",
     "start_time": "2021-10-22T23:31:38.121141Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Graminor_2019': [datetime.date(2019, 6, 6),\n",
      "                   datetime.date(2019, 6, 11),\n",
      "                   datetime.date(2019, 6, 28),\n",
      "                   datetime.date(2019, 7, 2),\n",
      "                   datetime.date(2019, 7, 5),\n",
      "                   datetime.date(2019, 7, 11),\n",
      "                   datetime.date(2019, 7, 15),\n",
      "                   datetime.date(2019, 7, 25),\n",
      "                   datetime.date(2019, 8, 5),\n",
      "                   datetime.date(2019, 8, 7),\n",
      "                   datetime.date(2019, 8, 15)],\n",
      " 'Graminor_2020': [datetime.date(2020, 6, 18),\n",
      "                   datetime.date(2020, 6, 24),\n",
      "                   datetime.date(2020, 7, 1),\n",
      "                   datetime.date(2020, 7, 4),\n",
      "                   datetime.date(2020, 7, 7),\n",
      "                   datetime.date(2020, 7, 13),\n",
      "                   datetime.date(2020, 7, 17),\n",
      "                   datetime.date(2020, 7, 20),\n",
      "                   datetime.date(2020, 7, 30),\n",
      "                   datetime.date(2020, 8, 4),\n",
      "                   datetime.date(2020, 8, 14)],\n",
      " 'Masbasis_2019': [datetime.date(2019, 6, 6),\n",
      "                   datetime.date(2019, 6, 26),\n",
      "                   datetime.date(2019, 6, 28),\n",
      "                   datetime.date(2019, 7, 5),\n",
      "                   datetime.date(2019, 7, 15),\n",
      "                   datetime.date(2019, 7, 22),\n",
      "                   datetime.date(2019, 7, 29),\n",
      "                   datetime.date(2019, 8, 7)],\n",
      " 'Masbasis_2020': [datetime.date(2020, 6, 18),\n",
      "                   datetime.date(2020, 6, 24),\n",
      "                   datetime.date(2020, 6, 26),\n",
      "                   datetime.date(2020, 7, 1),\n",
      "                   datetime.date(2020, 7, 8),\n",
      "                   datetime.date(2020, 7, 13),\n",
      "                   datetime.date(2020, 7, 17),\n",
      "                   datetime.date(2020, 7, 22),\n",
      "                   datetime.date(2020, 7, 30),\n",
      "                   datetime.date(2020, 8, 7),\n",
      "                   datetime.date(2020, 8, 12),\n",
      "                   datetime.date(2020, 8, 14)],\n",
      " 'Masbasis_2021': [datetime.date(2021, 6, 2),\n",
      "                   datetime.date(2021, 6, 17),\n",
      "                   datetime.date(2021, 6, 23),\n",
      "                   datetime.date(2021, 6, 24),\n",
      "                   datetime.date(2021, 7, 9),\n",
      "                   datetime.date(2021, 7, 22),\n",
      "                   datetime.date(2021, 7, 26)],\n",
      " 'Robot_2020': [datetime.date(2020, 6, 18),\n",
      "                datetime.date(2020, 6, 23),\n",
      "                datetime.date(2020, 6, 24),\n",
      "                datetime.date(2020, 6, 25),\n",
      "                datetime.date(2020, 6, 29),\n",
      "                datetime.date(2020, 7, 1),\n",
      "                datetime.date(2020, 7, 7),\n",
      "                datetime.date(2020, 7, 13),\n",
      "                datetime.date(2020, 7, 20),\n",
      "                datetime.date(2020, 7, 22),\n",
      "                datetime.date(2020, 7, 27),\n",
      "                datetime.date(2020, 7, 30),\n",
      "                datetime.date(2020, 8, 4),\n",
      "                datetime.date(2020, 8, 12)],\n",
      " 'Staur_2019': [datetime.date(2019, 7, 24),\n",
      "                datetime.date(2019, 8, 7),\n",
      "                datetime.date(2019, 8, 15),\n",
      "                datetime.date(2019, 8, 21),\n",
      "                datetime.date(2019, 8, 30)],\n",
      " 'Staur_2020': [datetime.date(2020, 6, 20),\n",
      "                datetime.date(2020, 6, 25),\n",
      "                datetime.date(2020, 7, 9),\n",
      "                datetime.date(2020, 7, 16),\n",
      "                datetime.date(2020, 7, 24),\n",
      "                datetime.date(2020, 7, 31)]}\n"
     ]
    }
   ],
   "source": [
    "sorted_field_year_dict = {}\n",
    "for key, dates_list in field_year_dict.items():\n",
    "    # Converting the dates to a datetime date object and sorting them in list\n",
    "    sorted_dated = sorted([\n",
    "        dt.strptime(date, '%d%m%y').date()\n",
    "        for date in dates_list])\n",
    "\n",
    "    sorted_field_year_dict[key] = sorted_dated\n",
    "\n",
    "pprint(sorted_field_year_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of remaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.151283Z",
     "start_time": "2021-10-22T23:31:38.136250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur 2019 Rows: [1328, 1328, 1328, 1328, 1328]\n",
      "Graminor 2019 Rows: [600, 600, 600, 600, 597, 300, 600, 600, 600, 600, 600]\n",
      "Masbasis 2019 Rows: [528, 528, 528, 528, 528, 528, 528, 528]\n",
      "Staur 2020 Rows: [1722, 1722, 1722, 1722, 1722, 1722]\n",
      "Graminor 2020 Rows: [400, 757, 400, 800, 800, 800, 400, 400, 787, 793, 800]\n",
      "Masbasis 2020 Rows: [688, 688, 688, 688, 688, 688, 688, 688, 688, 688, 688, 688]\n",
      "Robot 2020 Rows: [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96]\n",
      "Masbasis 2021 Rows: [696, 696, 696, 696, 696, 696, 696]\n"
     ]
    }
   ],
   "source": [
    "for field, dates in sorted_field_year_dict.items():\n",
    "    rows_df = []\n",
    "    for date in dates:\n",
    "        field_name = field.split('_')[0]+'_'+date.strftime('%d%m%y')\n",
    "        temp_df = locals()[field_name].copy()\n",
    "        rows_df.append(temp_df.shape[0])\n",
    "#         print(field_name, temp_df.shape)\n",
    "    print(field.split('_')[0], date.year, 'Rows:', rows_df)\n",
    "# sorted_field_year_dict\n",
    "#         print(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo: Dropping NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding NAN values\n",
    "### ToDo: Test: Raise error if missing values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.203144Z",
     "start_time": "2021-10-22T23:31:38.152281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in Staur_210819_mean_median_SP are 269\n",
      "Total missing values in Graminor_eastwest_020719_NIR_half_missing are 300\n"
     ]
    }
   ],
   "source": [
    "# Finding number of missing values in each dataframe\n",
    "df_with_nan = []\n",
    "missing_values = False\n",
    "for df in all_df:\n",
    "    if locals()[df].isna().sum().sum() > 0:\n",
    "        print(f'Total missing values in {df} are {locals()[df].isna().sum().sum()}')\n",
    "        missing_values = True\n",
    "        df_with_nan.append(df)\n",
    "#     if len(df_with_nan) > 0:\n",
    "#         raise ValueError\n",
    "if not missing_values:\n",
    "    print('No missing value found in any dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.219817Z",
     "start_time": "2021-10-22T23:31:38.204191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Staur_210819_mean_median_SP', 'Graminor_eastwest_020719_NIR_half_missing']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.252002Z",
     "start_time": "2021-10-22T23:31:38.222331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_210819_mean_median_SP:\n",
      " 5 columns or 61 rows to be dropped,\n",
      "Graminor_eastwest_020719_NIR_half_missing:\n",
      " 1 columns or 300 rows to be dropped,\n"
     ]
    }
   ],
   "source": [
    "# Finding which column has NAN values\n",
    "for df in df_with_nan:\n",
    "    print(f'{df}:\\n {locals()[df].shape[1]-locals()[df].dropna(axis=1).shape[1]} columns or {locals()[df].shape[0]-locals()[df].dropna().shape[0]} rows to be dropped,')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T23:34:49.024780Z",
     "start_time": "2021-10-21T23:34:49.007398Z"
    }
   },
   "source": [
    "## ToDo: Automate: Drop rows with missing values in df_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.264285Z",
     "start_time": "2021-10-22T23:31:38.252002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Staur_210819_mean_median_SP', (1328, 6)) Before dropping\n",
      "('Staur_210819_mean_median_SP', (1328, 6)) After dropping\n",
      "('Graminor_eastwest_020719_NIR_half_missing', (600, 6)) Before dropping\n",
      "('Graminor_eastwest_020719_NIR_half_missing', (600, 6)) After dropping\n"
     ]
    }
   ],
   "source": [
    "for df in df_with_nan:\n",
    "    print(f'{df, locals()[df].shape} Before dropping')\n",
    "#     locals()[df].dropna(inplace=True)\n",
    "    print(f'{df, locals()[df].shape} After dropping')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is only NIR values missing in **Graminor_eastwest_020719_NIR_half_missing**, we can keep them since they will be adjusted in Simpsons integration process. And we can use the data from other indices which is available. Same logic can be applied to the other dataset **Staur_210819_mean_median_SP**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T23:34:49.049321Z",
     "start_time": "2021-10-21T23:34:49.041194Z"
    }
   },
   "source": [
    "## ORRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T23:34:49.065304Z",
     "start_time": "2021-10-21T23:34:49.049617Z"
    }
   },
   "source": [
    "## ToDo: Droppping df with Nan from the all_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.274349Z",
     "start_time": "2021-10-22T23:31:38.264285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in all_df is 74\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of items in all_df is {len(all_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.303000Z",
     "start_time": "2021-10-22T23:31:38.274349Z"
    }
   },
   "outputs": [],
   "source": [
    "# for df in df_with_nan:\n",
    "#     all_df.remove(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ToDo: Update field_year_dict and sorted_field_year_dict after dropping the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.319513Z",
     "start_time": "2021-10-22T23:31:38.304010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in all_df now is 74\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of items in all_df now is {len(all_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of remaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.353543Z",
     "start_time": "2021-10-22T23:31:38.321505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur 2019 Rows: [1328, 1328, 1328, 1328, 1328]\n",
      "Graminor 2019 Rows: [600, 600, 600, 600, 597, 300, 600, 600, 600, 600, 600]\n",
      "Masbasis 2019 Rows: [528, 528, 528, 528, 528, 528, 528, 528]\n",
      "Staur 2020 Rows: [1722, 1722, 1722, 1722, 1722, 1722]\n",
      "Graminor 2020 Rows: [400, 757, 400, 800, 800, 800, 400, 400, 787, 793, 800]\n",
      "Masbasis 2020 Rows: [688, 688, 688, 688, 688, 688, 688, 688, 688, 688, 688, 688]\n",
      "Robot 2020 Rows: [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96]\n",
      "Masbasis 2021 Rows: [696, 696, 696, 696, 696, 696, 696]\n"
     ]
    }
   ],
   "source": [
    "for field, dates in sorted_field_year_dict.items():\n",
    "    rows_df = []\n",
    "    for date in dates:\n",
    "        field_name = field.split('_')[0]+'_'+date.strftime('%d%m%y')\n",
    "        temp_df = locals()[field_name].copy()\n",
    "        rows_df.append(temp_df.shape[0])\n",
    "#         print(field_name, temp_df.shape)\n",
    "    print(field.split('_')[0], date.year, 'Rows:', rows_df)\n",
    "# sorted_field_year_dict\n",
    "#         print(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify & drop duplicate sub-plots in each datasets, if any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if duplicates exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.446092Z",
     "start_time": "2021-10-22T23:31:38.354051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following 1 duplicates in Staur_210819 \n",
      "Identical Duplicates: 0\n",
      " Plot_ID  Duplicates: 1\n",
      "  Rows to be dropped: 2\n",
      "Following 108 duplicates in Staur_090720 \n",
      "Identical Duplicates: 0\n",
      " Plot_ID  Duplicates: 108\n",
      "  Rows to be dropped: 216\n",
      "Following 108 duplicates in Staur_160720 \n",
      "Identical Duplicates: 0\n",
      " Plot_ID  Duplicates: 108\n",
      "  Rows to be dropped: 216\n",
      "Following 108 duplicates in Staur_200620 \n",
      "Identical Duplicates: 0\n",
      " Plot_ID  Duplicates: 108\n",
      "  Rows to be dropped: 216\n",
      "Following 108 duplicates in Staur_240720 \n",
      "Identical Duplicates: 0\n",
      " Plot_ID  Duplicates: 108\n",
      "  Rows to be dropped: 216\n",
      "Following 108 duplicates in Staur_250620 \n",
      "Identical Duplicates: 0\n",
      " Plot_ID  Duplicates: 108\n",
      "  Rows to be dropped: 216\n",
      "Following 108 duplicates in Staur_310720 \n",
      "Identical Duplicates: 0\n",
      " Plot_ID  Duplicates: 108\n",
      "  Rows to be dropped: 216\n"
     ]
    }
   ],
   "source": [
    "found_duplicates = False\n",
    "for df in all_df_std:\n",
    "    duplicates = locals()[df][locals()[df].duplicated(subset='Plot_ID')]['Plot_ID']\n",
    "    if duplicates.size > 0:\n",
    "        found_duplicates = True\n",
    "        print(f'Following {duplicates.size} duplicates in {df} ')\n",
    "#         for x in range(duplicates.size):\n",
    "#             print(duplicates.iloc[x])\n",
    "        ident_dup = locals()[df].shape[0]-locals()[df].drop_duplicates(keep=False).shape[0]\n",
    "        plot_id_dup = locals()[df].shape[0] - locals()[df].drop_duplicates(subset = 'Plot_ID').shape[0]\n",
    "        print('Identical Duplicates:', ident_dup)\n",
    "        print(' Plot_ID  Duplicates:', plot_id_dup)\n",
    "        print('  Rows to be dropped:', plot_id_dup*2)\n",
    "\n",
    "# if found_duplicates:\n",
    "#     raise NameError\n",
    "# else:\n",
    "#     print(f'No duplicate subplots found in any dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding out which plots are duplicate/ non-unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.467776Z",
     "start_time": "2021-10-22T23:31:38.446092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_210819 Number of plots 1328, vs Number of duplicate plots 1\n",
      "Staur_090720 Number of plots 1722, vs Number of duplicate plots 108\n",
      "Staur_160720 Number of plots 1722, vs Number of duplicate plots 108\n",
      "Staur_200620 Number of plots 1722, vs Number of duplicate plots 108\n",
      "Staur_240720 Number of plots 1722, vs Number of duplicate plots 108\n",
      "Staur_250620 Number of plots 1722, vs Number of duplicate plots 108\n",
      "Staur_310720 Number of plots 1722, vs Number of duplicate plots 108\n"
     ]
    }
   ],
   "source": [
    "found_duplicates = False\n",
    "\n",
    "for df in all_df_std:\n",
    "    plot_list_series = locals()[df].Plot_ID\n",
    "    if len(plot_list_series[plot_list_series.duplicated()]) > 0:\n",
    "        found_duplicates = True\n",
    "#         print(f'Duplicate subplots in {df} are {plot_list_series[plot_list_series.duplicated()]}')\n",
    "        print(f'{df} Number of plots {len(plot_list_series)}, vs Number of duplicate plots {len(plot_list_series)-len(set(plot_list_series))}')\n",
    "\n",
    "# if found_duplicates:\n",
    "#     raise NameError\n",
    "# else:\n",
    "#     print(f'No duplicate subplots found in any dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicate rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop only identical duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.569596Z",
     "start_time": "2021-10-22T23:31:38.468752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No **identical** duplicate subplots found/dropped in any dataset.\n"
     ]
    }
   ],
   "source": [
    "found_duplicates = False\n",
    "for df in all_df_std:\n",
    "    dup_temp = False\n",
    "    size_before = locals()[df].shape\n",
    "    # Finding completely identical duplicate entries\n",
    "    duplicates = locals()[df][locals()[df].duplicated()]['Plot_ID']\n",
    "    if duplicates.size > 0:\n",
    "        dup_temp = True\n",
    "        found_duplicates = True\n",
    "        # Dropping duplicate entries in place\n",
    "        locals()[df].drop_duplicates(inplace=True)\n",
    "        print(f'{duplicates.size} duplicate entries deleted from the {df}.')\n",
    "    if dup_temp:\n",
    "        rows_dropped = size_before[0] - locals()[df].shape[0]\n",
    "        print(size_before[0], locals()[df].shape[0], rows_dropped)\n",
    "        assert rows_dropped == duplicates.size\n",
    "if not dup_temp:\n",
    "    print(f'No **identical** duplicate subplots found/dropped in any dataset.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.580191Z",
     "start_time": "2021-10-22T23:31:38.570842Z"
    }
   },
   "outputs": [],
   "source": [
    "### Drop all duplicate entries in Plot_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.652071Z",
     "start_time": "2021-10-22T23:31:38.580701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 duplicate entries deleted from the Staur_210819.\n",
      "216 duplicate entries deleted from the Staur_090720.\n",
      "216 duplicate entries deleted from the Staur_160720.\n",
      "216 duplicate entries deleted from the Staur_200620.\n",
      "216 duplicate entries deleted from the Staur_240720.\n",
      "216 duplicate entries deleted from the Staur_250620.\n",
      "216 duplicate entries deleted from the Staur_310720.\n",
      "Masbasis_260721 No duplicate subplots found/dropped in any dataset.\n"
     ]
    }
   ],
   "source": [
    "found_duplicates = False\n",
    "for df in all_df_std:\n",
    "    dup_temp = False\n",
    "    size_before = locals()[df].shape\n",
    "    # Finding identical entries in Plot_ID column\n",
    "    duplicates = locals()[df][locals()[df].duplicated(subset='Plot_ID')]['Plot_ID']\n",
    "    if duplicates.size > 0:\n",
    "        dup_temp = True\n",
    "        found_duplicates = True\n",
    "        # Dropping duplicate entries in place\n",
    "        locals()[df].drop_duplicates(subset = 'Plot_ID', keep=False, inplace=True)\n",
    "        print(f'{duplicates.size*2} duplicate entries deleted from the {df}.')\n",
    "    if dup_temp:\n",
    "        rows_dropped = size_before[0] - locals()[df].shape[0]\n",
    "#         print(size_before[0], locals()[df].shape[0], rows_dropped)\n",
    "        assert rows_dropped ==duplicates.size*2\n",
    "if not dup_temp:\n",
    "    print(f'{df} No duplicate subplots found/dropped in any dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.669707Z",
     "start_time": "2021-10-22T23:31:38.652071Z"
    }
   },
   "outputs": [],
   "source": [
    "## Summary of remaining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.694608Z",
     "start_time": "2021-10-22T23:31:38.670773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur 2019 Rows: [1328, 1328, 1328, 1326, 1328]\n",
      "Graminor 2019 Rows: [600, 600, 600, 600, 597, 300, 600, 600, 600, 600, 600]\n",
      "Masbasis 2019 Rows: [528, 528, 528, 528, 528, 528, 528, 528]\n",
      "Staur 2020 Rows: [1506, 1506, 1506, 1506, 1506, 1506]\n",
      "Graminor 2020 Rows: [400, 757, 400, 800, 800, 800, 400, 400, 787, 793, 800]\n",
      "Masbasis 2020 Rows: [688, 688, 688, 688, 688, 688, 688, 688, 688, 688, 688, 688]\n",
      "Robot 2020 Rows: [96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96]\n",
      "Masbasis 2021 Rows: [696, 696, 696, 696, 696, 696, 696]\n"
     ]
    }
   ],
   "source": [
    "for field, dates in sorted_field_year_dict.items():\n",
    "    rows_df = []\n",
    "    for date in dates:\n",
    "        field_name = field.split('_')[0]+'_'+date.strftime('%d%m%y')\n",
    "        temp_df = locals()[field_name].copy()\n",
    "        rows_df.append(temp_df.shape[0])\n",
    "#         print(field_name, temp_df.shape)\n",
    "    print(field.split('_')[0], date.year, 'Rows:', rows_df)\n",
    "# sorted_field_year_dict\n",
    "#         print(field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:38.719756Z",
     "start_time": "2021-10-22T23:31:38.694608Z"
    }
   },
   "outputs": [],
   "source": [
    "complete_dataframes = all_df_std.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting complete datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-22T23:31:39.219938Z",
     "start_time": "2021-10-22T23:31:38.720768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exporting complete df\n",
    "# Defining path\n",
    "os.makedirs(complete_df_path, exist_ok=True)\n",
    "\n",
    "# Test: Check if there are duplicate names in the complete_dataframes list\n",
    "# As the last file with the same name will overwrite the previously exported file, resulting in data loss\n",
    "if len(complete_dataframes) != len(set(complete_dataframes)):\n",
    "    print('There are duplicate names in the complete_dataframes list.\\nPlease check before exporting as it might result in data loss.')\n",
    "        \n",
    "    # Printing the names of the duplicate datasets, if any\n",
    "    find_duplicates=[]\n",
    "    for i in complete_dataframes:\n",
    "        if i not in find_duplicates:\n",
    "            find_duplicates.append(i)\n",
    "        else:\n",
    "            print(f'Duplicate dataset named \\'{i}\\'')\n",
    "    raise NameError\n",
    "    \n",
    "for df in complete_dataframes:\n",
    "    locals()[df].to_csv(complete_df_path+df+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T19:36:24.735714Z",
     "start_time": "2021-10-06T19:36:24.724977Z"
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# a_file = open(\"Data\\std_columns.json\", \"w\")\n",
    "# json.dump(std_columns, a_file)\n",
    "# a_file.close()\n",
    "\n",
    "# # a_file = open(\"Data\\std_columns.json\", \"r\")\n",
    "# # output = a_file.read()\n",
    "# # a_file.close()\n",
    "# # print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF SECTION"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.452px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
