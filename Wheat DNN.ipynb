{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "To do\n",
    "\n",
    "Check Time Series data\n",
    "\n",
    "Give a 2 page report to Sahameh about visualisation and indicate the data which has any problems, which is in consistant with the data from other dates\n",
    "Planting date for 2018 is given in master thesis\n",
    "Planting date for 2019 is May 05\n",
    "Planting date for 2020 and remaining data will be given by Sahameh in the week starrting from 16th November\n",
    "\n",
    "Must do normalisation of data before training\n",
    "\n",
    "Next step is Global Mix modelling\n",
    "Sahameh will share a paper from 2020 about using hyper spectral imaging, which will be basis of Mix Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning to predict Wheat Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory with data files\n",
    "# path = r\"C:\\Users\\fahad\\Documents\\Master Thesis\\Phenotyping\\Data\\2018\"\n",
    "# path = path.replace(\"\\\\\", \"/\") + '/'\n",
    "\n",
    "path = r'C:\\Users\\fahad\\Documents\\Master Thesis\\Phenotyping\\Data\\All'\n",
    "path = path.replace(\"\\\\\", \"/\") + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete.xlsx',\n",
       " 'Masbasis_2017.xlsx',\n",
       " 'Masbasis_2018_yp.xlsx',\n",
       " 'Robot_2017.xlsx',\n",
       " 'Robot_2018_YP.xlsx',\n",
       " 'Yield missing']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dir = os.listdir(path)\n",
    "list_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete.xlsx',\n",
       " 'Masbasis_2017.xlsx',\n",
       " 'Masbasis_2018_yp.xlsx',\n",
       " 'Robot_2017.xlsx',\n",
       " 'Robot_2018_YP.xlsx',\n",
       " 'Yield missing']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_list = []\n",
    "\n",
    "for i, name in enumerate(list_dir):\n",
    "    str = name[:-5]\n",
    "    locals()[str] = name\n",
    "#     print(locals()[str])\n",
    "    data_file_list.append(name)\n",
    "data_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graminor_18 = list_dir[2]\n",
    "# masbasis_17 = list_dir[3]\n",
    "# masbasis_18 = list_dir[4]\n",
    "# robot_17 = list_dir[5]\n",
    "# robot_18 = list_dir[6]\n",
    "\n",
    "# data_file_list = [graminor_18, masbasis_17, masbasis_18, robot_17, robot_18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robot_18 = 'Robot_2018_YP.xlsx'\n",
    "\n",
    "# data_file_list = [robot_18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Get the name of the variable as string\n",
    "\n",
    "import inspect\n",
    "\n",
    "def retrieve_name(var):\n",
    "        \"\"\"\n",
    "        Gets the name of var. Does it from the out most frame inner-wards.\n",
    "        :param var: variable to get name from.\n",
    "        :return: string\n",
    "        \"\"\"\n",
    "        for fi in reversed(inspect.stack()):\n",
    "            names = [var_name for var_name, var_val in fi.frame.f_locals.items() if var_val is var]\n",
    "            if len(names) > 0:\n",
    "                return names[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": false,
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2018_complete_26_06_18_df\n",
      "Graminor_2018_complete_02_07_18_df\n",
      "Graminor_2018_complete_19_07_18_df\n",
      "Masbasis_2017_14_07_17_df\n",
      "Masbasis_2017_17_07_17_df\n",
      "Masbasis_2017_20_07_17_df\n",
      "Masbasis_2017_01_08_17_df\n",
      "Masbasis_2018_yp_13_07_18_df\n",
      "Masbasis_2018_yp_26_07_18_df\n",
      "Robot_2017_14_06_17_df\n",
      "Robot_2017_19_06_17_df\n",
      "Robot_2017_29_06_17_df\n",
      "Robot_2017_03_07_17_df\n",
      "Robot_2017_14_07_17_df\n",
      "Robot_2017_17_07_17_df\n",
      "Robot_2017_14_08_17_df\n",
      "Robot_2018_YP_02_07_18_df\n",
      "Robot_2018_YP_smallfield05_07_18_df\n",
      "Robot_2018_YP_smallfield11_07_18_df\n",
      "Robot_2018_YP_smallfield19_07_18_df\n",
      "Robot_2018_YP_smallfield24_07_18_df\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "df_str_list = []\n",
    "\n",
    "for filename in data_file_list:\n",
    "    new_df = retrieve_name(filename) + '_df'\n",
    "    if filename[-3:] == 'csv':\n",
    "        locals()[new_df] = pd.read_csv(path + filename,\n",
    "                                       delimiter=';',\n",
    "                                       encoding=\"ISO-8859-1\")\n",
    "        df_str_list.append(new_df)\n",
    "        # Encoding has been defined to avoid UnicodeDecodeError while reading the csv\n",
    "#         display(locals()[new_df].head(10))    # Print the df in pretty format\n",
    "    elif filename[-4:] == 'xlsx':\n",
    "        locals()[new_df] = pd.ExcelFile(path + filename)\n",
    "        if len(locals()[new_df].sheet_names) == 1:\n",
    "            locals()[new_df] = pd.read_excel(path + filename)\n",
    "            df_str_list.append(new_df)\n",
    "        elif len(locals()[new_df].sheet_names) > 1:\n",
    "            for i in locals()[new_df].sheet_names:\n",
    "                # Replacing '.' and '-' in the sheet file name to '_'\n",
    "                k = i.replace('.', '_')\n",
    "                k = k.replace('-', '_')\n",
    "                new_sheet_df = retrieve_name(filename) + '_' + k + '_df'\n",
    "                locals()[new_sheet_df] = pd.read_excel(path + filename, sheet_name = i)\n",
    "                df_str_list.append(new_sheet_df)\n",
    "\n",
    "#         display(locals()[new_df].head(10))    # Print the df in pretty format\n",
    "\n",
    "print(*df_str_list, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Graminor_2018_complete_26_06_18_df_median_columns\n",
      "(599, 39)\n",
      "26-06-18_bluemedian\n",
      "26-06-18_greenmedian\n",
      "26-06-18_ndvimedian\n",
      "26-06-18_nirmedian\n",
      "26-06-18_redmedian\n",
      "26-06-18_rededgemedian\n",
      "26-06-18_mtci\n",
      "MAT\n",
      "26-06-18_evi\n",
      "02-07-18_mtci - 26-06-18_mtci\n",
      "19-07-18_mtci - 26-06-18_mtci\n",
      "\n",
      "\n",
      "Graminor_2018_complete_02_07_18_df_median_columns\n",
      "(599, 36)\n",
      "02-07-18_bluemedian\n",
      "02-07-18_greenmedian\n",
      "02-07-18_ndvimedian\n",
      "02-07-18_nirmedian\n",
      "02-07-18_redmedian\n",
      "02-07-18_rededgemedian\n",
      "02-07-18_mtci\n",
      "02-07-18MAT\n",
      "02-07-18_evi\n",
      "\n",
      "\n",
      "Graminor_2018_complete_19_07_18_df_median_columns\n",
      "(599, 36)\n",
      "19-07-18_bluemedian\n",
      "19-07-18_greenmedian\n",
      "19-07-18_ndvimedian\n",
      "19-07-18_nirmedian\n",
      "19-07-18_redmedian\n",
      "19-07-18_rededgemedian\n",
      "19-07-18_mtci\n",
      "19-07-18MAT\n",
      "19-07-18_evi\n",
      "\n",
      "\n",
      "Masbasis_2017_14_07_17_df_median_columns\n",
      "(560, 48)\n",
      "14-07-17_greenmedian\n",
      "14-07-17_ndvimedian\n",
      "14-07-17_nirmedian\n",
      "14-07-17_redmedian\n",
      "14-07-17_rededgemedian\n",
      "14-07-17_mtci\n",
      "MAT\n",
      "17-07-17_mtci - 14-07-17_mtci\n",
      "20-07-17_mtci - 14-07-17_mtci\n",
      "01-08-17_mtci - 14-07-17_mtci\n",
      "\n",
      "\n",
      "Masbasis_2017_17_07_17_df_median_columns\n",
      "(560, 46)\n",
      "17-07-17_greenmedian\n",
      "17-07-17_ndvimedian\n",
      "17-07-17_nirmedian\n",
      "17-07-17_redmedian\n",
      "17-07-17_rededgemedian\n",
      "17-07-17_mtci\n",
      "17-07-17MAT\n",
      "\n",
      "\n",
      "Masbasis_2017_20_07_17_df_median_columns\n",
      "(560, 46)\n",
      "20-07-17_greenmedian\n",
      "20-07-17_ndvimedian\n",
      "20-07-17_nirmedian\n",
      "20-07-17_redmedian\n",
      "20-07-17_rededgemedian\n",
      "20-07-17_mtci\n",
      "20-07-17MAT\n",
      "\n",
      "\n",
      "Masbasis_2017_01_08_17_df_median_columns\n",
      "(560, 44)\n",
      "01-08-17_greenmedian\n",
      "01-08-17_ndvimedian\n",
      "01-08-17_nirmedian\n",
      "01-08-17_redmedian\n",
      "01-08-17_rededgemedian\n",
      "01-08-17_mtci\n",
      "01-08-17MAT\n",
      "\n",
      "\n",
      "Masbasis_2018_yp_13_07_18_df_median_columns\n",
      "(528, 52)\n",
      "MAT\n",
      "13-07-18_bluemedian\n",
      "13-07-18_evi\n",
      "13-07-18_greenmedian\n",
      "13-07-18_mtci\n",
      "13-07-18_ndvimedian\n",
      "13-07-18_nirmedian\n",
      "13-07-18_rededgemedian\n",
      "13-07-18_redmedian\n",
      "26-07-18_mtci - 13-07-18_mtci\n",
      "\n",
      "\n",
      "Masbasis_2018_yp_26_07_18_df_median_columns\n",
      "(528, 49)\n",
      "26-07-18_bluemedian\n",
      "26-07-18_greenmedian\n",
      "26-07-18_ndvimedian\n",
      "26-07-18_nirmedian\n",
      "26-07-18_redmedian\n",
      "26-07-18_rededgemedian\n",
      "26-07-18_mtci\n",
      "26-07-18MAT\n",
      "26-07-18_evi\n",
      "\n",
      "\n",
      "Robot_2017_14_06_17_df_median_columns\n",
      "(96, 33)\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "\n",
      "\n",
      "Robot_2017_19_06_17_df_median_columns\n",
      "(96, 73)\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "\n",
      "\n",
      "Robot_2017_29_06_17_df_median_columns\n",
      "(96, 73)\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "\n",
      "\n",
      "Robot_2017_03_07_17_df_median_columns\n",
      "(96, 73)\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "\n",
      "\n",
      "Robot_2017_14_07_17_df_median_columns\n",
      "(96, 73)\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "\n",
      "\n",
      "Robot_2017_17_07_17_df_median_columns\n",
      "(96, 73)\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "\n",
      "\n",
      "Robot_2017_14_08_17_df_median_columns\n",
      "(96, 73)\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "\n",
      "\n",
      "Robot_2018_YP_02_07_18_df_median_columns\n",
      "(96, 22)\n",
      "_bluemedian\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "_evi\n",
      "\n",
      "\n",
      "Robot_2018_YP_smallfield05_07_18_df_median_columns\n",
      "(96, 22)\n",
      "_bluemedian\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "_evi\n",
      "\n",
      "\n",
      "Robot_2018_YP_smallfield11_07_18_df_median_columns\n",
      "(96, 22)\n",
      "_bluemedian\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "_evi\n",
      "\n",
      "\n",
      "Robot_2018_YP_smallfield19_07_18_df_median_columns\n",
      "(96, 28)\n",
      "_bluemedian\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "_evi\n",
      "\n",
      "\n",
      "Robot_2018_YP_smallfield24_07_18_df_median_columns\n",
      "(96, 30)\n",
      "_bluemedian\n",
      "_greenmedian\n",
      "_ndvimedian\n",
      "_nirmedian\n",
      "_redmedian\n",
      "_rededgemedian\n",
      "_mtci\n",
      "_evi\n"
     ]
    }
   ],
   "source": [
    "lists_of_median_cols = []\n",
    "\n",
    "for df in df_str_list:\n",
    "    list_of_columns = df+'_median_columns'\n",
    "    locals()[list_of_columns] = []\n",
    "    for strg in locals()[df].columns.tolist():\n",
    "        if strg.find('medi') != -1 or strg.find('mtci') != -1 or strg.find('evi') != -1 or strg.find('MAT') != -1:\n",
    "            locals()[list_of_columns].append(strg)\n",
    "#     # Append GrainYield to the end of the all lists\n",
    "#     locals()[list_of_columns].append('GrainYield')\n",
    "    lists_of_median_cols.append(list_of_columns)\n",
    "    \n",
    "    print('\\n', list_of_columns,locals() [df].shape, *locals()[list_of_columns], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete_26_06_18_df_median_columns',\n",
       " 'Graminor_2018_complete_02_07_18_df_median_columns',\n",
       " 'Graminor_2018_complete_19_07_18_df_median_columns',\n",
       " 'Masbasis_2017_14_07_17_df_median_columns',\n",
       " 'Masbasis_2017_17_07_17_df_median_columns',\n",
       " 'Masbasis_2017_20_07_17_df_median_columns',\n",
       " 'Masbasis_2017_01_08_17_df_median_columns',\n",
       " 'Masbasis_2018_yp_13_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_26_07_18_df_median_columns',\n",
       " 'Robot_2017_14_06_17_df_median_columns',\n",
       " 'Robot_2017_19_06_17_df_median_columns',\n",
       " 'Robot_2017_29_06_17_df_median_columns',\n",
       " 'Robot_2017_03_07_17_df_median_columns',\n",
       " 'Robot_2017_14_07_17_df_median_columns',\n",
       " 'Robot_2017_17_07_17_df_median_columns',\n",
       " 'Robot_2017_14_08_17_df_median_columns',\n",
       " 'Robot_2018_YP_02_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield05_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield11_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield19_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_of_median_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete_26_06_18_df_median_columns',\n",
       " 'Graminor_2018_complete_02_07_18_df_median_columns',\n",
       " 'Graminor_2018_complete_19_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_13_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_26_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_02_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield05_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield11_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield19_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a specific part of text from variable column name is present in which dataset\n",
    "\n",
    "text = 'blu'\n",
    "blue_data = []\n",
    "for i in lists_of_median_cols:\n",
    "    if any(text in s for s in locals()[i]):\n",
    "        blue_data.append(i)\n",
    "blue_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete_26_06_18_df_median_columns',\n",
       " 'Graminor_2018_complete_02_07_18_df_median_columns',\n",
       " 'Graminor_2018_complete_19_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_13_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_26_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_02_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield05_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield11_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield19_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a specific part of text from variable column name is present in which dataset\n",
    "\n",
    "text = 'redm'\n",
    "red_data = []\n",
    "for i in blue_data:\n",
    "    if any(text in s for s in locals()[i]):\n",
    "        red_data.append(i)\n",
    "red_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete_26_06_18_df_median_columns',\n",
       " 'Graminor_2018_complete_02_07_18_df_median_columns',\n",
       " 'Graminor_2018_complete_19_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_13_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_26_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_02_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield05_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield11_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield19_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a specific part of text from variable column name is present in which dataset\n",
    "\n",
    "text = 'rede'\n",
    "red_edge_data = []\n",
    "for i in blue_data:\n",
    "    if any(text in s for s in locals()[i]):\n",
    "        red_edge_data.append(i)\n",
    "red_edge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete_26_06_18_df_median_columns',\n",
       " 'Graminor_2018_complete_02_07_18_df_median_columns',\n",
       " 'Graminor_2018_complete_19_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_13_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_26_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_02_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield05_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield11_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield19_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a specific part of text from variable column name is present in which dataset\n",
    "\n",
    "text = 'green'\n",
    "green_data = []\n",
    "for i in blue_data:\n",
    "    if any(text in s for s in locals()[i]):\n",
    "        green_data.append(i)\n",
    "green_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete_26_06_18_df_median_columns',\n",
       " 'Graminor_2018_complete_02_07_18_df_median_columns',\n",
       " 'Graminor_2018_complete_19_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_13_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_26_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_02_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield05_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield11_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield19_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a specific part of text from variable column name is present in which dataset\n",
    "\n",
    "text = 'ndvi'\n",
    "ndvi_data = []\n",
    "for i in blue_data:\n",
    "    if any(text in s for s in locals()[i]):\n",
    "        ndvi_data.append(i)\n",
    "ndvi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete_26_06_18_df_median_columns',\n",
       " 'Graminor_2018_complete_02_07_18_df_median_columns',\n",
       " 'Graminor_2018_complete_19_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_13_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_26_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_02_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield05_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield11_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield19_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a specific part of text from variable column name is present in which dataset\n",
    "\n",
    "text = 'nir'\n",
    "nir_data = []\n",
    "for i in blue_data:\n",
    "    if any(text in s for s in locals()[i]):\n",
    "        nir_data.append(i)\n",
    "nir_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete_26_06_18_df_median_columns',\n",
       " 'Graminor_2018_complete_02_07_18_df_median_columns',\n",
       " 'Graminor_2018_complete_19_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_13_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_26_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_02_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield05_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield11_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield19_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a specific part of text from variable column name is present in which dataset\n",
    "\n",
    "text = 'mtci'\n",
    "mtci_data = []\n",
    "for i in blue_data:\n",
    "    if any(text in s for s in locals()[i]):\n",
    "        mtci_data.append(i)\n",
    "mtci_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complete_26_06_18_df_median_columns',\n",
       " 'Graminor_2018_complete_02_07_18_df_median_columns',\n",
       " 'Graminor_2018_complete_19_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_13_07_18_df_median_columns',\n",
       " 'Masbasis_2018_yp_26_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_02_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield05_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield11_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield19_07_18_df_median_columns',\n",
       " 'Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a specific part of text from variable column name is present in which dataset\n",
    "\n",
    "text = 'evi'\n",
    "evi_data = []\n",
    "for i in blue_data:\n",
    "    if any(text in s for s in locals()[i]):\n",
    "        evi_data.append(i)\n",
    "evi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['26-06-18_bluemedian',\n",
       " '26-06-18_greenmedian',\n",
       " '26-06-18_ndvimedian',\n",
       " '26-06-18_nirmedian',\n",
       " '26-06-18_redmedian',\n",
       " '26-06-18_rededgemedian',\n",
       " '26-06-18_mtci',\n",
       " 'MAT',\n",
       " '26-06-18_evi',\n",
       " '02-07-18_mtci - 26-06-18_mtci',\n",
       " '19-07-18_mtci - 26-06-18_mtci']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['02-07-18_bluemedian',\n",
       " '02-07-18_greenmedian',\n",
       " '02-07-18_ndvimedian',\n",
       " '02-07-18_nirmedian',\n",
       " '02-07-18_redmedian',\n",
       " '02-07-18_rededgemedian',\n",
       " '02-07-18_mtci',\n",
       " '02-07-18MAT',\n",
       " '02-07-18_evi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['19-07-18_bluemedian',\n",
       " '19-07-18_greenmedian',\n",
       " '19-07-18_ndvimedian',\n",
       " '19-07-18_nirmedian',\n",
       " '19-07-18_redmedian',\n",
       " '19-07-18_rededgemedian',\n",
       " '19-07-18_mtci',\n",
       " '19-07-18MAT',\n",
       " '19-07-18_evi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['MAT',\n",
       " '13-07-18_bluemedian',\n",
       " '13-07-18_evi',\n",
       " '13-07-18_greenmedian',\n",
       " '13-07-18_mtci',\n",
       " '13-07-18_ndvimedian',\n",
       " '13-07-18_nirmedian',\n",
       " '13-07-18_rededgemedian',\n",
       " '13-07-18_redmedian',\n",
       " '26-07-18_mtci - 13-07-18_mtci']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['26-07-18_bluemedian',\n",
       " '26-07-18_greenmedian',\n",
       " '26-07-18_ndvimedian',\n",
       " '26-07-18_nirmedian',\n",
       " '26-07-18_redmedian',\n",
       " '26-07-18_rededgemedian',\n",
       " '26-07-18_mtci',\n",
       " '26-07-18MAT',\n",
       " '26-07-18_evi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['_bluemedian',\n",
       " '_greenmedian',\n",
       " '_ndvimedian',\n",
       " '_nirmedian',\n",
       " '_redmedian',\n",
       " '_rededgemedian',\n",
       " '_mtci',\n",
       " '_evi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['_bluemedian',\n",
       " '_greenmedian',\n",
       " '_ndvimedian',\n",
       " '_nirmedian',\n",
       " '_redmedian',\n",
       " '_rededgemedian',\n",
       " '_mtci',\n",
       " '_evi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['_bluemedian',\n",
       " '_greenmedian',\n",
       " '_ndvimedian',\n",
       " '_nirmedian',\n",
       " '_redmedian',\n",
       " '_rededgemedian',\n",
       " '_mtci',\n",
       " '_evi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['_bluemedian',\n",
       " '_greenmedian',\n",
       " '_ndvimedian',\n",
       " '_nirmedian',\n",
       " '_redmedian',\n",
       " '_rededgemedian',\n",
       " '_mtci',\n",
       " '_evi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['_bluemedian',\n",
       " '_greenmedian',\n",
       " '_ndvimedian',\n",
       " '_nirmedian',\n",
       " '_redmedian',\n",
       " '_rededgemedian',\n",
       " '_mtci',\n",
       " '_evi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "for i in evi_data:\n",
    "    display(locals()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Robot_2018_YP_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for s in locals()[i] if 'blu' in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Robot_2018_YP_smallfield24_07_18_df_median_columns'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '2', 'blue_']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'blue' in [1,2,'blue_']\n",
    "\n",
    "[['1','2','blue_'] for s in ['1','2','blue_'] if \"blue\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['robot_18_02_07_18_df_median_columns',\n",
       " 'robot_18_smallfield05_07_18_df_median_columns',\n",
       " 'robot_18_smallfield11_07_18_df_median_columns',\n",
       " 'robot_18_smallfield19_07_18_df_median_columns',\n",
       " 'robot_18_smallfield24_07_18_df_median_columns']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_bluemedian</th>\n",
       "      <th>_greenmedian</th>\n",
       "      <th>_ndvimedian</th>\n",
       "      <th>_nirmedian</th>\n",
       "      <th>_redmedian</th>\n",
       "      <th>_rededgemedian</th>\n",
       "      <th>_mtci</th>\n",
       "      <th>_evi</th>\n",
       "      <th>GrainYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043859</td>\n",
       "      <td>0.098422</td>\n",
       "      <td>0.709592</td>\n",
       "      <td>0.459952</td>\n",
       "      <td>0.078071</td>\n",
       "      <td>0.172266</td>\n",
       "      <td>3.054160</td>\n",
       "      <td>0.596902</td>\n",
       "      <td>195.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046533</td>\n",
       "      <td>0.113445</td>\n",
       "      <td>0.742401</td>\n",
       "      <td>0.543418</td>\n",
       "      <td>0.080714</td>\n",
       "      <td>0.201865</td>\n",
       "      <td>2.819242</td>\n",
       "      <td>0.689079</td>\n",
       "      <td>223.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054283</td>\n",
       "      <td>0.120065</td>\n",
       "      <td>0.710549</td>\n",
       "      <td>0.603680</td>\n",
       "      <td>0.101180</td>\n",
       "      <td>0.221507</td>\n",
       "      <td>3.176109</td>\n",
       "      <td>0.696509</td>\n",
       "      <td>217.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051817</td>\n",
       "      <td>0.118176</td>\n",
       "      <td>0.702029</td>\n",
       "      <td>0.614528</td>\n",
       "      <td>0.105176</td>\n",
       "      <td>0.222565</td>\n",
       "      <td>3.338998</td>\n",
       "      <td>0.685736</td>\n",
       "      <td>188.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053026</td>\n",
       "      <td>0.121916</td>\n",
       "      <td>0.661188</td>\n",
       "      <td>0.526453</td>\n",
       "      <td>0.106715</td>\n",
       "      <td>0.218743</td>\n",
       "      <td>2.746707</td>\n",
       "      <td>0.593171</td>\n",
       "      <td>155.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.097113</td>\n",
       "      <td>0.751683</td>\n",
       "      <td>0.532777</td>\n",
       "      <td>0.075381</td>\n",
       "      <td>0.173760</td>\n",
       "      <td>3.649314</td>\n",
       "      <td>0.687587</td>\n",
       "      <td>283.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.033768</td>\n",
       "      <td>0.078753</td>\n",
       "      <td>0.787837</td>\n",
       "      <td>0.509926</td>\n",
       "      <td>0.060623</td>\n",
       "      <td>0.155035</td>\n",
       "      <td>3.758976</td>\n",
       "      <td>0.693194</td>\n",
       "      <td>269.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.037706</td>\n",
       "      <td>0.084296</td>\n",
       "      <td>0.791631</td>\n",
       "      <td>0.563518</td>\n",
       "      <td>0.064509</td>\n",
       "      <td>0.165148</td>\n",
       "      <td>3.958386</td>\n",
       "      <td>0.748015</td>\n",
       "      <td>278.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.035763</td>\n",
       "      <td>0.086257</td>\n",
       "      <td>0.823627</td>\n",
       "      <td>0.623495</td>\n",
       "      <td>0.060885</td>\n",
       "      <td>0.177705</td>\n",
       "      <td>3.816041</td>\n",
       "      <td>0.817470</td>\n",
       "      <td>337.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.031261</td>\n",
       "      <td>0.078824</td>\n",
       "      <td>0.850519</td>\n",
       "      <td>0.611248</td>\n",
       "      <td>0.050212</td>\n",
       "      <td>0.169358</td>\n",
       "      <td>3.708819</td>\n",
       "      <td>0.835836</td>\n",
       "      <td>349.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    _bluemedian  _greenmedian  _ndvimedian  _nirmedian  _redmedian  \\\n",
       "0      0.043859      0.098422     0.709592    0.459952    0.078071   \n",
       "1      0.046533      0.113445     0.742401    0.543418    0.080714   \n",
       "2      0.054283      0.120065     0.710549    0.603680    0.101180   \n",
       "3      0.051817      0.118176     0.702029    0.614528    0.105176   \n",
       "4      0.053026      0.121916     0.661188    0.526453    0.106715   \n",
       "..          ...           ...          ...         ...         ...   \n",
       "91     0.042935      0.097113     0.751683    0.532777    0.075381   \n",
       "92     0.033768      0.078753     0.787837    0.509926    0.060623   \n",
       "93     0.037706      0.084296     0.791631    0.563518    0.064509   \n",
       "94     0.035763      0.086257     0.823627    0.623495    0.060885   \n",
       "95     0.031261      0.078824     0.850519    0.611248    0.050212   \n",
       "\n",
       "    _rededgemedian     _mtci      _evi  GrainYield  \n",
       "0         0.172266  3.054160  0.596902  195.033333  \n",
       "1         0.201865  2.819242  0.689079  223.100000  \n",
       "2         0.221507  3.176109  0.696509  217.483333  \n",
       "3         0.222565  3.338998  0.685736  188.750000  \n",
       "4         0.218743  2.746707  0.593171  155.716667  \n",
       "..             ...       ...       ...         ...  \n",
       "91        0.173760  3.649314  0.687587  283.083333  \n",
       "92        0.155035  3.758976  0.693194  269.700000  \n",
       "93        0.165148  3.958386  0.748015  278.150000  \n",
       "94        0.177705  3.816041  0.817470  337.233333  \n",
       "95        0.169358  3.708819  0.835836  349.916667  \n",
       "\n",
       "[96 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot_18_02_07_18_df[robot_18_02_07_18_df_median_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['robot_18_02_07_18_df',\n",
       " 'robot_18_smallfield05_07_18_df',\n",
       " 'robot_18_smallfield11_07_18_df',\n",
       " 'robot_18_smallfield19_07_18_df',\n",
       " 'robot_18_smallfield24_07_18_df']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [locals()[df_str_list[0]][locals()[robot_col[0]]],\n",
    "               locals()[df_str_list[1]][locals()[robot_col[1]]],\n",
    "               locals()[df_str_list[2]][locals()[robot_col[2]]],\n",
    "               locals()[df_str_list[3]][locals()[robot_col[3]]],\n",
    "               locals()[df_str_list[4]][locals()[robot_col[4]]]]\n",
    "\n",
    "all_robot_2018 = pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_bluemedian</th>\n",
       "      <th>_greenmedian</th>\n",
       "      <th>_ndvimedian</th>\n",
       "      <th>_nirmedian</th>\n",
       "      <th>_redmedian</th>\n",
       "      <th>_rededgemedian</th>\n",
       "      <th>_mtci</th>\n",
       "      <th>_evi</th>\n",
       "      <th>GrainYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043859</td>\n",
       "      <td>0.098422</td>\n",
       "      <td>0.709592</td>\n",
       "      <td>0.459952</td>\n",
       "      <td>0.078071</td>\n",
       "      <td>0.172266</td>\n",
       "      <td>3.054160</td>\n",
       "      <td>0.596902</td>\n",
       "      <td>195.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046533</td>\n",
       "      <td>0.113445</td>\n",
       "      <td>0.742401</td>\n",
       "      <td>0.543418</td>\n",
       "      <td>0.080714</td>\n",
       "      <td>0.201865</td>\n",
       "      <td>2.819242</td>\n",
       "      <td>0.689079</td>\n",
       "      <td>223.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054283</td>\n",
       "      <td>0.120065</td>\n",
       "      <td>0.710549</td>\n",
       "      <td>0.603680</td>\n",
       "      <td>0.101180</td>\n",
       "      <td>0.221507</td>\n",
       "      <td>3.176109</td>\n",
       "      <td>0.696509</td>\n",
       "      <td>217.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051817</td>\n",
       "      <td>0.118176</td>\n",
       "      <td>0.702029</td>\n",
       "      <td>0.614528</td>\n",
       "      <td>0.105176</td>\n",
       "      <td>0.222565</td>\n",
       "      <td>3.338998</td>\n",
       "      <td>0.685736</td>\n",
       "      <td>188.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053026</td>\n",
       "      <td>0.121916</td>\n",
       "      <td>0.661188</td>\n",
       "      <td>0.526453</td>\n",
       "      <td>0.106715</td>\n",
       "      <td>0.218743</td>\n",
       "      <td>2.746707</td>\n",
       "      <td>0.593171</td>\n",
       "      <td>155.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.098741</td>\n",
       "      <td>0.205969</td>\n",
       "      <td>0.397984</td>\n",
       "      <td>0.582367</td>\n",
       "      <td>0.244175</td>\n",
       "      <td>0.320863</td>\n",
       "      <td>3.409994</td>\n",
       "      <td>0.366507</td>\n",
       "      <td>283.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.088336</td>\n",
       "      <td>0.200307</td>\n",
       "      <td>0.448477</td>\n",
       "      <td>0.606331</td>\n",
       "      <td>0.228501</td>\n",
       "      <td>0.332785</td>\n",
       "      <td>2.623099</td>\n",
       "      <td>0.408056</td>\n",
       "      <td>269.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.085717</td>\n",
       "      <td>0.195758</td>\n",
       "      <td>0.466433</td>\n",
       "      <td>0.611985</td>\n",
       "      <td>0.219292</td>\n",
       "      <td>0.331553</td>\n",
       "      <td>2.498041</td>\n",
       "      <td>0.429667</td>\n",
       "      <td>278.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.079853</td>\n",
       "      <td>0.188002</td>\n",
       "      <td>0.466873</td>\n",
       "      <td>0.610464</td>\n",
       "      <td>0.217030</td>\n",
       "      <td>0.327821</td>\n",
       "      <td>2.551135</td>\n",
       "      <td>0.425106</td>\n",
       "      <td>337.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.210163</td>\n",
       "      <td>0.490221</td>\n",
       "      <td>0.672563</td>\n",
       "      <td>0.229311</td>\n",
       "      <td>0.368493</td>\n",
       "      <td>2.184715</td>\n",
       "      <td>0.455767</td>\n",
       "      <td>349.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     _bluemedian  _greenmedian  _ndvimedian  _nirmedian  _redmedian  \\\n",
       "0       0.043859      0.098422     0.709592    0.459952    0.078071   \n",
       "1       0.046533      0.113445     0.742401    0.543418    0.080714   \n",
       "2       0.054283      0.120065     0.710549    0.603680    0.101180   \n",
       "3       0.051817      0.118176     0.702029    0.614528    0.105176   \n",
       "4       0.053026      0.121916     0.661188    0.526453    0.106715   \n",
       "..           ...           ...          ...         ...         ...   \n",
       "475     0.098741      0.205969     0.397984    0.582367    0.244175   \n",
       "476     0.088336      0.200307     0.448477    0.606331    0.228501   \n",
       "477     0.085717      0.195758     0.466433    0.611985    0.219292   \n",
       "478     0.079853      0.188002     0.466873    0.610464    0.217030   \n",
       "479     0.082278      0.210163     0.490221    0.672563    0.229311   \n",
       "\n",
       "     _rededgemedian     _mtci      _evi  GrainYield  \n",
       "0          0.172266  3.054160  0.596902  195.033333  \n",
       "1          0.201865  2.819242  0.689079  223.100000  \n",
       "2          0.221507  3.176109  0.696509  217.483333  \n",
       "3          0.222565  3.338998  0.685736  188.750000  \n",
       "4          0.218743  2.746707  0.593171  155.716667  \n",
       "..              ...       ...       ...         ...  \n",
       "475        0.320863  3.409994  0.366507  283.083333  \n",
       "476        0.332785  2.623099  0.408056  269.700000  \n",
       "477        0.331553  2.498041  0.429667  278.150000  \n",
       "478        0.327821  2.551135  0.425106  337.233333  \n",
       "479        0.368493  2.184715  0.455767  349.916667  \n",
       "\n",
       "[480 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_robot_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Graminor_2018_complet_df_yield_columns\n",
      "(599, 109)\n",
      "26-06-18GrainYield\n",
      "02-07-18GrainYield\n",
      "19-07-18GrainYield\n",
      "\n",
      "\n",
      "Graminor_2019_050719_df_yield_columns\n",
      "(601, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_060619_df_yield_columns\n",
      "(600, 49)\n",
      "\n",
      "\n",
      "___df_yield_columns\n",
      "(600, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_110619_df_yield_columns\n",
      "(600, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_150719_df_yield_columns\n",
      "(600, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_150819_df_yield_columns\n",
      "(600, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_220719_corrected_df_yield_columns\n",
      "(600, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_250719_df_yield_columns\n",
      "(600, 46)\n",
      "\n",
      "\n",
      "Graminor_2019_280619_corrected_df_yield_columns\n",
      "(600, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_east_020719_df_yield_columns\n",
      "(300, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_east_050819_df_yield_columns\n",
      "(300, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_east_110719_df_yield_columns\n",
      "(300, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_east_250619_corrected_df_yield_columns\n",
      "(300, 97)\n",
      "\n",
      "\n",
      "Graminor_2019_west_020719_df_yield_columns\n",
      "(300, 46)\n",
      "\n",
      "\n",
      "Graminor_2019_west_050819_df_yield_columns\n",
      "(300, 49)\n",
      "\n",
      "\n",
      "Graminor_2019_west_250619_correct_df_yield_columns\n",
      "(300, 49)\n",
      "\n",
      "\n",
      "Masbasis_2017_df_yield_columns\n",
      "(560, 179)\n",
      "14-07-17Yield\n",
      "17-07-17Yield\n",
      "20-07-17Yield\n",
      "01-08-17Yield\n",
      "\n",
      "\n",
      "Masbasis_2018_yp_df_yield_columns\n",
      "(528, 101)\n",
      "13-07-18GrainYield\n",
      "26-07-18GrainYield\n",
      "\n",
      "\n",
      "Robot_2017_14_06_17_df_yield_columns\n",
      "(96, 33)\n",
      "GrainYield\n",
      "HarvestYield \n",
      "\n",
      "\n",
      "Robot_2017_19_06_17_df_yield_columns\n",
      "(96, 73)\n",
      "GrainYield\n",
      "HarvestYield \n",
      "\n",
      "\n",
      "Robot_2017_29_06_17_df_yield_columns\n",
      "(96, 73)\n",
      "GrainYield\n",
      "HarvestYield \n",
      "\n",
      "\n",
      "Robot_2017_03_07_17_df_yield_columns\n",
      "(96, 73)\n",
      "GrainYield\n",
      "HarvestYield \n",
      "\n",
      "\n",
      "Robot_2017_14_07_17_df_yield_columns\n",
      "(96, 73)\n",
      "GrainYield\n",
      "HarvestYield \n",
      "\n",
      "\n",
      "Robot_2017_17_07_17_df_yield_columns\n",
      "(96, 73)\n",
      "GrainYield\n",
      "HarvestYield \n",
      "\n",
      "\n",
      "Robot_2017_14_08_17_df_yield_columns\n",
      "(96, 73)\n",
      "GrainYield\n",
      "HarvestYield \n",
      "\n",
      "\n",
      "name_02_07_18_df_yield_columns\n",
      "(96, 22)\n",
      "GrainYield\n",
      "\n",
      "\n",
      "name_smallfield05_07_18_df_yield_columns\n",
      "(96, 22)\n",
      "GrainYield\n",
      "\n",
      "\n",
      "name_smallfield11_07_18_df_yield_columns\n",
      "(96, 22)\n",
      "GrainYield\n",
      "\n",
      "\n",
      "name_smallfield19_07_18_df_yield_columns\n",
      "(96, 28)\n",
      "GrainYield\n",
      "\n",
      "\n",
      "name_smallfield24_07_18_df_yield_columns\n",
      "(96, 30)\n",
      "GrainYield\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2018_complet_df_yield_columns',\n",
       " 'Graminor_2019_050719_df_yield_columns',\n",
       " 'Graminor_2019_060619_df_yield_columns',\n",
       " '___df_yield_columns',\n",
       " 'Graminor_2019_110619_df_yield_columns',\n",
       " 'Graminor_2019_150719_df_yield_columns',\n",
       " 'Graminor_2019_150819_df_yield_columns',\n",
       " 'Graminor_2019_220719_corrected_df_yield_columns',\n",
       " 'Graminor_2019_250719_df_yield_columns',\n",
       " 'Graminor_2019_280619_corrected_df_yield_columns',\n",
       " 'Graminor_2019_east_020719_df_yield_columns',\n",
       " 'Graminor_2019_east_050819_df_yield_columns',\n",
       " 'Graminor_2019_east_110719_df_yield_columns',\n",
       " 'Graminor_2019_east_250619_corrected_df_yield_columns',\n",
       " 'Graminor_2019_west_020719_df_yield_columns',\n",
       " 'Graminor_2019_west_050819_df_yield_columns',\n",
       " 'Graminor_2019_west_250619_correct_df_yield_columns',\n",
       " 'Masbasis_2017_df_yield_columns',\n",
       " 'Masbasis_2018_yp_df_yield_columns',\n",
       " 'Robot_2017_14_06_17_df_yield_columns',\n",
       " 'Robot_2017_19_06_17_df_yield_columns',\n",
       " 'Robot_2017_29_06_17_df_yield_columns',\n",
       " 'Robot_2017_03_07_17_df_yield_columns',\n",
       " 'Robot_2017_14_07_17_df_yield_columns',\n",
       " 'Robot_2017_17_07_17_df_yield_columns',\n",
       " 'Robot_2017_14_08_17_df_yield_columns',\n",
       " 'name_02_07_18_df_yield_columns',\n",
       " 'name_smallfield05_07_18_df_yield_columns',\n",
       " 'name_smallfield11_07_18_df_yield_columns',\n",
       " 'name_smallfield19_07_18_df_yield_columns',\n",
       " 'name_smallfield24_07_18_df_yield_columns']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grain yield already appended to the list and dataframe\n",
    "\n",
    "lists_of_yield_cols = []\n",
    "\n",
    "for df in df_str_list:\n",
    "    list_of_columns = df+'_yield_columns'\n",
    "    locals()[list_of_columns] = []\n",
    "    for strg in locals()[df].columns.tolist():\n",
    "        if strg.find('Yield') != -1 or strg.find('yield') != -1 or strg.find('yie') != -1 or strg.find('YIE') != -1 :\n",
    "            locals()[list_of_columns].append(strg)\n",
    "    lists_of_yield_cols.append(list_of_columns)\n",
    "    \n",
    "    print('\\n', list_of_columns,locals() [df].shape, *locals()[list_of_columns], sep='\\n')\n",
    "\n",
    "lists_of_yield_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Split dataframe into data and target\n",
    "#==============================================================================\n",
    "\n",
    "X = all_robot_2018.iloc[:,:-1].values\n",
    "y = all_robot_2018.iloc[:,-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrainYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>283.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>269.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>278.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>337.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>349.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GrainYield\n",
       "0    195.033333\n",
       "1    223.100000\n",
       "2    217.483333\n",
       "3    188.750000\n",
       "4    155.716667\n",
       "..          ...\n",
       "475  283.083333\n",
       "476  269.700000\n",
       "477  278.150000\n",
       "478  337.233333\n",
       "479  349.916667\n",
       "\n",
       "[480 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Create separate train/test splits from Main data\n",
    "#==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Scale features using StandardScaler class in scikit-learn\n",
    "#==============================================================================\n",
    "\n",
    "# Initialise standard scaler and compute mean and STD from training data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "# Transform (standardise) both X_train and X_test with mean and STD from\n",
    "# training data\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Defining the function to vaiidate the model with the test data and\n",
    "# get the results from regression evaluation metrices in sklearn\n",
    "#==============================================================================\n",
    "pred = []\n",
    "accuracy = []\n",
    "\n",
    "\n",
    "def test_data_regression(model, X_test, y_test):\n",
    "    pred = []\n",
    "    accuracy = []\n",
    "    #==============================================================================\n",
    "    # Make predictions for test set\n",
    "    #==============================================================================\n",
    "\n",
    "    # Predict classes for samples in test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    #==============================================================================\n",
    "    # Compute performance\n",
    "    #==============================================================================\n",
    "\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(mae, ' mean_absolute_error')\n",
    "    accuracy.append(mae)\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(y_test, y_pred, squared=True)\n",
    "    print(mse, ' mean_squared_error')\n",
    "    accuracy.append(mse)\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print(rmse, ' root_mean_squared_error')\n",
    "    accuracy.append(rmse)\n",
    "\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(r2, ' r2_score')\n",
    "    accuracy.append(r2)\n",
    "\n",
    "    # Print accuracy computed from predictions on the test set\n",
    "    print(accuracy)\n",
    "\n",
    "    #==============================================================================\n",
    "    # Append Results\n",
    "    #==============================================================================\n",
    "    results = []\n",
    "    import datetime\n",
    "    datetime = datetime.datetime.now()\n",
    "    results.append((model, 'MAE = {}'.format(mae), 'MSE = {}'.format(mse),\n",
    "                    'RMSE = {}'.format(rmse), 'R2 = {}'.format(r2),\n",
    "                    'List = {}'.format(accuracy), datetime))\n",
    "\n",
    "    pd.DataFrame(np.asarray(results)).to_csv('results.csv',\n",
    "                                             mode='a',\n",
    "                                             header=None)\n",
    "    pred.extend(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.0835506761164  mean_absolute_error\n",
      "1699.8505542728835  mean_squared_error\n",
      "41.22924392070371  root_mean_squared_error\n",
      "0.36060148102803813  r2_score\n",
      "[32.0835506761164, 1699.8505542728835, 41.22924392070371, 0.36060148102803813]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000,\n",
    "                              max_depth=250,\n",
    "                              min_samples_split=5,\n",
    "                              random_state=0,\n",
    "                              n_jobs=-1)\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred = model.predict(X_test_std)\n",
    "test_data_regression(model, X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.06019113861013  mean_absolute_error\n",
      "2214.0427274094013  mean_squared_error\n",
      "47.05361545523788  root_mean_squared_error\n",
      "0.16718817587363421  r2_score\n",
      "[36.06019113861013, 2214.0427274094013, 47.05361545523788, 0.16718817587363421]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=10,\n",
    "                              max_depth=1,\n",
    "                              min_samples_split=10,\n",
    "                              random_state=0,\n",
    "                              n_jobs=-1)\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred = model.predict(X_test_std)\n",
    "test_data_regression(model, X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.65587873044957  mean_absolute_error\n",
      "1878.5982679737863  mean_squared_error\n",
      "43.34279949396193  root_mean_squared_error\n",
      "0.29336555659768737  r2_score\n",
      "[34.65587873044957, 1878.5982679737863, 43.34279949396193, 0.29336555659768737]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "model = PLSRegression(n_components=5)\n",
    "model.fit(X_train_std, y_train)\n",
    "y_pred = model.predict(X_test_std)\n",
    "test_data_regression(model, X_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-49.23579290605097\n",
      "{'randomforestregressor__max_depth': 1, 'randomforestregressor__min_samples_split': 10, 'randomforestregressor__n_estimators': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:335: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-e995d4f856a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# Inspect AUC of parameter grid combinations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     print(\"%0.3f +/- %0.2f %r\"\n\u001b[0;32m     36\u001b[0m           % (grid.cv_results_['mean_test_score'][r], \n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "pipe_line = make_pipeline(RandomForestRegressor())\n",
    "\n",
    "# Define ranges of parameter values:\n",
    "param_range  = list(range(1,200))                   # For n_components\n",
    "param_range2 = list(range(10, 100, 10))          # For max_iter\n",
    "param_range3 = list(range(1, 25,3))                   # For max_depth\n",
    "param_range4 = [x/10 for x in list(range(0, 10))]   # For learning_rate\n",
    "param_range5  = list(range(5,20))                   # For n_components\n",
    "\n",
    "\n",
    "# estimator.get_params().keys()\n",
    "# pipe_line.get_params().keys()\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_line, \n",
    "                  param_grid=[{'randomforestregressor__n_estimators': param_range2,\n",
    "                              'randomforestregressor__max_depth': param_range3,\n",
    "                               'randomforestregressor__min_samples_split': param_range3}], \n",
    "                  scoring='neg_root_mean_squared_error', \n",
    "                  cv=3,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X, y)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "\n",
    "# Inspect AUC of parameter grid combinations\n",
    "for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "    print(\"%0.3f +/- %0.2f %r\"\n",
    "          % (grid.cv_results_['mean_test_score'][r], \n",
    "             grid.cv_results_['std_test_score'][r] / 2.0, \n",
    "             grid.cv_results_['params'][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrainYield    223.1\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.iloc[1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191.60301085] [195.03333333]\n",
      "[187.75751859] [223.1]\n",
      "[170.11784903] [217.48333333]\n",
      "[204.85798152] [188.75]\n",
      "[183.56445347] [155.71666667]\n",
      "[200.19711721] [166.38333333]\n",
      "[162.51723369] [152.3]\n",
      "[194.78054727] [121.31666667]\n",
      "[211.99721477] [177.33333333]\n",
      "[236.54206402] [169.6]\n",
      "[184.38009797] [190.2]\n",
      "[218.52122335] [250.13333333]\n",
      "[179.84507064] [209.71666667]\n",
      "[183.443618] [220.51666667]\n",
      "[231.35547909] [162.58333333]\n",
      "[263.7157122] [130.31666667]\n",
      "[168.00579402] [136.65]\n",
      "[195.44135392] [114.25]\n",
      "[224.529156] [152.91666667]\n",
      "[198.87281238] [146.78333333]\n",
      "[247.2448209] [180.45]\n",
      "[213.30075601] [162.26666667]\n",
      "[236.91808657] [172.68333333]\n",
      "[184.81161724] [212.76666667]\n",
      "[202.69087844] [236.01666667]\n",
      "[199.110409] [218.65]\n",
      "[230.38077878] [161.06666667]\n",
      "[164.18844784] [195.11666667]\n",
      "[178.25894024] [169.78333333]\n",
      "[170.39992857] [158.21666667]\n",
      "[142.59845332] [118.01666667]\n",
      "[160.23855123] [125.08333333]\n",
      "[195.73690118] [181.26666667]\n",
      "[187.95141101] [171.45]\n",
      "[236.09674773] [235.83333333]\n",
      "[141.3502903] [239.96666667]\n",
      "[193.73669807] [176.2]\n",
      "[199.26251057] [175.46666667]\n",
      "[189.95744599] [168.26666667]\n",
      "[168.42200454] [220.]\n",
      "[194.20676074] [154.81666667]\n",
      "[160.8994875] [144.9]\n",
      "[226.73261062] [204.75]\n",
      "[163.82475354] [207.88333333]\n",
      "[176.97957633] [163.48333333]\n",
      "[174.3937306] [115.15]\n",
      "[163.5249338] [251.08333333]\n",
      "[170.39787339] [275.73333333]\n",
      "[209.63133749] [159.78333333]\n",
      "[223.26648708] [208.93333333]\n",
      "[205.29930193] [131.51666667]\n",
      "[224.79567013] [145.13333333]\n",
      "[228.70726269] [144.01666667]\n",
      "[179.96782264] [123.65]\n",
      "[155.86752255] [191.03333333]\n",
      "[203.74317085] [178.25]\n",
      "[183.26238382] [182.3]\n",
      "[187.21128481] [153.63333333]\n",
      "[172.13896321] [208.3]\n",
      "[165.1953702] [195.83333333]\n",
      "[210.34193731] [188.38333333]\n",
      "[189.31605664] [195.68333333]\n",
      "[178.79976896] [186.58333333]\n",
      "[213.80269586] [203.26666667]\n",
      "[251.11196326] [147.48333333]\n",
      "[190.52479262] [120.43333333]\n",
      "[204.44042702] [210.43333333]\n",
      "[172.81120794] [160.91666667]\n",
      "[142.16513675] [191.91666667]\n",
      "[181.46633684] [181.43333333]\n",
      "[173.9712862] [231.45]\n",
      "[209.60181706] [225.9]\n",
      "[237.20159778] [177.38333333]\n",
      "[236.28032824] [233.41666667]\n",
      "[176.51696765] [185.4]\n",
      "[239.43274827] [194.35]\n",
      "[241.1327578] [173.91666667]\n",
      "[176.20933831] [177.23333333]\n",
      "[202.60113334] [222.03333333]\n",
      "[202.71170558] [234.08333333]\n",
      "[168.25924306] [194.13333333]\n",
      "[170.47215948] [257.]\n",
      "[227.03574757] [223.5]\n",
      "[222.86510612] [320.11666667]\n",
      "[220.32539327] [133.81666667]\n",
      "[228.05094073] [264.56666667]\n",
      "[165.27789393] [204.15]\n",
      "[197.7935099] [203.63333333]\n",
      "[216.8364763] [197.68333333]\n",
      "[169.59014662] [243.56666667]\n",
      "[151.35353287] [234.45]\n",
      "[220.73652657] [283.08333333]\n",
      "[187.55703088] [269.7]\n",
      "[232.21836048] [278.15]\n",
      "[176.91667096] [337.23333333]\n",
      "[152.08076393] [349.91666667]\n",
      "[159.46124743] [195.03333333]\n",
      "[186.78212772] [223.1]\n",
      "[203.35917093] [217.48333333]\n",
      "[218.93129378] [188.75]\n",
      "[189.38862719] [155.71666667]\n",
      "[217.03753555] [166.38333333]\n",
      "[202.15852587] [152.3]\n",
      "[178.97411483] [121.31666667]\n",
      "[165.42313407] [177.33333333]\n",
      "[220.22624726] [169.6]\n",
      "[185.01751094] [190.2]\n",
      "[229.60787231] [250.13333333]\n",
      "[214.22894335] [209.71666667]\n",
      "[231.86220593] [220.51666667]\n",
      "[213.74873065] [162.58333333]\n",
      "[194.3773726] [130.31666667]\n",
      "[197.87888802] [136.65]\n",
      "[203.85634036] [114.25]\n",
      "[184.26002205] [152.91666667]\n",
      "[192.93637493] [146.78333333]\n",
      "[192.83721825] [180.45]\n",
      "[188.68725704] [162.26666667]\n",
      "[205.03051612] [172.68333333]\n",
      "[196.53056976] [212.76666667]\n",
      "[191.81039017] [236.01666667]\n",
      "[158.98242975] [218.65]\n",
      "[267.52180013] [161.06666667]\n",
      "[202.41829133] [195.11666667]\n",
      "[251.47556681] [169.78333333]\n",
      "[195.91581147] [158.21666667]\n",
      "[168.69763666] [118.01666667]\n",
      "[169.86023739] [125.08333333]\n",
      "[232.01507569] [181.26666667]\n",
      "[190.48088138] [171.45]\n",
      "[158.59660323] [235.83333333]\n",
      "[190.56469866] [239.96666667]\n",
      "[206.5383688] [176.2]\n",
      "[214.23647084] [175.46666667]\n",
      "[156.99773818] [168.26666667]\n",
      "[200.64425666] [220.]\n",
      "[238.18580763] [154.81666667]\n",
      "[188.20670602] [144.9]\n",
      "[175.71385997] [204.75]\n",
      "[197.6517282] [207.88333333]\n",
      "[226.79408695] [163.48333333]\n",
      "[205.16289646] [115.15]\n",
      "[179.06283048] [251.08333333]\n",
      "[177.9888569] [275.73333333]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    print(y_pred[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import cv2\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Neural networks\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Training\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define eval metric and loss function (DICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Metric used in the competition\n",
    "\"\"\" \n",
    "# Defining the dice_coef function\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# Defining the dice_loss function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Create U-net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Version of U-Net with dropout and size preservation (padding= 'same')\n",
    "\"\"\" \n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_deep_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True, n_classes = 1, growth_factor=2, upconv=True):\n",
    "\n",
    "    inputs = input_img\n",
    "    #inputs = BatchNormalization()(inputs)\n",
    "    \n",
    "    # Creating deep convnets using Conv2D and MaxPooling2D in each convolutional layer\n",
    "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #pool1 = Dropout(droprate)(pool1)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    # Applying batch normalization to each layer to be able to use deep convnets\n",
    "    pool1 = BatchNormalization()(pool1)\n",
    "    # Second Covnet\n",
    "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(dropout)(pool2)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    # Applying batch normalization\n",
    "    pool2 = BatchNormalization()(pool2)\n",
    "    # Third Covnet\n",
    "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(dropout)(pool3)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    # Applying batch normalization\n",
    "    pool3 = BatchNormalization()(pool3)\n",
    "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4_0 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_0)\n",
    "    pool4_1 = MaxPooling2D(pool_size=(2, 2))(conv4_0)\n",
    "    pool4_1 = Dropout(dropout)(pool4_1)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    # Applying batch normalization\n",
    "    pool4_1 = BatchNormalization()(pool4_1)\n",
    "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_1)\n",
    "    conv4_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv4_1)\n",
    "    pool4_2 = MaxPooling2D(pool_size=(2, 2))(conv4_1)\n",
    "    pool4_2 = Dropout(dropout)(pool4_2)\n",
    "\n",
    "    n_filters *= growth_factor\n",
    "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(pool4_2)\n",
    "    conv5 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    n_filters //= growth_factor\n",
    "    # Using image upsampling by either Conv2DTranspose or UpSampling2D\n",
    "    if upconv:\n",
    "        up6_1 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv5), conv4_1])\n",
    "    else:\n",
    "        up6_1 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4_1])\n",
    "    # Applying batch normalization\n",
    "    up6_1 = BatchNormalization()(up6_1)\n",
    "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_1)\n",
    "    conv6_1 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_1)\n",
    "    conv6_1 = Dropout(dropout)(conv6_1)\n",
    "\n",
    "    # Using image upsampling by either Conv2DTranspose or UpSampling2D\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up6_2 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_1), conv4_0])\n",
    "    else:\n",
    "        up6_2 = concatenate([UpSampling2D(size=(2, 2))(conv6_1), conv4_0])\n",
    "    up6_2 = BatchNormalization()(up6_2)\n",
    "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up6_2)\n",
    "    conv6_2 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv6_2)\n",
    "    conv6_2 = Dropout(dropout)(conv6_2)\n",
    "\n",
    "    # Using image upsampling by either Conv2DTranspose or UpSampling2D\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up7 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv6_2), conv3])\n",
    "    else:\n",
    "        up7 = concatenate([UpSampling2D(size=(2, 2))(conv6_2), conv3])\n",
    "    # Applying batch normalization\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = Dropout(dropout)(conv7)\n",
    "\n",
    "    # Using image upsampling by either Conv2DTranspose or UpSampling2D\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up8 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv7), conv2])\n",
    "    else:\n",
    "        up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
    "    # Applying batch normalization\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    conv8 = Dropout(dropout)(conv8)\n",
    "\n",
    "    # Using image upsampling by either Conv2DTranspose or UpSampling2D\n",
    "    n_filters //= growth_factor\n",
    "    if upconv:\n",
    "        up9 = concatenate([Conv2DTranspose(n_filters, (2, 2), strides=(2, 2), padding='same')(conv8), conv1])\n",
    "    else:\n",
    "        up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
    "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(n_filters, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, (1, 1), activation='sigmoid')(conv9)\n",
    "    \n",
    "    # Creating model and feeding the input image and the final convolutional layer into it\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input to `.fit()` should have rank 4. Got array with shape: (67, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-639feb388496>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Fit DataGen instance to X_train (Only needed for standardization etc.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mtrain_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Create flow for training images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m             raise ValueError('Input to `.fit()` should have rank 4. '\n\u001b[1;32m--> 936\u001b[1;33m                              'Got array with shape: ' + str(x.shape))\n\u001b[0m\u001b[0;32m    937\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m             warnings.warn(\n",
      "\u001b[1;31mValueError\u001b[0m: Input to `.fit()` should have rank 4. Got array with shape: (67, 8)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Data augmentation for training dataset\n",
    "\"\"\"\n",
    "\n",
    "# Define batch size for augmentation\n",
    "batch_size = 64\n",
    "# Define random seed\n",
    "seed = 123\n",
    "\n",
    "# Dict containing augmentation variables\n",
    "data_gen_args = dict(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    rotation_range=90,\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# Instantiate DataGenerator class with variables from dict\n",
    "train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Fit DataGen instance to X_train (Only needed for standardization etc.)\n",
    "train_datagen.fit(X_train)\n",
    "\n",
    "# Create flow for training images\n",
    "image_train_generator = train_datagen.flow(\n",
    "    X_train,\n",
    "    None,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# Create separate flow for training masks\n",
    "mask_train_generator = train_datagen.flow(\n",
    "    y_train,\n",
    "    None,\n",
    "    seed=seed,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# Combine generators into one which yields image and masks\n",
    "train_generator = zip(image_train_generator, mask_train_generator)\n",
    "\"\"\"\n",
    "Model creation and compilation\n",
    "\"\"\"\n",
    "\n",
    "# Define input class with correct shape\n",
    "input_img = Input(shape=(128, 128, 4))\n",
    "\n",
    "# Number of filters in the U-net\n",
    "n_filters = 64\n",
    "\n",
    "# Instantiate U-net without dropout with batchnorm\n",
    "model = get_deep_unet(input_img,\n",
    "                      n_filters=n_filters,\n",
    "                      dropout=0.0,\n",
    "                      batchnorm=True,\n",
    "                      n_classes=1)\n",
    "\n",
    "# Compile model using \"Adam\" with custom loss function and metrics\n",
    "model.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coef])\n",
    "\"\"\"\n",
    "Callbacks\n",
    "\"\"\"\n",
    "\n",
    "# Early stopping for saving compute time\n",
    "earlystopping = EarlyStopping(monitor='val_dice_coef',\n",
    "                              verbose=1,\n",
    "                              min_delta=0.01,\n",
    "                              patience=3,\n",
    "                              mode='max')\n",
    "\n",
    "# Saving best models\n",
    "model_path = '/content/drive/My Drive/Skole/CA2/tmp/unet.model'\n",
    "checkpoint = ModelCheckpoint(model_path,\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='min')\n",
    "\n",
    "# Reduce learning rate to improve accuracy on plateaus\n",
    "redlr = ReduceLROnPlateau(factor=0.1,\n",
    "                          patience=1,\n",
    "                          min_lr=1e-08,\n",
    "                          verbose=1,\n",
    "                          monitor='val_loss',\n",
    "                          mode='min'),\n",
    "\n",
    "# Collect callbacks in list\n",
    "callbacks_list = [redlr, earlystopping, checkpoint]\n",
    "\"\"\"\n",
    "Model training\n",
    "\"\"\"\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=(X_train.shape[0] // n_filters),\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    validation_steps=(X_val.shape[0] // n_filters),\n",
    "                    epochs=4,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
