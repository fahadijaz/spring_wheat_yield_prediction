{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9eef441",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = ['GrainYield']\n",
    "# target_features = ['Days2Maturity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105acfb2",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reflected-inventory",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:19.571238Z",
     "start_time": "2021-11-02T23:27:19.546305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# prints the location of current python env\n",
    "print(sys.prefix)\n",
    "# print which python executable am I running\n",
    "sys.executable\n",
    "\n",
    "# In Anaconda Prompt, run the following\n",
    "# where python\n",
    "# where pip\n",
    "\n",
    "# to find out where are the python executables located on disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "level-september",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:19.586336Z",
     "start_time": "2021-11-02T23:27:19.573232Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# print (sklearn.__version__)\n",
    "# !pip list -o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "average-columbia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.027003Z",
     "start_time": "2021-11-02T23:27:19.589329Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "# Dictionaries\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Iterate in loops\n",
    "import itertools\n",
    "from itertools import zip_longest\n",
    "\n",
    "# Simpsons integration\n",
    "from numpy import trapz\n",
    "from scipy.integrate import simps\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To display df nicely in loops\n",
    "from IPython.display import display \n",
    "# display(df1.head()) \n",
    "# display(df2.head())\n",
    "\n",
    "# Display rows and columns Pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# # For displaying max rows in series\n",
    "# pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62a5621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.184838Z",
     "start_time": "2021-11-02T23:27:21.028999Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from sklearn.metrics import mean_gamma_deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-surfing",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d066e93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.200932Z",
     "start_time": "2021-11-02T23:27:21.186833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fahad\\\\MegaSync\\\\NMBU\\\\GitHub\\\\vPheno'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the current working directory\n",
    "os.getcwd()\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796c4ee",
   "metadata": {},
   "source": [
    "## Finding Username folder to make general path for multi PC use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5204388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.216889Z",
     "start_time": "2021-11-02T23:27:21.203923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fahad', 'C:/Users/fahad/')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = str(os.getcwd()).split('\\\\')[2]\n",
    "user_path = r'C:/Users/'+username+'/'\n",
    "username, user_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a708728",
   "metadata": {},
   "source": [
    "## Declaring Import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448c66bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.232144Z",
     "start_time": "2021-11-02T23:27:21.218885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Simps.csv',\n",
       " 'Graminor_2019_Trapz.csv',\n",
       " 'Graminor_2020_Simps.csv',\n",
       " 'Graminor_2020_Trapz.csv',\n",
       " 'Masbasis_2019_Simps.csv',\n",
       " 'Masbasis_2019_Trapz.csv',\n",
       " 'Masbasis_2020_Simps.csv',\n",
       " 'Masbasis_2020_Trapz.csv',\n",
       " 'Robot_2020_Simps.csv',\n",
       " 'Robot_2020_Trapz.csv',\n",
       " 'Staur_2019_Simps.csv',\n",
       " 'Staur_2019_Trapz.csv',\n",
       " 'Staur_2020_Simps.csv',\n",
       " 'Staur_2020_Trapz.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = r'./Data/'\n",
    "path = r'./Data/3. merged data/'\n",
    "if target_features[0] == 'GrainYield':\n",
    "    export_path = './Data/4. results/'\n",
    "    export_path_comparability = './Data/4. results/comparability/'\n",
    "elif target_features[0] == 'Days2Maturity':\n",
    "    export_path = './Data/4. results_dm/'\n",
    "    export_path_comparability = './Data/4. results_dm/comparability/'\n",
    "\n",
    "# Create export_path folder if not exists already\n",
    "os.makedirs(path, exist_ok=True)\n",
    "os.makedirs(export_path, exist_ok=True)\n",
    "os.makedirs(export_path_comparability, exist_ok=True)\n",
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "disturbed-interval",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.248101Z",
     "start_time": "2021-11-02T23:27:21.234139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making dictionary of files in each folder, in case there are multiple types of data\n",
    "dict_paths = {}\n",
    "def explore(starting_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(starting_path):\n",
    "        dict_paths[dirpath.split('/')[-2]] = filenames\n",
    "#     pprint(dict_paths)\n",
    "explore(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede1524",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "## Creating list of complete files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mighty-atlas",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.263528Z",
     "start_time": "2021-11-02T23:27:21.250096Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 files found in the directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Simps.csv',\n",
       " 'Graminor_2019_Trapz.csv',\n",
       " 'Graminor_2020_Simps.csv',\n",
       " 'Graminor_2020_Trapz.csv',\n",
       " 'Masbasis_2019_Simps.csv',\n",
       " 'Masbasis_2019_Trapz.csv',\n",
       " 'Masbasis_2020_Simps.csv',\n",
       " 'Masbasis_2020_Trapz.csv',\n",
       " 'Robot_2020_Simps.csv',\n",
       " 'Robot_2020_Trapz.csv',\n",
       " 'Staur_2019_Simps.csv',\n",
       " 'Staur_2019_Trapz.csv',\n",
       " 'Staur_2020_Simps.csv',\n",
       " 'Staur_2020_Trapz.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of all files in directory tree at given path\n",
    "\n",
    "files_with_address = []\n",
    "files_list = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "    files_with_address += [os.path.join(dirpath, file) for file in filenames]\n",
    "    files_list.extend(filenames)\n",
    "    \n",
    "print(len(files_with_address), 'files found in the directory')\n",
    "# files_with_address\n",
    "files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeebb14",
   "metadata": {},
   "source": [
    "## Data Checking/control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84d976",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Check for duplicate filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2affa906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.278489Z",
     "start_time": "2021-11-02T23:27:21.266520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files are : 14\n",
      "Number of unique file names are: 14\n",
      "There is/are 0 duplicate file name/names.\n"
     ]
    }
   ],
   "source": [
    "print('Total number of files are :', len(files_list))\n",
    "\n",
    "print('Number of unique file names are:', len(set(files_list)))\n",
    "\n",
    "print('There is/are', len(files_list) - len(set(files_list)),'duplicate file name/names.')\n",
    "if len(files_list) - len(set(files_list)) > 0:\n",
    "    raise NameError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f118d1",
   "metadata": {},
   "source": [
    "# Importing data files to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad948136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.831736Z",
     "start_time": "2021-11-02T23:27:21.281480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps ===== (600, 123)\n",
      "Graminor_2019_Trapz ===== (600, 123)\n",
      "Graminor_2020_Simps ===== (800, 123)\n",
      "Graminor_2020_Trapz ===== (800, 123)\n",
      "Masbasis_2019_Simps ===== (528, 124)\n",
      "Masbasis_2019_Trapz ===== (528, 124)\n",
      "Masbasis_2020_Simps ===== (659, 126)\n",
      "Masbasis_2020_Trapz ===== (659, 126)\n",
      "Robot_2020_Simps ===== (96, 125)\n",
      "Robot_2020_Trapz ===== (96, 125)\n",
      "Staur_2019_Simps ===== (1328, 127)\n",
      "Staur_2019_Trapz ===== (1328, 127)\n",
      "Staur_2020_Simps ===== (1504, 124)\n",
      "Staur_2020_Trapz ===== (1504, 124)\n"
     ]
    }
   ],
   "source": [
    "all_df = []\n",
    "for data in files_with_address:\n",
    "    file_name = os.path.splitext(os.path.basename(data))[0]\n",
    "\n",
    "    # Replce all invalid characters in the name\n",
    "    file_name = file_name.replace(\" \", \"_\")\n",
    "    file_name = file_name.replace(\"-\", \"_\")\n",
    "    file_name = file_name.replace(\")\", \"\")\n",
    "    file_name = file_name.replace(\"(\", \"\")\n",
    "    df_name = file_name.replace(\".\", \"\")\n",
    "    # Test: Check if the same date is already present in the current dict key\n",
    "    if df_name in all_df:\n",
    "        print(f'A file with the same name {df_name} has already been imported. \\n Please check if there is duplication of data.')\n",
    "        raise NameError\n",
    "    all_df.append(df_name)\n",
    "\n",
    "    locals()[df_name] = pd.read_csv(data, index_col=False)\n",
    "    print(df_name, '=====', locals()[df_name].shape)\n",
    "# all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-territory",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.847281Z",
     "start_time": "2021-11-02T23:27:21.834294Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b51b4353",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.863237Z",
     "start_time": "2021-11-02T23:27:21.849276Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imported 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Simps',\n",
       " 'Graminor_2019_Trapz',\n",
       " 'Graminor_2020_Simps',\n",
       " 'Graminor_2020_Trapz',\n",
       " 'Masbasis_2019_Simps',\n",
       " 'Masbasis_2019_Trapz',\n",
       " 'Masbasis_2020_Simps',\n",
       " 'Masbasis_2020_Trapz',\n",
       " 'Robot_2020_Simps',\n",
       " 'Robot_2020_Trapz',\n",
       " 'Staur_2019_Simps',\n",
       " 'Staur_2019_Trapz',\n",
       " 'Staur_2020_Simps',\n",
       " 'Staur_2020_Trapz']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total imported {len(all_df)}')\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e8186b",
   "metadata": {},
   "source": [
    "# Finding yield columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-aside",
   "metadata": {},
   "source": [
    "## Importing Weather variables, yield columns, spectral indices, base indices columsn list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "peripheral-audit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.879194Z",
     "start_time": "2021-11-02T23:27:21.865232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+'vollebekk_weather_columns.json', \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "\n",
    "# Converting it to python format\n",
    "weather_cols_vollebekk = json.loads(output_str)\n",
    "a_file.close()\n",
    "\n",
    "pprint(len(weather_cols_vollebekk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "express-wheel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.894154Z",
     "start_time": "2021-11-02T23:27:21.882187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+'staur_weather_columns.json', \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "\n",
    "# Converting it to python format\n",
    "weather_cols_staur = json.loads(output_str)\n",
    "a_file.close()\n",
    "\n",
    "pprint(len(weather_cols_staur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "loved-vaccine",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.909022Z",
     "start_time": "2021-11-02T23:27:21.896150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Entry', 'Replicates', 'Name', 'Lodging', 'GrainYield', 'iBlock', 'Line', 'Pedigree', 'Block', 'Days2Maturity', 'CodeName', 'Heading_Date', 'Days2Heading', 'Maturity_Date']\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+\"yield_columns.json\", \"r\")\n",
    "output_str = a_file.read()\n",
    "\n",
    "# The file is imported as string\n",
    "# Converting it to python format\n",
    "yield_cols = json.loads(output_str)\n",
    "a_file.close()\n",
    "print(yield_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surgical-observation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.925976Z",
     "start_time": "2021-11-02T23:27:21.911017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NDVI', 'MTCI', 'DVI', 'GDVI', 'MTCI_CI', 'EXG', 'EXGR', 'RDVI', 'TDVI', 'GNDVI', 'NDRE', 'SCCI', 'EVI', 'TVI', 'VARI', 'GARI', 'GCI', 'GLI', 'NLI', 'MNLI', 'SAVI', 'GSAVI', 'OSAVI', 'GOSAVI', 'MSAVI2', 'MSR', 'GRVI', 'WDRVI', 'SR']\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+\"spectral_indices_columns.json\", \"r\")\n",
    "output_str = a_file.read()\n",
    "\n",
    "# The file is imported as string\n",
    "# Converting it to python format\n",
    "spectral_indices_all = json.loads(output_str)\n",
    "a_file.close()\n",
    "print(spectral_indices_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "southeast-plain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:21.955531Z",
     "start_time": "2021-11-02T23:27:21.931595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blue', 'Green', 'Red', 'RedEdge', 'NIR']\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+\"base_indices_columns.json\", \"r\")\n",
    "output_str = a_file.read()\n",
    "\n",
    "# The file is imported as string\n",
    "# Converting it to python format\n",
    "base_indices = json.loads(output_str)\n",
    "a_file.close()\n",
    "print(base_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-empty",
   "metadata": {},
   "source": [
    "## Defining categories of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0001fa8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:22.295846Z",
     "start_time": "2021-11-02T23:27:22.282881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Entry',\n",
       " 'Replicates',\n",
       " 'Name',\n",
       " 'Lodging',\n",
       " 'GrainYield',\n",
       " 'iBlock',\n",
       " 'Line',\n",
       " 'Pedigree',\n",
       " 'Block',\n",
       " 'Days2Maturity',\n",
       " 'CodeName',\n",
       " 'Heading_Date',\n",
       " 'Days2Heading',\n",
       " 'Maturity_Date']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToDo: Add check for duplicate columns in the df\n",
    "\n",
    "base_indices\n",
    "\n",
    "spectral_indices_all \n",
    "\n",
    "drop_indices = ['EVI', 'GLI', 'MTCI']\n",
    "\n",
    "spectral_indices = [x for x in spectral_indices_all if x not in drop_indices]\n",
    "\n",
    "# Staur weather columns are all also present in Vollebekk weather so they can be use as general weather features\n",
    "weather_features = weather_cols_staur.copy()\n",
    "\n",
    "environment_var = weather_features + ['Staur_Env', 'Vollebekk_Env']\n",
    "\n",
    "yield_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674436a",
   "metadata": {},
   "source": [
    "# Dropping DF which donot have DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f4f1158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps\n",
      "Graminor_2019_Trapz\n",
      "Graminor_2020_Simps\n",
      "Graminor_2020_Trapz\n",
      "Masbasis_2019_Simps\n",
      "Masbasis_2019_Trapz\n",
      "Masbasis_2020_Simps\n",
      "Masbasis_2020_Trapz\n",
      "Robot_2020_Simps\n",
      "Robot_2020_Trapz\n",
      "Staur_2019_Simps\n",
      "Staur_2019_Trapz\n",
      "Staur_2020_Simps\n",
      "Staur_2020_Trapz\n"
     ]
    }
   ],
   "source": [
    "# Dropping unnecessary columns\n",
    "all_df_dm = []\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    if target_features[0] in temp_df.columns.tolist():\n",
    "        all_df_dm.append(df)\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f6f603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed83a0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Graminor_2019_Simps',\n",
       "  'Graminor_2020_Simps',\n",
       "  'Masbasis_2019_Simps',\n",
       "  'Masbasis_2020_Simps',\n",
       "  'Robot_2020_Simps',\n",
       "  'Staur_2019_Simps',\n",
       "  'Staur_2020_Simps'],\n",
       " ['Graminor_2019_Trapz',\n",
       "  'Graminor_2020_Trapz',\n",
       "  'Masbasis_2019_Trapz',\n",
       "  'Masbasis_2020_Trapz',\n",
       "  'Robot_2020_Trapz',\n",
       "  'Staur_2019_Trapz',\n",
       "  'Staur_2020_Trapz'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_simps = [x for x in all_df_dm if 'Simps' in x]\n",
    "all_df_trapz = [x for x in all_df_dm if 'Trapz' in x]\n",
    "all_df_simps, all_df_trapz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-gnome",
   "metadata": {},
   "source": [
    "# Dropping unnecessary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "robust-making",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:22.717032Z",
     "start_time": "2021-11-02T23:27:22.676436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps (600, 123) ==> (600, 118)\n",
      "Graminor_2019_Trapz (600, 123) ==> (600, 118)\n",
      "Graminor_2020_Simps (800, 123) ==> (800, 118)\n",
      "Graminor_2020_Trapz (800, 123) ==> (800, 118)\n",
      "Masbasis_2019_Simps (528, 124) ==> (528, 118)\n",
      "Masbasis_2019_Trapz (528, 124) ==> (528, 118)\n",
      "Masbasis_2020_Simps (659, 126) ==> (659, 118)\n",
      "Masbasis_2020_Trapz (659, 126) ==> (659, 118)\n",
      "Robot_2020_Simps (96, 125) ==> (96, 118)\n",
      "Robot_2020_Trapz (96, 125) ==> (96, 118)\n",
      "Staur_2019_Simps (1328, 127) ==> (1328, 118)\n",
      "Staur_2019_Trapz (1328, 127) ==> (1328, 118)\n",
      "Staur_2020_Simps (1504, 124) ==> (1504, 118)\n",
      "Staur_2020_Trapz (1504, 124) ==> (1504, 118)\n"
     ]
    }
   ],
   "source": [
    "# Dropping unnecessary columns\n",
    "\n",
    "for df in all_df_dm:\n",
    "    temp_df = locals()[df].copy()\n",
    "    locals()[df] = temp_df[base_indices+spectral_indices_all+environment_var+['Name',target_features[0]]]\n",
    "    print(df, temp_df.shape, '==>', locals()[df].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-replication",
   "metadata": {},
   "source": [
    "# Dealing with Nan values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-criminal",
   "metadata": {},
   "source": [
    "## Dropping Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sensitive-europe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:23.121179Z",
     "start_time": "2021-11-02T23:27:23.029598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  rows dropped in  Graminor_2019_Simps\n",
      "1  rows dropped in  Graminor_2019_Trapz\n",
      "1  rows dropped in  Graminor_2020_Simps\n",
      "1  rows dropped in  Graminor_2020_Trapz\n",
      "6  rows dropped in  Masbasis_2019_Simps\n",
      "6  rows dropped in  Masbasis_2019_Trapz\n",
      "116  rows dropped in  Masbasis_2020_Simps\n",
      "116  rows dropped in  Masbasis_2020_Trapz\n",
      "8  rows dropped in  Robot_2020_Simps\n",
      "8  rows dropped in  Robot_2020_Trapz\n",
      "0  rows dropped in  Staur_2019_Simps\n",
      "0  rows dropped in  Staur_2019_Trapz\n",
      "568  rows dropped in  Staur_2020_Simps\n",
      "568  rows dropped in  Staur_2020_Trapz\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with missing value in any column\n",
    "\n",
    "for df in all_df_dm:\n",
    "    temp_df = locals()[df].copy()\n",
    "    locals()[df] = temp_df.dropna(axis=0)\n",
    "    print(temp_df.shape[0] - locals()[df].shape[0], ' rows dropped in ', df)\n",
    "#     print(locals()[df].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-chambers",
   "metadata": {},
   "source": [
    "# Plot one index for different fields to check comparability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "surgical-newfoundland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:23.232318Z",
     "start_time": "2021-11-02T23:27:23.223343Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for col in base_indices+spectral_indices:\n",
    "# #     col='Blue'\n",
    "#     fig_size=(8, 5)\n",
    "#     fig, ax = plt.subplots(figsize=fig_size)\n",
    "#     plots = ax\n",
    "\n",
    "#     for df in all_df_simps:\n",
    "# #         if not 'Robot' in df and  not 'Staur' in df:\n",
    "# #         if 'Gram' in df and  'Masb' in df:\n",
    "# #             if '2020' in df:\n",
    "#         temp_df = locals()[df].copy()\n",
    "#         ax.boxplot(sorted(temp_df[col].values), positions = [all_df_simps.index(df)], labels=[df.split('_')[0][:5]+'_'+df.split('_')[1]])\n",
    "# #         ax.plot(sorted(temp_df[col].values), label=df.split('_')[0]+'_'+df.split('_')[1])\n",
    "#     # Printing the band/index name in plot of the fiels_sample for reference\n",
    "#     text = col\n",
    "#     ax.text(.95, .98, text, ha='center', va='top', weight=100, color='blue', fontsize ='xx-large', transform=ax.transAxes)\n",
    "\n",
    "#     ax.legend(loc=1)\n",
    "#     plt.tight_layout()\n",
    "# #     plt.savefig(export_path_comparability+col+'_box.jpg',dpi=250, bbox_inches='tight', transform=ax.transAxes)\n",
    "#     plt.show()\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "military-perth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:23.247543Z",
     "start_time": "2021-11-02T23:27:23.234315Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for col in base_indices+spectral_indices:\n",
    "# #     col='Blue'\n",
    "#     fig_size=(8, 5)\n",
    "#     fig, ax = plt.subplots(figsize=fig_size)\n",
    "#     plots = ax\n",
    "\n",
    "#     for df in all_df_simps:\n",
    "# #         if not 'Robot' in df and  not 'Staur' in df:\n",
    "# #         if 'Gram' in df and  'Masb' in df:\n",
    "# #             if '2020' in df:\n",
    "#         temp_df = locals()[df].copy()\n",
    "# #         ax.boxplot(sorted(temp_df[col].values), positions = [all_df_simps.index(df)], labels=[df.split('_')[0][:5]+'_'+df.split('_')[1]])\n",
    "#         ax.plot(sorted(temp_df[col].values), label=df.split('_')[0]+'_'+df.split('_')[1])\n",
    "#     # Printing the band/index name in plot of the fiels_sample for reference\n",
    "#     text = col\n",
    "#     ax.text(.87, .6, text, ha='center', va='top', weight=100, color='blue', fontsize ='xx-large', transform=ax.transAxes)\n",
    "\n",
    "#     ax.legend(loc=1)\n",
    "#     plt.tight_layout()\n",
    "# #     plt.savefig(export_path_comparability+col+'_sorted.jpg',dpi=250, bbox_inches='tight', transform=ax.transAxes)\n",
    "#     plt.show()\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "later-demonstration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:23.263501Z",
     "start_time": "2021-11-02T23:27:23.250536Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for col in base_indices+spectral_indices:\n",
    "# #     col='Blue'\n",
    "#     fig_size=(8, 5)\n",
    "#     fig, ax = plt.subplots(figsize=fig_size)\n",
    "#     plots = ax\n",
    "\n",
    "#     for df in all_df_simps:\n",
    "# #         if not 'Robot' in df and  not 'Staur' in df:\n",
    "# #         if 'Gram' in df and  'Masb' in df:\n",
    "# #             if '2020' in df:\n",
    "#         temp_df = locals()[df].copy()\n",
    "# #         ax.boxplot(sorted(temp_df[col].values), positions = [all_df_simps.index(df)], labels=[df.split('_')[0][:5]+'_'+df.split('_')[1]])\n",
    "#         ax.plot((temp_df[col].values), label=df.split('_')[0]+'_'+df.split('_')[1])\n",
    "#     # Printing the band/index name in plot of the fiels_sample for reference\n",
    "#     text = col\n",
    "#     ax.text(.87, .6, text, ha='center', va='top', weight=100, color='blue', fontsize ='xx-large', transform=ax.transAxes)\n",
    "\n",
    "#     ax.legend(loc=1)\n",
    "#     plt.tight_layout()\n",
    "# #     plt.savefig(export_path_comparability+col+'_random.jpg',dpi=250, bbox_inches='tight', transform=ax.transAxes)\n",
    "#     plt.show()\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-stereo",
   "metadata": {},
   "source": [
    "# Normalizing the data using Z-Score from scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "frequent-battery",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:23.615563Z",
     "start_time": "2021-11-02T23:27:23.431526Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps\n",
      "Graminor_2019_Trapz\n",
      "Graminor_2020_Simps\n",
      "Graminor_2020_Trapz\n",
      "Masbasis_2019_Simps\n",
      "Masbasis_2019_Trapz\n",
      "Masbasis_2020_Simps\n",
      "Masbasis_2020_Trapz\n",
      "Robot_2020_Simps\n",
      "Robot_2020_Trapz\n",
      "Staur_2019_Simps\n",
      "Staur_2019_Trapz\n",
      "Staur_2020_Simps\n",
      "Staur_2020_Trapz\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "for df in all_df_dm:\n",
    "    temp_df = locals()[df].copy()\n",
    "    for col in temp_df.columns:\n",
    "        # Checking if the column is not a yield column\n",
    "        if col not in yield_cols+environment_var:\n",
    "            temp_df[col] = zscore(temp_df[col])\n",
    "    locals()[df] = temp_df.copy()\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-neutral",
   "metadata": {},
   "source": [
    "# Checking comparability after normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "protective-polls",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:23.677639Z",
     "start_time": "2021-11-02T23:27:23.659569Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for col in base_indices+spectral_indices:\n",
    "# #     col='Blue'\n",
    "#     fig_size=(8, 5)\n",
    "#     fig, ax = plt.subplots(figsize=fig_size)\n",
    "#     plots = ax\n",
    "\n",
    "#     for df in all_df_simps:\n",
    "# #         if not 'Robot' in df and  not 'Staur' in df:\n",
    "# #         if 'Gram' in df and  'Masb' in df:\n",
    "# #             if '2020' in df:\n",
    "#         temp_df = locals()[df].copy()\n",
    "#         ax.boxplot(sorted(temp_df[col].values), positions = [all_df_simps.index(df)], labels=[df.split('_')[0][:5]+'_'+df.split('_')[1]])\n",
    "# #         ax.plot(sorted(temp_df[col].values), label=df.split('_')[0]+'_'+df.split('_')[1])\n",
    "#     # Printing the band/index name in plot of the fiels_sample for reference\n",
    "#     text = col\n",
    "#     ax.text(.87, .6, text, ha='center', va='top', weight=100, color='blue', fontsize ='xx-large', transform=ax.transAxes)\n",
    "\n",
    "#     ax.legend(loc=1)\n",
    "#     plt.tight_layout()\n",
    "# #     plt.savefig(export_path_comparability+col+'_box.jpg',dpi=250, bbox_inches='tight', transform=ax.transAxes)\n",
    "#     plt.show()\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-agency",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-fancy",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "injured-saying",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:24.094075Z",
     "start_time": "2021-11-02T23:27:24.080574Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for df in all_df_simps:\n",
    "#     temp_df = locals()[df][base_indices+spectral_indices+[target_features[0]]].copy()\n",
    "#     data = temp_df.copy()\n",
    "#     for col in base_indices:\n",
    "#         print(df)\n",
    "#         df_a = temp_df[col]\n",
    "#         df_b = temp_df[target_features[0]]\n",
    "\n",
    "\n",
    "#         fig, ax = plt.subplots(1, figsize=(12,8))\n",
    "#         sns.kdeplot(df_a, y=df_b, cmap='Blues',\n",
    "#                    shade=True, thresh=0.05, clip=(-1,300))\n",
    "#         plt.scatter(df_a, df_b, color='orangered')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-threshold",
   "metadata": {},
   "source": [
    "## Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "proprietary-farming",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:24.387122Z",
     "start_time": "2021-11-02T23:27:24.370168Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for df in all_df_simps:\n",
    "#     print(df)\n",
    "#     temp_df = locals()[df][[target_features[0]]+spectral_indices].copy()\n",
    "# #     temp_df = locals()[df][spectral_indices+[target_features[0]]].copy()\n",
    "#     data = temp_df\n",
    "#     columns = temp_df.columns\n",
    "#     corr = data.corr()\n",
    "#     fig_size=(15,8)\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=fig_size)\n",
    "    \n",
    "#     mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "    \n",
    "#     ax = sns.heatmap(\n",
    "#         corr, mask=mask,\n",
    "#         vmin=-1, vmax=1, center=0,\n",
    "#         cmap=sns.diverging_palette(20, 220, n=200),\n",
    "#         square=True\n",
    "#     )    \n",
    "    \n",
    "#     ax.set_xticklabels(\n",
    "#         ax.get_xticklabels(),\n",
    "#         rotation=45,\n",
    "#         horizontalalignment='right'\n",
    "#     );\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-nightmare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-boring",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T00:12:18.775023Z",
     "start_time": "2021-11-01T00:12:18.513720Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20dbcd75",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4318ac",
   "metadata": {},
   "source": [
    "## Declaring functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-myanmar",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "departmental-extension",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:25.381609Z",
     "start_time": "2021-11-02T23:27:25.358487Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "\n",
    "def save_results(model, agg_method, train_field, test_field,\n",
    "                 training_features, importances, RMSE_test,\n",
    "                 RMSE_train, R2_test, R2_train, GKF_CV):\n",
    "\n",
    "    date_time = dt.now()\n",
    "    train_feat = []\n",
    "    if set(spectral_indices_all) <= set(training_features):\n",
    "        train_feat.append('spectral_indices_all')\n",
    "    elif set(spectral_indices) <= set(training_features):\n",
    "        train_feat.append('spectral_indices_select')\n",
    "    if set(weather_features) <= set(training_features):\n",
    "        train_feat.append('weather_features')\n",
    "    if set(base_indices) <= set(training_features):\n",
    "        train_feat.append('base_indices')\n",
    "    if set(['Staur_Env', 'Vollebekk_Env']) <= set(training_features):\n",
    "        train_feat.append('Environment_feature')\n",
    "        \n",
    "    results = {'Model': model,\n",
    "               'Aggregation_method': agg_method,\n",
    "               'Train_field': train_field,\n",
    "               'Test_field': test_field,\n",
    "               'Training_features': train_feat,\n",
    "               'Feature_Importances': importances,\n",
    "               'RMSE_test': RMSE_test,\n",
    "               'RMSE_train': RMSE_train,\n",
    "               'R2_test': R2_test,\n",
    "               'R2_train': R2_train,\n",
    "               'GKF_CV': GKF_CV,\n",
    "               'DataTime': date_time}\n",
    "\n",
    "    filename = export_path + 'results_org.csv'\n",
    "\n",
    "    with open(filename, \"a+\") as csvfile:\n",
    "        headers = results.keys()\n",
    "        writer = csv.DictWriter(csvfile, delimiter=',',\n",
    "                                lineterminator='\\n', fieldnames=headers)\n",
    "\n",
    "        # Check is the file is empty or not\n",
    "        fileEmpty = os.stat(filename).st_size == 0\n",
    "        # If empty, then add header\n",
    "        if fileEmpty:\n",
    "            writer.writeheader()  # file doesn't exist yet, write a header\n",
    "\n",
    "        # Write the current data as next row\n",
    "        writer.writerow(results)\n",
    "    del(results, date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb501a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "def save_grid_results(list_zip):\n",
    "    list_zip_list = list(list_zip[0])\n",
    "    \n",
    "    # Appending None entries to list to makeup for missing parameters\n",
    "    while len(list_zip_list)<14:\n",
    "        list_zip_list.append(None)\n",
    "    \n",
    "    model = list_zip_list[0]\n",
    "    pipe = list_zip_list[1]\n",
    "    train_score = list_zip_list[2]\n",
    "    test_score = list_zip_list[3]\n",
    "    p1 = list_zip_list[4]\n",
    "    p2 = list_zip_list[5]\n",
    "    p3 = list_zip_list[6]\n",
    "    p4 = list_zip_list[7]\n",
    "    p5 = list_zip_list[8]\n",
    "    p6 = list_zip_list[9]\n",
    "    p7 = list_zip_list[10]\n",
    "    p8 = list_zip_list[11]\n",
    "    p9 = list_zip_list[12]\n",
    "    p10 = list_zip_list[13]\n",
    "\n",
    "    train_feat = []\n",
    "    if set(spectral_indices_all) <= set(training_features):\n",
    "        train_feat.append('spectral_indices_all')\n",
    "    elif set(spectral_indices) <= set(training_features):\n",
    "        train_feat.append('spectral_indices_select')\n",
    "    if set(weather_features) <= set(training_features):\n",
    "        train_feat.append('weather_features')\n",
    "    if set(base_indices) <= set(training_features):\n",
    "        train_feat.append('base_indices')\n",
    "    if set(['Staur_Env', 'Vollebekk_Env']) <= set(training_features):\n",
    "        train_feat.append('Environment_feature')\n",
    "        \n",
    "    date_time = dt.now()\n",
    "        \n",
    "    results = {'Model': model,\n",
    "               'Pipeline': pipe,\n",
    "               'Train_score': train_score,\n",
    "               'Test_score': test_score,\n",
    "               'Parameter_1': p1,\n",
    "               'Parameter_2': p2,\n",
    "               'Parameter_3': p3,\n",
    "               'Parameter_4': p4,\n",
    "               'Parameter_5': p5,\n",
    "               'Parameter_6': p6,\n",
    "               'Parameter_7': p7,\n",
    "               'Parameter_8': p8,\n",
    "               'Parameter_9': p9,\n",
    "               'Parameter_10': p10,\n",
    "               'Aggregation_method': agg_method,\n",
    "               'Training_features': train_feat,\n",
    "               'DataTime': date_time}\n",
    "\n",
    "    filename = export_path + 'results_loop_org.csv'\n",
    "\n",
    "    with open(filename, \"a+\") as csvfile:\n",
    "        headers = results.keys()\n",
    "        writer = csv.DictWriter(csvfile, delimiter=',',\n",
    "                                lineterminator='\\n', fieldnames=headers)\n",
    "\n",
    "        # Check is the file is empty or not\n",
    "        fileEmpty = os.stat(filename).st_size == 0\n",
    "        # If empty, then add header\n",
    "        if fileEmpty:\n",
    "            writer.writeheader()  # file doesn't exist yet, write a header\n",
    "\n",
    "        # Write the current data as next row\n",
    "        writer.writerow(results)\n",
    "    del(results, date_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-barrel",
   "metadata": {},
   "source": [
    "### list_test_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "proud-mexican",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:25.588662Z",
     "start_time": "2021-11-02T23:27:25.578689Z"
    }
   },
   "outputs": [],
   "source": [
    "def list_test_train_df(all_df_, train_field, test_field, year):\n",
    "    # Returns a string list of train dfs and test dfs. Not conct\n",
    "    # Need to be conct afterwards\n",
    "    \n",
    "    # year = '2019', '2020', 'all' str\n",
    "#     train_field = 'Vollebekk' , 'Staur'\n",
    "#     test_field = 'Vollebekk' , 'Staur'\n",
    "\n",
    "    # Asserting if the user has given the right inputs\n",
    "    assert train_field != test_field\n",
    "    assert train_field == 'Vollebekk' or train_field == 'Staur'\n",
    "    assert test_field == 'Vollebekk' or test_field == 'Staur'\n",
    "    assert year == '2019' or year == '2020' or year == 'all'\n",
    "\n",
    "    # Filtering based on year\n",
    "    all_df_temp1 = [x for x in all_df_ if not 'Robot' in x]\n",
    "    if not year == 'all':\n",
    "        all_df_temp = [x for x in all_df_temp1 if year in x]\n",
    "    else:\n",
    "        all_df_temp = all_df_temp1.copy()\n",
    "        \n",
    "    # Making list of training dfs for conct before training\n",
    "    staur_df_list = []\n",
    "    staur_list = []\n",
    "    for x in all_df_temp:\n",
    "        if 'Staur' in x:\n",
    "            staur_list.append(x)\n",
    "#             staur_df_list.append(locals()[x])\n",
    "\n",
    "    # Making list of test dfs for conct before training\n",
    "    vollebekk_df_list = []\n",
    "    vollebekk_list = []\n",
    "    for x in all_df_temp:\n",
    "        if not 'Staur' in x and not 'Robot' in x:\n",
    "            vollebekk_list.append(x)\n",
    "#             vollebekk_df_list.append(locals()[x])\n",
    "    \n",
    "    train_df_list = []\n",
    "    train_str_list = []\n",
    "    test_df_list = []\n",
    "    test_str_list = []\n",
    "    # Assigning test and train sets based on given inputs\n",
    "    if train_field == 'Staur':\n",
    "#         train_df_list = staur_df_list.copy()\n",
    "        train_str_list = staur_list.copy()\n",
    "        print('Training data:', staur_list)\n",
    "        \n",
    "#         test_df_list = vollebekk_df_list.copy()\n",
    "        test_str_list = vollebekk_list.copy()\n",
    "        print('Test data:', vollebekk_list)\n",
    "    elif train_field == 'Vollebekk':\n",
    "#         train_df_list = vollebekk_df_list.copy()\n",
    "        train_str_list = vollebekk_list.copy()\n",
    "        print('Training data:', vollebekk_list)\n",
    "        \n",
    "#         test_df_list = staur_df_list.copy()\n",
    "        test_str_list = staur_list.copy()\n",
    "        print('Test data:', staur_list)\n",
    "    else:\n",
    "        raise NameError\n",
    "    \n",
    "    return (train_str_list, test_str_list)\n",
    "    del (all_df_temp1, all_df_temp, staur_df_list, staur_list, vollebekk_df_list, vollebekk_list, train_df_list, train_str_list, test_df_list, test_str_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-replication",
   "metadata": {},
   "source": [
    "### data_prep_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "choice-editor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:25.793321Z",
     "start_time": "2021-11-02T23:27:25.770385Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_prep_field(all_df_, train_field = ['Staur', 'Masbasis'], test_field = ['Staur', 'Masbasis'], \n",
    "#                 year_train = ['2019', 2020], year_test = ['2019', 2020]):\n",
    "\n",
    "def data_prep_field(all_df_, train_field, test_field, year):\n",
    "    \n",
    "    # year = '2019', '2020', 'all' str\n",
    "#     train_field = 'Vollebekk' , 'Staur'\n",
    "#     test_field = 'Vollebekk' , 'Staur'\n",
    "\n",
    "    # Asserting if the user has given the right inputs\n",
    "    assert train_field != test_field\n",
    "    assert train_field == 'Vollebekk' or train_field == 'Staur'\n",
    "    assert test_field == 'Vollebekk' or test_field == 'Staur'\n",
    "    assert year == '2019' or year == '2020' or year == 'all'\n",
    "\n",
    "    # Filtering based on year\n",
    "    all_df_temp1 = [x for x in all_df_ if not 'Robot' in x]\n",
    "    if not year == 'all':\n",
    "        all_df_temp = [x for x in all_df_temp1 if year in x]\n",
    "    else:\n",
    "        all_df_temp = all_df_temp1.copy()\n",
    "        \n",
    "    # Making list of training dfs for conct before training\n",
    "    staur_df_list = []\n",
    "    staur_list = []\n",
    "    print(all_df_temp)\n",
    "    for x in all_df_temp:\n",
    "        if 'Staur' in x:\n",
    "            staur_list.append(x)\n",
    "            print(staur_list)\n",
    "#             staur_df_list.append(locals()[x])\n",
    "\n",
    "    # Making list of test dfs for conct before training\n",
    "    vollebekk_df_list = []\n",
    "    vollebekk_list = []\n",
    "    for x in all_df_temp:\n",
    "        if not 'Staur' in x and not 'Robot' in x:\n",
    "            vollebekk_list.append(x)\n",
    "#             vollebekk_df_list.append(locals()[x])\n",
    "    \n",
    "    # Assigning test and train sets based on given inputs\n",
    "    if train_field == 'Staur':\n",
    "        train_df_list = staur_df_list.copy()\n",
    "        print('Training data:', staur_list)\n",
    "        \n",
    "        test_df_list = vollebekk_df_list.copy()\n",
    "        print('Test data:', vollebekk_list)\n",
    "    elif train_field == 'Vollebekk':\n",
    "        train_df_list = vollebekk_df_list.copy()\n",
    "        print('Training data:', vollebekk_list)\n",
    "        \n",
    "        test_df_list = staur_df_list.copy()\n",
    "        print('Test data:', staur_list)\n",
    "    else:\n",
    "        raise NameError\n",
    "        \n",
    "    train_df = pd.concat(train_df_list)\n",
    "    test_df = pd.concat(test_df_list)\n",
    "\n",
    "    X_train = train_df[training_features]\n",
    "    y_train = train_df[target_features].values.ravel()\n",
    "    X_test = test_df[training_features]\n",
    "    y_test = test_df[target_features].values.ravel()\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-metallic",
   "metadata": {},
   "source": [
    "### training_gkf_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "accessory-sellers",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T16:24:16.932594Z",
     "start_time": "2021-11-03T16:24:16.911652Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_gkf_std(model, X, y, gkf):\n",
    "    \n",
    "    current_model = make_pipeline(StandardScaler(), model)\n",
    "#     current_model = make_pipeline(model)\n",
    "\n",
    "    scores = cross_validate(current_model, X, y, cv=gkf,\n",
    "                            scoring=('r2', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True)\n",
    "#     RMSE_test = \"%0.2f (+/- %0.2f)\" % (-1*scores['test_neg_root_mean_squared_error'].mean(), \n",
    "#                                   -1*scores['test_neg_root_mean_squared_error'].std() * 2)\n",
    "#     RMSE_train = \"%0.2f (+/- %0.2f)\" % (-1*scores['train_neg_root_mean_squared_error'].mean(), \n",
    "#                                   -1*scores['train_neg_root_mean_squared_error'].std() * 2)\n",
    "\n",
    "\n",
    "#     R2_test = \"%0.2f (+/- %0.2f)\" % (scores['test_r2'].mean(), \n",
    "#                                   scores['test_r2'].std() * 2)\n",
    "#     R2_train = \"%0.2f (+/- %0.2f)\" % (scores['train_r2'].mean(), \n",
    "#                                   scores['train_r2'].std() * 2)\n",
    "\n",
    "    RMSE_test = \"%0.2f\" % (-1*scores['test_neg_root_mean_squared_error'].mean())\n",
    "    RMSE_train = \"%0.2f\" % (-1*scores['train_neg_root_mean_squared_error'].mean())\n",
    "\n",
    "\n",
    "    R2_test = \"%0.2f\" % (scores['test_r2'].mean())\n",
    "    R2_train = \"%0.2f\" % (scores['train_r2'].mean())\n",
    "    \n",
    "    print(str(model).split('()')[0])\n",
    "    print(current_model)\n",
    "    print(' RMSE Test:', RMSE_test, '       R2 Test:', R2_test)\n",
    "    print('RMSE Train:', RMSE_train, '      R2 Train:', R2_train)\n",
    "    \n",
    "    # Feature importance\n",
    "    current_model.fit(X, y)\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            feature_importance = current_model.steps[1][1].feature_importances_\n",
    "            success = True\n",
    "        except:\n",
    "            feature_importance = None\n",
    "            pass\n",
    "\n",
    "    # Saving results\n",
    "    GKF_CV = gkf\n",
    "    return feature_importance, RMSE_test, RMSE_train, R2_test, R2_train, GKF_CV\n",
    "    del(current_model, scores, feature_importance, success, RMSE_test, RMSE_train, R2_test, R2_train, GKF_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-relationship",
   "metadata": {},
   "source": [
    "### training_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hundred-progressive",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T16:24:23.677719Z",
     "start_time": "2021-11-03T16:24:23.661762Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_regr(model, X_train, y_train, X_test, y_test):\n",
    "    current_model = make_pipeline(StandardScaler(), model)\n",
    "#     current_model = make_pipeline(model)\n",
    "\n",
    "    current_model.fit(X_train, y_train)\n",
    "    y_pred_train = current_model.predict(X_train)\n",
    "    y_pred = current_model.predict(X_test)\n",
    "    \n",
    "    RMSE_test = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    RMSE_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "\n",
    "\n",
    "    R2_test = r2_score(y_test, y_pred)\n",
    "    R2_train = r2_score(y_train, y_pred_train)\n",
    "    \n",
    "    print(str(model).split('()')[0])\n",
    "    print(current_model)\n",
    "    print(' RMSE Test:', RMSE_test, '       R2 Test:', R2_test)\n",
    "    print('RMSE Train:', RMSE_train, '      R2 Train:', R2_train)\n",
    "\n",
    "    # Feature importance\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            feature_importance = current_model.steps[1][1].feature_importances_\n",
    "            success = True\n",
    "        except:\n",
    "            feature_importance = None\n",
    "            pass\n",
    "\n",
    "    GKF_CV = False\n",
    "    \n",
    "    return feature_importance, RMSE_test, RMSE_train, R2_test, R2_train, GKF_CV\n",
    "    del(current_model, y_pred_train, y_pred, feature_importance, success, RMSE_test, RMSE_train, R2_test, R2_train, GKF_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-columbus",
   "metadata": {},
   "source": [
    "### Plot Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "altered-inspiration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:26.728417Z",
     "start_time": "2021-11-02T23:27:26.715454Z"
    }
   },
   "outputs": [],
   "source": [
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# # Create plots folder if not exists already\n",
    "# os.makedirs(plots_export_path, exist_ok=True)\n",
    "\n",
    "# pdf = PdfPages(plots_export_path+'feat_imp.pdf')\n",
    "\n",
    "def plot_feat_imp(feature_importance, model, train_feat, threshold='all', sort_feat=True):\n",
    "    # threshold =  percentage of max(features_importance) or 'all' or top_x number of features\n",
    "    # Plotting feature importance\n",
    "    # Create arrays from feature importance and feature names\n",
    "\n",
    "    feature_names = train_feat.copy()\n",
    "    model_name =  str(model).split('(')[0]\n",
    "    \n",
    "    # Default threshold is 0, i.e. use all features\n",
    "    thres = 0\n",
    "\n",
    "    # Selecting features based on given threshold\n",
    "    if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "        thres = threshold * 0.01\n",
    "    elif str.lower(threshold) == 'all':\n",
    "        thres = 0\n",
    "\n",
    "    importances, names = zip(*(\n",
    "        (x, y) for x, y in zip(feature_importance, feature_names) if x >= thres*max(feature_importance)))\n",
    "    \n",
    "    # Finding and filtering top_x number of features\n",
    "    if isinstance(threshold, str):\n",
    "        if str.lower(threshold.split('_')[0]) == 'top':\n",
    "            top_x_feat = int(threshold.split('_')[1])\n",
    "            sort_imp, sorted_name = zip(*sorted(zip(feature_importance, feature_names), reverse=True))\n",
    "\n",
    "            importances, names = zip(*(\n",
    "                (x, y) for x, y in zip(feature_importance, feature_names) if y in sorted_name[:top_x_feat]))  \n",
    "    \n",
    "    # Sorting faeture importances if required\n",
    "    if sort_feat:\n",
    "        importances, names = zip(*sorted(zip(importances, names), reverse=True))\n",
    "\n",
    "    # Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':names,'feature_importance':importances}\n",
    "    feat_imp_df = pd.DataFrame(data)\n",
    "\n",
    "    # Sort the DataFrame in order decreasing feature importance\n",
    "#     feat_imp_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,5))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(y=feat_imp_df['feature_importance'], x=feat_imp_df['feature_names'], palette = 'winter'  )\n",
    "    #Add chart labels\n",
    "\n",
    "    plt.title(model_name + ' Feature Importance')\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.xlabel('Feature Names')\n",
    "    plt.ylabel('Feature Importance')\n",
    "    export_plots = export_path+'/Feature_Importance/'\n",
    "    os.makedirs(export_plots, exist_ok=True)\n",
    "#     plt.savefig(export_plots+'feature_importance'+model_name+'.jpg',dpi=150, bbox_inches='tight')\n",
    "#     plt.savefig(export_plots+col+feature_importance_'+model_name+'.pdf',dpi=500, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-flush",
   "metadata": {},
   "source": [
    "### Grid Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "least-triple",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:29:25.588097Z",
     "start_time": "2021-11-02T23:29:25.570300Z"
    }
   },
   "outputs": [],
   "source": [
    "def grid(Xtrain,\n",
    "         ytrain,\n",
    "         estimator,\n",
    "         params_grid,\n",
    "         scores,\n",
    "         cvs,\n",
    "         cores,\n",
    "         verb):\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    gs = GridSearchCV(estimator=estimator,\n",
    "                      param_grid=params_grid,\n",
    "                      scoring=scores,\n",
    "                      cv=cvs,\n",
    "                      n_jobs=cores,\n",
    "                      verbose=verb,\n",
    "                     return_train_score=True)\n",
    "\n",
    "    gs = gs.fit(Xtrain, ytrain)\n",
    "    print(estimator)\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    \n",
    "    t2 = time.time()\n",
    "\n",
    "    # Saving results to csv file\n",
    "    results = []\n",
    "    import datetime\n",
    "    datetime = datetime.datetime.now()\n",
    "\n",
    "    results.append((np.array((gs.best_estimator_, gs, score, gs.best_score_, gs.best_params_, \n",
    "                              gs.cv_results_['mean_train_score'].mean(),\n",
    "                             ((t2 - t1) / 60), datetime), dtype=object)))\n",
    "\n",
    "    pd.DataFrame(np.asarray(results)).to_csv(export_path+'results_grid.csv',\n",
    "                                             mode='a',\n",
    "                                             header=None)\n",
    "\n",
    "    print('Total time: ', (t2 - t1) / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-amplifier",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T00:29:29.251040Z",
     "start_time": "2021-10-14T00:29:29.236082Z"
    }
   },
   "source": [
    "## CPU Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bd85b6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:27.150567Z",
     "start_time": "2021-11-02T23:27:27.138598Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_version: 3.8.8.final.0 (64 bit)\n",
      "X86_64\n",
      "64\n",
      "8\n",
      "AMD64\n",
      "GenuineIntel\n",
      "Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz\n",
      "1.8000 GHz\n"
     ]
    }
   ],
   "source": [
    "# Number of cores in the system being used\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()\n",
    "\n",
    "import psutil\n",
    "psutil.cpu_count()\n",
    "\n",
    "import cpuinfo\n",
    "info = cpuinfo.get_cpu_info()\n",
    "print('python_version:', info['python_version'])\n",
    "print(info['arch'])\n",
    "print(info['bits'])\n",
    "print(info['count'])\n",
    "print(info['arch_string_raw'])\n",
    "print(info['vendor_id_raw'])\n",
    "print(info['brand_raw'])\n",
    "print(info['hz_advertised_friendly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f52b7",
   "metadata": {},
   "source": [
    "# ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c738348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:27.490830Z",
     "start_time": "2021-11-02T23:27:27.345541Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# import xgboost as xgb\n",
    "from sklearn.linear_model import Lasso\n",
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-implementation",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wanted-polymer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:27.584280Z",
     "start_time": "2021-11-02T23:27:27.568089Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold_all = 'top_25'\n",
    "sorted_all = True\n",
    "agg_method = 'Simpsons'\n",
    "# agg_method = 'Trapezoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a1923d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T23:27:27.599240Z",
     "start_time": "2021-11-02T23:27:27.586275Z"
    }
   },
   "outputs": [],
   "source": [
    "# training_features = base_indices + spectral_indices + environment_var\n",
    "# training_features = base_indices + spectral_indices + weather_features\n",
    "training_features =  spectral_indices + weather_features\n",
    "# training_features = spectral_indices\n",
    "\n",
    "target_features\n",
    "\n",
    "group_feature = ['Name']\n",
    "\n",
    "if agg_method == 'Simpsons':\n",
    "    all_df_now = all_df_simps.copy()\n",
    "elif agg_method == 'Trapezoid': \n",
    "    all_df_now = all_df_trapz.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-massage",
   "metadata": {},
   "source": [
    "## Fine Tuning the models using all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9bf2a2",
   "metadata": {},
   "source": [
    "### All data mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11d2823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = [x for x in all_df_now if not 'Robot' in x]\n",
    "\n",
    "# Making list of df for conct before training\n",
    "# This is different form list of srtings, as this is a list of actual dataframes\n",
    "df_list = []\n",
    "for x in temp_list:\n",
    "    df_list.append(locals()[x])\n",
    "\n",
    "# Conct all df to one df    \n",
    "df_ = pd.concat(df_list).reset_index(drop=True)\n",
    "\n",
    "# Shuffeling all the items/rows\n",
    "df_shuffle = df_.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "X = df_shuffle[training_features+['Name']]\n",
    "y = df_shuffle[target_features].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "groups = X_train[group_feature].values.ravel()\n",
    "\n",
    "X_train = X_train.drop(['Name'], axis=1).values\n",
    "X_test = X_test.drop(['Name'], axis=1).values\n",
    "\n",
    "gkf = list(GroupKFold(n_splits=6).split(X_train, y_train, groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-africa",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "turned-attention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T12:08:22.767054Z",
     "start_time": "2021-11-03T12:07:02.768422Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model RandomForestRegressor(random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:08<00:17,  8.86s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.959260288004484       R2 Test: 0.7172316788816002\n",
      "Training model RandomForestRegressor(min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:16<00:08,  8.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397811411162491       R2 Test: 0.7179341678005173\n",
      "Training model RandomForestRegressor(min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:23<00:00,  7.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:23<00:46, 23.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:08<00:17,  8.51s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462111686263817       R2 Test: 0.7153818218316459\n",
      "Training model RandomForestRegressor(min_samples_leaf=2, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:15<00:07,  7.55s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347201457412546       R2 Test: 0.717559598496077\n",
      "Training model RandomForestRegressor(min_samples_leaf=4, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:21<00:00,  7.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:44<00:22, 22.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.90s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(min_samples_leaf=2, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.61s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(min_samples_leaf=4, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.39s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:03<00:00, 21.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|                                                                            | 1/12 [01:03<11:43, 63.99s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_depth=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:05<00:11,  5.76s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8950176146339593       R2 Test: 0.7166952669570572\n",
      "Training model RandomForestRegressor(max_depth=10, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:11<00:05,  5.57s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.886539144226953       R2 Test: 0.7168680962616141\n",
      "Training model RandomForestRegressor(max_depth=10, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:16<00:00,  5.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:16<00:33, 16.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8656857547670985       R2 Test: 0.7168114603295719\n",
      "Training model RandomForestRegressor(max_depth=10, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:05<00:11,  5.51s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8882185978918709       R2 Test: 0.7152273965483388\n",
      "Training model RandomForestRegressor(max_depth=10, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:11<00:05,  5.65s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8839477244321633       R2 Test: 0.7163228476668793\n",
      "Training model RandomForestRegressor(max_depth=10, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:16<00:00,  5.65s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:33<00:16, 16.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8656857547670985       R2 Test: 0.7168114603295719\n",
      "Training model RandomForestRegressor(max_depth=10, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:05<00:10,  5.35s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8735704012896085       R2 Test: 0.7144614164691444\n",
      "Training model RandomForestRegressor(max_depth=10, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:10<00:05,  5.28s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8689905268118749       R2 Test: 0.7153834992378605\n",
      "Training model RandomForestRegressor(max_depth=10, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:15<00:00,  5.26s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:49<00:00, 16.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|                                                                     | 2/12 [01:53<09:13, 55.33s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8604733089502605       R2 Test: 0.7168826488391623\n",
      "Training model RandomForestRegressor(max_depth=20, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:15,  7.87s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9588855972829446       R2 Test: 0.7167758476698444\n",
      "Training model RandomForestRegressor(max_depth=20, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:14<00:07,  7.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9395615692017911       R2 Test: 0.7185729467572217\n",
      "Training model RandomForestRegressor(max_depth=20, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.81s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:20<00:40, 20.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.899164222377695       R2 Test: 0.7182961306691951\n",
      "Training model RandomForestRegressor(max_depth=20, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.83s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9459708083778462       R2 Test: 0.7158837831136503\n",
      "Training model RandomForestRegressor(max_depth=20, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.78s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.934462056804162       R2 Test: 0.7177461631883552\n",
      "Training model RandomForestRegressor(max_depth=20, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:39<00:19, 19.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.899164222377695       R2 Test: 0.7182961306691951\n",
      "Training model RandomForestRegressor(max_depth=20, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.60s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9181682167225743       R2 Test: 0.7157104151069877\n",
      "Training model RandomForestRegressor(max_depth=20, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.48s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9077969486464232       R2 Test: 0.7167888588485711\n",
      "Training model RandomForestRegressor(max_depth=20, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:58<00:00, 19.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|                                                              | 3/12 [02:51<08:31, 56.86s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903581541018448       R2 Test: 0.718178842080998\n",
      "Training model RandomForestRegressor(max_depth=30, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:15,  7.61s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9592604097510106       R2 Test: 0.7173347851760185\n",
      "Training model RandomForestRegressor(max_depth=30, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:14<00:07,  7.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397803155739511       R2 Test: 0.7178677749960254\n",
      "Training model RandomForestRegressor(max_depth=30, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.73s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:20<00:40, 20.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=30, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.84s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462118762198027       R2 Test: 0.7153522472452893\n",
      "Training model RandomForestRegressor(max_depth=30, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.78s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347222399213717       R2 Test: 0.717554484717462\n",
      "Training model RandomForestRegressor(max_depth=30, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:40<00:20, 20.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=30, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.71s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(max_depth=30, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.92s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(max_depth=30, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.57s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [01:00<00:00, 20.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|                                                       | 4/12 [03:52<07:46, 58.28s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_depth=40, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:15,  7.92s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.959260288004484       R2 Test: 0.7172316788816002\n",
      "Training model RandomForestRegressor(max_depth=40, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:14<00:07,  7.24s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397811411162491       R2 Test: 0.7179341678005173\n",
      "Training model RandomForestRegressor(max_depth=40, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.86s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:20<00:41, 20.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=40, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.87s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462111686263817       R2 Test: 0.7153818218316459\n",
      "Training model RandomForestRegressor(max_depth=40, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.71s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347201457412546       R2 Test: 0.717559598496077\n",
      "Training model RandomForestRegressor(max_depth=40, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.55s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:40<00:20, 20.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=40, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:12,  6.31s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(max_depth=40, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:12<00:06,  6.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(max_depth=40, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:58<00:00, 19.62s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|                                                | 5/12 [04:51<06:49, 58.48s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_depth=50, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:08<00:16,  8.12s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.959260288004484       R2 Test: 0.7172316788816002\n",
      "Training model RandomForestRegressor(max_depth=50, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:15<00:07,  7.56s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397811411162491       R2 Test: 0.7179341678005173\n",
      "Training model RandomForestRegressor(max_depth=50, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:21<00:00,  7.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:21<00:42, 21.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=50, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.79s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462111686263817       R2 Test: 0.7153818218316459\n",
      "Training model RandomForestRegressor(max_depth=50, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.78s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347201457412546       R2 Test: 0.717559598496077\n",
      "Training model RandomForestRegressor(max_depth=50, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.54s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:40<00:20, 20.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=50, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:12,  6.32s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(max_depth=50, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:12<00:06,  6.12s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(max_depth=50, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:17<00:00,  5.99s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:58<00:00, 19.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|                                         | 6/12 [05:50<05:51, 58.63s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_depth=60, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:08<00:16,  8.29s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.959260288004484       R2 Test: 0.7172316788816002\n",
      "Training model RandomForestRegressor(max_depth=60, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:15<00:07,  7.44s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397811411162491       R2 Test: 0.7179341678005173\n",
      "Training model RandomForestRegressor(max_depth=60, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:21<00:00,  7.08s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:21<00:42, 21.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=60, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.81s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462111686263817       R2 Test: 0.7153818218316459\n",
      "Training model RandomForestRegressor(max_depth=60, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.61s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347201457412546       R2 Test: 0.717559598496077\n",
      "Training model RandomForestRegressor(max_depth=60, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:40<00:20, 20.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=60, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:12,  6.27s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(max_depth=60, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:12<00:06,  6.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(max_depth=60, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.02s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:58<00:00, 19.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|                                  | 7/12 [06:48<04:53, 58.68s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_depth=70, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:15,  7.65s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.959260288004484       R2 Test: 0.7172316788816002\n",
      "Training model RandomForestRegressor(max_depth=70, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:14<00:07,  7.24s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397811411162491       R2 Test: 0.7179341678005173\n",
      "Training model RandomForestRegressor(max_depth=70, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.93s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:20<00:41, 20.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=70, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.89s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462111686263817       R2 Test: 0.7153818218316459\n",
      "Training model RandomForestRegressor(max_depth=70, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.72s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347201457412546       R2 Test: 0.717559598496077\n",
      "Training model RandomForestRegressor(max_depth=70, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.55s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:40<00:20, 20.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=70, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:12,  6.23s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(max_depth=70, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:12<00:06,  6.13s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(max_depth=70, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:17<00:00,  5.99s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:58<00:00, 19.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|                           | 8/12 [07:47<03:54, 58.59s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_depth=80, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:15,  7.68s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.959260288004484       R2 Test: 0.7172316788816002\n",
      "Training model RandomForestRegressor(max_depth=80, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:14<00:07,  7.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397811411162491       R2 Test: 0.7179341678005173\n",
      "Training model RandomForestRegressor(max_depth=80, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.96s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:20<00:41, 20.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=80, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:14,  7.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462111686263817       R2 Test: 0.7153818218316459\n",
      "Training model RandomForestRegressor(max_depth=80, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.76s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347201457412546       R2 Test: 0.717559598496077\n",
      "Training model RandomForestRegressor(max_depth=80, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.57s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:40<00:20, 20.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=80, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:12,  6.25s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(max_depth=80, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:12<00:06,  6.51s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(max_depth=80, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.36s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:59<00:00, 19.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|                    | 9/12 [08:47<02:56, 58.93s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_depth=90, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:15,  7.75s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.959260288004484       R2 Test: 0.7172316788816002\n",
      "Training model RandomForestRegressor(max_depth=90, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:14<00:07,  7.10s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397811411162491       R2 Test: 0.7179341678005173\n",
      "Training model RandomForestRegressor(max_depth=90, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:20<00:40, 20.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=90, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:14,  7.37s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462111686263817       R2 Test: 0.7153818218316459\n",
      "Training model RandomForestRegressor(max_depth=90, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:14<00:07,  7.02s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347201457412546       R2 Test: 0.717559598496077\n",
      "Training model RandomForestRegressor(max_depth=90, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.84s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:40<00:20, 20.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=90, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:12,  6.28s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(max_depth=90, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:12<00:06,  6.16s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(max_depth=90, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.02s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:58<00:00, 19.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|             | 10/12 [09:45<01:57, 58.92s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_depth=100, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:15,  7.65s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.959260288004484       R2 Test: 0.7172316788816002\n",
      "Training model RandomForestRegressor(max_depth=100, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:14<00:07,  7.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397811411162491       R2 Test: 0.7179341678005173\n",
      "Training model RandomForestRegressor(max_depth=100, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.75s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:20<00:40, 20.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=100, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.75s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462111686263817       R2 Test: 0.7153818218316459\n",
      "Training model RandomForestRegressor(max_depth=100, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.86s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347201457412546       R2 Test: 0.717559598496077\n",
      "Training model RandomForestRegressor(max_depth=100, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.70s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:40<00:20, 20.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=100, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:12,  6.49s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(max_depth=100, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:12<00:06,  6.29s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(max_depth=100, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.12s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:58<00:00, 19.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|      | 11/12 [10:44<00:58, 58.86s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_depth=110, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:15,  7.62s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.959260288004484       R2 Test: 0.7172316788816002\n",
      "Training model RandomForestRegressor(max_depth=110, min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:14<00:07,  7.07s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9397811411162491       R2 Test: 0.7179341678005173\n",
      "Training model RandomForestRegressor(max_depth=110, min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:20<00:00,  6.70s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:20<00:40, 20.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=110, min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:07<00:14,  7.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9462111686263817       R2 Test: 0.7153818218316459\n",
      "Training model RandomForestRegressor(max_depth=110, min_samples_leaf=2, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:13<00:06,  6.70s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9347201457412546       R2 Test: 0.717559598496077\n",
      "Training model RandomForestRegressor(max_depth=110, min_samples_leaf=4, min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:19<00:00,  6.52s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:39<00:19, 19.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8992233782506613       R2 Test: 0.7182436262425013\n",
      "Training model RandomForestRegressor(max_depth=110, min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:06<00:13,  6.93s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9183187360646867       R2 Test: 0.715039274701178\n",
      "Training model RandomForestRegressor(max_depth=110, min_samples_leaf=2, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:12<00:06,  6.41s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9079368589384953       R2 Test: 0.7165426639367254\n",
      "Training model RandomForestRegressor(max_depth=110, min_samples_leaf=4, min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:18<00:00,  6.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:58<00:00, 19.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 12/12 [11:43<00:00, 58.59s/it]\u001b[A\n",
      " 50%|                                         | 1/2 [11:43<11:43, 703.02s/it]\n",
      "  0%|                                                                                           | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8904098812598393       R2 Test: 0.7181719336480662\n",
      "Training model RandomForestRegressor(max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.24s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9594728157903251       R2 Test: 0.7139714869281295\n",
      "Training model RandomForestRegressor(max_features='sqrt', min_samples_leaf=2, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.12s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186239830334262       R2 Test: 0.7167488883835305\n",
      "Training model RandomForestRegressor(max_features='sqrt', min_samples_leaf=4, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_features='sqrt', min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313177450790368       R2 Test: 0.7130526888419904\n",
      "Training model RandomForestRegressor(max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.00s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.910516990565733       R2 Test: 0.7154070531129698\n",
      "Training model RandomForestRegressor(max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.00s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_features='sqrt', min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.07it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903606172027414       R2 Test: 0.7138131861562893\n",
      "Training model RandomForestRegressor(max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.09it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:08<00:00,  2.97s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|                                                                            | 1/12 [00:08<01:38,  8.91s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n",
      "Training model RandomForestRegressor(max_depth=10, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.18it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8695848335838341       R2 Test: 0.7115568926409368\n",
      "Training model RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.18it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8539079069799729       R2 Test: 0.7145589551823979\n",
      "Training model RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:02<00:05,  2.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8274657445889538       R2 Test: 0.7129682615826101\n",
      "Training model RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.19it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8583351077783821       R2 Test: 0.7138294977375947\n",
      "Training model RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.16it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8490145030824892       R2 Test: 0.71380521337471\n",
      "Training model RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:05<00:02,  2.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8274657445889538       R2 Test: 0.7129682615826101\n",
      "Training model RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.14it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8407502900238969       R2 Test: 0.7130617801414043\n",
      "Training model RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.20it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8335863992151048       R2 Test: 0.7124017859142706\n",
      "Training model RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:07<00:00,  2.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|                                                                     | 2/12 [00:16<01:21,  8.19s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8213543028838974       R2 Test: 0.713287784027655\n",
      "Training model RandomForestRegressor(max_depth=20, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.25s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9575570282815536       R2 Test: 0.7136106860969808\n",
      "Training model RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.11s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9180179436025657       R2 Test: 0.7144194134282718\n",
      "Training model RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.06s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8585970175088586       R2 Test: 0.7159558900095234\n",
      "Training model RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9307203384026663       R2 Test: 0.7139219966662691\n",
      "Training model RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.01s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9101637551040865       R2 Test: 0.717418793707105\n",
      "Training model RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8585970175088586       R2 Test: 0.7159558900095234\n",
      "Training model RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.05it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.889672188235977       R2 Test: 0.7141096735615136\n",
      "Training model RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.07it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747289355540016       R2 Test: 0.7129792269910584\n",
      "Training model RandomForestRegressor(max_depth=20, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:08<00:00,  2.97s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|                                                              | 3/12 [00:25<01:16,  8.53s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8497856829229892       R2 Test: 0.714719863115632\n",
      "Training model RandomForestRegressor(max_depth=30, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.26s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9593854918531263       R2 Test: 0.7137021911658068\n",
      "Training model RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.13s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186243607340134       R2 Test: 0.7167083771553013\n",
      "Training model RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.08s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.03s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313469803902507       R2 Test: 0.7128666682284004\n",
      "Training model RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9105134007049998       R2 Test: 0.7154347443850221\n",
      "Training model RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.07s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903118956513759       R2 Test: 0.7139223403346475\n",
      "Training model RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:00,  1.00it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_depth=30, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:09<00:00,  3.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 33%|                                                       | 4/12 [00:34<01:10,  8.82s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n",
      "Training model RandomForestRegressor(max_depth=40, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.29s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9594728157903251       R2 Test: 0.7139714869281295\n",
      "Training model RandomForestRegressor(max_depth=40, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.11s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186239830334262       R2 Test: 0.7167488883835305\n",
      "Training model RandomForestRegressor(max_depth=40, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.05s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=40, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313177450790368       R2 Test: 0.7130526888419904\n",
      "Training model RandomForestRegressor(max_depth=40, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.02s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.910516990565733       R2 Test: 0.7154070531129698\n",
      "Training model RandomForestRegressor(max_depth=40, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=40, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.08it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903606172027414       R2 Test: 0.7138131861562893\n",
      "Training model RandomForestRegressor(max_depth=40, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.02it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_depth=40, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:09<00:00,  3.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|                                                | 5/12 [00:43<01:02,  8.93s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n",
      "Training model RandomForestRegressor(max_depth=50, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.45s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9594728157903251       R2 Test: 0.7139714869281295\n",
      "Training model RandomForestRegressor(max_depth=50, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.31s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186239830334262       R2 Test: 0.7167488883835305\n",
      "Training model RandomForestRegressor(max_depth=50, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.24s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:07,  3.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=50, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.20s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313177450790368       R2 Test: 0.7130526888419904\n",
      "Training model RandomForestRegressor(max_depth=50, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.13s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.910516990565733       R2 Test: 0.7154070531129698\n",
      "Training model RandomForestRegressor(max_depth=50, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=50, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.02it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903606172027414       R2 Test: 0.7138131861562893\n",
      "Training model RandomForestRegressor(max_depth=50, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.09it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_depth=50, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:09<00:00,  3.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|                                         | 6/12 [00:53<00:55,  9.17s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n",
      "Training model RandomForestRegressor(max_depth=60, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.27s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9594728157903251       R2 Test: 0.7139714869281295\n",
      "Training model RandomForestRegressor(max_depth=60, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186239830334262       R2 Test: 0.7167488883835305\n",
      "Training model RandomForestRegressor(max_depth=60, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=60, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313177450790368       R2 Test: 0.7130526888419904\n",
      "Training model RandomForestRegressor(max_depth=60, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.01s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.910516990565733       R2 Test: 0.7154070531129698\n",
      "Training model RandomForestRegressor(max_depth=60, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=60, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.11it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903606172027414       R2 Test: 0.7138131861562893\n",
      "Training model RandomForestRegressor(max_depth=60, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.08it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_depth=60, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:08<00:00,  2.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|                                  | 7/12 [01:02<00:45,  9.11s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n",
      "Training model RandomForestRegressor(max_depth=70, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.24s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9594728157903251       R2 Test: 0.7139714869281295\n",
      "Training model RandomForestRegressor(max_depth=70, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.09s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186239830334262       R2 Test: 0.7167488883835305\n",
      "Training model RandomForestRegressor(max_depth=70, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=70, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.03s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313177450790368       R2 Test: 0.7130526888419904\n",
      "Training model RandomForestRegressor(max_depth=70, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.03s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.910516990565733       R2 Test: 0.7154070531129698\n",
      "Training model RandomForestRegressor(max_depth=70, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=70, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.06it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903606172027414       R2 Test: 0.7138131861562893\n",
      "Training model RandomForestRegressor(max_depth=70, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.06it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_depth=70, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:08<00:00,  2.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|                           | 8/12 [01:11<00:36,  9.04s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n",
      "Training model RandomForestRegressor(max_depth=80, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.23s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9594728157903251       R2 Test: 0.7139714869281295\n",
      "Training model RandomForestRegressor(max_depth=80, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.13s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186239830334262       R2 Test: 0.7167488883835305\n",
      "Training model RandomForestRegressor(max_depth=80, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.05s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=80, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313177450790368       R2 Test: 0.7130526888419904\n",
      "Training model RandomForestRegressor(max_depth=80, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:00,  1.00it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.910516990565733       R2 Test: 0.7154070531129698\n",
      "Training model RandomForestRegressor(max_depth=80, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=80, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.07it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903606172027414       R2 Test: 0.7138131861562893\n",
      "Training model RandomForestRegressor(max_depth=80, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.06it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_depth=80, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:08<00:00,  2.97s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|                    | 9/12 [01:20<00:26,  8.99s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n",
      "Training model RandomForestRegressor(max_depth=90, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.26s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9594728157903251       R2 Test: 0.7139714869281295\n",
      "Training model RandomForestRegressor(max_depth=90, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186239830334262       R2 Test: 0.7167488883835305\n",
      "Training model RandomForestRegressor(max_depth=90, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.08s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=90, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313177450790368       R2 Test: 0.7130526888419904\n",
      "Training model RandomForestRegressor(max_depth=90, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.05s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.910516990565733       R2 Test: 0.7154070531129698\n",
      "Training model RandomForestRegressor(max_depth=90, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=90, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.06it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903606172027414       R2 Test: 0.7138131861562893\n",
      "Training model RandomForestRegressor(max_depth=90, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.05it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_depth=90, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:09<00:00,  3.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|             | 10/12 [01:29<00:18,  9.07s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n",
      "Training model RandomForestRegressor(max_depth=100, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.26s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9594728157903251       R2 Test: 0.7139714869281295\n",
      "Training model RandomForestRegressor(max_depth=100, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186239830334262       R2 Test: 0.7167488883835305\n",
      "Training model RandomForestRegressor(max_depth=100, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.08s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=100, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.04s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313177450790368       R2 Test: 0.7130526888419904\n",
      "Training model RandomForestRegressor(max_depth=100, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.01s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.910516990565733       R2 Test: 0.7154070531129698\n",
      "Training model RandomForestRegressor(max_depth=100, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=100, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.07it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903606172027414       R2 Test: 0.7138131861562893\n",
      "Training model RandomForestRegressor(max_depth=100, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.07it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_depth=100, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:08<00:00,  2.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|      | 11/12 [01:38<00:09,  9.01s/it]\u001b[A\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n",
      "Training model RandomForestRegressor(max_depth=110, max_features='sqrt', random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.23s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9594728157903251       R2 Test: 0.7139714869281295\n",
      "Training model RandomForestRegressor(max_depth=110, max_features='sqrt', min_samples_leaf=2,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.11s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9186239830334262       R2 Test: 0.7167488883835305\n",
      "Training model RandomForestRegressor(max_depth=110, max_features='sqrt', min_samples_leaf=4,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:03<00:06,  3.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=110, max_features='sqrt', min_samples_split=5,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:01<00:02,  1.20s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.9313177450790368       R2 Test: 0.7130526888419904\n",
      "Training model RandomForestRegressor(max_depth=110, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:02<00:01,  1.21s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.910516990565733       R2 Test: 0.7154070531129698\n",
      "Training model RandomForestRegressor(max_depth=110, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=5, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:03<00:00,  1.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:06<00:03,  3.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8586557468517008       R2 Test: 0.7162201205716179\n",
      "Training model RandomForestRegressor(max_depth=110, max_features='sqrt', min_samples_split=10,\n",
      "                      random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 33%|                                                        | 1/3 [00:00<00:01,  1.07it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8903606172027414       R2 Test: 0.7138131861562893\n",
      "Training model RandomForestRegressor(max_depth=110, max_features='sqrt', min_samples_leaf=2,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 67%|                            | 2/3 [00:01<00:00,  1.07it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8747629519820224       R2 Test: 0.7130931801623266\n",
      "Training model RandomForestRegressor(max_depth=110, max_features='sqrt', min_samples_leaf=4,\n",
      "                      min_samples_split=10, random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:02<00:00,  1.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|| 3/3 [00:09<00:00,  3.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 12/12 [01:47<00:00,  8.99s/it]\u001b[A\n",
      "100%|| 2/2 [13:30<00:00, 405.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.8496702421632895       R2 Test: 0.7153080971356294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# RandomForestRegressor\n",
    "# ==============================================================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "results_RF = pd.DataFrame()\n",
    "sc = StandardScaler()\n",
    "\n",
    "for max_features in tqdm(['auto', 'sqrt']):\n",
    "    for max_depth in tqdm([None]+[int(x) for x in np.linspace(10, 110, num=11)]):\n",
    "        #         for n_estimators in [int(x) for x in np.linspace(start=10, stop=1000, num=10)]:\n",
    "        for min_samples_split in tqdm([2, 5, 10]):\n",
    "            for min_samples_leaf in tqdm([1, 2, 4]):\n",
    "                model = RandomForestRegressor(max_features=max_features,\n",
    "                                              max_depth=max_depth,\n",
    "#                                                   n_estimators=n_estimators,\n",
    "                                              min_samples_split=min_samples_split,\n",
    "                                              min_samples_leaf=min_samples_leaf,\n",
    "                                              random_state=1)\n",
    "                pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "                print('Training model', model)\n",
    "                pipefit = pipe.fit(X_train, y_train)\n",
    "                print('Making predictions')\n",
    "                pred_test = pipefit.predict(X_test)\n",
    "                test_score = r2_score(y_test, pred_test)\n",
    "                pred_train = pipefit.predict(X_train)\n",
    "                train_score = r2_score(y_train, pred_train)\n",
    "                print('R2 Train:', train_score, '      R2 Test:', test_score)\n",
    "                list_zip = list(zip([model],\n",
    "                                    [pipe],\n",
    "                                    [train_score],\n",
    "                                    [test_score],\n",
    "                                    \n",
    "                                    [max_features],\n",
    "                                    [max_depth],\n",
    "                                    [min_samples_split],\n",
    "                                    [min_samples_leaf]))\n",
    "                results_RF = results_RF.append(pd.DataFrame(list_zip))\n",
    "                save_grid_results(list_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-firmware",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "511b0d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model Lasso(alpha=0.0, max_iter=500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6771482095514435       R2 Test: 0.6833036096603174\n",
      "Training model Lasso(alpha=0.0, max_iter=500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6260226.682014802, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6248947.069116951, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6777299206307087       R2 Test: 0.6840659879891703\n",
      "Training model Lasso(alpha=0.0, random_state=1, selection='random', warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6216210.275593357, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6794182193041414       R2 Test: 0.6846580883032298\n",
      "Training model Lasso(alpha=0.0, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6210890.296122185, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6796925807585528       R2 Test: 0.6856073372846265\n",
      "Training model Lasso(alpha=0.0, max_iter=1500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6190270.169370677, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.680755999893218       R2 Test: 0.6859109017274712\n",
      "Training model Lasso(alpha=0.0, max_iter=1500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6189101.791226394, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6808162553751625       R2 Test: 0.6865429276006544\n",
      "Training model Lasso(alpha=0.0, max_iter=2000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6172885.052703985, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6816525834081766       R2 Test: 0.6868242813686689\n",
      "Training model Lasso(alpha=0.0, max_iter=2000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6175069.099289713, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6815399479739597       R2 Test: 0.6871866923147243\n",
      "Training model Lasso(alpha=0.0, max_iter=2500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6158987.138166405, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.682369325280296       R2 Test: 0.687513793326417\n",
      "Training model Lasso(alpha=0.0, max_iter=2500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6164587.72839251, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6820804921958235       R2 Test: 0.6877085145585373\n",
      "Training model Lasso(alpha=0.0, max_iter=3000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6147143.568791156, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6829801206671614       R2 Test: 0.6881387828837886\n",
      "Training model Lasso(alpha=0.0, max_iter=3000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6155787.280243562, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6825343480361884       R2 Test: 0.6881797437319545\n",
      "Training model Lasso(alpha=0.0, max_iter=3500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6136917.053534375, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6835075214991768       R2 Test: 0.6887344086958599\n",
      "Training model Lasso(alpha=0.0, max_iter=3500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6147859.038537921, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6829432225322394       R2 Test: 0.688625613471767\n",
      "Training model Lasso(alpha=0.0, max_iter=4000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6128040.778273897, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6839652878878266       R2 Test: 0.6891511082307306\n",
      "Training model Lasso(alpha=0.0, max_iter=4000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6140451.682218355, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6833252339787469       R2 Test: 0.6890533785925408\n",
      "Training model Lasso(alpha=0.0, max_iter=4500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6118403.532591814, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6844622989676961       R2 Test: 0.6896989373257678\n",
      "Training model Lasso(alpha=0.0, max_iter=4500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6133406.495753098, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6836885676373969       R2 Test: 0.6894644004534436\n",
      "Training model Lasso(alpha=0.0, max_iter=5000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6110336.6424134215, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6848783238290526       R2 Test: 0.6901328352887275\n",
      "Training model Lasso(alpha=0.0, max_iter=5000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6126645.834348014, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6840372277978222       R2 Test: 0.6898586664670824\n",
      "Training model Lasso(alpha=0.0, max_iter=5500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6102336.470466347, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6852909079043907       R2 Test: 0.6905748999375562\n",
      "Training model Lasso(alpha=0.0, max_iter=5500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6120127.305408619, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6843734007267069       R2 Test: 0.6902362078454936\n",
      "Training model Lasso(alpha=0.0, max_iter=6000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6095214.587223984, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6856581969616331       R2 Test: 0.690979805660249\n",
      "Training model Lasso(alpha=0.0, max_iter=6000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6113825.119980995, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6846984164094287       R2 Test: 0.6905973842275053\n",
      "Training model Lasso(alpha=0.0, max_iter=6500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6088504.354595528, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6860042564141844       R2 Test: 0.6913172657260797\n",
      "Training model Lasso(alpha=0.0, max_iter=6500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6107722.324567981, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.685013149170064       R2 Test: 0.6909428227750303\n",
      "Training model Lasso(alpha=0.0, max_iter=7000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6082074.279722009, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6863358675987439       R2 Test: 0.6916561707509238\n",
      "Training model Lasso(alpha=0.0, max_iter=7000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6101807.284572003, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6853181990269268       R2 Test: 0.6912732957815311\n",
      "Training model Lasso(alpha=0.0, max_iter=7500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6075761.3451336995, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6866614376361153       R2 Test: 0.6920066104505784\n",
      "Training model Lasso(alpha=0.0, max_iter=7500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6096071.830486546, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.685613987296998       R2 Test: 0.691589621881169\n",
      "Training model Lasso(alpha=0.0, max_iter=8000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6069633.602262828, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6869774569845759       R2 Test: 0.692281934932587\n",
      "Training model Lasso(alpha=0.0, max_iter=8000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6090510.100002802, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6859008163106872       R2 Test: 0.6918926046565128\n",
      "Training model Lasso(alpha=0.0, max_iter=8500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6064010.714826711, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6872674399785559       R2 Test: 0.6925952221563171\n",
      "Training model Lasso(alpha=0.0, max_iter=8500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6085117.728075882, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6861789111816552       R2 Test: 0.6921830012949098\n",
      "Training model Lasso(alpha=0.0, max_iter=9000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6058423.239762038, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6875555966892226       R2 Test: 0.692888817627946\n",
      "Training model Lasso(alpha=0.0, max_iter=9000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6079891.257537387, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6864484502026504       R2 Test: 0.6924615107200882\n",
      "Training model Lasso(alpha=0.0, max_iter=9500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6053113.118590342, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6878294497323899       R2 Test: 0.6931739234728964\n",
      "Training model Lasso(alpha=0.0, max_iter=9500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6074827.714534114, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6867095867409359       R2 Test: 0.6927287727001865\n",
      "Training model Lasso(alpha=0.0, max_iter=10000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6048221.577260337, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6880817158174155       R2 Test: 0.6934115614066386\n",
      "Training model Lasso(alpha=0.0, max_iter=10000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6069924.314103362, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6869624644223311       R2 Test: 0.6929853722915431\n",
      "Training model Lasso(alpha=0.0, max_iter=10500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6043480.002285177, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6883262478524415       R2 Test: 0.6936764974904246\n",
      "Training model Lasso(alpha=0.0, max_iter=10500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6065178.2676004395, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6872072270625442       R2 Test: 0.6932318462830649\n",
      "Training model Lasso(alpha=0.0, max_iter=11000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6038689.026991982, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.688573327555777       R2 Test: 0.6938734184218889\n",
      "Training model Lasso(alpha=0.0, max_iter=11000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6060586.66722753, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6874440246222355       R2 Test: 0.6934686898616735\n",
      "Training model Lasso(alpha=0.0, max_iter=11500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6034253.815431596, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6888020598471182       R2 Test: 0.6941319667900993\n",
      "Training model Lasso(alpha=0.0, max_iter=11500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6056146.426541699, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6876730162751353       R2 Test: 0.6936963626667203\n",
      "Training model Lasso(alpha=0.0, max_iter=12000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6030033.875747977, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.68901969015855       R2 Test: 0.6943467799928019\n",
      "Training model Lasso(alpha=0.0, max_iter=12000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6051854.259753516, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6878943714756506       R2 Test: 0.6939152939329132\n",
      "Training model Lasso(alpha=0.0, max_iter=12500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6026042.7141901655, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6892255219471363       R2 Test: 0.6945220802216927\n",
      "Training model Lasso(alpha=0.0, max_iter=12500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6047706.686476369, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.688108269713935       R2 Test: 0.6941258866946078\n",
      "Training model Lasso(alpha=0.0, max_iter=13000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6022191.825274694, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6894241196089032       R2 Test: 0.694742144593551\n",
      "Training model Lasso(alpha=0.0, max_iter=13000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6043700.052009547, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.688314899469852       R2 Test: 0.694328521147892\n",
      "Training model Lasso(alpha=0.0, max_iter=13500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6018569.910359377, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6896109086462108       R2 Test: 0.6949274534836961\n",
      "Training model Lasso(alpha=0.0, max_iter=13500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6039830.556073375, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6885144567310477       R2 Test: 0.6945235573094246\n",
      "Training model Lasso(alpha=0.0, max_iter=14000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6015234.950224304, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6897828988800112       R2 Test: 0.6951139939634459\n",
      "Training model Lasso(alpha=0.0, max_iter=14000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6036094.285139005, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6887071433256444       R2 Test: 0.6947113371129494\n",
      "Training model Lasso(alpha=0.0, max_iter=14500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6011960.6544851065, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6899517605355948       R2 Test: 0.695247719586751\n",
      "Training model Lasso(alpha=0.0, max_iter=14500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6032487.245167337, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6888931652338317       R2 Test: 0.6948921860686723\n",
      "Training model Lasso(alpha=0.0, max_iter=15000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6008824.477120586, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6901134991640393       R2 Test: 0.6954017733177751\n",
      "Training model Lasso(alpha=0.0, max_iter=15000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6029005.39278434, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6890727309800939       R2 Test: 0.6950664145891645\n",
      "Training model Lasso(alpha=0.0, max_iter=15500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6005750.733047761, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6902720179889471       R2 Test: 0.6955372228096688\n",
      "Training model Lasso(alpha=0.0, max_iter=15500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6025644.663771089, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6892460501639277       R2 Test: 0.6952343190640683\n",
      "Training model Lasso(alpha=0.0, max_iter=16000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6002778.324560528, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6904253107450713       R2 Test: 0.6957166012929544\n",
      "Training model Lasso(alpha=0.0, max_iter=16000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6022400.998324885, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6894133321570743       R2 Test: 0.6953961827470578\n",
      "Training model Lasso(alpha=0.0, max_iter=16500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6000030.456047965, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6905670235478594       R2 Test: 0.6958351140081924\n",
      "Training model Lasso(alpha=0.0, max_iter=16500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6019270.362926681, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6895747849757801       R2 Test: 0.6955522765030245\n",
      "Training model Lasso(alpha=0.0, max_iter=17000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5997329.2839965, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6907063281253811       R2 Test: 0.6959690019015106\n",
      "Training model Lasso(alpha=0.0, max_iter=17000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6016248.768886482, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6897306143243698       R2 Test: 0.6957028594512278\n",
      "Training model Lasso(alpha=0.0, max_iter=17500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5994818.770906266, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6908358000578361       R2 Test: 0.6961142267979272\n",
      "Training model Lasso(alpha=0.0, max_iter=17500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6013332.287777629, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6898810227992755       R2 Test: 0.6958481795307212\n",
      "Training model Lasso(alpha=0.0, max_iter=18000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5992278.494970089, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6909668069168343       R2 Test: 0.6962193525710784\n",
      "Training model Lasso(alpha=0.0, max_iter=18000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6010517.06404271, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6900262092389204       R2 Test: 0.695988474007287\n",
      "Training model Lasso(alpha=0.0, max_iter=18500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5989871.858363484, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6910909217415635       R2 Test: 0.6963512415752606\n",
      "Training model Lasso(alpha=0.0, max_iter=18500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6007799.325083782, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.690166368203353       R2 Test: 0.6961239699357982\n",
      "Training model Lasso(alpha=0.0, max_iter=19000, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5987501.60669965, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6912131601256268       R2 Test: 0.6964783674904585\n",
      "Training model Lasso(alpha=0.0, max_iter=19000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6005175.389150517, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6903016895674351       R2 Test: 0.6962548845880645\n",
      "Training model Lasso(alpha=0.0, max_iter=19500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5985224.533167165, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:346: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6913305931363287       R2 Test: 0.6965707572597576\n",
      "Training model Lasso(alpha=0.0, max_iter=19500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6002641.67132641, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6904323582121266       R2 Test: 0.6963814258533576\n",
      "Training model Lasso(alpha=0.5, max_iter=500, random_state=1, selection='random',\n",
      "      warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54642.048336114734, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9720.720377538353, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.658039220534493       R2 Test: 0.6780612389596601\n",
      "Training model Lasso(alpha=0.5, max_iter=500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580147377715808       R2 Test: 0.6781139663880977\n",
      "Training model Lasso(alpha=0.5, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580278660063701       R2 Test: 0.6781047696689664\n",
      "Training model Lasso(alpha=0.5, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5034.959778547287, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6580256587076259       R2 Test: 0.6780961105635721\n",
      "Training model Lasso(alpha=0.5, max_iter=1500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=1500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3944.726789860055, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6580278226593828       R2 Test: 0.6781183122983976\n",
      "Training model Lasso(alpha=0.5, max_iter=2000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=2000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580252395312238       R2 Test: 0.6781174024558393\n",
      "Training model Lasso(alpha=0.5, max_iter=2500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=2500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580252311680719       R2 Test: 0.6781174024025893\n",
      "Training model Lasso(alpha=0.5, max_iter=3000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=3000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=3500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=3500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=4000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=4000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=4500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=4500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=5000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=5000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=5500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=5500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=6000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=6000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=6500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=6500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=7000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=7000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=7500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=7500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=8000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=8000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=8500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=8500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=9000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=9000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=9500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=9500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=10000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=10000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=10500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=10500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=11000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=11000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=11500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=11500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=12000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=12000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=12500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=12500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=13000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=13000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=13500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=13500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=14000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=14000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=14500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=14500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=15000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=15000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=15500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=15500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=16000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=16000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=16500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=16500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=17000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=17000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=17500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=17500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=18000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=18000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=18500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=18500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=19000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=19000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(alpha=0.5, max_iter=19500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.658028562880189       R2 Test: 0.6781167646518873\n",
      "Training model Lasso(alpha=0.5, max_iter=19500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6580253060061212       R2 Test: 0.6781171706500464\n",
      "Training model Lasso(max_iter=500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499099541289773       R2 Test: 0.6725143993503226\n",
      "Training model Lasso(max_iter=500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10249.314084092155, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10036.935590226203, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6499082103023712       R2 Test: 0.6724798023833818\n",
      "Training model Lasso(random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499126930478567       R2 Test: 0.6725253187293183\n",
      "Training model Lasso(max_iter=1500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=1500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=2000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=2000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=2500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=2500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=3000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=3000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=3500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=3500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=4000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=4000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=4500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=4500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=5000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=5000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=5500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=5500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=6000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=6000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=6500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=6500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=7000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=7000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=7500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=7500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=8000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=8000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=8500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=8500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=9000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=9000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=9500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=9500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=10000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=10000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=10500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=10500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=11000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=11000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=11500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=11500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=12000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=12000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=12500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=12500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=13000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=13000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=13500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=13500, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=14000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=14000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=14500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=14500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=15000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=15000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=15500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=15500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=16000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=16000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=16500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=16500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=17000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=17000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=17500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=17500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=18000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=18000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=18500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=18500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=19000, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=19000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(max_iter=19500, random_state=1, selection='random', warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499114346522721       R2 Test: 0.6725182771404655\n",
      "Training model Lasso(max_iter=19500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6499133354206603       R2 Test: 0.6725237587706461\n",
      "Training model Lasso(alpha=1.5, max_iter=500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467435097626665       R2 Test: 0.6693126783441231\n",
      "Training model Lasso(alpha=1.5, random_state=1, selection='random', warm_start=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8358.522140586749, tolerance: 3878.080820501016\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=1500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=1500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=2000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=2000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=2500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=2500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=3000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=3000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=3500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=3500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=4000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=4000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=4500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=4500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=5000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=5000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=5500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=5500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=6000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=6000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=6500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=6500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=7000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=7000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=7500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=7500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=8000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=8000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=8500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=8500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=9000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=9000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=9500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=9500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=10000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=10000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=10500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=10500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=11000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=11000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=11500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=11500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=12000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=12000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=12500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=12500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=13000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=13000, random_state=1, warm_start=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=13500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=13500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=14000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=14000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=14500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=14500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=15000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=15000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=15500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=15500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=16000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=16000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=16500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=16500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=17000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=17000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=17500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=17500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=18000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=18000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=18500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=18500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=19000, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=19000, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n",
      "Training model Lasso(alpha=1.5, max_iter=19500, random_state=1, selection='random',\n",
      "      warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.646734116486881       R2 Test: 0.6692824883743638\n",
      "Training model Lasso(alpha=1.5, max_iter=19500, random_state=1, warm_start=True)\n",
      "Making predictions\n",
      "R2 Train: 0.6467358185523753       R2 Test: 0.669283863913695\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Lasso\n",
    "# ==============================================================================\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "results_LS = pd.DataFrame()\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "for alpha in tqdm([x/10 for x in range(0,20, 5)]):\n",
    "    for max_iter in tqdm(range(500, 20000, 500)):\n",
    "        for selection in tqdm(['random', 'cyclic']):\n",
    "            model = Lasso(alpha=alpha,\n",
    "                          max_iter=max_iter,\n",
    "                          selection=selection,\n",
    "                          warm_start=True,\n",
    "                          random_state=1\n",
    "                          )\n",
    "            pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "            print('Training model', model)\n",
    "            pipefit = pipe.fit(X_train, y_train)\n",
    "            print('Making predictions')\n",
    "            pred_test = pipefit.predict(X_test)\n",
    "            test_score = r2_score(y_test, pred_test)\n",
    "            pred_train = pipefit.predict(X_train)\n",
    "            train_score = r2_score(y_train, pred_train)\n",
    "            print('R2 Train:', train_score, '      R2 Test:', test_score)\n",
    "            list_zip = list(zip([model],\n",
    "                                [pipe],\n",
    "                                [train_score],\n",
    "                                [test_score],\n",
    "                                \n",
    "                                [alpha],\n",
    "                                [max_iter],\n",
    "                                [selection]))\n",
    "            results_LS = results_LS.append(pd.DataFrame(list_zip))\n",
    "            save_grid_results(list_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38339d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.plot( results_LS.iloc[:500,3], results_LS.iloc[:500,2])\n",
    "# plt.plot( results_LS.iloc[:,4], results_LS.iloc[:,2])\n",
    "\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ea8389",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4cce8273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n",
      "Training model LinearRegression()\n",
      "Making predictions\n",
      "R2 Train: 0.6973260177267564       R2 Test: 0.7038304348966248\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# LinearRegression\n",
    "# ==============================================================================\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "results_LR = pd.DataFrame()\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "for normalize in [True, False]:\n",
    "    for copy_X in [True, False]:\n",
    "        for positive in [True, False]:\n",
    "            for fit_intercept in [True, False]:\n",
    "                model = LinearRegression(\n",
    "#                     normalize=normalize,\n",
    "#                     copy_X=copy_X,\n",
    "#                     positive=positive,\n",
    "#                     fit_intercept=fit_intercept,\n",
    "                )\n",
    "                pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "                print('Training model', model)\n",
    "                pipefit = pipe.fit(X_train, y_train)\n",
    "                print('Making predictions')\n",
    "                pred_test = pipefit.predict(X_test)\n",
    "                test_score = r2_score(y_test, pred_test)\n",
    "                pred_train = pipefit.predict(X_train)\n",
    "                train_score = r2_score(y_train, pred_train)\n",
    "                print('R2 Train:', train_score, '      R2 Test:', test_score)\n",
    "                list_zip = list(zip([model],\n",
    "                                    [pipe],\n",
    "                                    [train_score],\n",
    "                                    [test_score],\n",
    "                                    \n",
    "                                    [normalize],\n",
    "                                    [copy_X],\n",
    "                                    [positive],\n",
    "                                    [fit_intercept]))\n",
    "                results_LR = results_LR.append(pd.DataFrame(list_zip))\n",
    "#                 save_grid_results(list_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-equilibrium",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "conceptual-batch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:301: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4727, 84)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "X_te = X.drop(['Name'], axis=1)\n",
    "\n",
    "X_new = SelectPercentile(f_regression, percentile=80).fit_transform(X_te, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.33, random_state=1)\n",
    "X_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "13543436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3167, 103)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "X_te = X.drop(['Name'], axis=1)\n",
    "\n",
    "X_new = VarianceThreshold().fit_transform(X_te, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.33, random_state=1)\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-facial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-15T18:32:26.716503Z",
     "start_time": "2021-09-15T18:32:26.697958Z"
    }
   },
   "source": [
    "## List of Final models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ebfd78",
   "metadata": {},
   "source": [
    "### SKLearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "waiting-field",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T12:12:03.715843Z",
     "start_time": "2021-11-03T12:12:03.697892Z"
    }
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestRegressor(random_state=1, n_jobs=-1),\n",
    "    RandomForestRegressor(max_depth=20, max_features='auto'),\n",
    "    Lasso(alpha=0.9, max_iter=150, selection='cyclic'),\n",
    "    GradientBoostingRegressor(subsample=0.8,\n",
    "                              learning_rate=0.4,\n",
    "                              random_state=500),\n",
    "    RandomForestRegressor(max_depth=250, min_samples_split=14,\n",
    "                          min_samples_leaf=3, random_state=1, n_jobs=-1),\n",
    "    RandomForestRegressor(n_estimators=1000,\n",
    "                          max_depth=250,\n",
    "                          min_samples_split=5,\n",
    "                          random_state=0,\n",
    "                          n_jobs=-1),\n",
    "    RandomForestRegressor(n_estimators=50,\n",
    "                          max_depth=100,\n",
    "                          min_samples_split=400,\n",
    "                          random_state=0,\n",
    "                          n_jobs=-1),\n",
    "    Lasso(alpha=4.5)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-stock",
   "metadata": {},
   "source": [
    "### Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-gardening",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T20:23:02.858530Z",
     "start_time": "2021-11-02T20:22:58.011126Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # Because we will need to instantiate\n",
    "    # the same model multiple times,\n",
    "    # we use a function to construct it.\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)])\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "religious-headquarters",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T17:13:59.509327Z",
     "start_time": "2021-11-03T17:13:59.482118Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "groups = X_train[group_feature].values.ravel()\n",
    "\n",
    "X_train = X_train.drop(['Name'], axis=1).values\n",
    "X_test = X_test.drop(['Name'], axis=1).values\n",
    "\n",
    "gkf = list(GroupKFold(n_splits=6).split(X_train, y_train, groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train_full)\n",
    "train_sc = sc.transform(X_train)\n",
    "test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "\n",
    "    # Prepare the validation data: data from partition # k\n",
    "    val_data = train_sc[i * num_val_samples:(i + 1) * num_val_samples]\n",
    "    val_targets = y_train_full[i * num_val_samples:(i + 1) * num_val_samples]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_sc[:i * num_val_samples], train_sc[(i + 1) * num_val_samples:]],\n",
    "        axis=0)\n",
    "\n",
    "    partial_train_targets = np.concatenate([\n",
    "        y_train_full[:i * num_val_samples],\n",
    "        y_train_full[(i + 1) * num_val_samples:]\n",
    "    ],\n",
    "                                           axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(partial_train_data,\n",
    "                        partial_train_targets,\n",
    "                        validation_data=(val_data, val_targets),\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=1,\n",
    "                        verbose=0)\n",
    "\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-proof",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "\n",
    "    for point in points:\n",
    "\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "\n",
    "    return smoothed_points\n",
    "\n",
    "\n",
    "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
    "\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a fresh, compiled model.\n",
    "model = build_model()\n",
    "\n",
    "# Train it on the entirety of the data.\n",
    "model.fit(train_sc, y_train_full, epochs=280, batch_size=16, verbose=0)\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(train_sc, y_train_full)\n",
    "print(test_mse_score, test_mae_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(test_sc)\n",
    "output = pd.DataFrame(y_test_pred)\n",
    "output['Id'] = output.index\n",
    "output['Predicted'] = output.iloc[:, 0:1]\n",
    "output[['Id', 'Predicted']].to_csv(\"submission_DNN_relusig.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e01a31",
   "metadata": {},
   "source": [
    "## Variations in Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-submission",
   "metadata": {},
   "source": [
    "### All data mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "homeless-scroll",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T17:07:16.680184Z",
     "start_time": "2021-11-03T17:03:20.583051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 3.54        R2 Test: 0.88\n",
      "RMSE Train: 1.31       R2 Train: 0.98\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 4.58        R2 Test: 0.80\n",
      "RMSE Train: 4.58       R2 Train: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.618951061027474, tolerance: 13.425073577844312\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.44147528954636, tolerance: 13.848278967065871\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 53.10005841006932, tolerance: 13.859737425149705\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.13234488260787, tolerance: 13.819424850299407\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51.647999958375294, tolerance: 13.912616467065874\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.5385875247448, tolerance: 14.137623970037458\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 3.93        R2 Test: 0.85\n",
      "RMSE Train: 1.29       R2 Train: 0.98\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 3.51        R2 Test: 0.88\n",
      "RMSE Train: 1.49       R2 Train: 0.98\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 5.42        R2 Test: 0.72\n",
      "RMSE Train: 5.44       R2 Train: 0.71\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 7.05        R2 Test: 0.52\n",
      "RMSE Train: 7.06       R2 Train: 0.52\n"
     ]
    }
   ],
   "source": [
    "temp_list = [x for x in all_df_now if not 'Robot' in x]\n",
    "\n",
    "# Making list of df for conct before training\n",
    "# This is different form list of srtings, as this is a list of actual dataframes\n",
    "df_list = []\n",
    "for x in temp_list:\n",
    "    df_list.append(locals()[x])\n",
    "\n",
    "df_ = pd.concat(df_list)\n",
    "\n",
    "# Shuffeling all the items\n",
    "df_shuffle = df_.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "X = df_shuffle[training_features]\n",
    "y = df_shuffle[target_features].values.ravel()\n",
    "groups = df_shuffle[group_feature].values.ravel()\n",
    "\n",
    "gkf = list(GroupKFold(n_splits=6).split(X, y, groups))\n",
    "# gkf = list(StratifiedGroupKFold(n_splits=6, shuffle=True, random_state=1).split(X, y, groups))\n",
    "\n",
    "#     Getting scores using cross_val_score\n",
    "for model in models:\n",
    "    importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_gkf_std(\n",
    "        model, X, y, gkf)\n",
    "    if importances is not None:\n",
    "        plot_feat_imp(importances,\n",
    "                      model,\n",
    "                      training_features,\n",
    "                      threshold=threshold_all)\n",
    "\n",
    "    save_results(model=model,\n",
    "                 agg_method=agg_method,\n",
    "                 train_field='all_mix',\n",
    "                 test_field='all_mix',\n",
    "                 training_features=training_features,\n",
    "                 importances=importances,\n",
    "                 RMSE_test=RMSE_test_temp,\n",
    "                 RMSE_train=RMSE_train_temp,\n",
    "                 R2_test=R2_test_temp,\n",
    "                 R2_train=R2_train_temp,\n",
    "                 GKF_CV=GKF_CV_temp)\n",
    "del (temp_list, df_list, df_, X, y, groups, gkf)\n",
    "del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-benchmark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T19:15:21.306505Z",
     "start_time": "2021-10-13T19:15:21.281069Z"
    }
   },
   "source": [
    "### Within same datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "documentary-profile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:53:01.328315Z",
     "start_time": "2021-11-01T11:53:00.862066Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_Simps\n",
      "Masbasis_2019_Simps\n",
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 1.25        R2 Test: 0.60\n",
      "RMSE Train: 0.46       R2 Train: 0.95\n",
      "Masbasis_2019_Simps\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 1.78        R2 Test: 0.19\n",
      "RMSE Train: 1.79       R2 Train: 0.19\n",
      "Masbasis_2019_Simps\n",
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 1.35        R2 Test: 0.52\n",
      "RMSE Train: 0.09       R2 Train: 1.00\n",
      "Masbasis_2019_Simps\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 1.23        R2 Test: 0.61\n",
      "RMSE Train: 0.54       R2 Train: 0.93\n",
      "Masbasis_2019_Simps\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 1.99        R2 Test: -0.01\n",
      "RMSE Train: 2.00       R2 Train: -0.00\n",
      "Masbasis_2019_Simps\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 1.99        R2 Test: -0.01\n",
      "RMSE Train: 2.00       R2 Train: 0.00\n",
      "Masbasis_2020_Simps\n",
      "Masbasis_2020_Simps\n",
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 1.50        R2 Test: 0.82\n",
      "RMSE Train: 0.56       R2 Train: 0.98\n",
      "Masbasis_2020_Simps\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 1.87        R2 Test: 0.73\n",
      "RMSE Train: 1.83       R2 Train: 0.74\n",
      "Masbasis_2020_Simps\n",
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 1.63        R2 Test: 0.79\n",
      "RMSE Train: 0.12       R2 Train: 1.00\n",
      "Masbasis_2020_Simps\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 1.50        R2 Test: 0.82\n",
      "RMSE Train: 0.64       R2 Train: 0.97\n",
      "Masbasis_2020_Simps\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 3.61        R2 Test: -0.00\n",
      "RMSE Train: 3.62       R2 Train: -0.00\n",
      "Masbasis_2020_Simps\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 3.61        R2 Test: -0.00\n",
      "RMSE Train: 3.62       R2 Train: 0.00\n",
      "Robot_2020_Simps\n",
      "Robot_2020_Simps\n",
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 2.25        R2 Test: 0.55\n",
      "RMSE Train: 0.87       R2 Train: 0.93\n",
      "Robot_2020_Simps\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 2.26        R2 Test: 0.55\n",
      "RMSE Train: 2.21       R2 Train: 0.57\n",
      "Robot_2020_Simps\n",
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 2.67        R2 Test: 0.37\n",
      "RMSE Train: 0.00       R2 Train: 1.00\n",
      "Robot_2020_Simps\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 2.28        R2 Test: 0.54\n",
      "RMSE Train: 0.99       R2 Train: 0.91\n",
      "Robot_2020_Simps\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 3.37        R2 Test: -0.01\n",
      "RMSE Train: 3.36       R2 Train: -0.00\n",
      "Robot_2020_Simps\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 3.37        R2 Test: -0.01\n",
      "RMSE Train: 3.36       R2 Train: 0.00\n",
      "Staur_2019_Simps\n",
      "Staur_2019_Simps\n",
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 6.03        R2 Test: 0.48\n",
      "RMSE Train: 2.16       R2 Train: 0.93\n",
      "Staur_2019_Simps\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 6.43        R2 Test: 0.42\n",
      "RMSE Train: 6.37       R2 Train: 0.44\n",
      "Staur_2019_Simps\n",
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 6.51        R2 Test: 0.40\n",
      "RMSE Train: 0.44       R2 Train: 1.00\n",
      "Staur_2019_Simps\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 6.04        R2 Test: 0.49\n",
      "RMSE Train: 2.50       R2 Train: 0.91\n",
      "Staur_2019_Simps\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 8.51        R2 Test: -0.01\n",
      "RMSE Train: 8.50       R2 Train: -0.00\n",
      "Staur_2019_Simps\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 8.13        R2 Test: 0.08\n",
      "RMSE Train: 8.06       R2 Train: 0.10\n"
     ]
    }
   ],
   "source": [
    "# Iterating through all possible permutations of the fields dataset\n",
    "for df in all_df_now:\n",
    "    df_ = locals()[df].copy()\n",
    "\n",
    "    X = df_[training_features]\n",
    "    y = df_[target_features].values.ravel()\n",
    "    groups = df_[group_feature].values.ravel()\n",
    "\n",
    "    gkf = list(GroupKFold(n_splits=3).split(X, y, groups))\n",
    "    print(df)\n",
    "    #     Getting scores using cross_val_score\n",
    "    for model in models:\n",
    "        print(df)\n",
    "        importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_gkf_std(\n",
    "            model, X, y, gkf)\n",
    "        if importances is not None:\n",
    "            plot_feat_imp(importances,\n",
    "                          model,\n",
    "                          training_features,\n",
    "                          threshold=threshold_all)\n",
    "\n",
    "        save_results(model=model,\n",
    "                     agg_method=agg_method,\n",
    "                     train_field=df,\n",
    "                     test_field=df,\n",
    "                     training_features=training_features,\n",
    "                     importances=importances,\n",
    "                     RMSE_test=RMSE_test_temp,\n",
    "                     RMSE_train=RMSE_train_temp,\n",
    "                     R2_test=R2_test_temp,\n",
    "                     R2_train=R2_train_temp,\n",
    "                     GKF_CV=GKF_CV_temp)\n",
    "    del (df, df_, X, y, groups, gkf)\n",
    "    del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-share",
   "metadata": {},
   "source": [
    "### One against all - one2one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "circular-reward",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:56:40.477598Z",
     "start_time": "2021-11-01T11:53:05.967388Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Iterating through all possible permutations of the fields dataset\n",
    "\n",
    "# for i in itertools.permutations(all_df_now, 2):\n",
    "#     train_df = locals()[i[0]].copy()\n",
    "#     test_df = locals()[i[1]].copy()\n",
    "    \n",
    "    \n",
    "#     X_train = train_df[training_features]\n",
    "#     y_train = train_df[target_features].values.ravel()\n",
    "#     X_test = test_df[training_features]\n",
    "#     y_test = test_df[target_features].values.ravel()\n",
    "    \n",
    "#     # Getting scores using cross_val_score\n",
    "#     for model in models:\n",
    "#         print('Training: ', i[0],'Test: ', i[1], ' : ', model)\n",
    "#         importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "#             model, X_train, y_train, X_test, y_test)\n",
    "#         if importances is not None:\n",
    "#             plot_feat_imp(importances, model, training_features, threshold=threshold_all, sort_feat=True)\n",
    "            \n",
    "#         save_results(model=model,\n",
    "#              agg_method=agg_method,\n",
    "#              train_field=i[0],\n",
    "#              test_field=i[1],\n",
    "#              training_features=training_features,\n",
    "#              importances=importances,\n",
    "#              RMSE_test=RMSE_test_temp,\n",
    "#              RMSE_train=RMSE_train_temp,\n",
    "#              R2_test=R2_test_temp,\n",
    "#              R2_train=R2_train_temp,\n",
    "#              GKF_CV=GKF_CV_temp)\n",
    "#     del (i, train_df, test_df, X_train, y_train, X_test, y_test)\n",
    "#     del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-essay",
   "metadata": {},
   "source": [
    "### One aganist all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "victorian-federal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T12:01:18.807981Z",
     "start_time": "2021-11-01T12:01:17.889651Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_Simps ['Masbasis_2020_Simps', 'Staur_2019_Simps']\n",
      "Training: All   Test:  Masbasis_2019_Simps  :  RandomForestRegressor(max_depth=20)\n",
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 15.416560756873537        R2 Test: -58.27555503225143\n",
      "RMSE Train: 1.5346695748953842       R2 Train: 0.9727501597257616\n",
      "Training: All   Test:  Masbasis_2019_Simps  :  Lasso(alpha=0.9, max_iter=150)\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 21.787897402779006        R2 Test: -117.39443100968519\n",
      "RMSE Train: 5.133908816043703       R2 Train: 0.6950486949920132\n",
      "Training: All   Test:  Masbasis_2019_Simps  :  GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 18.143114430940095        R2 Test: -81.0964373739025\n",
      "RMSE Train: 1.2969179583547477       R2 Train: 0.9805392666318304\n",
      "Training: All   Test:  Masbasis_2019_Simps  :  RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 15.088143910600026        R2 Test: -55.77697719945323\n",
      "RMSE Train: 1.755606037718881       R2 Train: 0.964339426274928\n",
      "Training: All   Test:  Masbasis_2019_Simps  :  RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 16.348677862919132        R2 Test: -65.66009136865735\n",
      "RMSE Train: 6.493333906335603       R2 Train: 0.51216869444474\n",
      "Training: All   Test:  Masbasis_2019_Simps  :  Lasso(alpha=4.5)\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 17.07191996860936        R2 Test: -71.68844260120585\n",
      "RMSE Train: 7.900208205944883       R2 Train: 0.277876848864098\n",
      "Masbasis_2020_Simps ['Masbasis_2019_Simps', 'Staur_2019_Simps']\n",
      "Training: All   Test:  Masbasis_2020_Simps  :  RandomForestRegressor(max_depth=20)\n",
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 17.796596924623717        R2 Test: -23.221405289196692\n",
      "RMSE Train: 1.5744143066273026       R2 Train: 0.9521406563416471\n",
      "Training: All   Test:  Masbasis_2020_Simps  :  Lasso(alpha=0.9, max_iter=150)\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 19.166802451303685        R2 Test: -27.094722163141164\n",
      "RMSE Train: 5.341568216501114       R2 Train: 0.44910828424661886\n",
      "Training: All   Test:  Masbasis_2020_Simps  :  GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 21.175213363284982        R2 Test: -33.29106695499989\n",
      "RMSE Train: 1.3338040763823473       R2 Train: 0.9656511054966477\n",
      "Training: All   Test:  Masbasis_2020_Simps  :  RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 17.65766486470546        R2 Test: -22.844704673244202\n",
      "RMSE Train: 1.7507068924544544       R2 Train: 0.9408226427510008\n",
      "Training: All   Test:  Masbasis_2020_Simps  :  RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 18.148725288245075        R2 Test: -24.189390668580796\n",
      "RMSE Train: 6.17691823303748       R2 Train: 0.263331010809994\n",
      "Training: All   Test:  Masbasis_2020_Simps  :  Lasso(alpha=4.5)\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 17.382236735162312        R2 Test: -22.106636328866564\n",
      "RMSE Train: 7.196737436443633       R2 Train: 0.0\n",
      "Staur_2019_Simps ['Masbasis_2019_Simps', 'Masbasis_2020_Simps']\n",
      "Training: All   Test:  Staur_2019_Simps  :  RandomForestRegressor(max_depth=20)\n",
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 8.291455391362502        R2 Test: 0.04908978652102525\n",
      "RMSE Train: 0.5188798027346745       R2 Train: 0.9976722058860048\n",
      "Training: All   Test:  Staur_2019_Simps  :  Lasso(alpha=0.9, max_iter=150)\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 132.32061795551195        R2 Test: -241.1770673768079\n",
      "RMSE Train: 2.3371965780311066       R2 Train: 0.9527717866123043\n",
      "Training: All   Test:  Staur_2019_Simps  :  GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 8.842254628222713        R2 Test: -0.08144393418595453\n",
      "RMSE Train: 0.45275157193093757       R2 Train: 0.9982277255890873\n",
      "Training: All   Test:  Staur_2019_Simps  :  RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 8.405198316491225        R2 Test: 0.02282149618969942\n",
      "RMSE Train: 0.5813485169072661       R2 Train: 0.9970779733604647\n",
      "Training: All   Test:  Staur_2019_Simps  :  RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 9.00241331936484        R2 Test: -0.12097485739419955\n",
      "RMSE Train: 2.9365122842705396       R2 Train: 0.9254453600508002\n",
      "Training: All   Test:  Staur_2019_Simps  :  Lasso(alpha=4.5)\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 83.38250617984866        R2 Test: -95.16739758497168\n",
      "RMSE Train: 5.3733517610143515       R2 Train: 0.7503672404957266\n"
     ]
    }
   ],
   "source": [
    "# Iterating through all possible permutations of the fields dataset\n",
    "for df in all_df_now:\n",
    "    if 'Robot' not in df:\n",
    "        temp_list = [\n",
    "            x for x in all_df_now if not 'Robot' in x if not df in x\n",
    "        ]\n",
    "        print(df, temp_list)\n",
    "\n",
    "        # Making list of df for conct before training\n",
    "        # This is different form list of srtings, as this is a list of actual dataframes\n",
    "        train_df_list = []\n",
    "        for x in temp_list:\n",
    "            train_df_list.append(locals()[x])\n",
    "\n",
    "        train_df = pd.concat(train_df_list)\n",
    "        test_df = locals()[df].copy()\n",
    "\n",
    "        X_train = train_df[training_features]\n",
    "        y_train = train_df[target_features].values.ravel()\n",
    "        X_test = test_df[training_features]\n",
    "        y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "        # Getting scores using cross_val_score\n",
    "        for model in models:\n",
    "            print('Training: All  ', 'Test: ', df, ' : ', model)\n",
    "            importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "                model, X_train, y_train, X_test, y_test)\n",
    "#             if importances is not None:\n",
    "#                 plot_feat_imp(importances,\n",
    "#                               model,\n",
    "#                               training_features,\n",
    "#                               threshold=threshold_all,\n",
    "#                               sort_feat=sorted_all)\n",
    "            save_results(model=model,\n",
    "                         agg_method=agg_method,\n",
    "                         train_field=temp_list,\n",
    "                         test_field=df,\n",
    "                         training_features=training_features,\n",
    "                         importances=importances,\n",
    "                         RMSE_test=RMSE_test_temp,\n",
    "                         RMSE_train=RMSE_train_temp,\n",
    "                         R2_test=R2_test_temp,\n",
    "                         R2_train=R2_train_temp,\n",
    "                         GKF_CV=GKF_CV_temp)\n",
    "        del (df, temp_list, train_df_list, train_df, test_df, X_train, y_train, X_test, y_test)\n",
    "        del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-exception",
   "metadata": {},
   "source": [
    "### Vollebekk ALL vs Staur ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-fancy",
   "metadata": {},
   "source": [
    "#### Training Staur, Test Vollebekk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "sustainable-stock",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T12:01:24.993488Z",
     "start_time": "2021-11-01T12:01:24.901733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: ['Staur_2019_Simps']\n",
      "Test data: ['Masbasis_2019_Simps', 'Masbasis_2020_Simps']\n",
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 12.426280317911278        R2 Test: -0.33503707353618695\n",
      "RMSE Train: 2.1460098856285885       R2 Train: 0.9362997097179242\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 11.37257382714576        R2 Test: -0.11822336602777916\n",
      "RMSE Train: 6.396654905386828       R2 Train: 0.4340425020057903\n",
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 13.983772260067875        R2 Test: -0.6906733934389535\n",
      "RMSE Train: 0.805519732978928       R2 Train: 0.9910250850286207\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 12.371003868436105        R2 Test: -0.32318606551424955\n",
      "RMSE Train: 2.4304715255002933       R2 Train: 0.9182930404862644\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 11.182147542487682        R2 Test: -0.08108905302042424\n",
      "RMSE Train: 8.503172829549682       R2 Train: -9.207919613163362e-05\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 11.084510903318119        R2 Test: -0.06229247020565776\n",
      "RMSE Train: 8.069579598292755       R2 Train: 0.09930076343183103\n"
     ]
    }
   ],
   "source": [
    "train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                   train_field = 'Staur', \n",
    "                                                   test_field = 'Vollebekk', \n",
    "                                                   year = 'all')\n",
    "\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "for x in train_str_list:\n",
    "    train_df_list.append(locals()[x])\n",
    "for x in test_str_list:\n",
    "    test_df_list.append(locals()[x])\n",
    "\n",
    "train_df = pd.concat(train_df_list)\n",
    "test_df = pd.concat(test_df_list)\n",
    "\n",
    "X_train = train_df[training_features]\n",
    "y_train = train_df[target_features].values.ravel()\n",
    "X_test = test_df[training_features]\n",
    "y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "# Getting scores using cross_val_score\n",
    "for model in models:\n",
    "    importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "        model, X_train, y_train, X_test, y_test)\n",
    "    if importances is not None:\n",
    "        plot_feat_imp(importances,\n",
    "                      model,\n",
    "                      training_features,\n",
    "                      threshold=threshold_all,\n",
    "                      sort_feat=sorted_all)\n",
    "    save_results(model=model,\n",
    "                 agg_method=agg_method,\n",
    "                 train_field=train_str_list,\n",
    "                 test_field=test_str_list,\n",
    "                 training_features=training_features,\n",
    "                 importances=importances,\n",
    "                 RMSE_test=RMSE_test_temp,\n",
    "                 RMSE_train=RMSE_train_temp,\n",
    "                 R2_test=R2_test_temp,\n",
    "                 R2_train=R2_train_temp,\n",
    "                 GKF_CV=GKF_CV_temp)\n",
    "del (train_str_list, test_str_list, train_df_list, test_df_list, train_df, test_df, X_train, y_train, X_test, y_test)\n",
    "del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-recognition",
   "metadata": {},
   "source": [
    "#### Training Vollebekk, Test Staur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "suburban-telephone",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T12:01:30.915386Z",
     "start_time": "2021-11-01T12:01:30.714864Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: ['Masbasis_2019_Simps', 'Masbasis_2020_Simps']\n",
      "Test data: ['Staur_2019_Simps']\n",
      "RandomForestRegressor(max_depth=20)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor', RandomForestRegressor(max_depth=20))])\n",
      " RMSE Test: 8.170336335386281        R2 Test: 0.0766680905416175\n",
      "RMSE Train: 0.513291521502656       R2 Train: 0.9977220760821792\n",
      "Lasso(alpha=0.9, max_iter=150)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=0.9, max_iter=150))])\n",
      " RMSE Test: 132.32061795551195        R2 Test: -241.1770673768079\n",
      "RMSE Train: 2.3371965780311066       R2 Train: 0.9527717866123043\n",
      "GradientBoostingRegressor(learning_rate=0.4, random_state=500, subsample=0.8)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gradientboostingregressor',\n",
      "                 GradientBoostingRegressor(learning_rate=0.4, random_state=500,\n",
      "                                           subsample=0.8))])\n",
      " RMSE Test: 8.842254628222713        R2 Test: -0.08144393418595453\n",
      "RMSE Train: 0.45275157193093757       R2 Train: 0.9982277255890873\n",
      "RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=250, min_samples_split=5,\n",
      "                                       n_estimators=1000, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 8.405198316491225        R2 Test: 0.02282149618969942\n",
      "RMSE Train: 0.5813485169072661       R2 Train: 0.9970779733604647\n",
      "RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(max_depth=100, min_samples_split=400,\n",
      "                                       n_estimators=50, n_jobs=-1,\n",
      "                                       random_state=0))])\n",
      " RMSE Test: 9.002413319364845        R2 Test: -0.12097485739420089\n",
      "RMSE Train: 2.9365122842705396       R2 Train: 0.9254453600508002\n",
      "Lasso(alpha=4.5)\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('lasso', Lasso(alpha=4.5))])\n",
      " RMSE Test: 83.38250617984866        R2 Test: -95.16739758497168\n",
      "RMSE Train: 5.3733517610143515       R2 Train: 0.7503672404957266\n"
     ]
    }
   ],
   "source": [
    "train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                   train_field = 'Vollebekk', \n",
    "                                                   test_field = 'Staur', \n",
    "                                                   year = 'all')\n",
    "\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "for x in train_str_list:\n",
    "    train_df_list.append(locals()[x])\n",
    "for x in test_str_list:\n",
    "    test_df_list.append(locals()[x])\n",
    "\n",
    "train_df = pd.concat(train_df_list)\n",
    "test_df = pd.concat(test_df_list)\n",
    "\n",
    "X_train = train_df[training_features]\n",
    "y_train = train_df[target_features].values.ravel()\n",
    "X_test = test_df[training_features]\n",
    "y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "# Getting scores using cross_val_score\n",
    "for model in models:\n",
    "    importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "        model, X_train, y_train, X_test, y_test)\n",
    "    if importances is not None:\n",
    "        plot_feat_imp(importances,\n",
    "                      model,\n",
    "                      training_features,\n",
    "                      threshold=threshold_all,\n",
    "                      sort_feat=sorted_all)\n",
    "    save_results(model=model,\n",
    "                 agg_method=agg_method,\n",
    "                 train_field=train_str_list,\n",
    "                 test_field=test_str_list,\n",
    "                 training_features=training_features,\n",
    "                 importances=importances,\n",
    "                 RMSE_test=RMSE_test_temp,\n",
    "                 RMSE_train=RMSE_train_temp,\n",
    "                 R2_test=R2_test_temp,\n",
    "                 R2_train=R2_train_temp,\n",
    "                 GKF_CV=GKF_CV_temp)\n",
    "del (train_str_list, test_str_list, train_df_list, test_df_list, train_df, test_df, X_train, y_train, X_test, y_test)\n",
    "del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-tourist",
   "metadata": {},
   "source": [
    "### 2020 Vollebekk vs 2020 Staur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-index",
   "metadata": {},
   "source": [
    "#### Training Staur, Test Vollebekk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "imported-import",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T12:01:30.991183Z",
     "start_time": "2021-11-01T12:01:30.917381Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: []\n",
      "Test data: ['Masbasis_2020_Simps']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-fa52c6fe2d62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtest_df_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \"\"\"\n\u001b[1;32m--> 285\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No objects to concatenate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                   train_field = 'Staur', \n",
    "                                                   test_field = 'Vollebekk', \n",
    "                                                   year = '2020')\n",
    "\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "for x in train_str_list:\n",
    "    train_df_list.append(locals()[x])\n",
    "for x in test_str_list:\n",
    "    test_df_list.append(locals()[x])\n",
    "\n",
    "train_df = pd.concat(train_df_list)\n",
    "test_df = pd.concat(test_df_list)\n",
    "\n",
    "X_train = train_df[training_features]\n",
    "y_train = train_df[target_features].values.ravel()\n",
    "X_test = test_df[training_features]\n",
    "y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "# Getting scores using cross_val_score\n",
    "for model in models:\n",
    "    importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "        model, X_train, y_train, X_test, y_test)\n",
    "    if importances is not None:\n",
    "        plot_feat_imp(importances,\n",
    "                      model,\n",
    "                      training_features,\n",
    "                      threshold=threshold_all,\n",
    "                      sort_feat=sorted_all)\n",
    "    save_results(model=model,\n",
    "                 agg_method=agg_method,\n",
    "                 train_field=train_str_list,\n",
    "                 test_field=test_str_list,\n",
    "                 training_features=training_features,\n",
    "                 importances=importances,\n",
    "                 RMSE_test=RMSE_test_temp,\n",
    "                 RMSE_train=RMSE_train_temp,\n",
    "                 R2_test=R2_test_temp,\n",
    "                 R2_train=R2_train_temp,\n",
    "                 GKF_CV=GKF_CV_temp)\n",
    "del (train_str_list, test_str_list, train_df_list, test_df_list, train_df, test_df, X_train, y_train, X_test, y_test)\n",
    "del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-fence",
   "metadata": {},
   "source": [
    "#### Training Vollebekk, Test Staur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-marriage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T12:01:31.099439Z",
     "start_time": "2021-11-01T12:01:30.994175Z"
    }
   },
   "outputs": [],
   "source": [
    "train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                   train_field = 'Vollebekk', \n",
    "                                                   test_field = 'Staur', \n",
    "                                                   year = '2020')\n",
    "\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "for x in train_str_list:\n",
    "    train_df_list.append(locals()[x])\n",
    "for x in test_str_list:\n",
    "    test_df_list.append(locals()[x])\n",
    "\n",
    "train_df = pd.concat(train_df_list)\n",
    "test_df = pd.concat(test_df_list)\n",
    "\n",
    "X_train = train_df[training_features]\n",
    "y_train = train_df[target_features].values.ravel()\n",
    "X_test = test_df[training_features]\n",
    "y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "# Getting scores using cross_val_score\n",
    "for model in models:\n",
    "    importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "        model, X_train, y_train, X_test, y_test)\n",
    "    if importances is not None:\n",
    "        plot_feat_imp(importances,\n",
    "                      model,\n",
    "                      training_features,\n",
    "                      threshold=threshold_all,\n",
    "                      sort_feat=sorted_all)\n",
    "    save_results(model=model,\n",
    "                 agg_method=agg_method,\n",
    "                 train_field=train_str_list,\n",
    "                 test_field=test_str_list,\n",
    "                 training_features=training_features,\n",
    "                 importances=importances,\n",
    "                 RMSE_test=RMSE_test_temp,\n",
    "                 RMSE_train=RMSE_train_temp,\n",
    "                 R2_test=R2_test_temp,\n",
    "                 R2_train=R2_train_temp,\n",
    "                 GKF_CV=GKF_CV_temp)\n",
    "del (train_str_list, test_str_list, train_df_list, test_df_list, train_df, test_df, X_train, y_train, X_test, y_test)\n",
    "del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-penguin",
   "metadata": {},
   "source": [
    "### 2019 Vollebekk vs 2019 Staur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-content",
   "metadata": {},
   "source": [
    "#### Training Staur, Test Vollebekk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-paris",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T12:01:56.838551Z",
     "start_time": "2021-11-01T12:01:56.786202Z"
    }
   },
   "outputs": [],
   "source": [
    "train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                   train_field = 'Staur', \n",
    "                                                   test_field = 'Vollebekk', \n",
    "                                                   year = '2019')\n",
    "\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "for x in train_str_list:\n",
    "    train_df_list.append(locals()[x])\n",
    "for x in test_str_list:\n",
    "    test_df_list.append(locals()[x])\n",
    "\n",
    "train_df = pd.concat(train_df_list)\n",
    "test_df = pd.concat(test_df_list)\n",
    "\n",
    "X_train = train_df[training_features]\n",
    "y_train = train_df[target_features].values.ravel()\n",
    "X_test = test_df[training_features]\n",
    "y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "# Getting scores using cross_val_score\n",
    "for model in models:\n",
    "    importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "        model, X_train, y_train, X_test, y_test)\n",
    "    if importances is not None:\n",
    "        plot_feat_imp(importances,\n",
    "                      model,\n",
    "                      training_features,\n",
    "                      threshold=threshold_all,\n",
    "                      sort_feat=sorted_all)\n",
    "    save_results(model=model,\n",
    "                 agg_method=agg_method,\n",
    "                 train_field=train_str_list,\n",
    "                 test_field=test_str_list,\n",
    "                 training_features=training_features,\n",
    "                 importances=importances,\n",
    "                 RMSE_test=RMSE_test_temp,\n",
    "                 RMSE_train=RMSE_train_temp,\n",
    "                 R2_test=R2_test_temp,\n",
    "                 R2_train=R2_train_temp,\n",
    "                 GKF_CV=GKF_CV_temp)\n",
    "del (train_str_list, test_str_list, train_df_list, test_df_list, train_df, test_df, X_train, y_train, X_test, y_test)\n",
    "del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-nickel",
   "metadata": {},
   "source": [
    "#### Training Vollebekk, Test Staur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-wednesday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T12:02:02.473352Z",
     "start_time": "2021-11-01T12:02:02.401154Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                   train_field = 'Vollebekk', \n",
    "                                                   test_field = 'Staur', \n",
    "                                                   year = '2019')\n",
    "\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "for x in train_str_list:\n",
    "    train_df_list.append(locals()[x])\n",
    "for x in test_str_list:\n",
    "    test_df_list.append(locals()[x])\n",
    "\n",
    "train_df = pd.concat(train_df_list)\n",
    "test_df = pd.concat(test_df_list)\n",
    "\n",
    "X_train = train_df[training_features]\n",
    "y_train = train_df[target_features].values.ravel()\n",
    "X_test = test_df[training_features]\n",
    "y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "# Getting scores using cross_val_score\n",
    "for model in models:\n",
    "    importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "        model, X_train, y_train, X_test, y_test)\n",
    "    if importances is not None:\n",
    "        plot_feat_imp(importances,\n",
    "                      model,\n",
    "                      training_features,\n",
    "                      threshold=threshold_all,\n",
    "                      sort_feat=sorted_all)\n",
    "    save_results(model=model,\n",
    "                 agg_method=agg_method,\n",
    "                 train_field=train_str_list,\n",
    "                 test_field=test_str_list,\n",
    "                 training_features=training_features,\n",
    "                 importances=importances,\n",
    "                 RMSE_test=RMSE_test_temp,\n",
    "                 RMSE_train=RMSE_train_temp,\n",
    "                 R2_test=R2_test_temp,\n",
    "                 R2_train=R2_train_temp,\n",
    "                 GKF_CV=GKF_CV_temp)\n",
    "del (train_str_list, test_str_list, train_df_list, test_df_list, train_df, test_df, X_train, y_train, X_test, y_test)\n",
    "del (importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-grammar",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-helen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "persistent-stage",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-startup",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-26T23:24:40.960614Z",
     "start_time": "2021-10-26T23:24:04.037Z"
    }
   },
   "source": [
    "# Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-failing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:17:41.848209Z",
     "start_time": "2021-11-01T11:17:41.828139Z"
    }
   },
   "outputs": [],
   "source": [
    "results_csv = pd.read_csv(export_path+'results_org.csv')\n",
    "res_df = results_csv[['Aggregation_method','Train_field', 'Test_field', 'RMSE_test', 'RMSE_train',\n",
    "       'R2_test', 'R2_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-midnight",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:27:20.939571Z",
     "start_time": "2021-11-01T11:27:20.912905Z"
    }
   },
   "outputs": [],
   "source": [
    "res_simp = res_df[res_df.Aggregation_method == 'Simpsons']\n",
    "res_simp.drop(['Aggregation_method'], axis=1, inplace=True)\n",
    "res_simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-repeat",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:27:53.878318Z",
     "start_time": "2021-11-01T11:27:53.861212Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_res_df = np.array(res_simp.iloc[49:-1,4:])\n",
    "plot_res_df = plot_res_df.astype(np.float)\n",
    "plot_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-peter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:28:07.601648Z",
     "start_time": "2021-11-01T11:28:07.427352Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "matrix = plot_res_df\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "xpos = [range(matrix.shape[0])]\n",
    "ypos = [range(matrix.shape[1])]\n",
    "xpos, ypos = np.meshgrid(xpos, ypos)\n",
    "xpos = xpos.flatten('F')\n",
    "ypos = ypos.flatten('F')\n",
    "zpos = np.zeros_like(xpos)\n",
    "\n",
    "dx = 0.5 * np.ones_like(zpos)\n",
    "dy = dx.copy()\n",
    "dz = matrix.flatten()\n",
    "\n",
    "ax.bar3d(xpos, ypos, zpos, dx, dy, dz,  zsort='average')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-kingdom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-question",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:22:06.786146Z",
     "start_time": "2021-11-01T11:22:06.649895Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "x, y = np.random.rand(2, 100) * 4\n",
    "hist, xedges, yedges = np.histogram2d(x, y, bins=4, range=[[0, 4], [0, 4]])\n",
    "\n",
    "# Construct arrays for the anchor positions of the 16 bars.\n",
    "xpos, ypos = np.meshgrid(xedges[:-1] + 0.25, yedges[:-1] + 0.25, indexing=\"ij\")\n",
    "xpos = xpos.ravel()\n",
    "ypos = ypos.ravel()\n",
    "zpos = 0\n",
    "\n",
    "# Construct arrays with the dimensions for the 16 bars.\n",
    "dx = dy = 0.5 * np.ones_like(zpos)\n",
    "dz = hist.ravel()\n",
    "\n",
    "ax.bar3d(xpos, ypos, zpos, dx, dy, dz, zsort='average')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-stanley",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-01T11:22:25.746094Z",
     "start_time": "2021-11-01T11:22:25.731456Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-faculty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T00:04:22.117512Z",
     "start_time": "2021-10-29T00:04:22.111656Z"
    }
   },
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-negative",
   "metadata": {},
   "source": [
    "# GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-latvia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T13:26:40.038309Z",
     "start_time": "2021-11-02T13:26:40.024401Z"
    }
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-james",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T00:30:12.174576Z",
     "start_time": "2021-11-02T00:30:12.161119Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold_all = 'top_25'\n",
    "sorted_all = True\n",
    "agg_method = 'Simpsons'\n",
    "# agg_method = 'Trapezoid'\n",
    "# training_features = base_indices + spectral_indices + environment_var\n",
    "# training_features = base_indices + spectral_indices + weather_features\n",
    "training_features =  spectral_indices + weather_features\n",
    "# training_features = spectral_indices\n",
    "\n",
    "target_features\n",
    "\n",
    "group_feature = ['Name']\n",
    "\n",
    "if agg_method == 'Simpsons':\n",
    "    all_df_now = all_df_simps.copy()\n",
    "elif agg_method == 'Trapezoid': \n",
    "    all_df_now = all_df_trapz.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-antarctica",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T20:16:41.223502Z",
     "start_time": "2021-11-02T20:16:41.198347Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_list = [x for x in all_df_now if not 'Robot' in x]\n",
    "\n",
    "# Making list of df for conct before training\n",
    "# This is different form list of srtings, as this is a list of actual dataframes\n",
    "df_list = []\n",
    "for x in temp_list:\n",
    "    df_list.append(locals()[x])\n",
    "\n",
    "df_ = pd.concat(df_list)\n",
    "\n",
    "X = df_[training_features].values\n",
    "y = df_[target_features].values\n",
    "groups = df_[group_feature].values.ravel()\n",
    "\n",
    "gkf = list(GroupKFold(n_splits=6).split(X, y, groups))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-doubt",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-accordance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T00:30:30.563329Z",
     "start_time": "2021-11-02T00:30:30.551361Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = ['neg_root_mean_squared_error', 'r2']\n",
    "cv = 5\n",
    "core = 6\n",
    "verbos = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a3922",
   "metadata": {},
   "source": [
    "## Trying several models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-surgery",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-pasta",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T20:14:12.487316Z",
     "start_time": "2021-11-02T20:14:12.477819Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = ['neg_root_mean_squared_error', 'r2']\n",
    "cv = 5\n",
    "core = 6\n",
    "verbos = 5\n",
    "\n",
    "#==============================================================================\n",
    "# RandomForestRegressor\n",
    "#==============================================================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "param_grid = {\n",
    "    'model__n_estimators': n_estimators,\n",
    "#                'model__max_features': max_features,\n",
    "#                'model__max_depth': max_depth,\n",
    "#                'model__min_samples_split': min_samples_split,\n",
    "#                'model__min_samples_leaf': min_samples_leaf,\n",
    "               'model__bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "# for score in scores:\n",
    "# grid(Xtrain = X,\n",
    "#             ytrain = y,\n",
    "#             estimator = pipe,\n",
    "#             params_grid = param_grid,\n",
    "#             scores=scores,\n",
    "#             cvs = cv,\n",
    "#             cores=core,\n",
    "#             verb=verbos)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-millennium",
   "metadata": {},
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# GradientBoostingRegressor\n",
    "#==============================================================================\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# param_grid   =  [{'model__loss' : ['ls', 'lad', 'huber', 'quantile'],\n",
    "# #                   'model__learning_rate' : [0.001, 0.01, 0.1, 1],\n",
    "# #                   'model__n_estimators' : range(0,500, 100),\n",
    "                  \n",
    "# #                   'model__max_depth':range(5,16,2), \n",
    "# #                   'model__min_samples_split':range(200,1100, 200), # 2100\n",
    "# #                   'model__min_samples_leaf':range(30,71,10),\n",
    "#                   'model__max_features':range(7,20,2),\n",
    "#                   'model__subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}]\n",
    "\n",
    "param_grid   =  [{'model__loss' : ['huber'],\n",
    "#                   'model__learning_rate' : [0.001, 0.01, 0.1, 1],\n",
    "#                   'model__n_estimators' : range(0,500, 100),\n",
    "                  \n",
    "                  'model__max_depth':range(5,16,2), \n",
    "#                   'model__min_samples_split':range(2,5), # 2100\n",
    "#                   'model__min_samples_leaf':range(1,2),\n",
    "#                   'model__max_features':range(5,6),\n",
    "                  'model__subsample':[0.7,0.8]}]\n",
    "# pipe.get_params()\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X.values,\n",
    "                ytrain = y.values,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-george",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Lasso\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__alpha' : [x*0.1 for x in range(1,10)],\n",
    "                  'model__max_iter' : [x for x in range(50, 10000, 50)],\n",
    "                  'model__selection' : ['cyclic','random']}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-assignment",
   "metadata": {},
   "source": [
    "### Ridge Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Ridge\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__alpha' : [x*1. for x in range(1,10)],\n",
    "                  'model__solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-australian",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# ElasticNet\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__alpha' : [x*0.1 for x in range(1,10)],\n",
    "                  'model__max_iter' : [x for x in range(50, 10000, 50)],\n",
    "                  'model__l1_ratio' : [x*0.1 for x in range(1,10)]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-environment",
   "metadata": {},
   "source": [
    "### OrthogonalMatchingPursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# OrthogonalMatchingPursuit\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "model = OrthogonalMatchingPursuit()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__fit_intercept' : [True, False],\n",
    "                  'model__n_nonzero_coefs' : [x for x in range(1,10)]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-parliament",
   "metadata": {},
   "source": [
    "### BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# BayesianRidge\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "model = BayesianRidge()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__n_iter' : [x for x in range(5, 150, 10)],\n",
    "                  'model__alpha_1' : [1.0],\n",
    "                  'model__alpha_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_1' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_2' : [1.0]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-escape",
   "metadata": {},
   "source": [
    "### ARDRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# ARDRegression\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import ARDRegression\n",
    "model = ARDRegression()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__n_iter' : [x for x in range(5, 150, 10)],\n",
    "                  'model__alpha_1' : [1.0],\n",
    "#                       'model__alpha_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_1' : [0.01],\n",
    "                  'model__lambda_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__verbose' : [True]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-synthesis",
   "metadata": {},
   "source": [
    "### RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# RANSACRegressor\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "model = RANSACRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__min_samples' : [x/.1 for x in range(1, 10)],\n",
    "                  'model__max_trials' : [x for x in range(1, 500,50)],\n",
    "                  'model__loss' : ['absolute_loss', 'squared_loss']}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-calgary",
   "metadata": {},
   "source": [
    "### TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# TheilSenRegressor\n",
    "#==============================================================================\n",
    "# from sklearn.linear_model import TheilSenRegressor\n",
    "# model = TheilSenRegressor()\n",
    "# sc = StandardScaler()\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# param_grid   =  [{'model__max_subpopulation' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "#                   'model__n_subsamples' : [x for x in range(9, 1300,50)],\n",
    "#                   'model__max_iter' :  [x for x in range(50, 1000, 50)]}]\n",
    "# estimator = pipe\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X,\n",
    "#                 ytrain = y,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=core,\n",
    "#                 verb=verbos)\n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-amplifier",
   "metadata": {},
   "source": [
    "### HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# HuberRegressor\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "model = HuberRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__epsilon' : [x/.01 for x in range(100, 200, 5)],\n",
    "                  'model__alpha' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-operator",
   "metadata": {},
   "source": [
    "### DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# DecisionTreeRegressor\n",
    "#==============================================================================\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__max_depth' : [None]+[x for x in range(1, 100,5)],\n",
    "                  'model__min_samples_leaf' : [x for x in range(1, 50,5)],\n",
    "                  'model__min_samples_split' : [2]+[x for x in range(1, 50,5)],\n",
    "                  'model__max_features' : [x for x in range(1, 10)]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-paraguay",
   "metadata": {},
   "source": [
    "### GaussianProcessRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# GaussianProcessRegressor\n",
    "#==============================================================================\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "model = GaussianProcessRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__kernel' : [None]+['rbf', 'sigmoid',  'linear', 'poly'],\n",
    "                  'model__alpha' : [x*0.0000000001 for x in [1,10,100,1000,10000,100000,1000000]]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-spider",
   "metadata": {},
   "source": [
    "### KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# KNeighborsRegressor\n",
    "#==============================================================================\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__n_neighbors' : [x for x in range(1, 100,5)],\n",
    "                  'model__weights' : ['uniform', 'distance'],\n",
    "                  'model__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                  'model__leaf_size' : [x for x in range(10, 50, 5)]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-score",
   "metadata": {},
   "source": [
    "### RadiusNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #==============================================================================\n",
    "# # RadiusNeighborsRegressor\n",
    "# #==============================================================================\n",
    "# from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "# model = RadiusNeighborsRegressor()\n",
    "# sc = StandardScaler()\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# param_grid   =  [{'model__radius' : [x*1. for x in range(1, 10)],\n",
    "#                   'model__weights' : ['uniform', 'distance'],\n",
    "#                   'model__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#                   'model__p' : [x for x in range(1, 10)]}]\n",
    "# estimator = pipe\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X,\n",
    "#                 ytrain = y,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=core,\n",
    "#                 verb=verbos)\n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-secretary",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab8b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T08:50:55.236435Z",
     "start_time": "2021-11-02T00:46:16.441777Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #==============================================================================\n",
    "# # SVR\n",
    "# #==============================================================================\n",
    "# from sklearn.svm import SVR\n",
    "# model = SVR()\n",
    "# sc = StandardScaler()\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# param_grid   =  [{'model__radius' : [x*1. for x in range(1, 10)],\n",
    "#                   'model__weights' : ['uniform', 'distance'],\n",
    "#                   'model__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#                   'model__p' : [x for x in range(1, 10)]}]\n",
    "# estimator = pipe\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X,\n",
    "#                 ytrain = y,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=core,\n",
    "#                 verb=verbos)\n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-france",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# RandomForestRegressor\n",
    "#==============================================================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__max_depth' : [x for x in range(1, 10)],\n",
    "                  'model__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'model__n_estimators' : [x for x in range(1, 1000, 50)]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_end = time.time()\n",
    "# tt = t_end - t_start\n",
    "# time_taken.append(tt)\n",
    "# print('Total time complete: ', (tt) / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a5ce0",
   "metadata": {},
   "source": [
    "## Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ac980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T00:04:29.929134Z",
     "start_time": "2021-10-29T00:04:29.847072Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# PERMUTATION\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "result = permutation_importance(gs_xgb_fitted, X_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "# ==================================\n",
    "# Feature selection\n",
    "# ===================================\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# define feature selection\n",
    "fs = SelectKBest(score_func=f_regression, k=10)\n",
    "# apply feature selection\n",
    "X_selected = fs.fit_transform(X, y)\n",
    "print(X_selected.shape)\n",
    "\n",
    "# Plot importances\n",
    "fig, ax = plt.subplots(figsize=(25, 25))\n",
    "ind = indices = np.argsort(result.importances_mean)[::-1]\n",
    "plt.barh(X_test.columns, result.importances_mean[ind])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea56464",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T00:04:29.932062Z",
     "start_time": "2021-10-29T00:04:29.848Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1': make_scorer(f1_score, average = 'macro')}\n",
    "grid_search_rfc = GridSearchCV(rfc, param_grid = grid_values, scoring = scoring, refit='f1')\n",
    "grid_search_rfc.fit(x_train, y_train)\n",
    "\n",
    "grid_search_rfc.best_params_\n",
    "grid_search_rfc.cv_results_\n",
    "\n",
    "# cv_results[mean_test_<metric_name>]\n",
    "grid_search_rfc.cv_results_['mean_test_recall']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-temple",
   "metadata": {},
   "source": [
    "## Restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-parliament",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-29T00:04:32.293Z"
    },
    "hide_output": false,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-consultancy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "350.547px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "801px",
    "left": "1469px",
    "right": "20px",
    "top": "130px",
    "width": "446px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
