{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of Data Science Special Syllabus Report, I am going to use the data from Robot Field for the year 2020. Following is a summary of the field and the dates when the data was collected from the field.\n",
    "\n",
    "\n",
    "Date of data collections  \n",
    "Subvplots in the field  \n",
    "Distribution of dates in the season  \n",
    "Days to heading  \n",
    "Days to maturity  \n",
    "Sowing dates  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "from copy import copy\n",
    "import pprint # pretty print\n",
    "import time\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To display df nicely in loops\n",
    "from IPython.display import display \n",
    "# display(df1.head()) \n",
    "# display(df2.head())\n",
    "\n",
    "# Display rows and columns Pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('display.max_rows',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fahad\\\\Documents\\\\GitHub\\\\vPheno\\\\DS Special Syllabus Report\\\\Code'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the current workinig directory\n",
    "os.getcwd()\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw',\n",
       " 'Robot_2020_mean_fixed_rows.csv',\n",
       " 'Robot_2020_median_fixed_rows.csv',\n",
       " 'Robot_2020_stdev_fixed_rows.csv',\n",
       " 'Robot_fixed_cols.csv']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './Data/'\n",
    "list_data = os.listdir(path)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hello: 100%|███████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 27.10files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot_2020_mean_fixed_rows ===== (96, 114)\n",
      "Robot_2020_median_fixed_rows ===== (96, 114)\n",
      "Robot_2020_stdev_fixed_rows ===== (96, 114)\n",
      "Robot_fixed_cols ===== (1344, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import_data = []\n",
    "for csv_data in tqdm(list_data, desc=\"hello\", unit=\"files\"):\n",
    "    if os.path.isfile(os.path.join(path, csv_data)):\n",
    "        df_name = csv_data[:-4]\n",
    "        import_data.append(df_name)\n",
    "\n",
    "        locals()[df_name] = pd.read_csv(path+csv_data)\n",
    "        print(df_name, '=====', locals()[df_name].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the median fixed rows dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Robot_2020_median_fixed_rows.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"GrainYield_180620\" column in features_df seems like the yield column as it contains the text \"GrainYield\". It is located at location 9\n"
     ]
    }
   ],
   "source": [
    "# ToDo: Add check for duplicate columns in the df\n",
    "\n",
    "general_col_names = ['Plot_ID', 'Blue', 'Green', 'Red', 'RedEdge', 'NIR', 'NDVI', 'MTCI', 'EVI']\n",
    "\n",
    "# list_agg_df\n",
    "yield_cols = ['GrainYield', 'Days2Heading', 'Days2Maturity']\n",
    "id_cols_new = ['Plot_ID']\n",
    "\n",
    "# Counter for location of column in columns list\n",
    "loc = 0\n",
    "\n",
    "# Dict for saving the name and location of the yield column\n",
    "loc_yield_cols = {}\n",
    "\n",
    "for cols in df.columns.tolist():\n",
    "    for y_col in yield_cols:\n",
    "        if not cols.find(y_col):\n",
    "            loc_yield_cols[cols] = loc\n",
    "            print(f'\\\"{cols}\\\" column in features_df seems like the yield column as it contains the text \\\"{y_col}\\\". It is located at location {loc}')\n",
    "    loc += 1\n",
    "\n",
    "yield_cols_found = list(loc_yield_cols.keys())\n",
    "target_cols=yield_cols_found[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating the data from different dates using simpsonian integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "from numpy import trapz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2020, 4, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sowing = '200420'\n",
    "sowing_date = datetime.datetime.strptime(sowing, '%d%m%y').date()\n",
    "sowing_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>GrainYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>453.658537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>439.024390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Plot_ID  GrainYield\n",
       "0     1101  453.658537\n",
       "1     1102  439.024390"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aoc = df[id_cols_new+yield_cols_found]\n",
    "# Renaming Grain_Yield Column #custom\n",
    "df_aoc.columns = [df_aoc.columns[0]]+['GrainYield']\n",
    "df_aoc.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expermienting with different integration methods to find AOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_entry =[]\n",
    "# list_s = []\n",
    "# list_trap = []\n",
    "# list_simp = []\n",
    "# list_saha = []\n",
    "\n",
    "# for sample in range(df.shape[0]):\n",
    "#     temp_cols = [x for x in df.columns if 'NIR' in x]\n",
    "\n",
    "#     temp_entries= [df[x][sample] for x in temp_cols]\n",
    "#     temp_dates = [datetime.datetime.strptime(date.split('_')[1], '%d%m%y').date() for date in temp_cols]\n",
    "#     days_sow = [(x-sowing_date).days for x in temp_dates]\n",
    "\n",
    "#     # df[[x for x in df.columns if 'NIR' in x]]\n",
    "#     plt.plot(days_sow, temp_entries)\n",
    "    \n",
    "#     data={'x':x,'y':y }\n",
    "#     ACC=[]\n",
    "#     A=pd.DataFrame(data, columns=['x','y'])\n",
    "#     AA=0\n",
    "#     for item in range(A.shape[0]-1):\n",
    "#         Ans=(float((A['y'][item]))+float((A['y'][item+1])))*((float((A['x'][item+1]))-float((A['x'][item]))))/2\n",
    "#         AA+=Ans\n",
    "# #         print(AA)\n",
    "#         ACC.append(AA)\n",
    "#     list_saha.append(AA)\n",
    "    \n",
    "#     x=np.array(days_sow)\n",
    "#     y=np.array(temp_entries)\n",
    "#     s = np.sum((x[1:] - x[:-1]) * (y[1:] + y[:-1]) / 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     list_s.append(s)\n",
    "#     list_trap.append(trapz(y,x))\n",
    "#     list_simp.append(simps(y,x))\n",
    "#     sample_entry.append(df[temp_cols[0]][sample])\n",
    "    \n",
    "# #     print(s)\n",
    "# #     print(trapz(y,x))\n",
    "# #     print(simps(y,x))\n",
    "# #     print(AA)\n",
    "# #     print('================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Printing the curves after calculating AOC\n",
    "# plt.plot(list_s)\n",
    "# plt.plot(list_trap)\n",
    "# plt.plot(list_saha)\n",
    "# plt.plot(list_simp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Printing each date as separate curve \n",
    "# for c in range(len(temp_cols)):\n",
    "#     plt.plot(df[temp_cols[c]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating AOC and creating new df with calculated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-048a32d2e782>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_aoc[col_name] = list_simp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>GrainYield</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>RedEdge</th>\n",
       "      <th>NIR</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>MTCI</th>\n",
       "      <th>EVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>453.658537</td>\n",
       "      <td>1.270117</td>\n",
       "      <td>3.574804</td>\n",
       "      <td>2.897804</td>\n",
       "      <td>8.875004</td>\n",
       "      <td>22.631580</td>\n",
       "      <td>40.903291</td>\n",
       "      <td>101.076190</td>\n",
       "      <td>-57.085557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>439.024390</td>\n",
       "      <td>1.495092</td>\n",
       "      <td>3.805574</td>\n",
       "      <td>3.254111</td>\n",
       "      <td>8.629345</td>\n",
       "      <td>20.161066</td>\n",
       "      <td>39.491722</td>\n",
       "      <td>97.146457</td>\n",
       "      <td>-38.910446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>409.756098</td>\n",
       "      <td>1.584922</td>\n",
       "      <td>3.948306</td>\n",
       "      <td>3.583516</td>\n",
       "      <td>8.738324</td>\n",
       "      <td>20.017410</td>\n",
       "      <td>38.085365</td>\n",
       "      <td>97.189108</td>\n",
       "      <td>-36.327292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>474.796748</td>\n",
       "      <td>1.444589</td>\n",
       "      <td>3.644177</td>\n",
       "      <td>3.156694</td>\n",
       "      <td>8.220482</td>\n",
       "      <td>19.640018</td>\n",
       "      <td>39.638214</td>\n",
       "      <td>102.365282</td>\n",
       "      <td>-37.747704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>411.382114</td>\n",
       "      <td>1.585311</td>\n",
       "      <td>3.905583</td>\n",
       "      <td>3.562433</td>\n",
       "      <td>8.761889</td>\n",
       "      <td>19.879974</td>\n",
       "      <td>38.147208</td>\n",
       "      <td>97.511420</td>\n",
       "      <td>-36.440043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1808</td>\n",
       "      <td>429.268293</td>\n",
       "      <td>1.520981</td>\n",
       "      <td>3.417367</td>\n",
       "      <td>3.202223</td>\n",
       "      <td>7.372470</td>\n",
       "      <td>17.024002</td>\n",
       "      <td>37.054909</td>\n",
       "      <td>101.300436</td>\n",
       "      <td>-30.625083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1809</td>\n",
       "      <td>414.634146</td>\n",
       "      <td>1.314370</td>\n",
       "      <td>3.146503</td>\n",
       "      <td>2.671316</td>\n",
       "      <td>6.870374</td>\n",
       "      <td>17.281909</td>\n",
       "      <td>39.580252</td>\n",
       "      <td>100.968635</td>\n",
       "      <td>-33.955230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1810</td>\n",
       "      <td>460.162602</td>\n",
       "      <td>1.551308</td>\n",
       "      <td>3.470261</td>\n",
       "      <td>3.015670</td>\n",
       "      <td>7.287466</td>\n",
       "      <td>17.290667</td>\n",
       "      <td>38.144403</td>\n",
       "      <td>99.040498</td>\n",
       "      <td>-31.795544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1811</td>\n",
       "      <td>443.902439</td>\n",
       "      <td>1.523404</td>\n",
       "      <td>3.377721</td>\n",
       "      <td>3.066436</td>\n",
       "      <td>7.192470</td>\n",
       "      <td>16.868812</td>\n",
       "      <td>37.260574</td>\n",
       "      <td>103.795235</td>\n",
       "      <td>-30.559981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1812</td>\n",
       "      <td>375.609756</td>\n",
       "      <td>1.394805</td>\n",
       "      <td>3.067711</td>\n",
       "      <td>2.801119</td>\n",
       "      <td>6.453812</td>\n",
       "      <td>16.205135</td>\n",
       "      <td>37.558512</td>\n",
       "      <td>111.527448</td>\n",
       "      <td>-30.015493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Plot_ID  GrainYield      Blue     Green       Red   RedEdge        NIR  \\\n",
       "0      1101  453.658537  1.270117  3.574804  2.897804  8.875004  22.631580   \n",
       "1      1102  439.024390  1.495092  3.805574  3.254111  8.629345  20.161066   \n",
       "2      1103  409.756098  1.584922  3.948306  3.583516  8.738324  20.017410   \n",
       "3      1104  474.796748  1.444589  3.644177  3.156694  8.220482  19.640018   \n",
       "4      1105  411.382114  1.585311  3.905583  3.562433  8.761889  19.879974   \n",
       "..      ...         ...       ...       ...       ...       ...        ...   \n",
       "91     1808  429.268293  1.520981  3.417367  3.202223  7.372470  17.024002   \n",
       "92     1809  414.634146  1.314370  3.146503  2.671316  6.870374  17.281909   \n",
       "93     1810  460.162602  1.551308  3.470261  3.015670  7.287466  17.290667   \n",
       "94     1811  443.902439  1.523404  3.377721  3.066436  7.192470  16.868812   \n",
       "95     1812  375.609756  1.394805  3.067711  2.801119  6.453812  16.205135   \n",
       "\n",
       "         NDVI        MTCI        EVI  \n",
       "0   40.903291  101.076190 -57.085557  \n",
       "1   39.491722   97.146457 -38.910446  \n",
       "2   38.085365   97.189108 -36.327292  \n",
       "3   39.638214  102.365282 -37.747704  \n",
       "4   38.147208   97.511420 -36.440043  \n",
       "..        ...         ...        ...  \n",
       "91  37.054909  101.300436 -30.625083  \n",
       "92  39.580252  100.968635 -33.955230  \n",
       "93  38.144403   99.040498 -31.795544  \n",
       "94  37.260574  103.795235 -30.559981  \n",
       "95  37.558512  111.527448 -30.015493  \n",
       "\n",
       "[96 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for col_name in general_col_names[1:]:\n",
    "    list_simp = []\n",
    "    temp_cols = [x for x in df.columns if col_name+'_' in x]\n",
    "    temp_dates = [datetime.datetime.strptime(date.split('_')[1], '%d%m%y').date() for date in temp_cols]\n",
    "    days_sow = [(x-sowing_date).days for x in temp_dates]\n",
    "\n",
    "    for sample in range(df.shape[0]):\n",
    "\n",
    "        temp_entries= [df[x][sample] for x in temp_cols]\n",
    "        list_simp.append(simps(temp_entries,days_sow))\n",
    "#     print(temp_cols)\n",
    "\n",
    "#     plt.plot(list_simp)\n",
    "    plt.show()\n",
    "    df_aoc[col_name] = list_simp\n",
    "df_aoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Trends Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Correlation heatmap of indices with target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Identify Dates and index with problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take average or delete dates with problems, out of trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecxclude the problematic data/dates\n",
    "or\n",
    "### Take average values where the problematic data is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup  \n",
    "Remove dates which have drop  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using on more columns data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Plot_ID', 'GrainYield', 'Blue', 'Green', 'Red', 'RedEdge', 'NIR',\n",
       "       'NDVI', 'MTCI', 'EVI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = df_aoc.copy()\n",
    "features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"GrainYield\" column in features_df seems like the yield column as it contains the text \"GrainYield\". It is located at location 1\n"
     ]
    }
   ],
   "source": [
    "# ToDo: Add check for duplicate columns in the features_df\n",
    "\n",
    "# list_agg_df\n",
    "yield_cols = ['GrainYield', 'Days2Heading', 'Days2Maturity']\n",
    "id_cols_new = ['Plot_ID']\n",
    "\n",
    "# Counter for location of column in columns list\n",
    "loc = 0\n",
    "\n",
    "# Dict for saving the name and location of the yield column\n",
    "loc_yield_cols = {}\n",
    "\n",
    "for cols in features_df.columns.tolist():\n",
    "    for y_col in yield_cols:\n",
    "        if not cols.find(y_col):\n",
    "            loc_yield_cols[cols] = loc\n",
    "            print(f'\\\"{cols}\\\" column in features_df seems like the yield column as it contains the text \\\"{y_col}\\\". It is located at location {loc}')\n",
    "    loc += 1\n",
    "\n",
    "yield_cols_found = list(loc_yield_cols.keys())\n",
    "target_cols=yield_cols_found[0]\n",
    "\n",
    "# # Droping yield columns, i.e. target variables and Plot_ID column\n",
    "# features_df.drop(columns = yield_cols_found+id_cols_new)\n",
    "# features_df[yield_cols_found]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Initializing the comments to be appended to results\n",
    "#==============================================================================\n",
    "\n",
    "comments = []\n",
    "comments.append('Median data only')\n",
    "comments.append('EVI included.')\n",
    "comments.append('Robot_2020_median_fixed_rows dataset.')\n",
    "comments.append(str(Robot_2020_median_fixed_rows.shape))\n",
    "comments.append('All data stacked as new columns.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Split dataframe into data and target\n",
    "#==============================================================================\n",
    "\n",
    "temp_X = features_df.drop(columns = yield_cols_found+id_cols_new)\n",
    "y = features_df[target_cols]\n",
    "# y = features_df[target_cols].values.flatten()\n",
    "comments.append('Drop Plot_ID.')\n",
    "comments.append('GrainYield Target.')\n",
    "X = temp_X.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>RedEdge</th>\n",
       "      <th>NIR</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>MTCI</th>\n",
       "      <th>EVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.270117</td>\n",
       "      <td>3.574804</td>\n",
       "      <td>2.897804</td>\n",
       "      <td>8.875004</td>\n",
       "      <td>22.631580</td>\n",
       "      <td>40.903291</td>\n",
       "      <td>101.076190</td>\n",
       "      <td>-57.085557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.495092</td>\n",
       "      <td>3.805574</td>\n",
       "      <td>3.254111</td>\n",
       "      <td>8.629345</td>\n",
       "      <td>20.161066</td>\n",
       "      <td>39.491722</td>\n",
       "      <td>97.146457</td>\n",
       "      <td>-38.910446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.584922</td>\n",
       "      <td>3.948306</td>\n",
       "      <td>3.583516</td>\n",
       "      <td>8.738324</td>\n",
       "      <td>20.017410</td>\n",
       "      <td>38.085365</td>\n",
       "      <td>97.189108</td>\n",
       "      <td>-36.327292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.444589</td>\n",
       "      <td>3.644177</td>\n",
       "      <td>3.156694</td>\n",
       "      <td>8.220482</td>\n",
       "      <td>19.640018</td>\n",
       "      <td>39.638214</td>\n",
       "      <td>102.365282</td>\n",
       "      <td>-37.747704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.585311</td>\n",
       "      <td>3.905583</td>\n",
       "      <td>3.562433</td>\n",
       "      <td>8.761889</td>\n",
       "      <td>19.879974</td>\n",
       "      <td>38.147208</td>\n",
       "      <td>97.511420</td>\n",
       "      <td>-36.440043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.520981</td>\n",
       "      <td>3.417367</td>\n",
       "      <td>3.202223</td>\n",
       "      <td>7.372470</td>\n",
       "      <td>17.024002</td>\n",
       "      <td>37.054909</td>\n",
       "      <td>101.300436</td>\n",
       "      <td>-30.625083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.314370</td>\n",
       "      <td>3.146503</td>\n",
       "      <td>2.671316</td>\n",
       "      <td>6.870374</td>\n",
       "      <td>17.281909</td>\n",
       "      <td>39.580252</td>\n",
       "      <td>100.968635</td>\n",
       "      <td>-33.955230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1.551308</td>\n",
       "      <td>3.470261</td>\n",
       "      <td>3.015670</td>\n",
       "      <td>7.287466</td>\n",
       "      <td>17.290667</td>\n",
       "      <td>38.144403</td>\n",
       "      <td>99.040498</td>\n",
       "      <td>-31.795544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1.523404</td>\n",
       "      <td>3.377721</td>\n",
       "      <td>3.066436</td>\n",
       "      <td>7.192470</td>\n",
       "      <td>16.868812</td>\n",
       "      <td>37.260574</td>\n",
       "      <td>103.795235</td>\n",
       "      <td>-30.559981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.394805</td>\n",
       "      <td>3.067711</td>\n",
       "      <td>2.801119</td>\n",
       "      <td>6.453812</td>\n",
       "      <td>16.205135</td>\n",
       "      <td>37.558512</td>\n",
       "      <td>111.527448</td>\n",
       "      <td>-30.015493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Blue     Green       Red   RedEdge        NIR       NDVI        MTCI  \\\n",
       "0   1.270117  3.574804  2.897804  8.875004  22.631580  40.903291  101.076190   \n",
       "1   1.495092  3.805574  3.254111  8.629345  20.161066  39.491722   97.146457   \n",
       "2   1.584922  3.948306  3.583516  8.738324  20.017410  38.085365   97.189108   \n",
       "3   1.444589  3.644177  3.156694  8.220482  19.640018  39.638214  102.365282   \n",
       "4   1.585311  3.905583  3.562433  8.761889  19.879974  38.147208   97.511420   \n",
       "..       ...       ...       ...       ...        ...        ...         ...   \n",
       "91  1.520981  3.417367  3.202223  7.372470  17.024002  37.054909  101.300436   \n",
       "92  1.314370  3.146503  2.671316  6.870374  17.281909  39.580252  100.968635   \n",
       "93  1.551308  3.470261  3.015670  7.287466  17.290667  38.144403   99.040498   \n",
       "94  1.523404  3.377721  3.066436  7.192470  16.868812  37.260574  103.795235   \n",
       "95  1.394805  3.067711  2.801119  6.453812  16.205135  37.558512  111.527448   \n",
       "\n",
       "          EVI  \n",
       "0  -57.085557  \n",
       "1  -38.910446  \n",
       "2  -36.327292  \n",
       "3  -37.747704  \n",
       "4  -36.440043  \n",
       "..        ...  \n",
       "91 -30.625083  \n",
       "92 -33.955230  \n",
       "93 -31.795544  \n",
       "94 -30.559981  \n",
       "95 -30.015493  \n",
       "\n",
       "[96 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "#==============================================================================\n",
    "# Defining the function to vaiidate the model with the test data and \n",
    "# get the results from regression evaluation metrices in sklearn\n",
    "#==============================================================================\n",
    "pred = []\n",
    "acc = []\n",
    "def test_data_regression(model):\n",
    "    pred = []\n",
    "    accuracy = {}\n",
    "    #==============================================================================\n",
    "    # Make predictions for test set\n",
    "    #==============================================================================\n",
    "\n",
    "    # Predict classes for samples in test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    features = X.columns\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    #==============================================================================\n",
    "    # Compute performance\n",
    "    #==============================================================================\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(y_test, y_pred, squared=True)\n",
    "    print(mse, ' mean_squared_error')\n",
    "#     accuracy.append(rmse)\n",
    "    accuracy['MSE'] = mse\n",
    "    \n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print(rmse, ' root_mean_squared_error')\n",
    "#     accuracy.append(rmse)\n",
    "    accuracy['RMSE'] = rmse\n",
    "\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(r2, ' r2_score')\n",
    "    accuracy['R2 Score'] = r2\n",
    "\n",
    "    acc.append(accuracy)\n",
    "    # Print accuracy computed from predictions on the test set\n",
    "    pp = pprint.PrettyPrinter(indent=4, width=80, depth=None, stream=None, compact=True, sort_dicts=False)\n",
    "    pp.pprint(accuracy)\n",
    "    \n",
    "    #==============================================================================\n",
    "    # Append Results\n",
    "    #==============================================================================\n",
    "    results = []\n",
    "    import datetime\n",
    "    datetime = datetime.datetime.now()\n",
    "    results.append(np.concatenate((np.array((model, mse, rmse, r2, accuracy, datetime, features, importances), dtype=object), np.array(comments))))\n",
    "#     results.extend(np.array(comments)) \n",
    "    print(results)\n",
    "    pd.DataFrame(np.asarray(results)).to_csv('results.csv',\n",
    "                                             mode='a',\n",
    "                                             header=None)\n",
    "    pred.extend(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid and Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(Xtrain,\n",
    "         ytrain,\n",
    "         estimator,\n",
    "         params_grid,\n",
    "         scores,\n",
    "         cvs,\n",
    "         cores,\n",
    "         verb):\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    gs = GridSearchCV(estimator=estimator,\n",
    "                      param_grid=params_grid,\n",
    "                      scoring=scores,\n",
    "                      cv=cvs,\n",
    "                      n_jobs=cores,\n",
    "                      verbose=verb)\n",
    "\n",
    "    gs = gs.fit(Xtrain, ytrain)\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    \n",
    "    t2 = time.time()\n",
    "\n",
    "    # Saving results to csv file\n",
    "    results = []\n",
    "    import datetime\n",
    "    datetime = datetime.datetime.now()\n",
    "\n",
    "    results.append(np.concatenate((np.array((gs.best_estimator_, gs, score, gs.best_score_, gs.best_params_, \n",
    "                             (t2 - t1) / 60, datetime), dtype=object), np.array(comments))))\n",
    "\n",
    "    pd.DataFrame(np.asarray(results)).to_csv('results.csv',\n",
    "                                             mode='a',\n",
    "                                             header=None)\n",
    "\n",
    "    print('Total time: ', (t2 - t1) / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "2748.887272918082  mean_squared_error\n",
      "52.42983189862506  root_mean_squared_error\n",
      "0.7216384614772118  r2_score\n",
      "{   'MSE': 2748.887272918082,\n",
      "    'RMSE': 52.42983189862506,\n",
      "    'R2 Score': 0.7216384614772118}\n",
      "[array([RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0),\n",
      "       2748.887272918082, 52.42983189862506, 0.7216384614772118,\n",
      "       {'MSE': 2748.887272918082, 'RMSE': 52.42983189862506, 'R2 Score': 0.7216384614772118},\n",
      "       datetime.datetime(2021, 5, 11, 11, 10, 46, 306275),\n",
      "       Index(['Blue', 'Green', 'Red', 'RedEdge', 'NIR', 'NDVI', 'MTCI', 'EVI'], dtype='object'),\n",
      "       array([0.02338744, 0.01643927, 0.04886216, 0.01477096, 0.0364987 ,\n",
      "       0.13912615, 0.62735129, 0.09356403]),\n",
      "       'Median data only', 'EVI included.',\n",
      "       'Robot_2020_median_fixed_rows dataset.', '(96, 114)',\n",
      "       'All data stacked as new columns.', 'Drop Plot_ID.',\n",
      "       'GrainYield Target.', 'Converted dates to ordinal.',\n",
      "       'Plot ID Dropped.',\n",
      "       'Test train split. test_Size=0.3, random_state=55'], dtype=object)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11130.995499800152  mean_squared_error\n",
      "105.50353311524762  root_mean_squared_error\n",
      "-0.1271619113451139  r2_score\n",
      "{   'MSE': 11130.995499800152,\n",
      "    'RMSE': 105.50353311524762,\n",
      "    'R2 Score': -0.1271619113451139}\n",
      "[array([RandomForestRegressor(max_depth=100, min_samples_split=400, n_estimators=50,\n",
      "                      n_jobs=-1, random_state=0),\n",
      "       11130.995499800152, 105.50353311524762, -0.1271619113451139,\n",
      "       {'MSE': 11130.995499800152, 'RMSE': 105.50353311524762, 'R2 Score': -0.1271619113451139},\n",
      "       datetime.datetime(2021, 5, 11, 11, 10, 46, 869901),\n",
      "       Index(['Blue', 'Green', 'Red', 'RedEdge', 'NIR', 'NDVI', 'MTCI', 'EVI'], dtype='object'),\n",
      "       array([0., 0., 0., 0., 0., 0., 0., 0.]), 'Median data only',\n",
      "       'EVI included.', 'Robot_2020_median_fixed_rows dataset.',\n",
      "       '(96, 114)', 'All data stacked as new columns.', 'Drop Plot_ID.',\n",
      "       'GrainYield Target.', 'Converted dates to ordinal.',\n",
      "       'Plot ID Dropped.',\n",
      "       'Test train split. test_Size=0.3, random_state=55'], dtype=object)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAa5UlEQVR4nO3deZRlZX3u8e9DM8tk7FYR0TaoQWVJK4VjciXREKcICWogOBCNxOFqjBeNXokL1ESN16hJjKaXUXACxRiuch3AIEZJq1QDzWCcGAyjKUTGtAPt7/6x38JjUdVVtbuqzqnu72ets2qfd79779/btbqeevc+tXeqCkmS5mu7YRcgSVqeDBBJUi8GiCSpFwNEktSLASJJ6sUAkST1YoBIknoxQDRSklyZZGOS2wZe91mAfT5poWqcw/FOSPKRpTre5iQ5JslXh12Htk4GiEbR71bVbgOva4dZTJLth3n8vpZr3Vo+DBAtC0n2TPJPSa5Lck2SNydZ0dbtl+TsJD9MckOSjybZq637MHA/4DNtNvOaJIckuXrK/u+cpbQZxCeTfCTJLcAxmzv+HGqvJC9N8t0ktyZ5U6t5XZJbknwiyY6t7yFJrk7yv9tYrkxy9JR/hw8lmUjy/STHJ9murTsmyblJ3pnkRuDjwPuAx7ax39T6PS3JBe3YVyU5YWD/q1u9z0/yn62G1w+sX9Fqu6yNZX2Sfdu6/ZOcleTGJN9O8uyB7Z6a5Jttm2uSHDfHb71GmAGi5eJk4A7ggcAjgEOBP27rArwFuA/wEGBf4ASAqnou8J/8Ylbz13M83mHAJ4G9gI/Ocvy5eDJwEPAY4DXAWuDoVusBwFEDfe8NrAT2AZ4PrE3ya23d3wF7Ar8KPAF4HvBHA9s+GrgcuCfwHODFwLo29r1an9vbdnsBTwNekuTwKfX+OvBrwBOBNyR5SGt/Vav1qcAewAuA/05yN+As4GPt2EcB/5DkYW27fwL+pKp2b+M9e/Z/Mo06A0Sj6PQkN7XX6UnuBTwFeGVV3V5V/wW8EzgSoKq+V1VnVdVPqmoC+Bu6H65bYl1VnV5VP6f7QTnj8efobVV1S1VdClwCnFlVl1fVzcDn6EJp0F+08XwZ+H/As9uM5w+A11XVrVV1JfAO4LkD211bVX9XVXdU1cbpCqmqc6rq4qr6eVVdBJzCXf+9TqyqjVW1AdgAHNja/xg4vqq+XZ0NVfVD4OnAlVX1wXbs84F/Bp7ZtvsZ8NAke1TVj9p6LXOeI9UoOryqvjj5JsmjgB2A65JMNm8HXNXW3xP4W+A3gN3buh9tYQ1XDSzff3PHn6MfDCxvnOb9vQfe/6iqbh94/3262dVKYMf2fnDdPjPUPa0kjwbeSjcT2BHYCThtSrfrB5b/G9itLe8LXDbNbu8PPHryNFmzPfDhtnwEcDzw1iQXAa+tqnWz1arR5gxEy8FVwE+AlVW1V3vtUVWTp0feAhTw8Krag+7UTQa2n3rL6duBXSfftN/sV03pM7jNbMdfaHdvp4Qm3Q+4FriB7jf5+09Zd80MdU/3HrrTTJ8G9q2qPemuk2SaftO5CthvhvYvD/z77NVOm70EoKrOq6rD6E5vnQ58Yo7H0wgzQDTyquo64EzgHUn2SLJduwg9edpld+A24KYk+wCvnrKLH9BdM5j0HWDndjF5B7rfjHfaguMvhhOT7JjkN+hOD51WVZvofvD+ZZLdk9yf7prE5j4y/APgvpMX6ZvdgRur6sdtdveH86jr/cCbkjwonYcnuQdwBvDgJM9NskN7HZzkIW0cRyfZs6p+BtwCbJrHMTWiDBAtF8+jO93yTbrTU58E9m7rTgQeCdxMd73gU1O2fQtwfLumcly77vBSuh+G19DNSK5m8zZ3/IV2fTvGtXQX8F9cVd9q615OV+/lwFfpZhMf2My+zgYuBa5PckNreynwxiS3Am9gfrOBv2n9z6QLgn8CdqmqW+k+WHBkq/t64G38IpifC1zZPtX2YrpZopa5+EApaXQkOQT4SFXdd8ilSLNyBiJJ6sUAkST14iksSVIvzkAkSb1sM39IuHLlylq9evWwy5CkZWX9+vU3VNXUv5MCtqEAWb16NePj48MuQ5KWlSTfn2mdp7AkSb0YIJKkXgwQSVIvBogkqRcDRJLUiwEiSerFAJEk9WKASJJ6MUAkSb0YIJKkXgwQSVIvBogkqRcDRJLUiwEiSerFAJEk9TJyzwNJsgm4eKDpVGBnYKeqet1AvzXAKVX1kCRXAmNVdcNS1ipJ27KRCxBgY1WtGWxI8mvA54DXDTQfCXxsCeuSJA1YFqewqurbwE1JHj3Q/Gy62YkkaQhGMUB2SXLhwOsPWvspdLMOkjwG+GFVfXdzO0pybJLxJOMTExOLXLYkbVuWxSms5lTg35P8L7ogOWW2HVXVWmAtwNjYWC1kkZK0rRvFAJlWVV3VLpY/ATgCeOxwK5KkbdsonsLanFOAdwKXVdXVwy5GkrZloxggU6+BvHVg3WnAw/DiuSQN3cidwqqqFZtZNwHsME376sWsSZJ0V6M4A5EkLQMGiCSpFwNEktSLASJJ6sUAkST1YoBIknoxQCRJvRggkqReDBBJUi8GiCSpFwNEktSLASJJ6sUAkST1YoBIknoxQCRJvRggkqReDBBJUi9LHiBJKsmHB95vn2QiyRlJ/mjgUbY/TXLx5GNtk9w7yalJLkvyzSSfTfLgJKuTXLLU45Ckbd0wHml7O3BAkl2qaiPw28A1AFX1QeCDAEmuBH6zqm5IEuDfgZOr6si2fg1wL+CqJR+BJGlop7A+BzytLR8FnDJL/98EflZV75tsqKoLq+ori1SfJGkWwwqQU4Ejk+wMPBz4+iz9DwDWz/cgSY5NMp5kfGJiokeZkqSZDCVAquoiYDXd7OOzi3ictVU1VlVjq1atWqzDSNI2aZifwvo08H+Y/fQVwKXAQYtbjiRpPoYZIB8A3lhVF8+h79nATkleNNmQ5OAkT1i06iRJmzW0AKmqq6vq3XPsW8DvAb/dPsZ7KXACcO0ilihJ2owl/xhvVe02Tds5wDlT2lZPeX8t8OwZdnvAwlQnSZor/xJdktSLASJJ6sUAkST1YoBIknoxQCRJvRggkqReDBBJUi8GiCSpFwNEktSLASJJ6sUAkST1YoBIknoxQCRJvRggkqReDBBJUi8GiCSplyUNkCSV5B0D749LckJbPiHJNUkuTPLdJJ9K8tC27qQkfzJlX4cn+Wxbvm0JhyFJYulnID8Bfj/JyhnWv7Oq1lTVg4CPA2cnWQWcAhw5pe+RrV2SNARLHSB3AGuBP5utY1V9HDgT+EPgi8D+SfYGSLIr8CTg9EWrVJK0WcO4BvIe4Ogke86h7/nA/lW1CfgUv3gm+jOAL1XVrZvbOMmxScaTjE9MTGxR0ZKkX7bkAVJVtwAfAl4xh+4ZWB48jTWn01dVtbaqxqpqbNWqVfOuVZI0s2F9CutdwAuBu83S7xHAf7Tlc4G9kxwIPA747KJVJ0ma1VACpKpuBD5BFyLTSnIEcChtplFV1bY5GfhsVf14CUqVJM1gmH8H8g5g6qex/mzyY7zAc4DfqqrBixenAAcCpy5RjZKkGWy/lAerqt0Gln8A7Drw/gTghFm2v4Bfvi5yl/1KkpaGf4kuSerFAJEk9WKASJJ6MUAkSb0YIJKkXgwQSVIvBogkqRcDRJLUiwEiSerFAJEk9WKASJJ6MUAkSb0YIJKkXgwQSVIvBogkqRcDRJLUy0gFSJJK8o6B98clOaEtn5DkuLZ8UpIr2tMLNyR54pBKlqRt1kgFCPAT4PeTTH3U7XReXVVrgFcC71vMoiRJdzVqAXIHsBb4s3lssw7YZ3HKkSTNZNQCBOA9wNFJ9pxj/ycDp0+3IsmxScaTjE9MTCxUfZIkRjBAquoW4EPAK2bp+vYklwMfAf5qhn2traqxqhpbtWrVAlcqSdu2kQuQ5l3AC4G7babPq4EHAscDJy9BTZKkASMZIFV1I/AJuhDZXL+fA+8GtkvyO0tRmySpM5IB0rwDmPXTWFVVwJuB1yx6RZKkO6X7+bv1Gxsbq/Hx8WGXIUnLSpL1VTU23bpRnoFIkkaYASJJ6sUAkST1YoBIknoxQCRJvRggkqReDBBJUi8GiCSpFwNEktSLASJJ6sUAkST1YoBIknoxQCRJvRggkqReDBBJUi8GiCSpFwNEktTLrAGSZFOSC5NckuQzSfaazwGS3Na+rk6yse1r8vW8afofk+Tv53MMSdLS234OfTZW1RqAJCcDLwP+sufxLpvclyRpeZvvKax1wD4ASfZL8vkk65N8Jcn+rf0BSdYlOS/Jm+ay0yR/lOQ7Sb4MPH6gfb8kX2v7euPkbKate3VrvyjJifMchyRpC805QJKsAJ4IfLo1rQVeXlUHAccB/9Da3w28t6oOBq6fspv9ppzC+o0kewMn0gXHbwMPHej/buDdbV/XDtRyKPAg4FHAGuCgJP9jmpqPTTKeZHxiYmKuQ5UkzcFcAmSXJBcCPwR+BTgryW7A44DT2rp/BPZu/R8PnNKWPzxlX5dV1ZqB11eARwPnVNVEVf0U+PhA/8cCp7Xljw20H9peFwDnA/vTBcovqaq1VTVWVWOrVq2aw1AlSXM152sgSfYEzqC7BnIScNNmrmfUPOuYb/8Ab6mqf5zndpKkBTLnU1hVdTPwCrrTVRuBK5I8CyCdA1vXc4Ej2/LRc9j114FDktwjyQ7AswbWfQ04oi0fOdD+BeAFbSZEkn2S3HOuY5Ekbbl5XUSvqguADXQ/zI8GXphkA3ApcFjr9qfAy5KcB+w5ZRdTr4G8oqquA06gu0D/RbpTUpNeCbwqyTfoTpHd3Oo4k+6U1rokFwOfBHafz1gkSVsmVfM9e7R0kuxKdwqtkhwJHFVVh8223XTGxsZqfHx8YQuUpK1ckvVVNTbdurlcAxmmg4C/TxLgJuAFwy1HkjRppAOkfUrrwFk7SpKWnPfCkiT1YoBIknoxQCRJvRggkqReDBBJUi8GiCSpFwNEktSLASJJ6sUAkST1YoBIknoxQCRJvRggkqReDBBJUi8GiCSpl5EIkCSb2hMKL0nymSR7zXP72xapNEnSDEYiQOieOrimqg4AbgReNuyCJEmbN4oPlFoHPBwgyX7Ae4BVwH8DL6qqbyV5AN0z0bcHPj+sQiVpWzYqMxAAkqwAngh8ujWtBV5eVQcBxwH/0NrfDby3qg4Grt/M/o5NMp5kfGJiYhErl6RtT6pq2DWQZBNwMbAaWA8cCuwCTADfHui6U1U9JMkPgXtX1c+S7AFcW1W7be4YY2NjNT4+vij1S9LWKsn6qhqbbt2ozEA2VtUa4P7AjnTXQLYDbmrXRiZfDxnYZvjJJ0nbsFEJEACq6mbgFXSnqzYCVyR5FkA6B7au5wJHtuWjl7xQSdJoBQhAVV0AbKALiKOBFybZAFwKHNa6/SnwsiTnAXsOpVBJ2saNxKewpl6/qKrfHXj75Gn6XwE8dqDprYtUmiRpBiM3A5EkLQ8GiCSpFwNEktSLASJJ6sUAkST1YoBIknoxQCRJvRggkqReDBBJUi8GiCSpFwNEktSLASJJ6sUAkST1YoBIknoxQCRJvRggkqReFi1AktwryceSXJ5kfZJ1SX5vsY4nSVpaixIgSQKcDvxbVf1qVR1E94ja+07pNxJPRJQkzd9izUB+C/hpVb1vsqGqvl9Vf5fkmCSnJfkMcGaSuyX5QJLzklyQ5DCAJCuSvL21X5TkT1r7IUnOSfLJJN9K8tEWWJKkJbRYM4CHAedvZv1jgYdX1Y1J/go4u6pekGQv4BtJvggcDdxcVQcn2Qk4N8mZbftHtGNcC5wLPB746tSDJDkWOBbgfve738KMTJIELNFF9CTvSbIhyXmt6ayqurEtHwq8NsmFwDnAzsD9WvvzWvvXgXsAD2rbfKOqrq6qnwMXAqunO25Vra2qsaoaW7Vq1YKPS5K2ZYs1A7kUOGLyTVW9LMlKYLw13T7QN8ARVfXtwR2001Ivr6ovTGk/BPjJQNMmFm8ckqQZLNYM5Gxg5yQvGWjbdYa+XwBePnkdI8kjBtpfkmSH1v7gJHdbpHolSfO0KAFSVQUcDjwhyRVJvgGcDPz5NN3fBOwAXJTkkvYe4P3AN4HzW/s/4kxDkkZGup/1W7+xsbEaHx+fvaMk6U5J1lfV2HTr/Et0SVIvBogkqRcDRJLUiwEiSerFAJEk9WKASJJ6MUAkSb0YIJKkXgwQSVIvBogkqRcDRJLUiwEiSerFAJEk9WKASJJ6MUAkSb0YIJKkXgwQSVIvQwuQJJuSXJhkQ5Lzkzyuta9uj7CVJI2wYT5jfGNVrQFI8jvAW4AnDLEeSdI8jMoprD2AH01tTHJMkr8feH9GkkPa8qFJ1rXZy2lJdluyaiVJQw2QXdoprG8B7wfeNNcNk6wEjgeeVFWPBMaBV03T79gk40nGJyYmFqpuSRKjcwrrscCHkhwwx20fAzwUODcJwI7AuqmdqmotsBZgbGysFqBmSVIzzAC5U1Wta7OKVVNW3cEvz5J2bl8DnFVVRy1FfZKkuxqJayBJ9gdWAD+csupKYE2S7ZLsCzyqtX8NeHySB7btd03y4KWqV5I03BnILkkubMsBnl9Vm9opqUnnAlcAFwOXAOcDVNVEkmOAU5Ls1PoeD3xnCeqWJDHEAKmqFTO0Xwkc0JYLOHqGfmcDBy9WfZKkzRuJU1iSpOXHAJEk9WKASJJ6MUAkSb0YIJKkXgwQSVIvBogkqRcDRJLUiwEiSerFAJEk9WKASJJ6MUAkSb0YIJKkXgwQSVIv6e6YvvVLMgF8f9h19LASuGHYRSwxx7z129bGC8t3zPevqqlPiwW2oQBZrpKMV9XYsOtYSo5567etjRe2zjF7CkuS1IsBIknqxQAZfWuHXcAQOOat37Y2XtgKx+w1EElSL85AJEm9GCCSpF4MkBGQ5FeSnJXku+3r3Wfo9+Qk307yvSSvnWb9cUkqycrFr7q/LR1vkrcn+VaSi5L8S5K9lqz4eZrD9yxJ/ratvyjJI+e67ajqO+Yk+yb5UpL/SHJpkj9d+ur72ZLvc1u/IskFSc5YuqoXQFX5GvIL+GvgtW35tcDbpumzArgM+FVgR2AD8NCB9fsCX6D7Y8mVwx7TYo4XOBTYvi2/bbrtR+E12/es9Xkq8DkgwGOAr89121F8beGY9wYe2ZZ3B76ztY95YP2rgI8BZwx7PPN5OQMZDYcBJ7flk4HDp+nzKOB7VXV5Vf0UOLVtN+mdwGuA5fCpiC0ab1WdWVV3tH5fA+67uOX2Ntv3jPb+Q9X5GrBXkr3nuO0o6j3mqrquqs4HqKpbgf8A9lnK4nvaku8zSe4LPA14/1IWvRAMkNFwr6q6DqB9vec0ffYBrhp4f3VrI8kzgGuqasNiF7pAtmi8U7yA7je7UTSXMczUZ67jHzVbMuY7JVkNPAL4+sKXuOC2dMzvovvl7+eLVN+i2X7YBWwrknwRuPc0q14/111M01ZJdm37OLRvbYthscY75RivB+4APjq/6pbMrGPYTJ+5bDuKtmTM3cpkN+CfgVdW1S0LWNti6T3mJE8H/quq1ic5ZKELW2wGyBKpqifNtC7JDyan8G1a+1/TdLua7jrHpPsC1wL7AQ8ANiSZbD8/yaOq6voFG8A8LeJ4J/fxfODpwBOrnUQeQZsdwyx9dpzDtqNoS8ZMkh3owuOjVfWpRaxzIW3JmJ8JPCPJU4GdgT2SfKSqnrOI9S6cYV+E8VUAb+eXLyr/9TR9tgcupwuLyQt1D5um35WM/kX0LRov8GTgm8CqYY9llnHO+j2jO/c9eHH1G/P5fo/aawvHHOBDwLuGPY6lGvOUPoewzC6iD70AXwVwD+Bfge+2r7/S2u8DfHag31PpPplyGfD6Gfa1HAJki8YLfI/ufPKF7fW+YY9pM2O9yxiAFwMvbssB3tPWXwyMzef7PYqvvmMGfp3u1M9FA9/bpw57PIv9fR7Yx7ILEG9lIknqxU9hSZJ6MUAkSb0YIJKkXgwQSVIvBogkqRcDRMtakk1JLkxySZLPzHZn3iQnJDlulj6HJ3nowPs3JpnxDyPnUetJSZ65pfuZ5zFf2e5WIC04A0TL3caqWlNVBwA3Ai9bgH0eDtwZIFX1hqr64gLsd0klWQG8EjBAtCgMEG1N1vGLG0zul+TzSdYn+UqS/ad2TvKiJOcl2ZDkn5PsmuRxwDOAt7eZzX6TM4ckT0nyiYHtD0nymbZ8aJJ1Sc5Pclq7n9OMklyZ5K/aNuNJHpnkC0kuS/Ligf3/W3vmyTeTvC/Jdm3dUUkubjOvtw3s97Y2Y/o63X3H7gN8KcmX2vr3tuNdmuTEKfWc2Oq/ePLfK8luST7Y2i5KckSf8WorNey/ZPTla0tewG3t6wrgNODJ7f2/Ag9qy48Gzm7LJwDHteV7DOznzcDL2/JJwDMH1p1Ed8+i7YH/BO7W2t8LPAdYCfzbQPufA2+YptY790t3x4CXtOV30v319e7AKrqb60H3l8k/pnvOxArgrFbHfVodq1pNZwOHt20KePbAMa9k4M4E/OKv/lcA5wAPH+g3Of6XAu9vy29j4NYiwN3nOl5fW//LmylqudslyYXAamA9cFb7bfhxwGntBpMAO02z7QFJ3gzsBexG90CuGVXVHUk+D/xukk/S3d/oNcAT6E55nduOtyPdbGg2n25fLwZ2q+4ZGLcm+fHAtZxvVNXlAElOobvdx8+Ac6pqorV/FPgfwOnAJrqbEc7k2UmOpQuevVvdF7V1kzcvXA/8flt+EnDkwL/Bj9odZPuMV1sZA0TL3caqWpNkT+AMumsgJwE3VdWaWbY9ie439w1JjqH7jX82H2/HuBE4r6puTfdT9KyqOmqetf+kff35wPLk+8n/m1PvNTTTrd4n/biqNk23IskDgOOAg1sQnER3B9ip9WwaOH6mqaHveLWV8RqItgpVdTPwCrofkBuBK5I8C+58HvWB02y2O3Bdu4X40QPtt7Z10zkHeCTwIrowge6piI9P8sB2vF2TPHjLRnSnRyV5QLv28QfAV+kesvSEJCvbhfKjgC/PsP3gWPYAbgduTnIv4ClzOP6ZwP+cfJPu+fWLOV4tIwaIthpVdQHdrbSPpAuEFybZAFzK9I+D/Qu6H8ZnAd8aaD8VeHWSC5LsN+UYm+hmOk9pX2mnko4BTklyEd0P2LtctO9pHfBW4BLgCuBfqnuK4+uAL9GN9/yq+r8zbL8W+FySL1X3xMoL6P49PgCcO4fjvxm4e7tYvwH4zUUer5YR78Yrjah0T6g7rqqePuRSpGk5A5Ek9eIMRJLUizMQSVIvBogkqRcDRJLUiwEiSerFAJEk9fL/ASISj6oB9rclAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=6)]: Done 630 out of 630 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50.29611996197668\n",
      "{'model__alpha': 7.0, 'model__solver': 'svd'}\n",
      "Total time:  0.06516565084457397 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=6)]: Done 630 out of 630 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3834.3483113899083\n",
      "{'model__alpha': 1.0, 'model__solver': 'svd'}\n",
      "Total time:  0.021300848325093588 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=6)]: Done 630 out of 630 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8991181939738405\n",
      "{'model__alpha': 1.0, 'model__solver': 'svd'}\n",
      "Total time:  0.02099459171295166 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 3582 candidates, totalling 35820 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=6)]: Done 9588 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=6)]: Done 13332 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=6)]: Done 17652 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=6)]: Done 22548 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=6)]: Done 28020 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 34068 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 35820 out of 35820 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-49.33198224195268\n",
      "{'model__alpha': 0.6000000000000001, 'model__max_iter': 400, 'model__selection': 'cyclic'}\n",
      "Total time:  1.5343698501586913 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 3582 candidates, totalling 35820 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=6)]: Done 9588 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=6)]: Done 13332 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=6)]: Done 17652 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=6)]: Done 22548 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 28020 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 34068 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 35820 out of 35820 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3743.916526686474\n",
      "{'model__alpha': 0.6000000000000001, 'model__max_iter': 650, 'model__selection': 'random'}\n",
      "Total time:  1.6455735206604003 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 3582 candidates, totalling 35820 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=6)]: Done 9588 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=6)]: Done 13332 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=6)]: Done 17652 tasks      | elapsed:   52.7s\n",
      "[Parallel(n_jobs=6)]: Done 22548 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 28020 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 34068 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 35820 out of 35820 | elapsed:  1.6min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 117611.74970101417, tolerance: 96.68213365241961\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8456708197661401\n",
      "{'model__alpha': 0.1, 'model__max_iter': 50, 'model__selection': 'random'}\n",
      "Total time:  1.629394284884135 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 16119 candidates, totalling 161190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=6)]: Done 12468 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=6)]: Done 18804 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=6)]: Done 26292 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=6)]: Done 34932 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 44724 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 67764 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 81012 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 95412 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done 110964 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=6)]: Done 127668 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=6)]: Done 145524 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=6)]: Done 161190 out of 161190 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50.29104461668186\n",
      "{'model__alpha': 0.1, 'model__l1_ratio': 0.1, 'model__max_iter': 150}\n",
      "Total time:  5.751443262894949 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 16119 candidates, totalling 161190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=6)]: Done 9588 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=6)]: Done 13332 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=6)]: Done 17652 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=6)]: Done 22548 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=6)]: Done 28020 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=6)]: Done 34068 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 40692 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 47892 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 64020 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 72948 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done 82452 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=6)]: Done 92532 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done 103188 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done 114420 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=6)]: Done 126228 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 138612 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=6)]: Done 151572 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=6)]: Done 161190 out of 161190 | elapsed:  5.5min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1750.7407514119113, tolerance: 96.68213365241961\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3840.059990110246\n",
      "{'model__alpha': 0.1, 'model__l1_ratio': 0.9, 'model__max_iter': 200}\n",
      "Total time:  5.546976904074351 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 16119 candidates, totalling 161190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=6)]: Done 9588 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=6)]: Done 13332 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=6)]: Done 17652 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=6)]: Done 22548 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=6)]: Done 28020 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=6)]: Done 34068 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 40692 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 47892 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 64020 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=6)]: Done 72948 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 82452 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done 92532 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=6)]: Done 103188 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done 114420 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=6)]: Done 126228 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 138612 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=6)]: Done 151572 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=6)]: Done 161190 out of 161190 | elapsed:  5.6min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 563.7051274554979, tolerance: 96.68213365241961\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9061214688099849\n",
      "{'model__alpha': 0.1, 'model__l1_ratio': 0.9, 'model__max_iter': 250}\n",
      "Total time:  5.617128038406372 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 132 out of 180 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 180 out of 180 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-47.817585318125495\n",
      "{'model__fit_intercept': True, 'model__n_nonzero_coefs': 5}\n",
      "Total time:  0.006345494588216146 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 132 out of 180 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 180 out of 180 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3523.4783408427306\n",
      "{'model__fit_intercept': True, 'model__n_nonzero_coefs': 5}\n",
      "Total time:  0.006289422512054443 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 132 out of 180 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 180 out of 180 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7800138640372956\n",
      "{'model__fit_intercept': True, 'model__n_nonzero_coefs': 5}\n",
      "Total time:  0.0063448786735534664 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 735 candidates, totalling 7350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=6)]: Done 7350 out of 7350 | elapsed:   17.9s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50.6189341395057\n",
      "{'model__alpha_1': 1.0, 'model__alpha_2': 1.0, 'model__lambda_1': 0.09999999999999999, 'model__lambda_2': 1.0, 'model__n_iter': 5}\n",
      "Total time:  0.30042601029078164 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 735 candidates, totalling 7350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=6)]: Done 7350 out of 7350 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3918.644830300052\n",
      "{'model__alpha_1': 1.0, 'model__alpha_2': 1e-06, 'model__lambda_1': 1e-06, 'model__lambda_2': 1.0, 'model__n_iter': 5}\n",
      "Total time:  0.320946458975474 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 735 candidates, totalling 7350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=6)]: Done 7350 out of 7350 | elapsed:   17.9s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9431148535427244\n",
      "{'model__alpha_1': 1.0, 'model__alpha_2': 1e-06, 'model__lambda_1': 0.01, 'model__lambda_2': 1.0, 'model__n_iter': 5}\n",
      "Total time:  0.30062615871429443 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 105 candidates, totalling 1050 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=6)]: Done 996 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 1050 out of 1050 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50.36070590193573\n",
      "{'model__alpha_1': 1.0, 'model__lambda_1': 0.01, 'model__lambda_2': 1e-06, 'model__n_iter': 5, 'model__verbose': True}\n",
      "Total time:  0.06771658658981324 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 105 candidates, totalling 1050 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=6)]: Done 996 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=6)]: Done 1050 out of 1050 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4057.8100892650573\n",
      "{'model__alpha_1': 1.0, 'model__lambda_1': 0.01, 'model__lambda_2': 1e-06, 'model__n_iter': 5, 'model__verbose': True}\n",
      "Total time:  0.06587016582489014 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 105 candidates, totalling 1050 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=6)]: Done 996 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 1050 out of 1050 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0047844703306208\n",
      "{'model__alpha_1': 1.0, 'model__lambda_1': 0.01, 'model__lambda_2': 1e-06, 'model__n_iter': 5, 'model__verbose': True}\n",
      "Total time:  0.06816068092981974 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 180 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done 720 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=6)]: Done 1032 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=6)]: Done 1530 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=6)]: Done 1789 out of 1800 | elapsed:   42.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 1800 out of 1800 | elapsed:   42.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-45.41036495480905\n",
      "{'model__loss': 'squared_loss', 'model__max_trials': 401, 'model__min_samples': 60.0}\n",
      "Total time:  0.7162825663884481 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 180 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=6)]: Done 684 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=6)]: Done 1188 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=6)]: Done 1674 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=6)]: Done 1800 out of 1800 | elapsed:   41.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3171.5276974938065\n",
      "{'model__loss': 'squared_loss', 'model__max_trials': 1, 'model__min_samples': 80.0}\n",
      "Total time:  0.6949450095494588 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 180 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 720 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=6)]: Done 996 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=6)]: Done 1536 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=6)]: Done 1800 out of 1800 | elapsed:   41.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5381303635117227\n",
      "{'model__loss': 'squared_loss', 'model__max_trials': 101, 'model__min_samples': 50.0}\n",
      "Total time:  0.6905596653620402 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 140 candidates, totalling 1400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 180 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=6)]: Done 540 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 1044 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=6)]: Done 1400 out of 1400 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-49.5784829730065\n",
      "{'model__alpha': 0.001, 'model__epsilon': 14500.0}\n",
      "Total time:  0.1619510054588318 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 140 candidates, totalling 1400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 180 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=6)]: Done 540 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 1044 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=6)]: Done 1400 out of 1400 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3780.448689244392\n",
      "{'model__alpha': 0.001, 'model__epsilon': 14500.0}\n",
      "Total time:  0.15577459732691448 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 140 candidates, totalling 1400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 180 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=6)]: Done 540 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 1044 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=6)]: Done 1400 out of 1400 | elapsed:    8.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8925059885024738\n",
      "{'model__alpha': 0.01, 'model__epsilon': 15500.0}\n",
      "Total time:  0.14591933091481527 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 20790 candidates, totalling 207900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=6)]: Done 12468 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=6)]: Done 18804 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=6)]: Done 26292 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=6)]: Done 34932 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 44724 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 67764 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 81012 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 95412 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=6)]: Done 110964 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 127668 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=6)]: Done 145524 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 164532 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=6)]: Done 184692 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=6)]: Done 206004 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=6)]: Done 207900 out of 207900 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-40.77264668788656\n",
      "{'model__max_depth': 6, 'model__max_features': 3, 'model__min_samples_leaf': 6, 'model__min_samples_split': 21}\n",
      "Total time:  6.293520092964172 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 20790 candidates, totalling 207900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=6)]: Done 12468 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=6)]: Done 18804 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=6)]: Done 26292 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=6)]: Done 34932 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 44724 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 67764 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=6)]: Done 81012 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done 95412 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 110964 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done 127668 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=6)]: Done 145524 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=6)]: Done 164532 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=6)]: Done 184692 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=6)]: Done 206004 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=6)]: Done 207900 out of 207900 | elapsed:  6.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2828.0438855105117\n",
      "{'model__max_depth': 71, 'model__max_features': 5, 'model__min_samples_leaf': 16, 'model__min_samples_split': 6}\n",
      "Total time:  6.531809771060944 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 20790 candidates, totalling 207900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=6)]: Done 12468 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=6)]: Done 18804 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=6)]: Done 26292 tasks      | elapsed:   50.1s\n",
      "[Parallel(n_jobs=6)]: Done 34932 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 44724 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 67764 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 81012 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 95412 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=6)]: Done 110964 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done 127668 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=6)]: Done 145524 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=6)]: Done 164532 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=6)]: Done 184692 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=6)]: Done 206004 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=6)]: Done 207900 out of 207900 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3107810695712801\n",
      "{'model__max_depth': 76, 'model__max_features': 6, 'model__min_samples_leaf': 16, 'model__min_samples_split': 36}\n",
      "Total time:  6.564848347504934 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 237 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=6)]: Done 350 out of 350 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-90.6742892572214\n",
      "{'model__alpha': 0.0001, 'model__kernel': None}\n",
      "Total time:  0.01716504096984863 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 237 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=6)]: Done 350 out of 350 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14272.243561984811\n",
      "{'model__alpha': 0.0001, 'model__kernel': None}\n",
      "Total time:  0.017407302061716715 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 237 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 350 out of 350 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.0215694254389405\n",
      "{'model__alpha': 0.0001, 'model__kernel': None}\n",
      "Total time:  0.01773975690205892 minutes\n",
      "r2\n",
      "Fitting 10 folds for each of 1280 candidates, totalling 12800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 86, n_neighbors = 91",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 560, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 607, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n    score = scorer._score(cached_call, estimator,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 206, in _score\n    y_pred = method_caller(estimator, \"predict\", X)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 53, in _cached_call\n    return getattr(estimator, method)(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 119, in <lambda>\n    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 408, in predict\n    return self.steps[-1][-1].predict(Xt, **predict_params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\", line 176, in predict\n    neigh_dist, neigh_ind = self.kneighbors(X)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 616, in kneighbors\n    raise ValueError(\nValueError: Expected n_neighbors <= n_samples,  but n_samples = 86, n_neighbors = 91\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-106bdc26a588>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m     grid(Xtrain = X,\n\u001b[0m\u001b[0;32m    331\u001b[0m                 \u001b[0mytrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                 \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-e0165dbe9c63>\u001b[0m in \u001b[0;36mgrid\u001b[1;34m(Xtrain, ytrain, estimator, params_grid, scores, cvs, cores, verb)\u001b[0m\n\u001b[0;32m     17\u001b[0m                       verbose=verb)\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 86, n_neighbors = 91"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "import time, datetime\n",
    "from datetime import datetime as dt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "comments.append('Converted dates to ordinal.')\n",
    "comments.append('Plot ID Dropped.')\n",
    "\n",
    "comments.append('Test train split. test_Size=0.3, random_state=55')\n",
    "cv = 10\n",
    "core=6\n",
    "verbos=5\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "time_taken = []\n",
    "t_start=time.time()\n",
    "\n",
    "#==============================================================================\n",
    "# Create separate train/test splits\n",
    "#==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=5)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "#==============================================================================\n",
    "# Training best performing models\n",
    "#==============================================================================\n",
    "#==============================================================================\n",
    "# Finding out feature importance\n",
    "#==============================================================================\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 1000, max_depth=250, min_samples_split=5, random_state=0, n_jobs = -1)\n",
    "model.fit(X_train, y_train)\n",
    "# Finding feature importance\n",
    "features = X.columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "# Running predictions\n",
    "test_data_regression(model)\n",
    "# Plotting feature importance\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 50, max_depth=100, min_samples_split=400, random_state=0, n_jobs = -1)\n",
    "model.fit(X_train, y_train)\n",
    "# Finding feature importance\n",
    "features = X.columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "# Running predictions\n",
    "test_data_regression(model)\n",
    "# Plotting feature importance\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "# Ridge\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__alpha' : [x*1. for x in range(1,10)],\n",
    "                  'model__solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# Lasso\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__alpha' : [x*0.1 for x in range(1,10)],\n",
    "                  'model__max_iter' : [x for x in range(50, 10000, 50)],\n",
    "                  'model__selection' : ['cyclic','random']}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# ElasticNet\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__alpha' : [x*0.1 for x in range(1,10)],\n",
    "                  'model__max_iter' : [x for x in range(50, 10000, 50)],\n",
    "                  'model__l1_ratio' : [x*0.1 for x in range(1,10)]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# OrthogonalMatchingPursuit\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "model = OrthogonalMatchingPursuit()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__fit_intercept' : [True, False],\n",
    "                  'model__n_nonzero_coefs' : [x for x in range(1,10)]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# BayesianRidge\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "model = BayesianRidge()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__n_iter' : [x for x in range(5, 150, 10)],\n",
    "                  'model__alpha_1' : [1.0],\n",
    "                  'model__alpha_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_1' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_2' : [1.0]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# ARDRegression\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import ARDRegression\n",
    "model = ARDRegression()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__n_iter' : [x for x in range(5, 150, 10)],\n",
    "                  'model__alpha_1' : [1.0],\n",
    "#                       'model__alpha_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_1' : [0.01],\n",
    "                  'model__lambda_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__verbose' : [True]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# RANSACRegressor\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "model = RANSACRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__min_samples' : [x/.1 for x in range(1, 10)],\n",
    "                  'model__max_trials' : [x for x in range(1, 500,50)],\n",
    "                  'model__loss' : ['absolute_loss', 'squared_loss']}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# TheilSenRegressor\n",
    "#==============================================================================\n",
    "# from sklearn.linear_model import TheilSenRegressor\n",
    "# model = TheilSenRegressor()\n",
    "# sc = StandardScaler()\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# param_grid   =  [{'model__max_subpopulation' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "#                   'model__n_subsamples' : [x for x in range(9, 1300,50)],\n",
    "#                   'model__max_iter' :  [x for x in range(50, 1000, 50)]}]\n",
    "# estimator = pipe\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X,\n",
    "#                 ytrain = y,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=core,\n",
    "#                 verb=verbos)\n",
    "#     print(score)\n",
    "#==============================================================================\n",
    "# HuberRegressor\n",
    "#==============================================================================\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "model = HuberRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__epsilon' : [x/.01 for x in range(100, 200, 5)],\n",
    "                  'model__alpha' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# DecisionTreeRegressor\n",
    "#==============================================================================\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__max_depth' : [None]+[x for x in range(1, 100,5)],\n",
    "                  'model__min_samples_leaf' : [x for x in range(1, 50,5)],\n",
    "                  'model__min_samples_split' : [2]+[x for x in range(1, 50,5)],\n",
    "                  'model__max_features' : [x for x in range(1, 10)]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# GaussianProcessRegressor\n",
    "#==============================================================================\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "model = GaussianProcessRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__kernel' : [None]+['rbf', 'sigmoid',  'linear', 'poly'],\n",
    "                  'model__alpha' : [x*0.0000000001 for x in [1,10,100,1000,10000,100000,1000000]]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "#==============================================================================\n",
    "# KNeighborsRegressor\n",
    "#==============================================================================\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "param_grid   =  [{'model__n_neighbors' : [x for x in range(1, 100,5)],\n",
    "                  'model__weights' : ['uniform', 'distance'],\n",
    "                  'model__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                  'model__leaf_size' : [x for x in range(10, 50, 5)]}]\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)\n",
    "# #==============================================================================\n",
    "# # RadiusNeighborsRegressor\n",
    "# #==============================================================================\n",
    "# from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "# model = RadiusNeighborsRegressor()\n",
    "# sc = StandardScaler()\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# param_grid   =  [{'model__radius' : [x*1. for x in range(1, 10)],\n",
    "#                   'model__weights' : ['uniform', 'distance'],\n",
    "#                   'model__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#                   'model__p' : [x for x in range(1, 10)]}]\n",
    "# estimator = pipe\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X,\n",
    "#                 ytrain = y,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=core,\n",
    "#                 verb=verbos)\n",
    "#     print(score)\n",
    "# #==============================================================================\n",
    "# # RandomForestRegressor\n",
    "# #==============================================================================\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# model = RandomForestRegressor()\n",
    "# sc = StandardScaler()\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# param_grid   =  [{'model__radius' : [x*1. for x in range(1, 10)],\n",
    "#                   'model__weights' : ['uniform', 'distance'],\n",
    "#                   'model__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#                   'model__p' : [x for x in range(1, 10)]}]\n",
    "# estimator = pipe\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X,\n",
    "#                 ytrain = y,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=core,\n",
    "#                 verb=verbos)\n",
    "#     print(score)\n",
    "# #==============================================================================\n",
    "# # SVR\n",
    "# #==============================================================================\n",
    "# from sklearn.svm import SVR\n",
    "# model = SVR()\n",
    "# sc = StandardScaler()\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# param_grid   =  [{'model__radius' : [x*1. for x in range(1, 10)],\n",
    "#                   'model__weights' : ['uniform', 'distance'],\n",
    "#                   'model__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#                   'model__p' : [x for x in range(1, 10)]}]\n",
    "# estimator = pipe\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X,\n",
    "#                 ytrain = y,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=core,\n",
    "#                 verb=verbos)\n",
    "#     print(score)\n",
    "\n",
    "t_end = time.time()\n",
    "tt = t_end - t_start\n",
    "time_taken.append(tt)\n",
    "print('Total time complete: ', (tt) / 60, 'minutes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More models to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=6)]: Done 120 out of 120 | elapsed:   28.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-46.717480315136996\n",
      "{'model__loss': 'huber', 'model__max_depth': 5, 'model__subsample': 0.7}\n",
      "Total time:  0.47979431549708046 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=6)]: Done 120 out of 120 | elapsed:   28.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3579.2473516201994\n",
      "{'model__loss': 'huber', 'model__max_depth': 15, 'model__subsample': 0.7}\n",
      "Total time:  0.49063383738199867 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=6)]: Done 120 out of 120 | elapsed:   29.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6330201429311257\n",
      "{'model__loss': 'huber', 'model__max_depth': 5, 'model__subsample': 0.8}\n",
      "Total time:  0.49445970058441163 minutes\n",
      "r2\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "import time, datetime\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "comments.append('Converted dates to ordinal.')\n",
    "comments.append('Plot ID Dropped.')\n",
    "\n",
    "comments.append('Test train split. test_Size=0.3, random_state=55')\n",
    "cv = 10\n",
    "core=6\n",
    "verbos=5\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "# GradientBoostingRegressor\n",
    "#==============================================================================\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# param_grid   =  [{'model__loss' : ['ls', 'lad', 'huber', 'quantile'],\n",
    "# #                   'model__learning_rate' : [0.001, 0.01, 0.1, 1],\n",
    "# #                   'model__n_estimators' : range(0,500, 100),\n",
    "                  \n",
    "# #                   'model__max_depth':range(5,16,2), \n",
    "# #                   'model__min_samples_split':range(200,1100, 200), # 2100\n",
    "# #                   'model__min_samples_leaf':range(30,71,10),\n",
    "#                   'model__max_features':range(7,20,2),\n",
    "#                   'model__subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}]\n",
    "\n",
    "param_grid   =  [{'model__loss' : ['huber'],\n",
    "#                   'model__learning_rate' : [0.001, 0.01, 0.1, 1],\n",
    "#                   'model__n_estimators' : range(0,500, 100),\n",
    "                  \n",
    "                  'model__max_depth':range(5,16,2), \n",
    "#                   'model__min_samples_split':range(2,5), # 2100\n",
    "#                   'model__min_samples_leaf':range(1,2),\n",
    "#                   'model__max_features':range(5,6),\n",
    "                  'model__subsample':[0.7,0.8]}]\n",
    "# pipe.get_params()\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X.values,\n",
    "                ytrain = y.values,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=6)]: Done 870 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 1446 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 2160 out of 2160 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-44.214065043928905\n",
      "{'model__bootstrap': False, 'model__max_depth': 110, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 2, 'model__min_samples_split': 2}\n",
      "Total time:  2.173795998096466 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=6)]: Done 870 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 1446 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 2160 out of 2160 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3020.381517242362\n",
      "{'model__bootstrap': True, 'model__max_depth': 20, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 1, 'model__min_samples_split': 5}\n",
      "Total time:  2.093098441759745 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=6)]: Done 870 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 1446 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 2160 out of 2160 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16173636699258503\n",
      "{'model__bootstrap': True, 'model__max_depth': 100, 'model__max_features': 'auto', 'model__min_samples_leaf': 2, 'model__min_samples_split': 2}\n",
      "Total time:  2.0905689160029093 minutes\n",
      "r2\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "import time, datetime\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "comments.append('Converted dates to ordinal.')\n",
    "comments.append('Plot ID Dropped.')\n",
    "comments.append('Test train split. test_Size=0.3, random_state=55')\n",
    "cv = 5\n",
    "core=6\n",
    "verbos=5\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "#==============================================================================\n",
    "# RandomForestRegressor\n",
    "#==============================================================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "param_grid = {\n",
    "#     'model__n_estimators': n_estimators,\n",
    "               'model__max_features': max_features,\n",
    "               'model__max_depth': max_depth,\n",
    "               'model__min_samples_split': min_samples_split,\n",
    "               'model__min_samples_leaf': min_samples_leaf,\n",
    "               'model__bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Fitting 5 folds for each of 4320 candidates, totalling 21600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=6)]: Done 870 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=6)]: Done 1446 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=6)]: Done 2166 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=6)]: Done 2580 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=6)]: Done 3030 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=6)]: Done 3516 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=6)]: Done 4038 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=6)]: Done 4596 tasks      | elapsed: 43.1min\n",
      "[Parallel(n_jobs=6)]: Done 5190 tasks      | elapsed: 48.8min\n",
      "[Parallel(n_jobs=6)]: Done 5820 tasks      | elapsed: 55.0min\n",
      "[Parallel(n_jobs=6)]: Done 6486 tasks      | elapsed: 60.8min\n",
      "[Parallel(n_jobs=6)]: Done 7188 tasks      | elapsed: 67.1min\n",
      "[Parallel(n_jobs=6)]: Done 7926 tasks      | elapsed: 74.3min\n",
      "[Parallel(n_jobs=6)]: Done 8700 tasks      | elapsed: 81.8min\n",
      "[Parallel(n_jobs=6)]: Done 9510 tasks      | elapsed: 813.8min\n",
      "[Parallel(n_jobs=6)]: Done 10356 tasks      | elapsed: 824.8min\n",
      "[Parallel(n_jobs=6)]: Done 11238 tasks      | elapsed: 836.8min\n",
      "[Parallel(n_jobs=6)]: Done 12156 tasks      | elapsed: 848.8min\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "import time, datetime\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "comments.append('Converted dates to ordinal.')\n",
    "comments.append('Plot ID Dropped.')\n",
    "comments.append('Test train split. test_Size=0.3, random_state=55')\n",
    "cv = 5\n",
    "core=6\n",
    "verbos=5\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "\n",
    "#==============================================================================\n",
    "# RandomForestRegressor\n",
    "#==============================================================================\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "sc = StandardScaler()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "param_grid = {\n",
    "    'model__n_estimators': n_estimators,\n",
    "               'model__max_features': max_features,\n",
    "               'model__max_depth': max_depth,\n",
    "               'model__min_samples_split': min_samples_split,\n",
    "               'model__min_samples_leaf': min_samples_leaf,\n",
    "               'model__bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X,\n",
    "                ytrain = y,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=core,\n",
    "                verb=verbos)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# PERMUTATION\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "result = permutation_importance(gs_xgb_fitted, X_test, y_test, n_repeats=100, random_state=0)\n",
    "\n",
    "# ==================================\n",
    "# Feature selection\n",
    "# ===================================\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# define feature selection\n",
    "fs = SelectKBest(score_func=f_regression, k=10)\n",
    "# apply feature selection\n",
    "X_selected = fs.fit_transform(X, y)\n",
    "print(X_selected.shape)\n",
    "\n",
    "# Plot importances\n",
    "fig, ax = plt.subplots(figsize=(25, 25))\n",
    "ind = indices = np.argsort(result.importances_mean)[::-1]\n",
    "plt.barh(X_test.columns, result.importances_mean[ind])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'precision': make_scorer(precision_score, average = 'macro'),\n",
    "           'recall': make_scorer(recall_score, average = 'macro'),\n",
    "           'f1': make_scorer(f1_score, average = 'macro')}\n",
    "grid_search_rfc = GridSearchCV(rfc, param_grid = grid_values, scoring = scoring, refit='f1')\n",
    "grid_search_rfc.fit(x_train, y_train)\n",
    "\n",
    "grid_search_rfc.best_params_\n",
    "grid_search_rfc.cv_results_\n",
    "\n",
    "# cv_results[‘mean_test_<metric_name>’]\n",
    "grid_search_rfc.cv_results_['mean_test_recall']\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "354.46px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
