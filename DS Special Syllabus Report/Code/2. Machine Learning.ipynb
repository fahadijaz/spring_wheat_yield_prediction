{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(range(7,20,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of Data Science Special Syllabus Report, I am going to use the data from Robot Field for the year 2020. Following is a summary of the field and the dates when the data was collected from the field.\n",
    "\n",
    "\n",
    "Date of data collections  \n",
    "Subvplots in the field  \n",
    "Distribution of dates in the season  \n",
    "Days to heading  \n",
    "Days to maturity  \n",
    "Sowing dates  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "from copy import copy\n",
    "import pprint # pretty print\n",
    "import time\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To display df nicely in loops\n",
    "from IPython.display import display \n",
    "# display(df1.head()) \n",
    "# display(df2.head())\n",
    "\n",
    "# Display rows and columns Pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('display.max_rows',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fahad\\\\Documents\\\\GitHub\\\\vPheno\\\\DS Special Syllabus Report\\\\Code'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the current workinig directory\n",
    "os.getcwd()\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw',\n",
       " 'Robot_2020_mean_fixed_rows.csv',\n",
       " 'Robot_2020_median_fixed_rows.csv',\n",
       " 'Robot_2020_stdev_fixed_rows.csv',\n",
       " 'Robot_fixed_cols.csv']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './Data/'\n",
    "list_data = os.listdir(path)\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hello: 100%|█████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 104.66files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot_2020_mean_fixed_rows ===== (96, 114)\n",
      "Robot_2020_median_fixed_rows ===== (96, 114)\n",
      "Robot_2020_stdev_fixed_rows ===== (96, 114)\n",
      "Robot_fixed_cols ===== (1344, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import_data = []\n",
    "for csv_data in tqdm(list_data, desc=\"hello\", unit=\"files\"):\n",
    "    if os.path.isfile(os.path.join(path, csv_data)):\n",
    "        df_name = csv_data[:-4]\n",
    "        import_data.append(df_name)\n",
    "\n",
    "        locals()[df_name] = pd.read_csv(path+csv_data)\n",
    "        print(df_name, '=====', locals()[df_name].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Mean and Std_Dev columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>Blue_Median_Value</th>\n",
       "      <th>Green_Median_Value</th>\n",
       "      <th>Red_Median_Value</th>\n",
       "      <th>RedEdge_Median_Value</th>\n",
       "      <th>NIR_Median_Value</th>\n",
       "      <th>NDVI_Median_Value</th>\n",
       "      <th>MTCI_Median_Value</th>\n",
       "      <th>EVI_Median_Value</th>\n",
       "      <th>GrainYield</th>\n",
       "      <th>Days2Heading</th>\n",
       "      <th>Days2Maturity</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.051635</td>\n",
       "      <td>0.028147</td>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.465755</td>\n",
       "      <td>0.885390</td>\n",
       "      <td>2.803551</td>\n",
       "      <td>-1.261239</td>\n",
       "      <td>453.658537</td>\n",
       "      <td>62</td>\n",
       "      <td>109</td>\n",
       "      <td>2020-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.055910</td>\n",
       "      <td>0.035009</td>\n",
       "      <td>0.145149</td>\n",
       "      <td>0.458687</td>\n",
       "      <td>0.858816</td>\n",
       "      <td>2.861652</td>\n",
       "      <td>-1.100831</td>\n",
       "      <td>439.024390</td>\n",
       "      <td>62</td>\n",
       "      <td>113</td>\n",
       "      <td>2020-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>0.026808</td>\n",
       "      <td>0.057188</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.149912</td>\n",
       "      <td>0.468715</td>\n",
       "      <td>0.863303</td>\n",
       "      <td>2.768063</td>\n",
       "      <td>-1.156627</td>\n",
       "      <td>409.756098</td>\n",
       "      <td>60</td>\n",
       "      <td>106</td>\n",
       "      <td>2020-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.048598</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.131659</td>\n",
       "      <td>0.455760</td>\n",
       "      <td>0.874434</td>\n",
       "      <td>3.206094</td>\n",
       "      <td>-1.163352</td>\n",
       "      <td>474.796748</td>\n",
       "      <td>61</td>\n",
       "      <td>110</td>\n",
       "      <td>2020-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>0.029282</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>0.153574</td>\n",
       "      <td>0.473269</td>\n",
       "      <td>0.858489</td>\n",
       "      <td>2.720606</td>\n",
       "      <td>-1.136098</td>\n",
       "      <td>411.382114</td>\n",
       "      <td>61</td>\n",
       "      <td>106</td>\n",
       "      <td>2020-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>1808</td>\n",
       "      <td>0.033788</td>\n",
       "      <td>0.062602</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.250196</td>\n",
       "      <td>0.490993</td>\n",
       "      <td>1.428498</td>\n",
       "      <td>-0.273772</td>\n",
       "      <td>429.268293</td>\n",
       "      <td>61</td>\n",
       "      <td>105</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>1809</td>\n",
       "      <td>0.025289</td>\n",
       "      <td>0.053867</td>\n",
       "      <td>0.065721</td>\n",
       "      <td>0.147120</td>\n",
       "      <td>0.267604</td>\n",
       "      <td>0.601344</td>\n",
       "      <td>1.501041</td>\n",
       "      <td>-0.383402</td>\n",
       "      <td>414.634146</td>\n",
       "      <td>60</td>\n",
       "      <td>102</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>1810</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.067794</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.162150</td>\n",
       "      <td>0.280264</td>\n",
       "      <td>0.569404</td>\n",
       "      <td>1.406162</td>\n",
       "      <td>-0.352456</td>\n",
       "      <td>460.162602</td>\n",
       "      <td>62</td>\n",
       "      <td>107</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>1811</td>\n",
       "      <td>0.032249</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.236998</td>\n",
       "      <td>0.487644</td>\n",
       "      <td>1.384678</td>\n",
       "      <td>-0.262991</td>\n",
       "      <td>443.902439</td>\n",
       "      <td>62</td>\n",
       "      <td>105</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>1812</td>\n",
       "      <td>0.025546</td>\n",
       "      <td>0.045265</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>0.121298</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>0.515266</td>\n",
       "      <td>1.909100</td>\n",
       "      <td>-0.267007</td>\n",
       "      <td>375.609756</td>\n",
       "      <td>61</td>\n",
       "      <td>105</td>\n",
       "      <td>2020-07-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Plot_ID  Blue_Median_Value  Green_Median_Value  Red_Median_Value  \\\n",
       "0        1101           0.021905            0.051635          0.028147   \n",
       "1        1102           0.028108            0.055910          0.035009   \n",
       "2        1103           0.026808            0.057188          0.034401   \n",
       "3        1104           0.024750            0.048598          0.030623   \n",
       "4        1105           0.029282            0.059577          0.035984   \n",
       "...       ...                ...                 ...               ...   \n",
       "1339     1808           0.033788            0.062602          0.084690   \n",
       "1340     1809           0.025289            0.053867          0.065721   \n",
       "1341     1810           0.034920            0.067794          0.076857   \n",
       "1342     1811           0.032249            0.059999          0.080487   \n",
       "1343     1812           0.025546            0.045265          0.069339   \n",
       "\n",
       "      RedEdge_Median_Value  NIR_Median_Value  NDVI_Median_Value  \\\n",
       "0                 0.142298          0.465755           0.885390   \n",
       "1                 0.145149          0.458687           0.858816   \n",
       "2                 0.149912          0.468715           0.863303   \n",
       "3                 0.131659          0.455760           0.874434   \n",
       "4                 0.153574          0.473269           0.858489   \n",
       "...                    ...               ...                ...   \n",
       "1339              0.153530          0.250196           0.490993   \n",
       "1340              0.147120          0.267604           0.601344   \n",
       "1341              0.162150          0.280264           0.569404   \n",
       "1342              0.146993          0.236998           0.487644   \n",
       "1343              0.121298          0.217778           0.515266   \n",
       "\n",
       "      MTCI_Median_Value  EVI_Median_Value  GrainYield  Days2Heading  \\\n",
       "0              2.803551         -1.261239  453.658537            62   \n",
       "1              2.861652         -1.100831  439.024390            62   \n",
       "2              2.768063         -1.156627  409.756098            60   \n",
       "3              3.206094         -1.163352  474.796748            61   \n",
       "4              2.720606         -1.136098  411.382114            61   \n",
       "...                 ...               ...         ...           ...   \n",
       "1339           1.428498         -0.273772  429.268293            61   \n",
       "1340           1.501041         -0.383402  414.634146            60   \n",
       "1341           1.406162         -0.352456  460.162602            62   \n",
       "1342           1.384678         -0.262991  443.902439            62   \n",
       "1343           1.909100         -0.267007  375.609756            61   \n",
       "\n",
       "      Days2Maturity        Date  \n",
       "0               109  2020-07-01  \n",
       "1               113  2020-07-01  \n",
       "2               106  2020-07-01  \n",
       "3               110  2020-07-01  \n",
       "4               106  2020-07-01  \n",
       "...             ...         ...  \n",
       "1339            105  2020-07-30  \n",
       "1340            102  2020-07-30  \n",
       "1341            107  2020-07-30  \n",
       "1342            105  2020-07-30  \n",
       "1343            105  2020-07-30  \n",
       "\n",
       "[1344 rows x 13 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_all = Robot_fixed_cols.columns\n",
    "mean_cols = columns_all[columns_all.str.contains(pat='Mean', case=False)]\n",
    "std_cols = columns_all[columns_all.str.contains(pat='Std_Dev', case=False)]\n",
    "\n",
    "Robot_fixed_cols.drop(columns=mean_cols, inplace=True)\n",
    "Robot_fixed_cols.drop(columns=std_cols, inplace=True)\n",
    "\n",
    "Robot_fixed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the comments to be appended to results\n",
    "comments = []\n",
    "comments.append('Median columns only')\n",
    "comments.append('EVI included.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Trends Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Correlation heatmap of indices with target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Identify Dates and index with problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take average or delete dates with problems, out of trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecxclude the problematic data/dates\n",
    "or\n",
    "### Take average values where the problematic data is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup  \n",
    "Remove dates which have drop  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Plot_ID  Blue_Median_Value  Green_Median_Value  Red_Median_Value  \\\n",
       "0        1101           0.021905            0.051635          0.028147   \n",
       "1        1102           0.028108            0.055910          0.035009   \n",
       "2        1103           0.026808            0.057188          0.034401   \n",
       "3        1104           0.024750            0.048598          0.030623   \n",
       "4        1105           0.029282            0.059577          0.035984   \n",
       "...       ...                ...                 ...               ...   \n",
       "1339     1808           0.033788            0.062602          0.084690   \n",
       "1340     1809           0.025289            0.053867          0.065721   \n",
       "1341     1810           0.034920            0.067794          0.076857   \n",
       "1342     1811           0.032249            0.059999          0.080487   \n",
       "1343     1812           0.025546            0.045265          0.069339   \n",
       "\n",
       "      RedEdge_Median_Value  NIR_Median_Value  NDVI_Median_Value  \\\n",
       "0                 0.142298          0.465755           0.885390   \n",
       "1                 0.145149          0.458687           0.858816   \n",
       "2                 0.149912          0.468715           0.863303   \n",
       "3                 0.131659          0.455760           0.874434   \n",
       "4                 0.153574          0.473269           0.858489   \n",
       "...                    ...               ...                ...   \n",
       "1339              0.153530          0.250196           0.490993   \n",
       "1340              0.147120          0.267604           0.601344   \n",
       "1341              0.162150          0.280264           0.569404   \n",
       "1342              0.146993          0.236998           0.487644   \n",
       "1343              0.121298          0.217778           0.515266   \n",
       "\n",
       "      MTCI_Median_Value  EVI_Median_Value  GrainYield  Days2Heading  \\\n",
       "0              2.803551         -1.261239  453.658537            62   \n",
       "1              2.861652         -1.100831  439.024390            62   \n",
       "2              2.768063         -1.156627  409.756098            60   \n",
       "3              3.206094         -1.163352  474.796748            61   \n",
       "4              2.720606         -1.136098  411.382114            61   \n",
       "...                 ...               ...         ...           ...   \n",
       "1339           1.428498         -0.273772  429.268293            61   \n",
       "1340           1.501041         -0.383402  414.634146            60   \n",
       "1341           1.406162         -0.352456  460.162602            62   \n",
       "1342           1.384678         -0.262991  443.902439            62   \n",
       "1343           1.909100         -0.267007  375.609756            61   \n",
       "\n",
       "      Days2Maturity        Date  \n",
       "0               109  2020-07-01  \n",
       "1               113  2020-07-01  \n",
       "2               106  2020-07-01  \n",
       "3               110  2020-07-01  \n",
       "4               106  2020-07-01  \n",
       "...             ...         ...  \n",
       "1339            105  2020-07-30  \n",
       "1340            102  2020-07-30  \n",
       "1341            107  2020-07-30  \n",
       "1342            105  2020-07-30  \n",
       "1343            105  2020-07-30  \n",
       "\n",
       "[1344 rows x 13 columns]>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Robot_fixed_cols.copy()\n",
    "comments.append('Robot_fixed_cols dataset.')\n",
    "comments.append(str(Robot_fixed_cols.shape))\n",
    "comments.append('All data stacked on top of each other.')\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"GrainYield\" column in df seems like the yield column as it contains the text \"GrainYield\". It is located at location 9\n",
      "\"Days2Heading\" column in df seems like the yield column as it contains the text \"Days2Heading\". It is located at location 10\n",
      "\"Days2Maturity\" column in df seems like the yield column as it contains the text \"Days2Maturity\". It is located at location 11\n"
     ]
    }
   ],
   "source": [
    "# ToDo: Add check for duplicate columns in the df\n",
    "\n",
    "# list_agg_df\n",
    "yield_cols = ['GrainYield', 'Days2Heading', 'Days2Maturity']\n",
    "id_cols_new = ['Plot_ID']\n",
    "\n",
    "# Counter for location of column in columns list\n",
    "loc = 0\n",
    "\n",
    "# Dict for saving the name and location of the yield column\n",
    "loc_yield_cols = {}\n",
    "\n",
    "for cols in df.columns.tolist():\n",
    "    for y_col in yield_cols:\n",
    "        if not cols.find(y_col):\n",
    "            loc_yield_cols[cols] = loc\n",
    "            print(f'\\\"{cols}\\\" column in df seems like the yield column as it contains the text \\\"{y_col}\\\". It is located at location {loc}')\n",
    "    loc += 1\n",
    "\n",
    "yield_cols_found = list(loc_yield_cols.keys())\n",
    "target_cols=yield_cols_found[0]\n",
    "\n",
    "# # Droping yield columns, i.e. target variables and Plot_ID column\n",
    "# Robot_2020_all.drop(columns = yield_cols_found+id_cols_new)\n",
    "# Robot_2020_all[yield_cols_found]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "#==============================================================================\n",
    "# Split dataframe into data and target\n",
    "#==============================================================================\n",
    "\n",
    "temp_X = df.drop(columns = yield_cols_found)\n",
    "y = df[target_cols]\n",
    "# y = df[target_cols].values.flatten()\n",
    "comments.append('Drop Days2Heading and Days2Maturity features.')\n",
    "comments.append('GrainYield Target.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting dates to ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1344 entries, 0 to 1343\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Plot_ID               1344 non-null   int64  \n",
      " 1   Blue_Median_Value     1344 non-null   float64\n",
      " 2   Green_Median_Value    1344 non-null   float64\n",
      " 3   Red_Median_Value      1344 non-null   float64\n",
      " 4   RedEdge_Median_Value  1344 non-null   float64\n",
      " 5   NIR_Median_Value      1344 non-null   float64\n",
      " 6   NDVI_Median_Value     1344 non-null   float64\n",
      " 7   MTCI_Median_Value     1344 non-null   float64\n",
      " 8   EVI_Median_Value      1344 non-null   float64\n",
      " 9   Date                  1344 non-null   object \n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 105.1+ KB\n",
      "The entries in Date column are objects, instead of datetime object. We need to convert them.\n"
     ]
    }
   ],
   "source": [
    "temp_X\n",
    "temp_X.info()\n",
    "print('The entries in Date column are objects, instead of datetime object. We need to convert them.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1344 entries, 0 to 1343\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Plot_ID               1344 non-null   int64         \n",
      " 1   Blue_Median_Value     1344 non-null   float64       \n",
      " 2   Green_Median_Value    1344 non-null   float64       \n",
      " 3   Red_Median_Value      1344 non-null   float64       \n",
      " 4   RedEdge_Median_Value  1344 non-null   float64       \n",
      " 5   NIR_Median_Value      1344 non-null   float64       \n",
      " 6   NDVI_Median_Value     1344 non-null   float64       \n",
      " 7   MTCI_Median_Value     1344 non-null   float64       \n",
      " 8   EVI_Median_Value      1344 non-null   float64       \n",
      " 9   Date                  1344 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(8), int64(1)\n",
      "memory usage: 105.1 KB\n"
     ]
    }
   ],
   "source": [
    "# Converting dates to datetime objects in pandas\n",
    "temp_X['Date'] = pd.to_datetime(temp_X['Date'])\n",
    "\n",
    "temp_X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020-07-01T00:00:00.000000000', '2020-08-04T00:00:00.000000000',\n",
       "       '2020-07-07T00:00:00.000000000', '2020-08-12T00:00:00.000000000',\n",
       "       '2020-07-13T00:00:00.000000000', '2020-06-18T00:00:00.000000000',\n",
       "       '2020-07-20T00:00:00.000000000', '2020-07-22T00:00:00.000000000',\n",
       "       '2020-06-23T00:00:00.000000000', '2020-06-24T00:00:00.000000000',\n",
       "       '2020-06-25T00:00:00.000000000', '2020-07-27T00:00:00.000000000',\n",
       "       '2020-06-29T00:00:00.000000000', '2020-07-30T00:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_X.Date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_Median_Value</th>\n",
       "      <th>Green_Median_Value</th>\n",
       "      <th>Red_Median_Value</th>\n",
       "      <th>RedEdge_Median_Value</th>\n",
       "      <th>NIR_Median_Value</th>\n",
       "      <th>NDVI_Median_Value</th>\n",
       "      <th>MTCI_Median_Value</th>\n",
       "      <th>EVI_Median_Value</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.051635</td>\n",
       "      <td>0.028147</td>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.465755</td>\n",
       "      <td>0.885390</td>\n",
       "      <td>2.803551</td>\n",
       "      <td>-1.261239</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.055910</td>\n",
       "      <td>0.035009</td>\n",
       "      <td>0.145149</td>\n",
       "      <td>0.458687</td>\n",
       "      <td>0.858816</td>\n",
       "      <td>2.861652</td>\n",
       "      <td>-1.100831</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026808</td>\n",
       "      <td>0.057188</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.149912</td>\n",
       "      <td>0.468715</td>\n",
       "      <td>0.863303</td>\n",
       "      <td>2.768063</td>\n",
       "      <td>-1.156627</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.048598</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.131659</td>\n",
       "      <td>0.455760</td>\n",
       "      <td>0.874434</td>\n",
       "      <td>3.206094</td>\n",
       "      <td>-1.163352</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029282</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>0.153574</td>\n",
       "      <td>0.473269</td>\n",
       "      <td>0.858489</td>\n",
       "      <td>2.720606</td>\n",
       "      <td>-1.136098</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>0.033788</td>\n",
       "      <td>0.062602</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.250196</td>\n",
       "      <td>0.490993</td>\n",
       "      <td>1.428498</td>\n",
       "      <td>-0.273772</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>0.025289</td>\n",
       "      <td>0.053867</td>\n",
       "      <td>0.065721</td>\n",
       "      <td>0.147120</td>\n",
       "      <td>0.267604</td>\n",
       "      <td>0.601344</td>\n",
       "      <td>1.501041</td>\n",
       "      <td>-0.383402</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.067794</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.162150</td>\n",
       "      <td>0.280264</td>\n",
       "      <td>0.569404</td>\n",
       "      <td>1.406162</td>\n",
       "      <td>-0.352456</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>0.032249</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.236998</td>\n",
       "      <td>0.487644</td>\n",
       "      <td>1.384678</td>\n",
       "      <td>-0.262991</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>0.025546</td>\n",
       "      <td>0.045265</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>0.121298</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>0.515266</td>\n",
       "      <td>1.909100</td>\n",
       "      <td>-0.267007</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Blue_Median_Value  Green_Median_Value  Red_Median_Value  \\\n",
       "0              0.021905            0.051635          0.028147   \n",
       "1              0.028108            0.055910          0.035009   \n",
       "2              0.026808            0.057188          0.034401   \n",
       "3              0.024750            0.048598          0.030623   \n",
       "4              0.029282            0.059577          0.035984   \n",
       "...                 ...                 ...               ...   \n",
       "1339           0.033788            0.062602          0.084690   \n",
       "1340           0.025289            0.053867          0.065721   \n",
       "1341           0.034920            0.067794          0.076857   \n",
       "1342           0.032249            0.059999          0.080487   \n",
       "1343           0.025546            0.045265          0.069339   \n",
       "\n",
       "      RedEdge_Median_Value  NIR_Median_Value  NDVI_Median_Value  \\\n",
       "0                 0.142298          0.465755           0.885390   \n",
       "1                 0.145149          0.458687           0.858816   \n",
       "2                 0.149912          0.468715           0.863303   \n",
       "3                 0.131659          0.455760           0.874434   \n",
       "4                 0.153574          0.473269           0.858489   \n",
       "...                    ...               ...                ...   \n",
       "1339              0.153530          0.250196           0.490993   \n",
       "1340              0.147120          0.267604           0.601344   \n",
       "1341              0.162150          0.280264           0.569404   \n",
       "1342              0.146993          0.236998           0.487644   \n",
       "1343              0.121298          0.217778           0.515266   \n",
       "\n",
       "      MTCI_Median_Value  EVI_Median_Value    Date  \n",
       "0              2.803551         -1.261239  737607  \n",
       "1              2.861652         -1.100831  737607  \n",
       "2              2.768063         -1.156627  737607  \n",
       "3              3.206094         -1.163352  737607  \n",
       "4              2.720606         -1.136098  737607  \n",
       "...                 ...               ...     ...  \n",
       "1339           1.428498         -0.273772  737636  \n",
       "1340           1.501041         -0.383402  737636  \n",
       "1341           1.406162         -0.352456  737636  \n",
       "1342           1.384678         -0.262991  737636  \n",
       "1343           1.909100         -0.267007  737636  \n",
       "\n",
       "[1344 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the entries in Date column to ordinal values\n",
    "# This is supposed to improve the predictions over the one hot encoding\n",
    "\n",
    "import time, datetime\n",
    "from datetime import datetime as dt\n",
    "\n",
    "X = temp_X.copy()\n",
    "\n",
    "X['Date'] = temp_X['Date'].apply(dt.toordinal)\n",
    "X.drop(columns=['Plot_ID'], inplace=True)\n",
    "comments.append('Converted dates to ordinal.')\n",
    "comments.append('Plot ID Dropped.')\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_Median_Value</th>\n",
       "      <th>Green_Median_Value</th>\n",
       "      <th>Red_Median_Value</th>\n",
       "      <th>RedEdge_Median_Value</th>\n",
       "      <th>NIR_Median_Value</th>\n",
       "      <th>NDVI_Median_Value</th>\n",
       "      <th>MTCI_Median_Value</th>\n",
       "      <th>EVI_Median_Value</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.051635</td>\n",
       "      <td>0.028147</td>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.465755</td>\n",
       "      <td>0.885390</td>\n",
       "      <td>2.803551</td>\n",
       "      <td>-1.261239</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.055910</td>\n",
       "      <td>0.035009</td>\n",
       "      <td>0.145149</td>\n",
       "      <td>0.458687</td>\n",
       "      <td>0.858816</td>\n",
       "      <td>2.861652</td>\n",
       "      <td>-1.100831</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026808</td>\n",
       "      <td>0.057188</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.149912</td>\n",
       "      <td>0.468715</td>\n",
       "      <td>0.863303</td>\n",
       "      <td>2.768063</td>\n",
       "      <td>-1.156627</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.048598</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.131659</td>\n",
       "      <td>0.455760</td>\n",
       "      <td>0.874434</td>\n",
       "      <td>3.206094</td>\n",
       "      <td>-1.163352</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029282</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>0.153574</td>\n",
       "      <td>0.473269</td>\n",
       "      <td>0.858489</td>\n",
       "      <td>2.720606</td>\n",
       "      <td>-1.136098</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>0.033788</td>\n",
       "      <td>0.062602</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.250196</td>\n",
       "      <td>0.490993</td>\n",
       "      <td>1.428498</td>\n",
       "      <td>-0.273772</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>0.025289</td>\n",
       "      <td>0.053867</td>\n",
       "      <td>0.065721</td>\n",
       "      <td>0.147120</td>\n",
       "      <td>0.267604</td>\n",
       "      <td>0.601344</td>\n",
       "      <td>1.501041</td>\n",
       "      <td>-0.383402</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.067794</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.162150</td>\n",
       "      <td>0.280264</td>\n",
       "      <td>0.569404</td>\n",
       "      <td>1.406162</td>\n",
       "      <td>-0.352456</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>0.032249</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.236998</td>\n",
       "      <td>0.487644</td>\n",
       "      <td>1.384678</td>\n",
       "      <td>-0.262991</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>0.025546</td>\n",
       "      <td>0.045265</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>0.121298</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>0.515266</td>\n",
       "      <td>1.909100</td>\n",
       "      <td>-0.267007</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Blue_Median_Value  Green_Median_Value  Red_Median_Value  \\\n",
       "0              0.021905            0.051635          0.028147   \n",
       "1              0.028108            0.055910          0.035009   \n",
       "2              0.026808            0.057188          0.034401   \n",
       "3              0.024750            0.048598          0.030623   \n",
       "4              0.029282            0.059577          0.035984   \n",
       "...                 ...                 ...               ...   \n",
       "1339           0.033788            0.062602          0.084690   \n",
       "1340           0.025289            0.053867          0.065721   \n",
       "1341           0.034920            0.067794          0.076857   \n",
       "1342           0.032249            0.059999          0.080487   \n",
       "1343           0.025546            0.045265          0.069339   \n",
       "\n",
       "      RedEdge_Median_Value  NIR_Median_Value  NDVI_Median_Value  \\\n",
       "0                 0.142298          0.465755           0.885390   \n",
       "1                 0.145149          0.458687           0.858816   \n",
       "2                 0.149912          0.468715           0.863303   \n",
       "3                 0.131659          0.455760           0.874434   \n",
       "4                 0.153574          0.473269           0.858489   \n",
       "...                    ...               ...                ...   \n",
       "1339              0.153530          0.250196           0.490993   \n",
       "1340              0.147120          0.267604           0.601344   \n",
       "1341              0.162150          0.280264           0.569404   \n",
       "1342              0.146993          0.236998           0.487644   \n",
       "1343              0.121298          0.217778           0.515266   \n",
       "\n",
       "      MTCI_Median_Value  EVI_Median_Value    Date  \n",
       "0              2.803551         -1.261239  737607  \n",
       "1              2.861652         -1.100831  737607  \n",
       "2              2.768063         -1.156627  737607  \n",
       "3              3.206094         -1.163352  737607  \n",
       "4              2.720606         -1.136098  737607  \n",
       "...                 ...               ...     ...  \n",
       "1339           1.428498         -0.273772  737636  \n",
       "1340           1.501041         -0.383402  737636  \n",
       "1341           1.406162         -0.352456  737636  \n",
       "1342           1.384678         -0.262991  737636  \n",
       "1343           1.909100         -0.267007  737636  \n",
       "\n",
       "[1344 rows x 9 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#==============================================================================\n",
    "# Create separate train/test splits from Main data\n",
    "#==============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=5)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "comments.append('Test train split. test_Size=0.3, random_state=55')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#==============================================================================\n",
    "# Scale features using StandardScaler class in scikit-learn \n",
    "#==============================================================================\n",
    "\n",
    "# Initialise standard scaler and compute mean and STD from training data\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "# Transform (standardise) both X_train and X_test with mean and STD from\n",
    "# training data\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "comments.append('Standard scaler fit transform.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_Median_Value</th>\n",
       "      <th>Green_Median_Value</th>\n",
       "      <th>Red_Median_Value</th>\n",
       "      <th>RedEdge_Median_Value</th>\n",
       "      <th>NIR_Median_Value</th>\n",
       "      <th>NDVI_Median_Value</th>\n",
       "      <th>MTCI_Median_Value</th>\n",
       "      <th>EVI_Median_Value</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.051635</td>\n",
       "      <td>0.028147</td>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.465755</td>\n",
       "      <td>0.885390</td>\n",
       "      <td>2.803551</td>\n",
       "      <td>-1.261239</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.055910</td>\n",
       "      <td>0.035009</td>\n",
       "      <td>0.145149</td>\n",
       "      <td>0.458687</td>\n",
       "      <td>0.858816</td>\n",
       "      <td>2.861652</td>\n",
       "      <td>-1.100831</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026808</td>\n",
       "      <td>0.057188</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.149912</td>\n",
       "      <td>0.468715</td>\n",
       "      <td>0.863303</td>\n",
       "      <td>2.768063</td>\n",
       "      <td>-1.156627</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.048598</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.131659</td>\n",
       "      <td>0.455760</td>\n",
       "      <td>0.874434</td>\n",
       "      <td>3.206094</td>\n",
       "      <td>-1.163352</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029282</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>0.153574</td>\n",
       "      <td>0.473269</td>\n",
       "      <td>0.858489</td>\n",
       "      <td>2.720606</td>\n",
       "      <td>-1.136098</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>0.033788</td>\n",
       "      <td>0.062602</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.250196</td>\n",
       "      <td>0.490993</td>\n",
       "      <td>1.428498</td>\n",
       "      <td>-0.273772</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>0.025289</td>\n",
       "      <td>0.053867</td>\n",
       "      <td>0.065721</td>\n",
       "      <td>0.147120</td>\n",
       "      <td>0.267604</td>\n",
       "      <td>0.601344</td>\n",
       "      <td>1.501041</td>\n",
       "      <td>-0.383402</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.067794</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.162150</td>\n",
       "      <td>0.280264</td>\n",
       "      <td>0.569404</td>\n",
       "      <td>1.406162</td>\n",
       "      <td>-0.352456</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>0.032249</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.236998</td>\n",
       "      <td>0.487644</td>\n",
       "      <td>1.384678</td>\n",
       "      <td>-0.262991</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>0.025546</td>\n",
       "      <td>0.045265</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>0.121298</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>0.515266</td>\n",
       "      <td>1.909100</td>\n",
       "      <td>-0.267007</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Blue_Median_Value  Green_Median_Value  Red_Median_Value  \\\n",
       "0              0.021905            0.051635          0.028147   \n",
       "1              0.028108            0.055910          0.035009   \n",
       "2              0.026808            0.057188          0.034401   \n",
       "3              0.024750            0.048598          0.030623   \n",
       "4              0.029282            0.059577          0.035984   \n",
       "...                 ...                 ...               ...   \n",
       "1339           0.033788            0.062602          0.084690   \n",
       "1340           0.025289            0.053867          0.065721   \n",
       "1341           0.034920            0.067794          0.076857   \n",
       "1342           0.032249            0.059999          0.080487   \n",
       "1343           0.025546            0.045265          0.069339   \n",
       "\n",
       "      RedEdge_Median_Value  NIR_Median_Value  NDVI_Median_Value  \\\n",
       "0                 0.142298          0.465755           0.885390   \n",
       "1                 0.145149          0.458687           0.858816   \n",
       "2                 0.149912          0.468715           0.863303   \n",
       "3                 0.131659          0.455760           0.874434   \n",
       "4                 0.153574          0.473269           0.858489   \n",
       "...                    ...               ...                ...   \n",
       "1339              0.153530          0.250196           0.490993   \n",
       "1340              0.147120          0.267604           0.601344   \n",
       "1341              0.162150          0.280264           0.569404   \n",
       "1342              0.146993          0.236998           0.487644   \n",
       "1343              0.121298          0.217778           0.515266   \n",
       "\n",
       "      MTCI_Median_Value  EVI_Median_Value    Date  \n",
       "0              2.803551         -1.261239  737607  \n",
       "1              2.861652         -1.100831  737607  \n",
       "2              2.768063         -1.156627  737607  \n",
       "3              3.206094         -1.163352  737607  \n",
       "4              2.720606         -1.136098  737607  \n",
       "...                 ...               ...     ...  \n",
       "1339           1.428498         -0.273772  737636  \n",
       "1340           1.501041         -0.383402  737636  \n",
       "1341           1.406162         -0.352456  737636  \n",
       "1342           1.384678         -0.262991  737636  \n",
       "1343           1.909100         -0.267007  737636  \n",
       "\n",
       "[1344 rows x 9 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "#==============================================================================\n",
    "# Defining the function to vaiidate the model with the test data and \n",
    "# get the results from regression evaluation metrices in sklearn\n",
    "#==============================================================================\n",
    "pred = []\n",
    "acc = []\n",
    "def test_data_regression(model):\n",
    "    pred = []\n",
    "    accuracy = {}\n",
    "    #==============================================================================\n",
    "    # Make predictions for test set\n",
    "    #==============================================================================\n",
    "\n",
    "    # Predict classes for samples in test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    #==============================================================================\n",
    "    # Compute performance\n",
    "    #==============================================================================\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(y_test, y_pred, squared=True)\n",
    "    print(mse, ' mean_squared_error')\n",
    "#     accuracy.append(rmse)\n",
    "    accuracy['MSE'] = mse\n",
    "    \n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    print(rmse, ' root_mean_squared_error')\n",
    "#     accuracy.append(rmse)\n",
    "    accuracy['RMSE'] = rmse\n",
    "\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(r2, ' r2_score')\n",
    "    accuracy['R2 Score'] = r2\n",
    "\n",
    "    acc.append(accuracy)\n",
    "    # Print accuracy computed from predictions on the test set\n",
    "    pp = pprint.PrettyPrinter(indent=4, width=80, depth=None, stream=None, compact=True, sort_dicts=False)\n",
    "    pp.pprint(accuracy)\n",
    "    \n",
    "    #==============================================================================\n",
    "    # Append Results\n",
    "    #==============================================================================\n",
    "    results = []\n",
    "    import datetime\n",
    "    datetime = datetime.datetime.now()\n",
    "    results.append(np.concatenate((np.array((model, mse, rmse, r2, accuracy, datetime), dtype=object), np.array(comments))))\n",
    "#     results.extend(np.array(comments)) \n",
    "    print(results)\n",
    "    pd.DataFrame(np.asarray(results)).to_csv('results.csv',\n",
    "                                             mode='a',\n",
    "                                             header=None)\n",
    "    pred.extend(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "4655.863348382419  mean_squared_error\n",
      "68.23388709711926  root_mean_squared_error\n",
      "0.5692016100143511  r2_score\n",
      "{   'MSE': 4655.863348382419,\n",
      "    'RMSE': 68.23388709711926,\n",
      "    'R2 Score': 0.5692016100143511}\n",
      "[array([RandomForestRegressor(max_depth=250, min_samples_split=5, n_estimators=1000,\n",
      "                      n_jobs=-1, random_state=0),\n",
      "       4655.863348382419, 68.23388709711926, 0.5692016100143511,\n",
      "       {'MSE': 4655.863348382419, 'RMSE': 68.23388709711926, 'R2 Score': 0.5692016100143511},\n",
      "       datetime.datetime(2021, 4, 30, 18, 9, 28, 770208),\n",
      "       'Median columns only', 'EVI included.',\n",
      "       'Robot_fixed_cols dataset.', '(1344, 13)',\n",
      "       'All data stacked on top of each other.',\n",
      "       'Drop Days2Heading and Days2Maturity features.',\n",
      "       'GrainYield Target.', 'Converted dates to ordinal.',\n",
      "       'Plot ID Dropped.',\n",
      "       'Test train split. test_Size=0.3, random_state=55',\n",
      "       'Standard scaler fit transform.'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 1000, max_depth=250, min_samples_split=5, random_state=0, n_jobs = -1)\n",
    "# model = RandomForestRegressor(n_estimators = 50, max_depth=100, min_samples_split=400, random_state=0, n_jobs = -1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "test_data_regression(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_Median_Value</th>\n",
       "      <th>Green_Median_Value</th>\n",
       "      <th>Red_Median_Value</th>\n",
       "      <th>RedEdge_Median_Value</th>\n",
       "      <th>NIR_Median_Value</th>\n",
       "      <th>NDVI_Median_Value</th>\n",
       "      <th>MTCI_Median_Value</th>\n",
       "      <th>EVI_Median_Value</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.051635</td>\n",
       "      <td>0.028147</td>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.465755</td>\n",
       "      <td>0.885390</td>\n",
       "      <td>2.803551</td>\n",
       "      <td>-1.261239</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.055910</td>\n",
       "      <td>0.035009</td>\n",
       "      <td>0.145149</td>\n",
       "      <td>0.458687</td>\n",
       "      <td>0.858816</td>\n",
       "      <td>2.861652</td>\n",
       "      <td>-1.100831</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026808</td>\n",
       "      <td>0.057188</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>0.149912</td>\n",
       "      <td>0.468715</td>\n",
       "      <td>0.863303</td>\n",
       "      <td>2.768063</td>\n",
       "      <td>-1.156627</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.048598</td>\n",
       "      <td>0.030623</td>\n",
       "      <td>0.131659</td>\n",
       "      <td>0.455760</td>\n",
       "      <td>0.874434</td>\n",
       "      <td>3.206094</td>\n",
       "      <td>-1.163352</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029282</td>\n",
       "      <td>0.059577</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>0.153574</td>\n",
       "      <td>0.473269</td>\n",
       "      <td>0.858489</td>\n",
       "      <td>2.720606</td>\n",
       "      <td>-1.136098</td>\n",
       "      <td>737607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>0.033788</td>\n",
       "      <td>0.062602</td>\n",
       "      <td>0.084690</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.250196</td>\n",
       "      <td>0.490993</td>\n",
       "      <td>1.428498</td>\n",
       "      <td>-0.273772</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>0.025289</td>\n",
       "      <td>0.053867</td>\n",
       "      <td>0.065721</td>\n",
       "      <td>0.147120</td>\n",
       "      <td>0.267604</td>\n",
       "      <td>0.601344</td>\n",
       "      <td>1.501041</td>\n",
       "      <td>-0.383402</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.067794</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.162150</td>\n",
       "      <td>0.280264</td>\n",
       "      <td>0.569404</td>\n",
       "      <td>1.406162</td>\n",
       "      <td>-0.352456</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>0.032249</td>\n",
       "      <td>0.059999</td>\n",
       "      <td>0.080487</td>\n",
       "      <td>0.146993</td>\n",
       "      <td>0.236998</td>\n",
       "      <td>0.487644</td>\n",
       "      <td>1.384678</td>\n",
       "      <td>-0.262991</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>0.025546</td>\n",
       "      <td>0.045265</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>0.121298</td>\n",
       "      <td>0.217778</td>\n",
       "      <td>0.515266</td>\n",
       "      <td>1.909100</td>\n",
       "      <td>-0.267007</td>\n",
       "      <td>737636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Blue_Median_Value  Green_Median_Value  Red_Median_Value  \\\n",
       "0              0.021905            0.051635          0.028147   \n",
       "1              0.028108            0.055910          0.035009   \n",
       "2              0.026808            0.057188          0.034401   \n",
       "3              0.024750            0.048598          0.030623   \n",
       "4              0.029282            0.059577          0.035984   \n",
       "...                 ...                 ...               ...   \n",
       "1339           0.033788            0.062602          0.084690   \n",
       "1340           0.025289            0.053867          0.065721   \n",
       "1341           0.034920            0.067794          0.076857   \n",
       "1342           0.032249            0.059999          0.080487   \n",
       "1343           0.025546            0.045265          0.069339   \n",
       "\n",
       "      RedEdge_Median_Value  NIR_Median_Value  NDVI_Median_Value  \\\n",
       "0                 0.142298          0.465755           0.885390   \n",
       "1                 0.145149          0.458687           0.858816   \n",
       "2                 0.149912          0.468715           0.863303   \n",
       "3                 0.131659          0.455760           0.874434   \n",
       "4                 0.153574          0.473269           0.858489   \n",
       "...                    ...               ...                ...   \n",
       "1339              0.153530          0.250196           0.490993   \n",
       "1340              0.147120          0.267604           0.601344   \n",
       "1341              0.162150          0.280264           0.569404   \n",
       "1342              0.146993          0.236998           0.487644   \n",
       "1343              0.121298          0.217778           0.515266   \n",
       "\n",
       "      MTCI_Median_Value  EVI_Median_Value    Date  \n",
       "0              2.803551         -1.261239  737607  \n",
       "1              2.861652         -1.100831  737607  \n",
       "2              2.768063         -1.156627  737607  \n",
       "3              3.206094         -1.163352  737607  \n",
       "4              2.720606         -1.136098  737607  \n",
       "...                 ...               ...     ...  \n",
       "1339           1.428498         -0.273772  737636  \n",
       "1340           1.501041         -0.383402  737636  \n",
       "1341           1.406162         -0.352456  737636  \n",
       "1342           1.384678         -0.262991  737636  \n",
       "1343           1.909100         -0.267007  737636  \n",
       "\n",
       "[1344 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X.columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid and Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "\n",
    "pca = PCA()\n",
    "sc = StandardScaler()\n",
    "# model = LogisticRegression(max_iter=10000, tol=0.1)\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model =  SVR()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('pca', pca), ('model', model)])\n",
    "\n",
    "\n",
    "# Define the pipeline (scaling and classification method):\n",
    "\n",
    "# Define ranges of parameter values:\n",
    "param_range  = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0] # For regularization parameter C.\n",
    "param_range2 = [0.0000001,0.000001,0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]         # For scaling parameter gamma og rbf-kernel.\n",
    "param_range3 = [x for x in range(50)]\n",
    "param_range4 = [x for x in range(10)]\n",
    "param_range5 = [x for x in range(100)]\n",
    "# , 'rbf', 'sigmoid'\n",
    "# 'linear', 'poly'\n",
    "param_grid   =  [{'model__kernel' : (['sigmoid']),'model__C' : [1,5,10],\n",
    "                 'model__degree' : [3,8],'model__coef0' : [0.01,10,0.5],'model__gamma' : ('auto','scale')}]\n",
    "\n",
    "\n",
    "# param_grid   = [{'randomforestregressor__max_depth': param_range3,\n",
    "#                  'randomforestregressor__min_samples_split': param_range5,\n",
    "#                  'randomforestregressor__n_estimators': param_range4,\n",
    "#                  'pca__n_components': [5,6,7,8,9,10,11,12,13]}]\n",
    "\n",
    "estimator = pipe\n",
    "# score = 'neg_mean_squared_error'\n",
    "score = 'r2'\n",
    "cv = 3\n",
    "\n",
    "# pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid and Random search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(Xtrain=X_train,\n",
    "         ytrain=y_train,\n",
    "         estimator=pipe,\n",
    "         params_grid=param_grid,\n",
    "         scores=score,\n",
    "         cvs=cv,\n",
    "         cores=-1,\n",
    "         verb=5):\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    gs = GridSearchCV(estimator=estimator,\n",
    "                      param_grid=params_grid,\n",
    "                      scoring=scores,\n",
    "                      cv=cvs,\n",
    "                      n_jobs=cores,\n",
    "                      verbose=verb)\n",
    "\n",
    "    gs = gs.fit(Xtrain, ytrain)\n",
    "    print(gs.best_score_)\n",
    "    print(gs.best_params_)\n",
    "    \n",
    "    t2 = time.time()\n",
    "\n",
    "    # Saving results to csv file\n",
    "    results = []\n",
    "    import datetime\n",
    "    datetime = datetime.datetime.now()\n",
    "    results.append(np.array((gs.best_estimator_, gs, score, gs.best_score_, gs.best_params_, \n",
    "                             (t2 - t1) / 60, datetime), dtype=object), np.array(comments))\n",
    "\n",
    "    pd.DataFrame(np.asarray(results)).to_csv('results.csv',\n",
    "                                             mode='a',\n",
    "                                             header=None)\n",
    "\n",
    "    print('Total time: ', (t2 - t1) / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def rand_search(Xtrain=X_train,\n",
    "                ytrain=y_train,\n",
    "                estimator=pipe,\n",
    "                params_grid=param_grid,\n",
    "                scores=score,\n",
    "                cvs=cv,\n",
    "                n_iter_search=25,\n",
    "                cores=-1,\n",
    "                verb=5):\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    random_search = RandomizedSearchCV(estimator,\n",
    "                                       param_distributions=params_grid,\n",
    "                                       n_iter=n_iter_search,\n",
    "                                       scoring=scores,\n",
    "                                       cv=cvs,\n",
    "                                       verbose=verb)\n",
    "\n",
    "    random_search = random_search.fit(Xtrain, ytrain)\n",
    "    print(random_search.best_score_)\n",
    "    print(random_search.best_params_)\n",
    "\n",
    "    t2 = time.time()\n",
    "    \n",
    "    # Saving results to csv file\n",
    "    results = []\n",
    "    import datetime\n",
    "    datetime = datetime.datetime.now()\n",
    "    results.append(np.array((gs.best_estimator_, gs, score, gs.best_score_, gs.best_params_, \n",
    "                             (t2 - t1) / 60, datetime), dtype=object))\n",
    "\n",
    "    pd.DataFrame(np.asarray(results)).to_csv('results.csv',\n",
    "                                             mode='a',\n",
    "                                             header=None)\n",
    "\n",
    "\n",
    "    print('Total time: ', (t2 - t1) / 60, 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# , 'rbf', 'sigmoid'\n",
    "# 'linear', 'poly'\n",
    "param_grid   =  [{'model__kernel' : ('linear','poly'),'model__C' : [x for x in range(30,35)],\n",
    "                 'model__degree' : [x for x in range(1,8)],'model__coef0' : [x/100 for x in range(50,63,5)],\n",
    "                  'model__gamma' : ('auto','scale'),\n",
    "                 'pca__n_components': [5,6,7,8,9,10,11,12,13]}]\n",
    "\n",
    "\n",
    "# param_grid   = [{'randomforestregressor__max_depth': param_range3,\n",
    "#                  'randomforestregressor__min_samples_split': param_range5,\n",
    "#                  'randomforestregressor__n_estimators': param_range4,\n",
    "#                  'pca__n_components': [5,6,7,8,9,10,11,12,13]}]\n",
    "\n",
    "estimator = pipe\n",
    "# score = 'neg_mean_squared_error'\n",
    "score = 'r2'\n",
    "cv = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid(Xtrain = X_train_std,\n",
    "#             ytrain = y_train_std,\n",
    "#             estimator = pipe,\n",
    "#             params_grid = param_grid,\n",
    "#             scores=score,\n",
    "#             cvs = cv,\n",
    "#             cores=6,\n",
    "#             verb=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "\n",
    "pca = PCA()\n",
    "sc = StandardScaler()\n",
    "# Define the pipeline (scaling and classification method):\n",
    "\n",
    "# Define ranges of parameter values:\n",
    "param_range  = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0] # For regularization parameter C.\n",
    "param_range2 = [0.0000001,0.000001,0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]         # For scaling parameter gamma og rbf-kernel.\n",
    "param_range3 = [x for x in range(50)]\n",
    "param_range4 = [x for x in range(10)]\n",
    "param_range5 = [x for x in range(100)]\n",
    "# , 'rbf', 'sigmoid'\n",
    "# 'linear', 'poly'\n",
    "param_grid   =  [{'model__kernel' : (['sigmoid']),'model__C' : [1,5,10],\n",
    "                 'model__degree' : [3,8],'model__coef0' : [0.01,10,0.5],'model__gamma' : ('auto','scale')}]\n",
    "\n",
    "\n",
    "# param_grid   = [{'randomforestregressor__max_depth': param_range3,\n",
    "#                  'randomforestregressor__min_samples_split': param_range5,\n",
    "#                  'randomforestregressor__n_estimators': param_range4,\n",
    "#                  'pca__n_components': [5,6,7,8,9,10,11,12,13]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 630 out of 630 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-67.198966244721\n",
      "{'model__alpha': 1.0, 'model__solver': 'lsqr'}\n",
      "Total time:  0.01333242654800415 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=6)]: Done 630 out of 630 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6655.268708760681\n",
      "{'model__alpha': 1.0, 'model__solver': 'lsqr'}\n",
      "Total time:  0.014162854353586832 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3116912451929214\n",
      "{'model__alpha': 1.0, 'model__solver': 'lsqr'}\n",
      "Total time:  0.01611698865890503 minutes\n",
      "r2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 630 out of 630 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__alpha' : [x*1. for x in range(1,10)],\n",
    "                  'model__solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}]\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=6,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Batch computation too fast (0.0066s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Batch computation too fast (0.0338s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Batch computation too fast (0.0429s.) Setting batch_size=8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 980 candidates, totalling 9800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Batch computation too fast (0.0835s.) Setting batch_size=16.\n",
      "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 124 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 132 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 140 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 148 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done 156 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done 164 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done 172 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done 180 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done 196 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Batch computation too fast (0.1007s.) Setting batch_size=32.\n",
      "[Parallel(n_jobs=6)]: Done 212 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 228 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 244 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 260 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 292 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 308 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 324 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 340 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 356 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 404 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=6)]: Done 436 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 468 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 532 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 564 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 596 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=6)]: Done 628 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=6)]: Done 660 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=6)]: Done 692 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=6)]: Done 724 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=6)]: Done 756 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=6)]: Done 820 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=6)]: Done 852 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=6)]: Done 884 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=6)]: Done 916 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=6)]: Done 948 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=6)]: Done 980 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=6)]: Done 1012 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=6)]: Done 1044 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=6)]: Done 1076 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=6)]: Done 1108 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=6)]: Done 1172 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=6)]: Done 1204 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=6)]: Done 1236 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=6)]: Done 1268 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=6)]: Done 1300 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=6)]: Done 1332 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done 1364 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done 1396 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done 1428 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done 1460 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done 1492 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done 1524 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done 1556 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done 1588 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=6)]: Done 1620 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=6)]: Done 1652 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=6)]: Done 1684 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=6)]: Done 1716 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=6)]: Done 1748 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=6)]: Done 1780 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=6)]: Done 1844 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=6)]: Done 1876 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=6)]: Done 1908 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=6)]: Done 1940 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=6)]: Done 1972 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=6)]: Done 2004 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=6)]: Done 2036 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=6)]: Done 2068 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=6)]: Done 2100 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=6)]: Done 2132 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=6)]: Done 2164 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=6)]: Done 2196 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=6)]: Done 2228 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=6)]: Done 2260 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=6)]: Done 2292 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=6)]: Done 2324 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=6)]: Done 2356 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=6)]: Done 2388 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=6)]: Done 2420 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=6)]: Done 2452 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=6)]: Done 2484 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=6)]: Done 2516 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=6)]: Done 2548 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=6)]: Done 2580 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=6)]: Done 2612 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=6)]: Done 2644 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=6)]: Done 2676 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=6)]: Done 2708 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=6)]: Done 2740 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=6)]: Done 2772 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=6)]: Done 2804 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=6)]: Done 2836 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 2868 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 2900 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 2932 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done 2964 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done 2996 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done 3028 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done 3060 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done 3092 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done 3124 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 3156 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 3220 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=6)]: Done 3284 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=6)]: Done 3316 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=6)]: Done 3348 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=6)]: Done 3380 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=6)]: Done 3412 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=6)]: Done 3444 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=6)]: Done 3476 tasks      | elapsed:    4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 3508 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=6)]: Done 3540 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=6)]: Done 3572 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=6)]: Done 3604 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=6)]: Done 3636 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=6)]: Done 3668 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=6)]: Done 3700 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=6)]: Done 3732 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=6)]: Done 3764 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=6)]: Done 3796 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=6)]: Done 3860 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=6)]: Done 3892 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=6)]: Done 3924 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=6)]: Done 3956 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=6)]: Done 3988 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=6)]: Done 4020 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=6)]: Done 4052 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=6)]: Done 4084 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done 4116 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done 4148 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done 4180 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done 4212 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done 4244 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done 4276 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=6)]: Done 4308 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=6)]: Done 4340 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=6)]: Done 4372 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=6)]: Done 4404 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=6)]: Done 4436 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=6)]: Done 4468 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 4500 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 4532 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 4564 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 4596 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 4628 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=6)]: Done 4660 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=6)]: Done 4692 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=6)]: Done 4724 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=6)]: Done 4756 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=6)]: Done 4788 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=6)]: Done 4820 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=6)]: Done 4852 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=6)]: Done 4884 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=6)]: Done 4916 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=6)]: Done 4948 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=6)]: Done 4980 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=6)]: Done 5012 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=6)]: Done 5044 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=6)]: Done 5076 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=6)]: Done 5108 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=6)]: Done 5140 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=6)]: Done 5172 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=6)]: Done 5204 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=6)]: Done 5236 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=6)]: Done 5268 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=6)]: Done 5300 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=6)]: Done 5332 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=6)]: Done 5364 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=6)]: Done 5396 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=6)]: Done 5428 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done 5460 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done 5492 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done 5524 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done 5556 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done 5588 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done 5620 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=6)]: Done 5652 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=6)]: Done 5684 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=6)]: Done 5716 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=6)]: Done 5748 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=6)]: Done 5780 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=6)]: Done 5812 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done 5844 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done 5876 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done 5908 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done 5940 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done 5972 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done 6004 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=6)]: Done 6036 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=6)]: Done 6068 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=6)]: Done 6100 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=6)]: Done 6132 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=6)]: Done 6164 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=6)]: Done 6196 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done 6228 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done 6260 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done 6292 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done 6324 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=6)]: Done 6356 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=6)]: Done 6388 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=6)]: Done 6452 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=6)]: Done 6484 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=6)]: Done 6516 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=6)]: Done 6548 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=6)]: Done 6580 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=6)]: Done 6612 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=6)]: Done 6644 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=6)]: Done 6676 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=6)]: Done 6708 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=6)]: Done 6740 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=6)]: Done 6772 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done 6804 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done 6836 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done 6868 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done 6900 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done 6932 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done 6964 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=6)]: Done 6996 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=6)]: Done 7028 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=6)]: Done 7060 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=6)]: Done 7092 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=6)]: Done 7124 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=6)]: Done 7156 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=6)]: Done 7188 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=6)]: Done 7220 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=6)]: Done 7252 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=6)]: Done 7316 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=6)]: Done 7348 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=6)]: Done 7380 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=6)]: Done 7412 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=6)]: Done 7444 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=6)]: Done 7476 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=6)]: Done 7508 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=6)]: Done 7540 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=6)]: Done 7572 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=6)]: Done 7604 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=6)]: Done 7636 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=6)]: Done 7668 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=6)]: Done 7700 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=6)]: Done 7732 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=6)]: Done 7764 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=6)]: Done 7796 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=6)]: Done 7828 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=6)]: Done 7860 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=6)]: Done 7892 tasks      | elapsed:   10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 7924 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=6)]: Done 7956 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=6)]: Done 7988 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=6)]: Done 8020 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=6)]: Done 8052 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=6)]: Done 8084 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=6)]: Done 8116 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=6)]: Done 8148 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=6)]: Done 8180 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=6)]: Done 8212 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=6)]: Done 8244 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=6)]: Done 8276 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=6)]: Done 8308 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=6)]: Done 8340 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=6)]: Done 8372 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=6)]: Done 8404 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=6)]: Done 8436 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=6)]: Done 8468 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=6)]: Done 8500 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=6)]: Done 8532 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=6)]: Done 8564 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=6)]: Done 8596 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=6)]: Done 8628 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=6)]: Done 8660 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=6)]: Done 8692 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=6)]: Done 8724 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=6)]: Done 8756 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=6)]: Done 8788 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=6)]: Done 8820 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=6)]: Done 8852 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=6)]: Done 8884 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=6)]: Done 8916 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=6)]: Done 8948 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=6)]: Done 8980 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=6)]: Done 9012 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=6)]: Done 9044 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=6)]: Done 9076 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=6)]: Done 9108 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=6)]: Done 9140 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=6)]: Done 9172 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=6)]: Done 9204 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=6)]: Done 9236 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=6)]: Done 9268 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=6)]: Done 9300 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=6)]: Done 9332 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=6)]: Done 9364 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=6)]: Done 9396 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=6)]: Done 9428 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=6)]: Done 9460 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=6)]: Done 9492 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=6)]: Done 9524 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=6)]: Done 9556 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=6)]: Done 9588 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=6)]: Done 9620 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9621 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9622 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9623 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9624 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9656 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9657 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9658 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9659 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9660 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9661 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9662 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9663 tasks      | elapsed:   13.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24614456049643635\n",
      "{'model__alpha': 6.0, 'model__solver': 'sag', 'pca__n_components': 7}\n",
      "Total time:  0.23138504823048908 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 9664 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 9665 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=6)]: Done 9800 out of 9800 | elapsed:   13.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('pca', pca), ('model', model)])\n",
    "\n",
    "params_pca = [1,2,3,4,5,6,7]\n",
    "param_grid   =  [{'pca__n_components' : params_pca,\n",
    "                  'model__alpha' : [x*1. for x in range(1,100,5)],\n",
    "                  'model__solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}]\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "# score = 'neg_mean_squared_error'\n",
    "# score = 'neg_mean_absolute_error'\n",
    "score = 'r2'\n",
    "cv = 10\n",
    "\n",
    "grid(Xtrain = X_train_std,\n",
    "            ytrain = y_train,\n",
    "            estimator = pipe,\n",
    "            params_grid = param_grid,\n",
    "            scores=score,\n",
    "            cvs = cv,\n",
    "            cores=6,\n",
    "            verb=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3582 candidates, totalling 35820 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=6)]: Done 12468 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=6)]: Done 18804 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=6)]: Done 26292 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=6)]: Done 34932 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=6)]: Done 35820 out of 35820 | elapsed:   53.1s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2591.9418709501624, tolerance: 916.8450781561908\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-67.21519257109519\n",
      "{'model__alpha': 0.1, 'model__max_iter': 350, 'model__selection': 'cyclic'}\n",
      "Total time:  0.8883313735326132 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 3582 candidates, totalling 35820 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=6)]: Done 12468 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=6)]: Done 18804 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=6)]: Done 26292 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=6)]: Done 34932 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=6)]: Done 35820 out of 35820 | elapsed:   56.2s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 115260.35257146508, tolerance: 916.8450781561908\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6657.548388715373\n",
      "{'model__alpha': 0.1, 'model__max_iter': 400, 'model__selection': 'random'}\n",
      "Total time:  0.9405562082926432 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 3582 candidates, totalling 35820 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 282 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=6)]: Done 3066 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=6)]: Done 7098 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=6)]: Done 12282 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=6)]: Done 18618 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=6)]: Done 26106 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=6)]: Done 34746 tasks      | elapsed:   58.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311368824471978\n",
      "{'model__alpha': 0.1, 'model__max_iter': 400, 'model__selection': 'random'}\n",
      "Total time:  1.003538393974304 minutes\n",
      "r2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 35820 out of 35820 | elapsed:  1.0min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 73141.30956394877, tolerance: 916.8450781561908\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__alpha' : [x*0.1 for x in range(1,10)],\n",
    "                  'model__max_iter' : [x for x in range(50, 10000, 50)],\n",
    "                  'model__selection' : ['cyclic','random']}]\n",
    "\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=6,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16119 candidates, totalling 161190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=6)]: Done 5748 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=6)]: Done 13812 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=6)]: Done 24180 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=6)]: Done 36852 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=6)]: Done 51828 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=6)]: Done 69108 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 88692 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 110580 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 134772 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 160796 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 161190 out of 161190 | elapsed:  2.6min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 877419.108143169, tolerance: 916.8450781561908\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-68.00384519083332\n",
      "{'model__alpha': 0.1, 'model__l1_ratio': 0.9, 'model__max_iter': 100}\n",
      "Total time:  2.592602022488912 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 16119 candidates, totalling 161190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done 12468 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=6)]: Done 18804 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=6)]: Done 26292 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=6)]: Done 34932 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=6)]: Done 44724 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=6)]: Done 67764 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 81012 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 95412 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 110964 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 127668 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 145524 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 161190 out of 161190 | elapsed:  2.7min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 877419.108143169, tolerance: 916.8450781561908\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6756.403466337346\n",
      "{'model__alpha': 0.1, 'model__l1_ratio': 0.9, 'model__max_iter': 100}\n",
      "Total time:  2.6927709658940633 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 16119 candidates, totalling 161190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=6)]: Done 5748 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=6)]: Done 13812 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=6)]: Done 24180 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=6)]: Done 36852 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=6)]: Done 51828 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=6)]: Done 69108 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 88692 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 110580 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 134772 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done 160796 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done 161190 out of 161190 | elapsed:  2.7min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 877419.108143169, tolerance: 916.8450781561908\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3013005530743831\n",
      "{'model__alpha': 0.1, 'model__l1_ratio': 0.9, 'model__max_iter': 100}\n",
      "Total time:  2.6756309866905212 minutes\n",
      "r2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__alpha' : [x*0.1 for x in range(1,10)],\n",
    "                  'model__max_iter' : [x for x in range(50, 10000, 50)],\n",
    "                  'model__l1_ratio' : [x*0.1 for x in range(1,10)]}]\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=6,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OrthogonalMatchingPursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "-67.11162898315615\n",
      "{'model__fit_intercept': True, 'model__n_nonzero_coefs': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 132 out of 180 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 180 out of 180 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:  0.0033333897590637207 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 132 out of 180 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 180 out of 180 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 132 out of 180 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6641.569814139092\n",
      "{'model__fit_intercept': True, 'model__n_nonzero_coefs': 7}\n",
      "Total time:  0.0037020484606424967 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "0.31287780309079255\n",
      "{'model__fit_intercept': True, 'model__n_nonzero_coefs': 7}\n",
      "Total time:  0.0038677334785461428 minutes\n",
      "r2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 180 out of 180 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "model = OrthogonalMatchingPursuit()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__fit_intercept' : [True, False],\n",
    "                  'model__n_nonzero_coefs' : [x for x in range(1,10)]}]\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=6,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 477799 candidates, totalling 4777990 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 5748 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 13812 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=6)]: Done 24180 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=6)]: Done 36852 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=6)]: Done 51828 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=6)]: Done 69108 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 88692 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 110580 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 134772 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 161268 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done 190068 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=6)]: Done 221172 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 254580 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=6)]: Done 285564 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=6)]: Done 314076 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=6)]: Done 344316 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=6)]: Done 376284 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=6)]: Done 409980 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=6)]: Done 445404 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=6)]: Done 482556 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=6)]: Done 521436 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=6)]: Done 562044 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=6)]: Done 604380 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=6)]: Done 648444 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=6)]: Done 694236 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=6)]: Done 741756 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=6)]: Done 781884 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=6)]: Done 808596 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=6)]: Done 861300 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=6)]: Done 915732 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=6)]: Done 937332 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=6)]: Done 994212 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=6)]: Done 1053828 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=6)]: Done 1113252 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=6)]: Done 1159524 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=6)]: Done 1224324 tasks      | elapsed: 27.2min\n",
      "[Parallel(n_jobs=6)]: Done 1280796 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=6)]: Done 1338180 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=6)]: Done 1409268 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=6)]: Done 1459092 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=6)]: Done 1535748 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=6)]: Done 1583364 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=6)]: Done 1632948 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=6)]: Done 1711572 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=6)]: Done 1794516 tasks      | elapsed: 41.0min\n",
      "[Parallel(n_jobs=6)]: Done 1864956 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=6)]: Done 1939716 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=6)]: Done 1996884 tasks      | elapsed: 46.0min\n",
      "[Parallel(n_jobs=6)]: Done 2063076 tasks      | elapsed: 47.9min\n",
      "[Parallel(n_jobs=6)]: Done 2143188 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=6)]: Done 2211396 tasks      | elapsed: 51.5min\n",
      "[Parallel(n_jobs=6)]: Done 2294700 tasks      | elapsed: 53.4min\n",
      "[Parallel(n_jobs=6)]: Done 2384796 tasks      | elapsed: 55.5min\n",
      "[Parallel(n_jobs=6)]: Done 2455524 tasks      | elapsed: 57.3min\n",
      "[Parallel(n_jobs=6)]: Done 2520324 tasks      | elapsed: 59.0min\n",
      "[Parallel(n_jobs=6)]: Done 2619684 tasks      | elapsed: 61.0min\n",
      "[Parallel(n_jobs=6)]: Done 2720772 tasks      | elapsed: 62.9min\n",
      "[Parallel(n_jobs=6)]: Done 2823588 tasks      | elapsed: 64.9min\n",
      "[Parallel(n_jobs=6)]: Done 2928132 tasks      | elapsed: 67.0min\n",
      "[Parallel(n_jobs=6)]: Done 3034404 tasks      | elapsed: 69.1min\n",
      "[Parallel(n_jobs=6)]: Done 3142404 tasks      | elapsed: 71.2min\n",
      "[Parallel(n_jobs=6)]: Done 3252132 tasks      | elapsed: 73.3min\n",
      "[Parallel(n_jobs=6)]: Done 3363588 tasks      | elapsed: 75.5min\n",
      "[Parallel(n_jobs=6)]: Done 3476772 tasks      | elapsed: 77.7min\n",
      "[Parallel(n_jobs=6)]: Done 3591684 tasks      | elapsed: 79.9min\n",
      "[Parallel(n_jobs=6)]: Done 3708324 tasks      | elapsed: 82.2min\n",
      "[Parallel(n_jobs=6)]: Done 3826692 tasks      | elapsed: 84.5min\n",
      "[Parallel(n_jobs=6)]: Done 3946788 tasks      | elapsed: 86.9min\n",
      "[Parallel(n_jobs=6)]: Done 4068612 tasks      | elapsed: 89.2min\n",
      "[Parallel(n_jobs=6)]: Done 4192164 tasks      | elapsed: 91.7min\n",
      "[Parallel(n_jobs=6)]: Done 4317444 tasks      | elapsed: 94.1min\n",
      "[Parallel(n_jobs=6)]: Done 4444452 tasks      | elapsed: 96.6min\n",
      "[Parallel(n_jobs=6)]: Done 4573188 tasks      | elapsed: 99.1min\n",
      "[Parallel(n_jobs=6)]: Done 4703652 tasks      | elapsed: 101.6min\n",
      "[Parallel(n_jobs=6)]: Done 4777990 out of 4777990 | elapsed: 103.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  10  iterations\n",
      "-67.21933161246935\n",
      "{'model__alpha_1': 1.0, 'model__alpha_2': 1e-06, 'model__lambda_1': 1e-06, 'model__lambda_2': 1.0, 'model__n_iter': 50, 'model__verbose': True}\n",
      "Total time:  103.3246371905009 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 477799 candidates, totalling 4777990 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=6)]: Done 5748 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 13812 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=6)]: Done 24180 tasks      | elapsed:   31.1s\n",
      "[Parallel(n_jobs=6)]: Done 28740 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=6)]: Done 31548 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=6)]: Done 34788 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=6)]: Done 38460 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 45516 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 63660 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 81660 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 109788 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done 140892 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done 174300 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=6)]: Done 210012 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=6)]: Done 248028 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=6)]: Done 288348 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=6)]: Done 330972 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=6)]: Done 375900 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=6)]: Done 423132 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=6)]: Done 472668 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=6)]: Done 524508 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=6)]: Done 578652 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=6)]: Done 635100 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=6)]: Done 693852 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=6)]: Done 754908 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=6)]: Done 818268 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=6)]: Done 883932 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=6)]: Done 951900 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=6)]: Done 1022172 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=6)]: Done 1094748 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=6)]: Done 1169628 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=6)]: Done 1246812 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=6)]: Done 1326300 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=6)]: Done 1408092 tasks      | elapsed: 27.7min\n",
      "[Parallel(n_jobs=6)]: Done 1492188 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=6)]: Done 1578588 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=6)]: Done 1667292 tasks      | elapsed: 32.8min\n",
      "[Parallel(n_jobs=6)]: Done 1758300 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=6)]: Done 1851612 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=6)]: Done 1947228 tasks      | elapsed: 38.3min\n",
      "[Parallel(n_jobs=6)]: Done 2045148 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=6)]: Done 2145372 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=6)]: Done 2247900 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=6)]: Done 2352732 tasks      | elapsed: 46.1min\n",
      "[Parallel(n_jobs=6)]: Done 2459868 tasks      | elapsed: 48.2min\n",
      "[Parallel(n_jobs=6)]: Done 2569308 tasks      | elapsed: 50.3min\n",
      "[Parallel(n_jobs=6)]: Done 2681052 tasks      | elapsed: 52.5min\n",
      "[Parallel(n_jobs=6)]: Done 2795100 tasks      | elapsed: 54.7min\n",
      "[Parallel(n_jobs=6)]: Done 2911452 tasks      | elapsed: 57.0min\n",
      "[Parallel(n_jobs=6)]: Done 3030108 tasks      | elapsed: 59.3min\n",
      "[Parallel(n_jobs=6)]: Done 3151068 tasks      | elapsed: 61.6min\n",
      "[Parallel(n_jobs=6)]: Done 3274332 tasks      | elapsed: 64.0min\n",
      "[Parallel(n_jobs=6)]: Done 3399900 tasks      | elapsed: 66.5min\n",
      "[Parallel(n_jobs=6)]: Done 3527772 tasks      | elapsed: 69.0min\n",
      "[Parallel(n_jobs=6)]: Done 3657948 tasks      | elapsed: 71.5min\n",
      "[Parallel(n_jobs=6)]: Done 3790428 tasks      | elapsed: 74.1min\n",
      "[Parallel(n_jobs=6)]: Done 3925212 tasks      | elapsed: 76.7min\n",
      "[Parallel(n_jobs=6)]: Done 4062300 tasks      | elapsed: 79.3min\n",
      "[Parallel(n_jobs=6)]: Done 4201692 tasks      | elapsed: 82.1min\n",
      "[Parallel(n_jobs=6)]: Done 4343388 tasks      | elapsed: 84.8min\n",
      "[Parallel(n_jobs=6)]: Done 4487388 tasks      | elapsed: 87.6min\n",
      "[Parallel(n_jobs=6)]: Done 4633692 tasks      | elapsed: 90.4min\n",
      "[Parallel(n_jobs=6)]: Done 4771980 tasks      | elapsed: 93.1min\n",
      "[Parallel(n_jobs=6)]: Done 4777990 out of 4777990 | elapsed: 93.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  10  iterations\n",
      "-6660.228677944468\n",
      "{'model__alpha_1': 1.0, 'model__alpha_2': 1e-06, 'model__lambda_1': 1e-06, 'model__lambda_2': 1.0, 'model__n_iter': 50, 'model__verbose': True}\n",
      "Total time:  93.49243084192275 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 477799 candidates, totalling 4777990 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 5748 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=6)]: Done 13812 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=6)]: Done 23816 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=6)]: Done 26244 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=6)]: Done 29052 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=6)]: Done 38268 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=6)]: Done 52956 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 64428 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 88620 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=6)]: Done 95460 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 107916 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done 131244 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done 156300 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=6)]: Done 183084 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=6)]: Done 211596 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=6)]: Done 241836 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=6)]: Done 273804 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=6)]: Done 307500 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=6)]: Done 342924 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=6)]: Done 368652 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=6)]: Done 394572 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=6)]: Done 421644 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=6)]: Done 449868 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=6)]: Done 479244 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=6)]: Done 509772 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=6)]: Done 541452 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=6)]: Done 574284 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=6)]: Done 608268 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=6)]: Done 643404 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=6)]: Done 679692 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=6)]: Done 717132 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=6)]: Done 755724 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=6)]: Done 795468 tasks      | elapsed: 17.6min\n",
      "[Parallel(n_jobs=6)]: Done 836364 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=6)]: Done 878412 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=6)]: Done 921612 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=6)]: Done 965964 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=6)]: Done 1011468 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=6)]: Done 1058124 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=6)]: Done 1105932 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=6)]: Done 1154892 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=6)]: Done 1205004 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=6)]: Done 1256268 tasks      | elapsed: 27.6min\n",
      "[Parallel(n_jobs=6)]: Done 1308684 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=6)]: Done 1362252 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=6)]: Done 1416972 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=6)]: Done 1472844 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=6)]: Done 1529868 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=6)]: Done 1588044 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=6)]: Done 1647372 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=6)]: Done 1707852 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=6)]: Done 1769484 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=6)]: Done 1832268 tasks      | elapsed: 40.1min\n",
      "[Parallel(n_jobs=6)]: Done 1896204 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=6)]: Done 1961292 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=6)]: Done 2027532 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=6)]: Done 2094924 tasks      | elapsed: 45.3min\n",
      "[Parallel(n_jobs=6)]: Done 2163468 tasks      | elapsed: 46.6min\n",
      "[Parallel(n_jobs=6)]: Done 2233164 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=6)]: Done 2304012 tasks      | elapsed: 49.4min\n",
      "[Parallel(n_jobs=6)]: Done 2376012 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=6)]: Done 2449164 tasks      | elapsed: 52.3min\n",
      "[Parallel(n_jobs=6)]: Done 2523468 tasks      | elapsed: 53.7min\n",
      "[Parallel(n_jobs=6)]: Done 2598924 tasks      | elapsed: 55.2min\n",
      "[Parallel(n_jobs=6)]: Done 2675532 tasks      | elapsed: 56.7min\n",
      "[Parallel(n_jobs=6)]: Done 2753292 tasks      | elapsed: 58.2min\n",
      "[Parallel(n_jobs=6)]: Done 2832204 tasks      | elapsed: 59.8min\n",
      "[Parallel(n_jobs=6)]: Done 2912268 tasks      | elapsed: 61.3min\n",
      "[Parallel(n_jobs=6)]: Done 2993484 tasks      | elapsed: 62.9min\n",
      "[Parallel(n_jobs=6)]: Done 3075852 tasks      | elapsed: 64.5min\n",
      "[Parallel(n_jobs=6)]: Done 3159372 tasks      | elapsed: 66.1min\n",
      "[Parallel(n_jobs=6)]: Done 3244044 tasks      | elapsed: 67.8min\n",
      "[Parallel(n_jobs=6)]: Done 3329868 tasks      | elapsed: 69.5min\n",
      "[Parallel(n_jobs=6)]: Done 3416844 tasks      | elapsed: 71.2min\n",
      "[Parallel(n_jobs=6)]: Done 3504972 tasks      | elapsed: 72.9min\n",
      "[Parallel(n_jobs=6)]: Done 3594252 tasks      | elapsed: 74.6min\n",
      "[Parallel(n_jobs=6)]: Done 3684684 tasks      | elapsed: 76.4min\n",
      "[Parallel(n_jobs=6)]: Done 3776268 tasks      | elapsed: 78.2min\n",
      "[Parallel(n_jobs=6)]: Done 3869004 tasks      | elapsed: 79.9min\n",
      "[Parallel(n_jobs=6)]: Done 3962892 tasks      | elapsed: 81.8min\n",
      "[Parallel(n_jobs=6)]: Done 4057932 tasks      | elapsed: 83.6min\n",
      "[Parallel(n_jobs=6)]: Done 4154124 tasks      | elapsed: 85.5min\n",
      "[Parallel(n_jobs=6)]: Done 4251468 tasks      | elapsed: 87.4min\n",
      "[Parallel(n_jobs=6)]: Done 4349964 tasks      | elapsed: 89.3min\n",
      "[Parallel(n_jobs=6)]: Done 4449612 tasks      | elapsed: 91.2min\n",
      "[Parallel(n_jobs=6)]: Done 4550412 tasks      | elapsed: 93.2min\n",
      "[Parallel(n_jobs=6)]: Done 4652364 tasks      | elapsed: 95.1min\n",
      "[Parallel(n_jobs=6)]: Done 4755468 tasks      | elapsed: 97.2min\n",
      "[Parallel(n_jobs=6)]: Done 4777990 out of 4777990 | elapsed: 97.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  10  iterations\n",
      "0.3111986069879795\n",
      "{'model__alpha_1': 1.0, 'model__alpha_2': 1e-06, 'model__lambda_1': 1e-06, 'model__lambda_2': 1.0, 'model__n_iter': 50, 'model__verbose': True}\n",
      "Total time:  97.83360948959987 minutes\n",
      "r2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "model = BayesianRidge()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__n_iter' : [x for x in range(50, 10000, 50)],\n",
    "                  'model__alpha_1' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__alpha_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_1' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__verbose' : [True]}]\n",
    "\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=6,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in range(5, 150, 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARDRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24010 candidates, totalling 240100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=6)]: Done 1362 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done 3378 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=6)]: Done 5970 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=6)]: Done 9138 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=6)]: Done 12882 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=6)]: Done 17202 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 22098 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 27570 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 33618 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 40242 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done 47442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=6)]: Done 55218 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 63570 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=6)]: Done 72498 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=6)]: Done 82002 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=6)]: Done 92082 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=6)]: Done 102738 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=6)]: Done 113970 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=6)]: Done 125778 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=6)]: Done 137812 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=6)]: Done 150102 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=6)]: Done 163638 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=6)]: Done 177750 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=6)]: Done 192438 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=6)]: Done 207702 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=6)]: Done 223542 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=6)]: Done 239958 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=6)]: Done 240100 out of 240100 | elapsed: 13.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-67.13900316406462\n",
      "{'model__alpha_1': 1.0, 'model__alpha_2': 1e-06, 'model__lambda_1': 0.01, 'model__lambda_2': 9.999999999999999e-05, 'model__n_iter': 101}\n",
      "Total time:  13.000765061378479 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 24010 candidates, totalling 240100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=6)]: Done 9588 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=6)]: Done 13332 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=6)]: Done 17652 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=6)]: Done 22548 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 28020 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 34068 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 40692 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 47892 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 64020 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done 72948 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=6)]: Done 82452 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 92532 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=6)]: Done 103188 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=6)]: Done 114420 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=6)]: Done 126228 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=6)]: Done 138612 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=6)]: Done 151572 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=6)]: Done 165108 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=6)]: Done 179220 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=6)]: Done 193908 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=6)]: Done 209172 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=6)]: Done 225012 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=6)]: Done 240100 out of 240100 | elapsed: 12.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6649.446495775375\n",
      "{'model__alpha_1': 1.0, 'model__alpha_2': 1e-06, 'model__lambda_1': 0.01, 'model__lambda_2': 9.999999999999999e-05, 'model__n_iter': 101}\n",
      "Total time:  12.514347740014394 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 24010 candidates, totalling 240100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=6)]: Done 1812 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=6)]: Done 3828 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=6)]: Done 6420 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=6)]: Done 9588 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=6)]: Done 13332 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=6)]: Done 17652 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=6)]: Done 22548 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 28020 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 34068 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 40692 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 47892 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 64020 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 72948 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=6)]: Done 82452 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 92532 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=6)]: Done 103188 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=6)]: Done 114420 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=6)]: Done 126228 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=6)]: Done 138612 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=6)]: Done 151572 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=6)]: Done 165108 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=6)]: Done 179220 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=6)]: Done 193908 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=6)]: Done 209172 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=6)]: Done 225012 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=6)]: Done 240100 out of 240100 | elapsed: 12.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3119010582479148\n",
      "{'model__alpha_1': 1.0, 'model__alpha_2': 1e-06, 'model__lambda_1': 0.01, 'model__lambda_2': 9.999999999999999e-05, 'model__n_iter': 101}\n",
      "Total time:  12.507806340853373 minutes\n",
      "r2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ARDRegression\n",
    "model = ARDRegression()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__n_iter' : [x for x in range(1, 500,50)],\n",
    "                  'model__alpha_1' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__alpha_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_1' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "                  'model__lambda_2' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]]}]\n",
    "\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=6,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 180 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=6)]: Done 564 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=6)]: Done 690 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=6)]: Done 852 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=6)]: Done 1434 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=6)]: Done 1668 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=6)]: Done 1800 out of 1800 | elapsed:   55.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-67.46152868265435\n",
      "{'model__loss': 'absolute_loss', 'model__max_trials': 351, 'model__min_samples': 30.0}\n",
      "Total time:  0.9307370185852051 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 180 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=6)]: Done 564 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=6)]: Done 690 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=6)]: Done 852 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=6)]: Done 1434 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=6)]: Done 1668 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=6)]: Done 1800 out of 1800 | elapsed:   55.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7127.403622099427\n",
      "{'model__loss': 'absolute_loss', 'model__max_trials': 151, 'model__min_samples': 80.0}\n",
      "Total time:  0.929290242989858 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 180 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 204 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=6)]: Done 546 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=6)]: Done 672 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=6)]: Done 834 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=6)]: Done 1416 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=6)]: Done 1650 tasks      | elapsed:   47.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26208984930752743\n",
      "{'model__loss': 'absolute_loss', 'model__max_trials': 1, 'model__min_samples': 80.0}\n",
      "Total time:  0.933847979704539 minutes\n",
      "r2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 1800 out of 1800 | elapsed:   55.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "model = RANSACRegressor()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__min_samples' : [x/.1 for x in range(1, 10)],\n",
    "                  'model__max_trials' : [x for x in range(1, 500,50)],\n",
    "                  'model__loss' : ['absolute_loss', 'squared_loss']}]\n",
    "\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=6,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TheilSenRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3458 candidates, totalling 34580 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=6)]: Done 12468 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=6)]: Done 18804 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=6)]: Done 26292 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=6)]: Done 34467 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=6)]: Done 34580 out of 34580 | elapsed:   33.3s finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object TheilSenRegressor(max_iter=500, max_subpopulation=1.0, n_subsamples=409), as the constructor either does not set or modifies parameter max_subpopulation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-2de1bb1e6302>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     grid(Xtrain = X_train_std,\n\u001b[0m\u001b[0;32m     19\u001b[0m                 \u001b[0mytrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-16db00b493b4>\u001b[0m in \u001b[0;36mgrid\u001b[1;34m(Xtrain, ytrain, estimator, params_grid, scores, cvs, cores, verb)\u001b[0m\n\u001b[0;32m     17\u001b[0m                       verbose=verb)\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# we clone again after setting params in case some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[0;32m    762\u001b[0m                 **self.best_params_))\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# XXX: not handling dictionaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# XXX: not handling dictionaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# XXX: not handling dictionaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# XXX: not handling dictionaries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mestimator_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mestimator_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msafe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object TheilSenRegressor(max_iter=500, max_subpopulation=1.0, n_subsamples=409), as the constructor either does not set or modifies parameter max_subpopulation"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import TheilSenRegressor\n",
    "# model = TheilSenRegressor()\n",
    "\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "# param_grid   =  [{'model__max_subpopulation' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]],\n",
    "#                   'model__n_subsamples' : [x for x in range(9, 1300,50)],\n",
    "#                   'model__max_iter' :  [x for x in range(50, 1000, 50)]}]\n",
    "\n",
    "# pipe.get_params()\n",
    "\n",
    "# estimator = pipe\n",
    "\n",
    "# scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "# cv = 10\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X_train_std,\n",
    "#                 ytrain = y_train,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=6,\n",
    "#                 verb=5)\n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuberRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 140 candidates, totalling 1400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=6)]: Done 786 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=6)]: Done 1400 out of 1400 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-67.11601951670664\n",
      "{'model__alpha': 9.999999999999999e-06, 'model__epsilon': 10000.0}\n",
      "Total time:  0.19075722694396974 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 140 candidates, totalling 1400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 180 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=6)]: Done 540 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=6)]: Done 1044 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=6)]: Done 1400 out of 1400 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6654.510405952045\n",
      "{'model__alpha': 0.01, 'model__epsilon': 10000.0}\n",
      "Total time:  0.1508657972017924 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 140 candidates, totalling 1400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 180 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=6)]: Done 540 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 1044 tasks      | elapsed:    8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31176165054235033\n",
      "{'model__alpha': 0.01, 'model__epsilon': 10000.0}\n",
      "Total time:  0.1800036072731018 minutes\n",
      "r2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 1400 out of 1400 | elapsed:   10.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "model = HuberRegressor()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__epsilon' : [x/.01 for x in range(100, 200, 5)],\n",
    "                  'model__alpha' : [x*0.000001 for x in [1,10,100,1000,10000,100000,1000000]]}]\n",
    "\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=6,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20790 candidates, totalling 207900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=6)]: Done 5748 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=6)]: Done 13812 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=6)]: Done 24180 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=6)]: Done 36852 tasks      | elapsed:   41.4s\n",
      "[Parallel(n_jobs=6)]: Done 51828 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=6)]: Done 67860 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 74772 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 82980 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 92052 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 101988 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 112788 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 124452 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=6)]: Done 136980 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done 150372 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done 164628 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=6)]: Done 179748 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=6)]: Done 195732 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=6)]: Done 207900 out of 207900 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-52.662119808253024\n",
      "{'model__max_depth': 91, 'model__max_features': 7, 'model__min_samples_leaf': 6, 'model__min_samples_split': 21}\n",
      "Total time:  4.661316029230753 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 20790 candidates, totalling 207900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 3252 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 7284 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=6)]: Done 12468 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=6)]: Done 18804 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=6)]: Done 26292 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=6)]: Done 34932 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=6)]: Done 44724 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=6)]: Done 55668 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 67764 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 81012 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 95412 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 110964 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 127668 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 143028 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done 161844 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=6)]: Done 182004 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 203316 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=6)]: Done 207900 out of 207900 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4610.726233586867\n",
      "{'model__max_depth': None, 'model__max_features': 8, 'model__min_samples_leaf': 1, 'model__min_samples_split': 36}\n",
      "Total time:  4.865469698111216 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 20790 candidates, totalling 207900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done 372 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done 5748 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=6)]: Done 13812 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=6)]: Done 24180 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=6)]: Done 36852 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=6)]: Done 51828 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 69108 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 88692 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 109332 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 127188 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=6)]: Done 147060 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=6)]: Done 168660 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=6)]: Done 191988 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=6)]: Done 207900 out of 207900 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5258772846698527\n",
      "{'model__max_depth': 86, 'model__max_features': 8, 'model__min_samples_leaf': 1, 'model__min_samples_split': 36}\n",
      "Total time:  4.3642670750617985 minutes\n",
      "r2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__max_depth' : [None]+[x for x in range(1, 100,5)],\n",
    "                  'model__min_samples_leaf' : [x for x in range(1, 50,5)],\n",
    "                  'model__min_samples_split' : [2]+[x for x in range(1, 50,5)],\n",
    "                  'model__max_features' : [x for x in range(1, 10)]}]\n",
    "\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=6,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b5fec669aca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianProcessRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 243 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=7)]: Done 350 out of 350 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-78.01943299134054\n",
      "{'model__alpha': 0.0001, 'model__kernel': None}\n",
      "Total time:  0.04724022150039673 minutes\n",
      "neg_mean_absolute_error\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done 243 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=7)]: Done 350 out of 350 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13488.486682818035\n",
      "{'model__alpha': 0.0001, 'model__kernel': None}\n",
      "Total time:  0.030754383405049643 minutes\n",
      "neg_mean_squared_error\n",
      "Fitting 10 folds for each of 35 candidates, totalling 350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=7)]: Done 120 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3967078914742873\n",
      "{'model__alpha': 0.0001, 'model__kernel': None}\n",
      "Total time:  0.03500665823618571 minutes\n",
      "r2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Done 323 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=7)]: Done 350 out of 350 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "model = GaussianProcessRegressor()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "# , \n",
    "param_grid   =  [{'model__kernel' : [None]+['rbf', 'sigmoid',  'linear', 'poly'],\n",
    "                  'model__alpha' : [x*0.0000000001 for x in [1,10,100,1000,10000,100000,1000000]]}]\n",
    "\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=7,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1280 candidates, totalling 12800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   4 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=7)]: Done  67 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=7)]: Done 1157 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=7)]: Done 3173 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=7)]: Done 5765 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=7)]: Done 8933 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=7)]: Done 12677 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=7)]: Done 12800 out of 12800 | elapsed:   31.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-50.87729198749018\n",
      "{'model__algorithm': 'auto', 'model__leaf_size': 10, 'model__n_neighbors': 6, 'model__weights': 'distance'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "append() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-d1262aa79259>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     grid(Xtrain = X_train_std,\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mytrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-89-37542f7a4d5e>\u001b[0m in \u001b[0;36mgrid\u001b[1;34m(Xtrain, ytrain, estimator, params_grid, scores, cvs, cores, verb)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mdatetime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     results.append(np.array((gs.best_estimator_, gs, score, gs.best_score_, gs.best_params_, \n\u001b[0m\u001b[0;32m     30\u001b[0m                              (t2 - t1) / 60, datetime), dtype=object), np.array(comments))\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: append() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "param_grid   =  [{'model__n_neighbors' : [x for x in range(1, 100,5)],\n",
    "                  'model__weights' : ['uniform', 'distance'],\n",
    "                  'model__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                  'model__leaf_size' : [x for x in range(10, 50, 5)]}]\n",
    "\n",
    "pipe.get_params()\n",
    "\n",
    "estimator = pipe\n",
    "\n",
    "scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "cv = 10\n",
    "\n",
    "for score in scores:\n",
    "    grid(Xtrain = X_train_std,\n",
    "                ytrain = y_train,\n",
    "                estimator = pipe,\n",
    "                params_grid = param_grid,\n",
    "                scores=score,\n",
    "                cvs = cv,\n",
    "                cores=7,\n",
    "                verb=5)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadiusNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 648 candidates, totalling 6480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 560, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 607, in _score\n    scores = scorer(estimator, X_test, y_test)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 87, in __call__\n    score = scorer._score(cached_call, estimator,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 212, in _score\n    return self._sign * self._score_func(y_true, y_pred,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n    return f(**kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 178, in mean_absolute_error\n    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 86, in _check_reg_targets\n    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 72, in inner_f\n    return f(**kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 644, in check_array\n    _assert_all_finite(array,\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 96, in _assert_all_finite\n    raise ValueError(\nValueError: Input contains NaN, infinity or a value too large for dtype('float64').\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-92baa60a67aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     grid(Xtrain = X_train_std,\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mytrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-16db00b493b4>\u001b[0m in \u001b[0;36mgrid\u001b[1;34m(Xtrain, ytrain, estimator, params_grid, scores, cvs, cores, verb)\u001b[0m\n\u001b[0;32m     17\u001b[0m                       verbose=verb)\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "# model = RadiusNeighborsRegressor()\n",
    "\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('model', model)])\n",
    "\n",
    "# param_grid   =  [{'model__radius' : [x*1. for x in range(1, 10)],\n",
    "#                   'model__weights' : ['uniform', 'distance'],\n",
    "#                   'model__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#                   'model__p' : [x for x in range(1, 10)]}]\n",
    "\n",
    "# pipe.get_params()\n",
    "\n",
    "# estimator = pipe\n",
    "\n",
    "# scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "# cv = 10\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X_train_std,\n",
    "#                 ytrain = y_train,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=7,\n",
    "#                 verb=5)\n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IsotonicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://github.com/scikit-learn/scikit-learn/issues/17333\n",
    "\n",
    "# import sklearn\n",
    "# class IsotonicWrapper(sklearn.isotonic.IsotonicRegression):\n",
    "#     def fit(self, X, y, sample_weight=None):\n",
    "#         super().fit(X.ravel(), y, sample_weight=sample_weight)\n",
    "\n",
    "#     def predict(self, T):\n",
    "#         return super().predict(T.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_params() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 520, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 141, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 53, in _set_params\n    super().set_params(**params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 243, in set_params\n    valid_params = self.get_params(deep=True)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 130, in get_params\n    return self._get_params('steps', deep=deep)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 35, in _get_params\n    for key, value in estimator.get_params(deep=True).items():\nTypeError: get_params() missing 1 required positional argument: 'self'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-cbf812925457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     grid(Xtrain = X_train_std,\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mytrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-16db00b493b4>\u001b[0m in \u001b[0;36mgrid\u001b[1;34m(Xtrain, ytrain, estimator, params_grid, scores, cvs, cores, verb)\u001b[0m\n\u001b[0;32m     17\u001b[0m                       verbose=verb)\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_params() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "# from sklearn.isotonic import IsotonicRegression\n",
    "# model = IsotonicRegression()\n",
    "\n",
    "# pipe = Pipeline(steps=[('sc', sc), ('iw',IsotonicWrapper), ('model', model)])\n",
    "\n",
    "# param_grid   =  [{\n",
    "# #     'model__y_min' : [None]+[x*1. for x in range(1, 10)],\n",
    "# #                   'model__y_max' : [None]+[x*1. for x in range(1, 10)],\n",
    "#                   'model__increasing' : ['auto', True, False],\n",
    "#                   'model__out_of_bounds' : ['nan', 'clip', 'raise']}]\n",
    "\n",
    "# pipe.get_params()\n",
    "\n",
    "# estimator = pipe\n",
    "\n",
    "# scores = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "# cv = 10\n",
    "\n",
    "# for score in scores:\n",
    "#     grid(Xtrain = X_train_std,\n",
    "#                 ytrain = y_train,\n",
    "#                 estimator = pipe,\n",
    "#                 params_grid = param_grid,\n",
    "#                 scores=score,\n",
    "#                 cvs = cv,\n",
    "#                 cores=7,\n",
    "#                 verb=5)\n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_est = []\n",
    "def refit_inst(best_index_):\n",
    "#     best_est.append(best_score_)\n",
    "#     print(scoring)\n",
    "#     best_est.append(best_params_)\n",
    "    return  best_index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 108 | elapsed:    2.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "best_index_ returned is not an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-33fab285d29d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                  refit=refit_inst, return_train_score=True)\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;31m# print(gs.best_score_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# print(gs.best_params_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    745\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_index_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_index_ returned is not an integer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m                 if (self.best_index_ < 0 or\n\u001b[0;32m    749\u001b[0m                    self.best_index_ >= len(results[\"params\"])):\n",
      "\u001b[1;31mTypeError\u001b[0m: best_index_ returned is not an integer"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "# Define the pipeline (scaling and classification method):\n",
    "pipe_forest = make_pipeline(StandardScaler(), PCA(), RandomForestRegressor(random_state=0, n_jobs = -1))\n",
    "\n",
    "# Define ranges of parameter values:\n",
    "param_range  = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0] # For regularization parameter C.\n",
    "param_range2 = [0.0000001,0.000001,0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]         # For scaling parameter gamma og rbf-kernel.\n",
    "param_range3 = [x for x in range(47,56,1)]\n",
    "param_range4 = [x for x in range(30, 40,7)]\n",
    "param_range5 = [x for x in range(30, 40,7)]\n",
    "\n",
    "param_grid   = [{'randomforestregressor__max_depth': param_range3,\n",
    "                 'randomforestregressor__min_samples_split': param_range5,\n",
    "                 'randomforestregressor__n_estimators': param_range4}]\n",
    "\n",
    "\n",
    "scoring = {'R2': 'r2', 'MSE': 'neg_mean_squared_error','MAE': 'neg_mean_absolute_error'}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_forest, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring=scoring, \n",
    "                  cv=3,\n",
    "                  n_jobs=-1,\n",
    "                  verbose = 5,\n",
    "                 refit=refit_inst, return_train_score=True)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "# print(gs.best_score_)\n",
    "# print(gs.best_params_)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print('Total time: ',(t2-t1)/60, 'minutes')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_index_.keys()\n",
    "gs.best_index_['params']\n",
    "gs.multimetric_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gs.cv_results_\n",
    "results.keys()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Plotting the result of Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 13))\n",
    "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",\n",
    "          fontsize=16)\n",
    "\n",
    "plt.xlabel(\"min_samples_split\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "ax = plt.gca()\n",
    "# ax.set_xlim(0, 4)\n",
    "# ax.set_ylim(0.73, 1)\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(results['param_randomforestregressor__min_samples_split'].data, dtype=float)\n",
    "\n",
    "for scorer, color in zip(sorted(scoring), ['g', 'k']):\n",
    "    for sample, style in (('train', '--'), ('test', '-')):\n",
    "        sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n",
    "        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
    "        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
    "                        sample_score_mean + sample_score_std,\n",
    "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
    "        ax.plot(X_axis, sample_score_mean, style, color=color,\n",
    "                alpha=1 if sample == 'test' else 0.7,\n",
    "                label=\"%s (%s)\" % (scorer, sample))\n",
    "\n",
    "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "    best_score = results['mean_test_%s' % scorer][best_index]\n",
    "\n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
    "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score,\n",
    "                (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([          nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,  -67.8542745 ,\n",
       "        -66.97815493,  -67.2131984 ,  -66.98850192,  -66.85226674,\n",
       "        -66.86269573,  -66.9489902 ,  -66.91552033,  -66.88361706,\n",
       "                 nan,  -76.85525443,  -75.97436922,  -75.94935764,\n",
       "        -75.76660294,  -75.71520734,  -75.7574098 ,  -75.73944889,\n",
       "        -75.73874181,  -75.6930075 ,           nan,  -82.12725151,\n",
       "        -81.82196011,  -81.80120331,  -81.62880773,  -81.6515553 ,\n",
       "        -81.72409499,  -81.76248622,  -81.74658907,  -81.72207523,\n",
       "                 nan,  -86.99976564,  -86.9984111 ,  -87.03442872,\n",
       "        -86.98386326,  -87.04199194,  -87.08212954,  -87.05627751,\n",
       "        -87.01442221,  -87.01650149,           nan,  -90.86585691,\n",
       "        -90.62371252,  -90.68319346,  -90.48959185,  -90.46529029,\n",
       "        -90.44827453,  -90.48814524,  -90.43535023,  -90.47420137,\n",
       "                 nan,  -91.33174874,  -91.31641078,  -91.36132026,\n",
       "        -91.19000003,  -91.14052972,  -91.12247472,  -91.14671557,\n",
       "        -91.11092137,  -91.16269767,           nan,  -93.0481319 ,\n",
       "        -93.04812964,  -93.04644325,  -92.9688845 ,  -92.92146652,\n",
       "        -92.85259388,  -92.89999463,  -92.85473607,  -92.88467613,\n",
       "                 nan,  -97.31138465,  -96.90611516,  -96.87456695,\n",
       "        -97.03946134,  -96.64722406,  -96.72873081,  -96.9691471 ,\n",
       "        -96.93764807,  -96.93559285,           nan, -101.26164683,\n",
       "       -101.27132118, -101.27582112, -101.27323722, -101.26799106,\n",
       "       -101.25602979, -101.25065915, -101.24868217, -101.24979785,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,  -67.8542745 ,\n",
       "        -66.97815493,  -67.2131984 ,  -66.98850192,  -66.85226674,\n",
       "        -66.86269573,  -66.94883301,  -66.91537944,  -66.8834884 ,\n",
       "                 nan,  -76.85525443,  -75.97436922,  -75.94935764,\n",
       "        -75.76660294,  -75.71520734,  -75.7574098 ,  -75.73944889,\n",
       "        -75.73874181,  -75.6930075 ,           nan,  -82.12725151,\n",
       "        -81.82196011,  -81.80120331,  -81.62880773,  -81.6515553 ,\n",
       "        -81.72409499,  -81.76248622,  -81.74658907,  -81.72207523,\n",
       "                 nan,  -86.99976564,  -86.9984111 ,  -87.03442872,\n",
       "        -86.98386326,  -87.04199194,  -87.08212954,  -87.05627751,\n",
       "        -87.01442221,  -87.01650149,           nan,  -90.86585691,\n",
       "        -90.62371252,  -90.68319346,  -90.48959185,  -90.46529029,\n",
       "        -90.44827453,  -90.48814524,  -90.43535023,  -90.47420137,\n",
       "                 nan,  -91.33174874,  -91.31641078,  -91.36132026,\n",
       "        -91.19000003,  -91.14052972,  -91.12247472,  -91.14671557,\n",
       "        -91.11092137,  -91.16269767,           nan,  -93.0481319 ,\n",
       "        -93.04812964,  -93.04644325,  -92.9688845 ,  -92.92146652,\n",
       "        -92.85259388,  -92.89999463,  -92.85473607,  -92.88467613,\n",
       "                 nan,  -97.31138465,  -96.90611516,  -96.87456695,\n",
       "        -97.03946134,  -96.64722406,  -96.72873081,  -96.9691471 ,\n",
       "        -96.93764807,  -96.93559285,           nan, -101.26164683,\n",
       "       -101.27132118, -101.27582112, -101.27323722, -101.26799106,\n",
       "       -101.25602979, -101.25065915, -101.24868217, -101.24979785,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,  -67.8542745 ,\n",
       "        -66.97815493,  -67.2131984 ,  -66.98850192,  -66.85226674,\n",
       "        -66.86269573,  -66.94883301,  -66.91537944,  -66.8834884 ,\n",
       "                 nan,  -76.85525443,  -75.97436922,  -75.94935764,\n",
       "        -75.76660294,  -75.71520734,  -75.7574098 ,  -75.73944889,\n",
       "        -75.73874181,  -75.6930075 ,           nan,  -82.12725151,\n",
       "        -81.82196011,  -81.80120331,  -81.62880773,  -81.6515553 ,\n",
       "        -81.72409499,  -81.76248622,  -81.74658907,  -81.72207523,\n",
       "                 nan,  -86.99976564,  -86.9984111 ,  -87.03442872,\n",
       "        -86.98386326,  -87.04199194,  -87.08212954,  -87.05627751,\n",
       "        -87.01442221,  -87.01650149,           nan,  -90.86585691,\n",
       "        -90.62371252,  -90.68319346,  -90.48959185,  -90.46529029,\n",
       "        -90.44827453,  -90.48814524,  -90.43535023,  -90.47420137,\n",
       "                 nan,  -91.33174874,  -91.31641078,  -91.36132026,\n",
       "        -91.19000003,  -91.14052972,  -91.12247472,  -91.14671557,\n",
       "        -91.11092137,  -91.16269767,           nan,  -93.0481319 ,\n",
       "        -93.04812964,  -93.04644325,  -92.9688845 ,  -92.92146652,\n",
       "        -92.85259388,  -92.89999463,  -92.85473607,  -92.88467613,\n",
       "                 nan,  -97.31138465,  -96.90611516,  -96.87456695,\n",
       "        -97.03946134,  -96.64722406,  -96.72873081,  -96.9691471 ,\n",
       "        -96.93764807,  -96.93559285,           nan, -101.26164683,\n",
       "       -101.27132118, -101.27582112, -101.27323722, -101.26799106,\n",
       "       -101.25602979, -101.25065915, -101.24868217, -101.24979785,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,  -67.8542745 ,\n",
       "        -66.97815493,  -67.2131984 ,  -66.98850192,  -66.85226674,\n",
       "        -66.86269573,  -66.94883301,  -66.91537944,  -66.8834884 ,\n",
       "                 nan,  -76.85525443,  -75.97436922,  -75.94935764,\n",
       "        -75.76660294,  -75.71520734,  -75.7574098 ,  -75.73944889,\n",
       "        -75.73874181,  -75.6930075 ,           nan,  -82.12725151,\n",
       "        -81.82196011,  -81.80120331,  -81.62880773,  -81.6515553 ,\n",
       "        -81.72409499,  -81.76248622,  -81.74658907,  -81.72207523,\n",
       "                 nan,  -86.99976564,  -86.9984111 ,  -87.03442872,\n",
       "        -86.98386326,  -87.04199194,  -87.08212954,  -87.05627751,\n",
       "        -87.01442221,  -87.01650149,           nan,  -90.86585691,\n",
       "        -90.62371252,  -90.68319346,  -90.48959185,  -90.46529029,\n",
       "        -90.44827453,  -90.48814524,  -90.43535023,  -90.47420137,\n",
       "                 nan,  -91.33174874,  -91.31641078,  -91.36132026,\n",
       "        -91.19000003,  -91.14052972,  -91.12247472,  -91.14671557,\n",
       "        -91.11092137,  -91.16269767,           nan,  -93.0481319 ,\n",
       "        -93.04812964,  -93.04644325,  -92.9688845 ,  -92.92146652,\n",
       "        -92.85259388,  -92.89999463,  -92.85473607,  -92.88467613,\n",
       "                 nan,  -97.31138465,  -96.90611516,  -96.87456695,\n",
       "        -97.03946134,  -96.64722406,  -96.72873081,  -96.9691471 ,\n",
       "        -96.93764807,  -96.93559285,           nan, -101.26164683,\n",
       "       -101.27132118, -101.27582112, -101.27323722, -101.26799106,\n",
       "       -101.25602979, -101.25065915, -101.24868217, -101.24979785,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,  -67.8542745 ,\n",
       "        -66.97815493,  -67.2131984 ,  -66.98850192,  -66.85226674,\n",
       "        -66.86269573,  -66.94883301,  -66.91537944,  -66.8834884 ,\n",
       "                 nan,  -76.85525443,  -75.97436922,  -75.94935764,\n",
       "        -75.76660294,  -75.71520734,  -75.7574098 ,  -75.73944889,\n",
       "        -75.73874181,  -75.6930075 ,           nan,  -82.12725151,\n",
       "        -81.82196011,  -81.80120331,  -81.62880773,  -81.6515553 ,\n",
       "        -81.72409499,  -81.76248622,  -81.74658907,  -81.72207523,\n",
       "                 nan,  -86.99976564,  -86.9984111 ,  -87.03442872,\n",
       "        -86.98386326,  -87.04199194,  -87.08212954,  -87.05627751,\n",
       "        -87.01442221,  -87.01650149,           nan,  -90.86585691,\n",
       "        -90.62371252,  -90.68319346,  -90.48959185,  -90.46529029,\n",
       "        -90.44827453,  -90.48814524,  -90.43535023,  -90.47420137,\n",
       "                 nan,  -91.33174874,  -91.31641078,  -91.36132026,\n",
       "        -91.19000003,  -91.14052972,  -91.12247472,  -91.14671557,\n",
       "        -91.11092137,  -91.16269767,           nan,  -93.0481319 ,\n",
       "        -93.04812964,  -93.04644325,  -92.9688845 ,  -92.92146652,\n",
       "        -92.85259388,  -92.89999463,  -92.85473607,  -92.88467613,\n",
       "                 nan,  -97.31138465,  -96.90611516,  -96.87456695,\n",
       "        -97.03946134,  -96.64722406,  -96.72873081,  -96.9691471 ,\n",
       "        -96.93764807,  -96.93559285,           nan, -101.26164683,\n",
       "       -101.27132118, -101.27582112, -101.27323722, -101.26799106,\n",
       "       -101.25602979, -101.25065915, -101.24868217, -101.24979785,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,  -67.8542745 ,\n",
       "        -66.97815493,  -67.2131984 ,  -66.98850192,  -66.85226674,\n",
       "        -66.86269573,  -66.94883301,  -66.91537944,  -66.8834884 ,\n",
       "                 nan,  -76.85525443,  -75.97436922,  -75.94935764,\n",
       "        -75.76660294,  -75.71520734,  -75.7574098 ,  -75.73944889,\n",
       "        -75.73874181,  -75.6930075 ,           nan,  -82.12725151,\n",
       "        -81.82196011,  -81.80120331,  -81.62880773,  -81.6515553 ,\n",
       "        -81.72409499,  -81.76248622,  -81.74658907,  -81.72207523,\n",
       "                 nan,  -86.99976564,  -86.9984111 ,  -87.03442872,\n",
       "        -86.98386326,  -87.04199194,  -87.08212954,  -87.05627751,\n",
       "        -87.01442221,  -87.01650149,           nan,  -90.86585691,\n",
       "        -90.62371252,  -90.68319346,  -90.48959185,  -90.46529029,\n",
       "        -90.44827453,  -90.48814524,  -90.43535023,  -90.47420137,\n",
       "                 nan,  -91.33174874,  -91.31641078,  -91.36132026,\n",
       "        -91.19000003,  -91.14052972,  -91.12247472,  -91.14671557,\n",
       "        -91.11092137,  -91.16269767,           nan,  -93.0481319 ,\n",
       "        -93.04812964,  -93.04644325,  -92.9688845 ,  -92.92146652,\n",
       "        -92.85259388,  -92.89999463,  -92.85473607,  -92.88467613,\n",
       "                 nan,  -97.31138465,  -96.90611516,  -96.87456695,\n",
       "        -97.03946134,  -96.64722406,  -96.72873081,  -96.9691471 ,\n",
       "        -96.93764807,  -96.93559285,           nan, -101.26164683,\n",
       "       -101.27132118, -101.27582112, -101.27323722, -101.26799106,\n",
       "       -101.25602979, -101.25065915, -101.24868217, -101.24979785,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,  -67.8542745 ,\n",
       "        -66.97815493,  -67.2131984 ,  -66.98850192,  -66.85226674,\n",
       "        -66.86269573,  -66.94883301,  -66.91537944,  -66.8834884 ,\n",
       "                 nan,  -76.85525443,  -75.97436922,  -75.94935764,\n",
       "        -75.76660294,  -75.71520734,  -75.7574098 ,  -75.73944889,\n",
       "        -75.73874181,  -75.6930075 ,           nan,  -82.12725151,\n",
       "        -81.82196011,  -81.80120331,  -81.62880773,  -81.6515553 ,\n",
       "        -81.72409499,  -81.76248622,  -81.74658907,  -81.72207523,\n",
       "                 nan,  -86.99976564,  -86.9984111 ,  -87.03442872,\n",
       "        -86.98386326,  -87.04199194,  -87.08212954,  -87.05627751,\n",
       "        -87.01442221,  -87.01650149,           nan,  -90.86585691,\n",
       "        -90.62371252,  -90.68319346,  -90.48959185,  -90.46529029,\n",
       "        -90.44827453,  -90.48814524,  -90.43535023,  -90.47420137,\n",
       "                 nan,  -91.33174874,  -91.31641078,  -91.36132026,\n",
       "        -91.19000003,  -91.14052972,  -91.12247472,  -91.14671557,\n",
       "        -91.11092137,  -91.16269767,           nan,  -93.0481319 ,\n",
       "        -93.04812964,  -93.04644325,  -92.9688845 ,  -92.92146652,\n",
       "        -92.85259388,  -92.89999463,  -92.85473607,  -92.88467613,\n",
       "                 nan,  -97.31138465,  -96.90611516,  -96.87456695,\n",
       "        -97.03946134,  -96.64722406,  -96.72873081,  -96.9691471 ,\n",
       "        -96.93764807,  -96.93559285,           nan, -101.26164683,\n",
       "       -101.27132118, -101.27582112, -101.27323722, -101.26799106,\n",
       "       -101.25602979, -101.25065915, -101.24868217, -101.24979785,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,  -67.8542745 ,\n",
       "        -66.97815493,  -67.2131984 ,  -66.98850192,  -66.85226674,\n",
       "        -66.86269573,  -66.94883301,  -66.91537944,  -66.8834884 ,\n",
       "                 nan,  -76.85525443,  -75.97436922,  -75.94935764,\n",
       "        -75.76660294,  -75.71520734,  -75.7574098 ,  -75.73944889,\n",
       "        -75.73874181,  -75.6930075 ,           nan,  -82.12725151,\n",
       "        -81.82196011,  -81.80120331,  -81.62880773,  -81.6515553 ,\n",
       "        -81.72409499,  -81.76248622,  -81.74658907,  -81.72207523,\n",
       "                 nan,  -86.99976564,  -86.9984111 ,  -87.03442872,\n",
       "        -86.98386326,  -87.04199194,  -87.08212954,  -87.05627751,\n",
       "        -87.01442221,  -87.01650149,           nan,  -90.86585691,\n",
       "        -90.62371252,  -90.68319346,  -90.48959185,  -90.46529029,\n",
       "        -90.44827453,  -90.48814524,  -90.43535023,  -90.47420137,\n",
       "                 nan,  -91.33174874,  -91.31641078,  -91.36132026,\n",
       "        -91.19000003,  -91.14052972,  -91.12247472,  -91.14671557,\n",
       "        -91.11092137,  -91.16269767,           nan,  -93.0481319 ,\n",
       "        -93.04812964,  -93.04644325,  -92.9688845 ,  -92.92146652,\n",
       "        -92.85259388,  -92.89999463,  -92.85473607,  -92.88467613,\n",
       "                 nan,  -97.31138465,  -96.90611516,  -96.87456695,\n",
       "        -97.03946134,  -96.64722406,  -96.72873081,  -96.9691471 ,\n",
       "        -96.93764807,  -96.93559285,           nan, -101.26164683,\n",
       "       -101.27132118, -101.27582112, -101.27323722, -101.26799106,\n",
       "       -101.25602979, -101.25065915, -101.24868217, -101.24979785,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,  -67.8542745 ,\n",
       "        -66.97815493,  -67.2131984 ,  -66.98850192,  -66.85226674,\n",
       "        -66.86269573,  -66.94883301,  -66.91537944,  -66.8834884 ,\n",
       "                 nan,  -76.85525443,  -75.97436922,  -75.94935764,\n",
       "        -75.76660294,  -75.71520734,  -75.7574098 ,  -75.73944889,\n",
       "        -75.73874181,  -75.6930075 ,           nan,  -82.12725151,\n",
       "        -81.82196011,  -81.80120331,  -81.62880773,  -81.6515553 ,\n",
       "        -81.72409499,  -81.76248622,  -81.74658907,  -81.72207523,\n",
       "                 nan,  -86.99976564,  -86.9984111 ,  -87.03442872,\n",
       "        -86.98386326,  -87.04199194,  -87.08212954,  -87.05627751,\n",
       "        -87.01442221,  -87.01650149,           nan,  -90.86585691,\n",
       "        -90.62371252,  -90.68319346,  -90.48959185,  -90.46529029,\n",
       "        -90.44827453,  -90.48814524,  -90.43535023,  -90.47420137,\n",
       "                 nan,  -91.33174874,  -91.31641078,  -91.36132026,\n",
       "        -91.19000003,  -91.14052972,  -91.12247472,  -91.14671557,\n",
       "        -91.11092137,  -91.16269767,           nan,  -93.0481319 ,\n",
       "        -93.04812964,  -93.04644325,  -92.9688845 ,  -92.92146652,\n",
       "        -92.85259388,  -92.89999463,  -92.85473607,  -92.88467613,\n",
       "                 nan,  -97.31138465,  -96.90611516,  -96.87456695,\n",
       "        -97.03946134,  -96.64722406,  -96.72873081,  -96.9691471 ,\n",
       "        -96.93764807,  -96.93559285,           nan, -101.26164683,\n",
       "       -101.27132118, -101.27582112, -101.27323722, -101.26799106,\n",
       "       -101.25602979, -101.25065915, -101.24868217, -101.24979785])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = gs.cv_results_['mean_test_score']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID SEARCH\n",
    "0.9999993865442208\n",
    "{'model__C': 5, 'model__coef0': 0.01, 'model__degree': 3, 'model__gamma': 'auto', 'model__kernel': 'linear'}\n",
    "Total time:  1.481740701198578 minutes\n",
    "\n",
    "RANDOM SEARCH\n",
    "0.9999993866165158\n",
    "{'model__kernel': 'linear', 'model__gamma': 'scale', 'model__degree': 8, 'model__coef0': 0.5, 'model__C': 5}\n",
    "Total time:  3.4482144872347513 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier based on all training samples using the \"optimal parameters\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = gs.best_estimator_\n",
    "# clf.fit(X_train, y_train)\n",
    "# print('Test accuracy: %.3f' % clf.score(X_test, y_test))\n",
    "# # ... or:\n",
    "# #gs.decision_function(X_train) # (silly)\n",
    "# print('Test accuracy: %.3f' % gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape scores to follow parameters and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "scores = gs.cv_results_['mean_test_score'][len(param_range):].reshape(len(param_range),len(param_range2))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot)\n",
    "plt.xlabel('gamma') # 1/(softness of decision boundary), i.e. small = soft\n",
    "plt.ylabel('C')     # 1/(size of support vector margin), i.e. large = tight margin\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(param_range2)), param_range2)\n",
    "plt.yticks(np.arange(len(param_range)), param_range)\n",
    "plt.title('Grid Search Accuracy Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "354.46px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
