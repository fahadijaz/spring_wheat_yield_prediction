{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e8e7e9",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba29506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T14:30:06.971639Z",
     "start_time": "2021-11-14T14:30:05.413907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing functions \n",
    "\n",
    "from functions.save_results import save_results, save_grid_results\n",
    "from functions.split_data import list_test_train_df, data_prep_field\n",
    "from functions.regression import training_regr, training_gkf_std, grid\n",
    "from functions.plot_featimp import plot_feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19537608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T14:30:07.086957Z",
     "start_time": "2021-11-14T14:30:06.976464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# Dictionaries\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Iterate in loops\n",
    "import itertools\n",
    "from itertools import zip_longest\n",
    "\n",
    "# Simpsons integration\n",
    "from numpy import trapz\n",
    "from scipy.integrate import simps\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To display df nicely in loops\n",
    "from IPython.display import display \n",
    "# Display rows and columns Pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# # For displaying max rows in series\n",
    "# pd.options.display.max_rows = 10\n",
    "\n",
    "# ML Models\n",
    "\n",
    "import time\n",
    "# Pre.Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.model_selection import StratifiedGroupKFold\n",
    "# Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Models\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Metrices\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "# Importing data\n",
    "\n",
    "# Prints the current working directory\n",
    "os.getcwd()\n",
    "# os.listdir()\n",
    "\n",
    "## Finding Username folder to make general path for multi PC use\n",
    "\n",
    "username = str(os.getcwd()).split('\\\\')[2]\n",
    "user_path = r'C:/Users/'+username+'/'\n",
    "user_path_complete = r'C:\\Users\\fahad\\MegaSync\\NMBU\\GitHub\\vPheno\\\\'\n",
    "username, user_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d68f9f",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361479cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T14:30:07.103891Z",
     "start_time": "2021-11-14T14:30:07.088958Z"
    }
   },
   "outputs": [],
   "source": [
    "### SKLearn Models\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=1),\n",
    "    RandomForestRegressor(\n",
    "        max_depth=20, max_features='auto', n_jobs=-1, random_state=1),\n",
    "    Lasso(alpha=0.9, max_iter=150, selection='cyclic', random_state=1),\n",
    "    GradientBoostingRegressor(random_state=1),\n",
    "    GradientBoostingRegressor(subsample=0.8,\n",
    "                              learning_rate=0.4,\n",
    "                              random_state=1),\n",
    "    #           RandomForestRegressor(max_depth=250, min_samples_split=14,\n",
    "    #                                 min_samples_leaf=3, n_jobs=-1, random_state=1),\n",
    "    #           RandomForestRegressor(n_estimators=1000,\n",
    "    #                                 max_depth=250,\n",
    "    #                                 min_samples_split=5,\n",
    "    #                                 n_jobs=-1, random_state=1),\n",
    "    RandomForestRegressor(n_estimators=50,\n",
    "                          max_depth=100,\n",
    "                          min_samples_split=400,\n",
    "                          n_jobs=-1, random_state=1),\n",
    "    # Low overfitting\n",
    "    RandomForestRegressor(n_estimators=230,\n",
    "                          max_depth=20,\n",
    "                          min_samples_leaf=2,\n",
    "                          n_jobs=-1, random_state=1),\n",
    "    # Low overfitting\n",
    "    RandomForestRegressor(n_estimators=120,\n",
    "                          max_depth=50,\n",
    "                          min_samples_leaf=4,\n",
    "                          n_jobs=-1, random_state=1),\n",
    "    Lasso(alpha=0, max_iter=50000, random_state=1, selection='random')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7747216b",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdeacf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T14:30:07.119768Z",
     "start_time": "2021-11-14T14:30:07.108797Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "threshold_all = 'top_25'\n",
    "sort_feature_imp = True\n",
    "show_feat_imp_plot = True\n",
    "save_feat_imp_plot = True\n",
    "save_results_now = True\n",
    "agg_method = 'Simpsons'\n",
    "# agg_method = 'Trapezoid'\n",
    "\n",
    "group_feature = ['Name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18de998",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc51ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T14:30:07.149359Z",
     "start_time": "2021-11-14T14:30:07.121634Z"
    }
   },
   "outputs": [],
   "source": [
    "## Declaring Import paths\n",
    "main_path = r'./Data/'\n",
    "path = r'./Data/3. merged data/'\n",
    "\n",
    "# Create path folder if not exists already\n",
    "os.makedirs(path, exist_ok=True)\n",
    "# os.listdir(path)\n",
    "\n",
    "# Making dictionary of files in each folder, in case there are multiple types of data\n",
    "dict_paths = {}\n",
    "def explore(starting_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(starting_path):\n",
    "        dict_paths[dirpath.split('/')[-2]] = filenames\n",
    "#     pprint(dict_paths)\n",
    "explore(path)\n",
    "\n",
    "# Data Preparation\n",
    "## Creating list of complete files\n",
    "# Get the list of all files in directory tree at given path\n",
    "\n",
    "files_with_address = []\n",
    "files_list = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "    files_with_address += [os.path.join(dirpath, file) for file in filenames]\n",
    "    files_list.extend(filenames)\n",
    "\n",
    "print(len(files_with_address), 'files found in the directory')\n",
    "# files_with_address\n",
    "# files_list\n",
    "\n",
    "## Data Checking/control\n",
    "### Check for duplicate filenames\n",
    "\n",
    "print('Total number of files are :', len(files_list))\n",
    "print('Number of unique file names are:', len(set(files_list)))\n",
    "print('There is/are', len(files_list) - len(set(files_list)),'duplicate file name/names.')\n",
    "if len(files_list) - len(set(files_list)) > 0:\n",
    "    raise NameError\n",
    "\n",
    "\n",
    "\n",
    "# Finding yield columns\n",
    "## Importing Weather variables, yield columns, spectral indices, base indices columsn list\n",
    "\n",
    "a_file = open(main_path+'vollebekk_weather_columns.json', \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "# Converting it to python format\n",
    "weather_cols_vollebekk = json.loads(output_str)\n",
    "a_file.close()\n",
    "pprint(len(weather_cols_vollebekk))\n",
    "\n",
    "a_file = open(main_path+'staur_weather_columns.json', \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "# Converting it to python format\n",
    "weather_cols_staur = json.loads(output_str)\n",
    "a_file.close()\n",
    "pprint(len(weather_cols_staur))\n",
    "\n",
    "a_file = open(main_path+\"yield_columns.json\", \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "# Converting it to python format\n",
    "yield_cols = json.loads(output_str)\n",
    "a_file.close()\n",
    "print(yield_cols)\n",
    "\n",
    "a_file = open(main_path+\"spectral_indices_columns.json\", \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "# Converting it to python format\n",
    "spectral_indices_all = json.loads(output_str)\n",
    "a_file.close()\n",
    "print(spectral_indices_all)\n",
    "\n",
    "a_file = open(main_path+\"base_indices_columns.json\", \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "# Converting it to python format\n",
    "base_indices = json.loads(output_str)\n",
    "a_file.close()\n",
    "print(base_indices)\n",
    "\n",
    "## XXXXXX Defining categories of features\n",
    "\n",
    "# ToDo: Add check for duplicate columns in the df\n",
    "base_indices\n",
    "spectral_indices_all \n",
    "drop_indices = ['EVI', 'GLI', 'MTCI']\n",
    "spectral_indices = [x for x in spectral_indices_all if x not in drop_indices]\n",
    "\n",
    "# Staur weather columns are all also present in Vollebekk weather so they can be use as general weather features\n",
    "weather_features = weather_cols_staur.copy()\n",
    "environment_var = weather_features + ['Staur_Env', 'Vollebekk_Env']\n",
    "# yield_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb20f77b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-13T17:28:04.924985Z",
     "start_time": "2021-11-13T17:28:04.907034Z"
    }
   },
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878b116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-14T17:12:57.824629Z",
     "start_time": "2021-11-14T14:30:07.151518Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for target_features in [\n",
    "    ['Days2Maturity'],\n",
    "    ['GrainYield']\n",
    "]:\n",
    "\n",
    "    feature_counter = 0\n",
    "    for training_features in [base_indices + spectral_indices_all + environment_var,\n",
    "                              base_indices + spectral_indices_all + weather_features,\n",
    "                              base_indices + spectral_indices + weather_features,\n",
    "                              spectral_indices_all + weather_features,\n",
    "                              spectral_indices + weather_features,\n",
    "                              spectral_indices_all,\n",
    "                              spectral_indices,\n",
    "                              weather_features\n",
    "                             ]:\n",
    "        feature_counter += 1\n",
    "\n",
    "        # Importing data files to Pandas\n",
    "\n",
    "        all_df = []\n",
    "        for data in files_with_address:\n",
    "            file_name = os.path.splitext(os.path.basename(data))[0]\n",
    "\n",
    "            # Replce all invalid characters in the name\n",
    "            file_name = file_name.replace(\" \", \"_\")\n",
    "            file_name = file_name.replace(\"-\", \"_\")\n",
    "            file_name = file_name.replace(\")\", \"\")\n",
    "            file_name = file_name.replace(\"(\", \"\")\n",
    "            df_name = file_name.replace(\".\", \"\")\n",
    "            # Test: Check if the same date is already present in the current dict key\n",
    "            if df_name in all_df:\n",
    "                print(f'A file with the same name {df_name} has already been imported. \\n Please check if there is duplication of data.')\n",
    "                raise NameError\n",
    "            all_df.append(df_name)\n",
    "\n",
    "            locals()[df_name] = pd.read_csv(data, index_col=False)\n",
    "            print(df_name, '=====', locals()[df_name].shape)\n",
    "        # all_df\n",
    "\n",
    "        print(f'Total imported {len(all_df)}')\n",
    "        # all_df\n",
    "\n",
    "        # Dropping DF which donot have the Target Feature\n",
    "        # Dropping unnecessary columns\n",
    "        all_df_dm = []\n",
    "        for df in all_df:\n",
    "            temp_df = locals()[df].copy()\n",
    "            if target_features[0] in temp_df.columns.tolist():\n",
    "                all_df_dm.append(df)\n",
    "        #         print(df)\n",
    "\n",
    "        all_df_simps = [x for x in all_df_dm if 'Simps' in x]\n",
    "        all_df_trapz = [x for x in all_df_dm if 'Trapz' in x]\n",
    "        # all_df_simps, all_df_trapz\n",
    "\n",
    "        # Dropping unnecessary columns\n",
    "\n",
    "        for df in all_df_dm:\n",
    "            temp_df = locals()[df].copy()\n",
    "            locals()[df] = temp_df[base_indices+spectral_indices_all+environment_var+['Name',target_features[0]]]\n",
    "            print(df, temp_df.shape, '==>', locals()[df].shape)\n",
    "\n",
    "\n",
    "        # Dropping Missing values\n",
    "        # Dropping rows with missing value in any column\n",
    "\n",
    "        for df in all_df_dm:\n",
    "            temp_df = locals()[df].copy()\n",
    "            locals()[df] = temp_df.dropna(axis=0)\n",
    "            print(temp_df.shape[0] - locals()[df].shape[0], ' rows dropped in ', df)\n",
    "        #     print(locals()[df].shape[0])\n",
    "\n",
    "        # Normalizing the data using Z-Score from scipy\n",
    "\n",
    "        from scipy.stats import zscore\n",
    "\n",
    "        for df in all_df_dm:\n",
    "            temp_df = locals()[df].copy()\n",
    "            for col in temp_df.columns:\n",
    "                # Checking if the column is not a yield column\n",
    "                if col not in yield_cols+environment_var:\n",
    "                    temp_df[col] = zscore(temp_df[col])\n",
    "            locals()[df] = temp_df.copy()\n",
    "            print(df)\n",
    "\n",
    "        # Checking which data to use\n",
    "        if agg_method == 'Simpsons':\n",
    "            all_df_now = all_df_simps.copy()\n",
    "        elif agg_method == 'Trapezoid': \n",
    "            all_df_now = all_df_trapz.copy()\n",
    "\n",
    "\n",
    "        ## Declaring export paths\n",
    "        if target_features[0] == 'GrainYield':\n",
    "            export_path = './Data/4. results/'\n",
    "            export_path_comparability = './Data/4. results/comparability/'\n",
    "        elif target_features[0] == 'Days2Maturity':\n",
    "            export_path = './Data/4. results_dm/'\n",
    "            export_path_comparability = './Data/4. results_dm/comparability/'\n",
    "\n",
    "        # Create export_path folder if not exists already\n",
    "        os.makedirs(export_path, exist_ok=True)\n",
    "        os.makedirs(export_path_comparability, exist_ok=True)\n",
    "\n",
    "\n",
    "        ## Variations in Datasets\n",
    "\n",
    "        ### All data mixed\n",
    "\n",
    "        temp_list = [x for x in all_df_now if not 'Robot' in x]\n",
    "\n",
    "        # Making list of df for conct before training\n",
    "        # This is different form list of srtings, as this is a list of actual dataframes\n",
    "        df_list = []\n",
    "        for x in temp_list:\n",
    "            df_list.append(locals()[x])\n",
    "\n",
    "        df_ = pd.concat(df_list)\n",
    "\n",
    "        # Shuffeling all the items\n",
    "        df_shuffle = df_.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "        X = df_shuffle[training_features]\n",
    "        y = df_shuffle[target_features].values.ravel()\n",
    "        groups = df_shuffle[group_feature].values.ravel()\n",
    "\n",
    "        gkf = list(GroupKFold(n_splits=6).split(X, y, groups))\n",
    "        # gkf = list(StratifiedGroupKFold(n_splits=6, shuffle=True, random_state=1).split(X, y, groups))\n",
    "\n",
    "        #     Getting scores using cross_val_score\n",
    "        for model in models:\n",
    "        #     X_train, X_test, y_train, y_test = train_test_split(\n",
    "        #         X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "        #     importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "        #         model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "            importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_gkf_std(\n",
    "                model, X, y, gkf)\n",
    "            if importances is not None:\n",
    "                plot_feat_imp(feature_importance=importances,\n",
    "                              model=model,\n",
    "                              train_feat=training_features,\n",
    "                              feature_group = feature_counter,\n",
    "                              threshold=threshold_all,\n",
    "                              sort_feat=sort_feature_imp,\n",
    "                              show_plot=show_feat_imp_plot,\n",
    "                              save_plot=save_feat_imp_plot,\n",
    "                              export_path=export_path,\n",
    "                              save_suffix='all_mixed')\n",
    "            if save_results_now:\n",
    "                save_results(model=model,\n",
    "                             agg_method=agg_method,\n",
    "                             train_field='all_mix',\n",
    "                             test_field='all_mix',\n",
    "                             features_all=[training_features,\n",
    "                                           base_indices,\n",
    "                                           spectral_indices_all,\n",
    "                                           spectral_indices,\n",
    "                                           weather_features, export_path],\n",
    "                             importances=importances,\n",
    "                             RMSE_test=RMSE_test_temp,\n",
    "                             RMSE_train=RMSE_train_temp,\n",
    "                             R2_test=R2_test_temp,\n",
    "                             R2_train=R2_train_temp,\n",
    "                             GKF_CV=GKF_CV_temp)\n",
    "\n",
    "        ### Within same datasets:\n",
    "\n",
    "        # Iterating through all possible permutations of the fields dataset\n",
    "        for df in all_df_now:\n",
    "            df_ = locals()[df].copy()\n",
    "\n",
    "            X = df_[training_features]\n",
    "            y = df_[target_features].values.ravel()\n",
    "            groups = df_[group_feature].values.ravel()\n",
    "\n",
    "            gkf = list(GroupKFold(n_splits=6).split(X, y, groups))\n",
    "            print(df)\n",
    "            #     Getting scores using cross_val_score\n",
    "            for model in models:\n",
    "                print(df)\n",
    "                importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_gkf_std(\n",
    "                    model, X, y, gkf)\n",
    "                if importances is not None:\n",
    "                    plot_feat_imp(feature_importance=importances,\n",
    "                                  model=model,\n",
    "                                  train_feat=training_features,\n",
    "                                  feature_group = feature_counter,\n",
    "                                  threshold=threshold_all,\n",
    "                                  sort_feat=sort_feature_imp,\n",
    "                                  show_plot=show_feat_imp_plot,\n",
    "                                  save_plot=save_feat_imp_plot,\n",
    "                                  export_path=export_path,\n",
    "                                  save_suffix=str(df+'_66-33'))\n",
    "                if save_results_now:\n",
    "                    save_results(model=model,\n",
    "                                 agg_method=agg_method,\n",
    "                                 train_field=df,\n",
    "                                 test_field=df,\n",
    "                                 features_all=[training_features,\n",
    "                                               base_indices,\n",
    "                                               spectral_indices_all,\n",
    "                                               spectral_indices,\n",
    "                                               weather_features, export_path],\n",
    "                                 importances=importances,\n",
    "                                 RMSE_test=RMSE_test_temp,\n",
    "                                 RMSE_train=RMSE_train_temp,\n",
    "                                 R2_test=R2_test_temp,\n",
    "                                 R2_train=R2_train_temp,\n",
    "                                 GKF_CV=GKF_CV_temp)\n",
    "\n",
    "        ### One against all - one2one\n",
    "\n",
    "        # # Iterating through all possible permutations of the fields dataset\n",
    "\n",
    "        # for i in itertools.permutations(all_df_now, 2):\n",
    "        #     train_df = locals()[i[0]].copy()\n",
    "        #     test_df = locals()[i[1]].copy()\n",
    "\n",
    "\n",
    "        #     X_train = train_df[training_features]\n",
    "        #     y_train = train_df[target_features].values.ravel()\n",
    "        #     X_test = test_df[training_features]\n",
    "        #     y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "        #     # Getting scores using cross_val_score\n",
    "        #     for model in models:\n",
    "        #         print('Training: ', i[0],'Test: ', i[1], ' : ', model)\n",
    "        #         importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "        #             model, X_train, y_train, X_test, y_test)\n",
    "        #         if importances is not None:\n",
    "        #             plot_feat_imp(feature_importance=importances,\n",
    "        #                           model=model,\n",
    "        #                           train_feat=training_features,\n",
    "        #                           feature_group = feature_counter,\n",
    "        #                           threshold=threshold_all,\n",
    "        #                           sort_feat=sort_feature_imp,\n",
    "        #                           show_plot=show_feat_imp_plot,\n",
    "        #                           save_plot=save_feat_imp_plot,\n",
    "        #                           export_path=export_path,\n",
    "        #                           save_suffix=i[0]+'_Vs_'+i[1])\n",
    "        #         if save_results_now:\n",
    "        #             save_results(model=model,\n",
    "        #                          agg_method=agg_method,\n",
    "        #                          train_field=i[0],\n",
    "        #                          test_field=i[1],\n",
    "        #                          features_all=[training_features,\n",
    "        #                                        base_indices,\n",
    "        #                                        spectral_indices_all,\n",
    "        #                                        spectral_indices,\n",
    "        #                                        weather_features, export_path],\n",
    "        #                          importances=importances,\n",
    "        #                          RMSE_test=RMSE_test_temp,\n",
    "        #                          RMSE_train=RMSE_train_temp,\n",
    "        #                          R2_test=R2_test_temp,\n",
    "        #                          R2_train=R2_train_temp,\n",
    "        #                          GKF_CV=GKF_CV_temp)\n",
    "\n",
    "        ### One aganist all together\n",
    "\n",
    "        # Iterating through all possible permutations of the fields dataset\n",
    "        for df in all_df_now:\n",
    "            if 'Robot' not in df:\n",
    "                temp_list = [\n",
    "                    x for x in all_df_now if not 'Robot' in x if not df in x\n",
    "                ]\n",
    "                print(df, temp_list)\n",
    "\n",
    "                # Making list of df for conct before training\n",
    "                # This is different form list of srtings, as this is a list of actual dataframes\n",
    "                train_df_list = []\n",
    "                for x in temp_list:\n",
    "                    train_df_list.append(locals()[x])\n",
    "\n",
    "                train_df = pd.concat(train_df_list)\n",
    "                test_df = locals()[df].copy()\n",
    "\n",
    "                X_train = train_df[training_features]\n",
    "                y_train = train_df[target_features].values.ravel()\n",
    "                X_test = test_df[training_features]\n",
    "                y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "                # Getting scores using cross_val_score\n",
    "                for model in models:\n",
    "                    print('Training: All  ', 'Test: ', df, ' : ', model)\n",
    "                    importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "                        model, X_train, y_train, X_test, y_test)\n",
    "                if importances is not None:\n",
    "                    plot_feat_imp(feature_importance=importances,\n",
    "                                  model=model,\n",
    "                                  train_feat=training_features,\n",
    "                                  feature_group = feature_counter,\n",
    "                                  threshold=threshold_all,\n",
    "                                  sort_feat=sort_feature_imp,\n",
    "                                  show_plot=show_feat_imp_plot,\n",
    "                                  save_plot=save_feat_imp_plot,\n",
    "                                  export_path=export_path,\n",
    "                                  save_suffix=df+'_Vs_all')\n",
    "                if save_results_now:\n",
    "                    save_results(model=model,\n",
    "                                 agg_method=agg_method,\n",
    "                                 train_field=temp_list,\n",
    "                                 test_field=df,\n",
    "                                 features_all=[training_features,\n",
    "                                               base_indices,\n",
    "                                               spectral_indices_all,\n",
    "                                               spectral_indices,\n",
    "                                               weather_features, export_path],\n",
    "                                 importances=importances,\n",
    "                                 RMSE_test=RMSE_test_temp,\n",
    "                                 RMSE_train=RMSE_train_temp,\n",
    "                                 R2_test=R2_test_temp,\n",
    "                                 R2_train=R2_train_temp,\n",
    "                                 GKF_CV=GKF_CV_temp)\n",
    "\n",
    "        ### Vollebekk ALL vs Staur ALL\n",
    "\n",
    "        #### Training Staur, Test Vollebekk\n",
    "\n",
    "        train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                           train_field = 'Staur', \n",
    "                                                           test_field = 'Vollebekk', \n",
    "                                                           year = 'all')\n",
    "        suffix_title = 'Staur_Vs_Vollebekk_all'\n",
    "\n",
    "        train_df_list = []\n",
    "        test_df_list = []\n",
    "        for x in train_str_list:\n",
    "            train_df_list.append(locals()[x])\n",
    "        for x in test_str_list:\n",
    "            test_df_list.append(locals()[x])\n",
    "\n",
    "        if len(train_str_list) > 0 and len(test_str_list) > 0:\n",
    "            train_df = pd.concat(train_df_list)\n",
    "            test_df = pd.concat(test_df_list)\n",
    "\n",
    "            X_train = train_df[training_features]\n",
    "            y_train = train_df[target_features].values.ravel()\n",
    "            X_test = test_df[training_features]\n",
    "            y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "            # Getting scores using cross_val_score\n",
    "            for model in models:\n",
    "                importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "                    model, X_train, y_train, X_test, y_test)\n",
    "                if importances is not None:\n",
    "                    plot_feat_imp(feature_importance=importances,\n",
    "                                  model=model,\n",
    "                                  train_feat=training_features,\n",
    "                                  feature_group = feature_counter,\n",
    "                                  threshold=threshold_all,\n",
    "                                  sort_feat=sort_feature_imp,\n",
    "                                  show_plot=show_feat_imp_plot,\n",
    "                                  save_plot=save_feat_imp_plot,\n",
    "                                  export_path=export_path,\n",
    "                                  save_suffix='Staur_Vs_Vollebekk_all')\n",
    "                if save_results_now:\n",
    "                    save_results(model=model,\n",
    "                                 agg_method=agg_method,\n",
    "                                 train_field=train_str_list,\n",
    "                                 test_field=test_str_list,\n",
    "                                 features_all=[training_features,\n",
    "                                               base_indices,\n",
    "                                               spectral_indices_all,\n",
    "                                               spectral_indices,\n",
    "                                               weather_features, export_path],\n",
    "                                 importances=importances,\n",
    "                                 RMSE_test=RMSE_test_temp,\n",
    "                                 RMSE_train=RMSE_train_temp,\n",
    "                                 R2_test=R2_test_temp,\n",
    "                                 R2_train=R2_train_temp,\n",
    "                                 GKF_CV=GKF_CV_temp)\n",
    "\n",
    "        #### Training Vollebekk, Test Staur\n",
    "\n",
    "        train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                           train_field = 'Vollebekk', \n",
    "                                                           test_field = 'Staur', \n",
    "                                                           year = 'all')\n",
    "\n",
    "        suffix_title = 'VollebekK_Vs_Staur_all'\n",
    "\n",
    "        train_df_list = []\n",
    "        test_df_list = []\n",
    "        for x in train_str_list:\n",
    "            train_df_list.append(locals()[x])\n",
    "        for x in test_str_list:\n",
    "            test_df_list.append(locals()[x])\n",
    "\n",
    "        if len(train_str_list) > 0 and len(test_str_list) > 0:\n",
    "            train_df = pd.concat(train_df_list)\n",
    "            test_df = pd.concat(test_df_list)\n",
    "\n",
    "            X_train = train_df[training_features]\n",
    "            y_train = train_df[target_features].values.ravel()\n",
    "            X_test = test_df[training_features]\n",
    "            y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "            # Getting scores using cross_val_score\n",
    "            for model in models:\n",
    "                importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "                    model, X_train, y_train, X_test, y_test)\n",
    "                if importances is not None:\n",
    "                    plot_feat_imp(feature_importance=importances,\n",
    "                                  model=model,\n",
    "                                  train_feat=training_features,\n",
    "                                  feature_group = feature_counter,\n",
    "                                  threshold=threshold_all,\n",
    "                                  sort_feat=sort_feature_imp,\n",
    "                                  show_plot=show_feat_imp_plot,\n",
    "                                  save_plot=save_feat_imp_plot,\n",
    "                                  export_path=export_path,\n",
    "                                  save_suffix='Staur_Vs_Vollebekk_all')\n",
    "                if save_results_now:\n",
    "                    save_results(model=model,\n",
    "                                 agg_method=agg_method,\n",
    "                                 train_field=train_str_list,\n",
    "                                 test_field=test_str_list,\n",
    "                                 features_all=[training_features,\n",
    "                                               base_indices,\n",
    "                                               spectral_indices_all,\n",
    "                                               spectral_indices,\n",
    "                                               weather_features, export_path],\n",
    "                                 importances=importances,\n",
    "                                 RMSE_test=RMSE_test_temp,\n",
    "                                 RMSE_train=RMSE_train_temp,\n",
    "                                 R2_test=R2_test_temp,\n",
    "                                 R2_train=R2_train_temp,\n",
    "                                 GKF_CV=GKF_CV_temp)\n",
    "\n",
    "        ### 2020 Vollebekk vs 2020 Staur\n",
    "\n",
    "        #### Training Staur, Test Vollebekk\n",
    "\n",
    "        train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                           train_field = 'Staur', \n",
    "                                                           test_field = 'Vollebekk', \n",
    "                                                           year = '2020')\n",
    "        suffix_title = 'Staur_Vs_Vollebekk_2020'\n",
    "\n",
    "        train_df_list = []\n",
    "        test_df_list = []\n",
    "        for x in train_str_list:\n",
    "            train_df_list.append(locals()[x])\n",
    "        for x in test_str_list:\n",
    "            test_df_list.append(locals()[x])\n",
    "\n",
    "        if len(train_str_list) > 0 and len(test_str_list) > 0:\n",
    "            train_df = pd.concat(train_df_list)\n",
    "            test_df = pd.concat(test_df_list)\n",
    "\n",
    "            X_train = train_df[training_features]\n",
    "            y_train = train_df[target_features].values.ravel()\n",
    "            X_test = test_df[training_features]\n",
    "            y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "            # Getting scores using cross_val_score\n",
    "            for model in models:\n",
    "                importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "                    model, X_train, y_train, X_test, y_test)\n",
    "                if importances is not None:\n",
    "                    plot_feat_imp(feature_importance=importances,\n",
    "                                  model=model,\n",
    "                                  train_feat=training_features,\n",
    "                                  feature_group = feature_counter,\n",
    "                                  threshold=threshold_all,\n",
    "                                  sort_feat=sort_feature_imp,\n",
    "                                  show_plot=show_feat_imp_plot,\n",
    "                                  save_plot=save_feat_imp_plot,\n",
    "                                  export_path=export_path,\n",
    "                                  save_suffix='Staur_Vs_Vollebekk_all')\n",
    "                if save_results_now:\n",
    "                    save_results(model=model,\n",
    "                                 agg_method=agg_method,\n",
    "                                 train_field=train_str_list,\n",
    "                                 test_field=test_str_list,\n",
    "                                 features_all=[training_features,\n",
    "                                               base_indices,\n",
    "                                               spectral_indices_all,\n",
    "                                               spectral_indices,\n",
    "                                               weather_features, export_path],\n",
    "                                 importances=importances,\n",
    "                                 RMSE_test=RMSE_test_temp,\n",
    "                                 RMSE_train=RMSE_train_temp,\n",
    "                                 R2_test=R2_test_temp,\n",
    "                                 R2_train=R2_train_temp,\n",
    "                                 GKF_CV=GKF_CV_temp)\n",
    "\n",
    "        #### Training Vollebekk, Test Staur\n",
    "\n",
    "        train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                           train_field = 'Vollebekk', \n",
    "                                                           test_field = 'Staur', \n",
    "                                                           year = '2020')\n",
    "        suffix_title = 'VollebekK_Vs_Staur_2020'\n",
    "\n",
    "        train_df_list = []\n",
    "        test_df_list = []\n",
    "        for x in train_str_list:\n",
    "            train_df_list.append(locals()[x])\n",
    "        for x in test_str_list:\n",
    "            test_df_list.append(locals()[x])\n",
    "\n",
    "        if len(train_str_list) > 0 and len(test_str_list) > 0:\n",
    "            train_df = pd.concat(train_df_list)\n",
    "            test_df = pd.concat(test_df_list)\n",
    "\n",
    "            X_train = train_df[training_features]\n",
    "            y_train = train_df[target_features].values.ravel()\n",
    "            X_test = test_df[training_features]\n",
    "            y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "            # Getting scores using cross_val_score\n",
    "            for model in models:\n",
    "                importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "                    model, X_train, y_train, X_test, y_test)\n",
    "                if importances is not None:\n",
    "                    plot_feat_imp(feature_importance=importances,\n",
    "                                  model=model,\n",
    "                                  train_feat=training_features,\n",
    "                                  feature_group = feature_counter,\n",
    "                                  threshold=threshold_all,\n",
    "                                  sort_feat=sort_feature_imp,\n",
    "                                  show_plot=show_feat_imp_plot,\n",
    "                                  save_plot=save_feat_imp_plot,\n",
    "                                  export_path=export_path,\n",
    "                                  save_suffix='Staur_Vs_Vollebekk_all')\n",
    "                if save_results_now:\n",
    "                    save_results(model=model,\n",
    "                                 agg_method=agg_method,\n",
    "                                 train_field=train_str_list,\n",
    "                                 test_field=test_str_list,\n",
    "                                 features_all=[training_features,\n",
    "                                               base_indices,\n",
    "                                               spectral_indices_all,\n",
    "                                               spectral_indices,\n",
    "                                               weather_features, export_path],\n",
    "                                 importances=importances,\n",
    "                                 RMSE_test=RMSE_test_temp,\n",
    "                                 RMSE_train=RMSE_train_temp,\n",
    "                                 R2_test=R2_test_temp,\n",
    "                                 R2_train=R2_train_temp,\n",
    "                                 GKF_CV=GKF_CV_temp)\n",
    "\n",
    "        ### 2019 Vollebekk vs 2019 Staur\n",
    "\n",
    "        #### Training Staur, Test Vollebekk\n",
    "\n",
    "        train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                           train_field = 'Staur', \n",
    "                                                           test_field = 'Vollebekk', \n",
    "                                                           year = '2019')\n",
    "        suffix_title = 'Staur_Vs_Vollebekk_2019'\n",
    "\n",
    "        train_df_list = []\n",
    "        test_df_list = []\n",
    "        for x in train_str_list:\n",
    "            train_df_list.append(locals()[x])\n",
    "        for x in test_str_list:\n",
    "            test_df_list.append(locals()[x])\n",
    "\n",
    "        if len(train_str_list) > 0 and len(test_str_list) > 0:\n",
    "            train_df = pd.concat(train_df_list)\n",
    "            test_df = pd.concat(test_df_list)\n",
    "\n",
    "            X_train = train_df[training_features]\n",
    "            y_train = train_df[target_features].values.ravel()\n",
    "            X_test = test_df[training_features]\n",
    "            y_test = test_df[target_features].values.ravel()\n",
    "\n",
    "            # Getting scores using cross_val_score\n",
    "            for model in models:\n",
    "                importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "                    model, X_train, y_train, X_test, y_test)\n",
    "                if importances is not None:\n",
    "                    plot_feat_imp(feature_importance=importances,\n",
    "                                  model=model,\n",
    "                                  train_feat=training_features,\n",
    "                                  feature_group = feature_counter,\n",
    "                                  threshold=threshold_all,\n",
    "                                  sort_feat=sort_feature_imp,\n",
    "                                  show_plot=show_feat_imp_plot,\n",
    "                                  save_plot=save_feat_imp_plot,\n",
    "                                  export_path=export_path,\n",
    "                                  save_suffix='Staur_Vs_Vollebekk_all')\n",
    "                if save_results_now:\n",
    "                    save_results(model=model,\n",
    "                                 agg_method=agg_method,\n",
    "                                 train_field=train_str_list,\n",
    "                                 test_field=test_str_list,\n",
    "                                 features_all=[training_features,\n",
    "                                               base_indices,\n",
    "                                               spectral_indices_all,\n",
    "                                               spectral_indices,\n",
    "                                               weather_features, export_path],\n",
    "                                 importances=importances,\n",
    "                                 RMSE_test=RMSE_test_temp,\n",
    "                                 RMSE_train=RMSE_train_temp,\n",
    "                                 R2_test=R2_test_temp,\n",
    "                                 R2_train=R2_train_temp,\n",
    "                                 GKF_CV=GKF_CV_temp)\n",
    "\n",
    "        #### Training Vollebekk, Test Staur\n",
    "\n",
    "        train_str_list, test_str_list = list_test_train_df(all_df_now,\n",
    "                                                           train_field = 'Vollebekk', \n",
    "                                                           test_field = 'Staur', \n",
    "                                                           year = '2019')\n",
    "        suffix_title = 'Vollebekk_Vs_Staur_2019'\n",
    "\n",
    "        train_df_list = []\n",
    "        test_df_list = []\n",
    "        for x in train_str_list:\n",
    "            train_df_list.append(locals()[x])\n",
    "        for x in test_str_list:\n",
    "            test_df_list.append(locals()[x])\n",
    "\n",
    "        if len(train_str_list) > 0 and len(test_str_list) > 0:\n",
    "            train_df = pd.concat(train_df_list)\n",
    "            test_df = pd.concat(test_df_list)\n",
    "\n",
    "            X_train = train_df[training_features]\n",
    "            y_train = train_df[target_features].values.ravel()\n",
    "            X_test = test_df[training_features]\n",
    "            y_test = test_df[target_features].values.ravel()\n",
    "            print('ok')\n",
    "            # Getting scores using cross_val_score\n",
    "            for model in models:\n",
    "                importances, RMSE_test_temp, RMSE_train_temp, R2_test_temp, R2_train_temp, GKF_CV_temp = training_regr(\n",
    "                    model, X_train, y_train, X_test, y_test)\n",
    "                if importances is not None:\n",
    "                    plot_feat_imp(feature_importance=importances,\n",
    "                                  model=model,\n",
    "                                  train_feat=training_features,\n",
    "                                  feature_group = feature_counter,\n",
    "                                  threshold=threshold_all,\n",
    "                                  sort_feat=sort_feature_imp,\n",
    "                                  show_plot=show_feat_imp_plot,\n",
    "                                  save_plot=save_feat_imp_plot,\n",
    "                                  export_path=export_path,\n",
    "                                  save_suffix='Staur_Vs_Vollebekk_all')\n",
    "                if save_results_now:\n",
    "                    save_results(model=model,\n",
    "                                 agg_method=agg_method,\n",
    "                                 train_field=train_str_list,\n",
    "                                 test_field=test_str_list,\n",
    "                                 features_all=[training_features,\n",
    "                                               base_indices,\n",
    "                                               spectral_indices_all,\n",
    "                                               spectral_indices,\n",
    "                                               weather_features, export_path],\n",
    "                                 importances=importances,\n",
    "                                 RMSE_test=RMSE_test_temp,\n",
    "                                 RMSE_train=RMSE_train_temp,\n",
    "                                   R2_test=R2_test_temp,\n",
    "                                 R2_train=R2_train_temp,\n",
    "                                 GKF_CV=GKF_CV_temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791a0de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "350.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "801px",
    "left": "1469px",
    "right": "20px",
    "top": "130px",
    "width": "446px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
