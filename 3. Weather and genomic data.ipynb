{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather and Genomics Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Half datasets, with separate files for east and west subplots have been merged manually in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.155067Z",
     "start_time": "2021-10-03T02:54:40.961704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "\n",
    "# Dictionaries\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Iterate in loops\n",
    "from itertools import zip_longest\n",
    "\n",
    "# Simpsons integration\n",
    "from numpy import trapz\n",
    "from scipy.integrate import simps\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To display df nicely in loops\n",
    "from IPython.display import display \n",
    "# display(df1.head()) \n",
    "# display(df2.head())\n",
    "\n",
    "# Display rows and columns Pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.171006Z",
     "start_time": "2021-10-03T02:54:42.157044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fahad\\\\MegaSync\\\\NMBU\\\\GitHub\\\\vPheno'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the current working directory\n",
    "os.getcwd()\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Username folder to make general path for multi PC use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.185968Z",
     "start_time": "2021-10-03T02:54:42.172005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fahad', 'C:/Users/fahad/')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = str(os.getcwd()).split('\\\\')[2]\n",
    "user_path = r'C:/Users/'+username+'/'\n",
    "username, user_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.200936Z",
     "start_time": "2021-10-03T02:54:42.187964Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all.csv',\n",
       " 'Graminor_2020_all.csv',\n",
       " 'Masbasis_2019_all.csv',\n",
       " 'Masbasis_2020_all_lodg.csv',\n",
       " 'Robot_2020_all.csv',\n",
       " 'Staur_2019_all.csv',\n",
       " 'Staur_2020_all_lodg.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = r'./Data/'\n",
    "path = r'./Data/renamed_merged/'\n",
    "export_path = './Data/results/'\n",
    "\n",
    "# Create export_path folder if not exists already\n",
    "os.makedirs(path, exist_ok=True)\n",
    "os.makedirs(export_path, exist_ok=True)\n",
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Creating list of complete files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.216884Z",
     "start_time": "2021-10-03T02:54:42.203923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 files found in the directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all.csv',\n",
       " 'Graminor_2020_all.csv',\n",
       " 'Masbasis_2019_all.csv',\n",
       " 'Masbasis_2020_all_lodg.csv',\n",
       " 'Robot_2020_all.csv',\n",
       " 'Staur_2019_all.csv',\n",
       " 'Staur_2020_all_lodg.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of all files in directory tree at given path\n",
    "\n",
    "files_with_address = []\n",
    "files_list = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "    files_with_address += [os.path.join(dirpath, file) for file in filenames]\n",
    "    files_list.extend(filenames)\n",
    "    \n",
    "print(len(files_with_address), 'files found in the directory')\n",
    "# files_with_address\n",
    "files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Checking/control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Check for duplicate filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.232841Z",
     "start_time": "2021-10-03T02:54:42.218880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files are : 7\n",
      "Number of unique file names are: 7\n",
      "There is/are 0 duplicate file name/names.\n"
     ]
    }
   ],
   "source": [
    "print('Total number of files are :', len(files_list))\n",
    "\n",
    "print('Number of unique file names are:', len(set(files_list)))\n",
    "\n",
    "print('There is/are', len(files_list) - len(set(files_list)),'duplicate file name/names.')\n",
    "if len(files_list) - len(set(files_list)) > 0:\n",
    "    raise NameError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data files to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.688915Z",
     "start_time": "2021-10-03T02:54:42.233838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_all ===== (600, 378)\n",
      "Graminor_2020_all ===== (400, 378)\n",
      "Masbasis_2019_all ===== (528, 278)\n",
      "Masbasis_2020_all_lodg ===== (659, 416)\n",
      "Robot_2020_all ===== (96, 484)\n",
      "Staur_2019_all ===== (1328, 176)\n",
      "Staur_2020_all_lodg ===== (1504, 209)\n",
      "Wall time: 445 ms\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "%%time\n",
    "\n",
    "all_df = []\n",
    "for data in files_with_address:\n",
    "    file_name = os.path.splitext(os.path.basename(data))[0]\n",
    "\n",
    "    # Replce all invalid characters in the name\n",
    "    file_name = file_name.replace(\" \", \"_\")\n",
    "    file_name = file_name.replace(\"-\", \"_\")\n",
    "    file_name = file_name.replace(\")\", \"\")\n",
    "    file_name = file_name.replace(\"(\", \"\")\n",
    "    df_name = file_name.replace(\".\", \"\")\n",
    "    # Test: Check if the same date is already present in the current dict key\n",
    "    if df_name in all_df:\n",
    "        print(f'A file with the same name {df_name} has already been imported. \\n Please check if there is duplication of data.')\n",
    "        raise NameError\n",
    "    all_df.append(df_name)\n",
    "\n",
    "    locals()[df_name] = pd.read_csv(data, index_col=False)\n",
    "    print(df_name, '=====', locals()[df_name].shape)\n",
    "# all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.704851Z",
     "start_time": "2021-10-03T02:54:42.691887Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imported 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all',\n",
       " 'Graminor_2020_all',\n",
       " 'Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all',\n",
       " 'Staur_2020_all_lodg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total imported {len(all_df)}')\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding yield columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.735218Z",
     "start_time": "2021-10-03T02:54:42.706848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"GrainYield\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Pedigree\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 8\n",
      "\"GrainYield\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Pedigree\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 8\n",
      "\"GrainYield\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Line\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Line\". It is located at location 8\n",
      "\"Days2Heading\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 9\n",
      "\"Days2Maturity\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 10\n",
      "\"GrainYield\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Line\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Line\". It is located at location 8\n",
      "\"Maturity_Date\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Maturity_Date\". It is located at location 9\n",
      "\"Days2Heading\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 10\n",
      "\"Days2Maturity\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 11\n",
      "\"Lodging\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Lodging\". It is located at location 12\n",
      "\"GrainYield\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"CodeName\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"CodeName\". It is located at location 8\n",
      "\"Heading_Date\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Heading_Date\". It is located at location 9\n",
      "\"Maturity_Date\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Maturity_Date\". It is located at location 10\n",
      "\"Days2Heading\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 11\n",
      "\"Days2Maturity\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 12\n",
      "\"GrainYield\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Line\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Line\". It is located at location 8\n",
      "\"Days2Heading\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 9\n",
      "\"Days2Maturity\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 10\n",
      "\"GrainYield\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Pedigree\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 8\n",
      "\"Lodging\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Lodging\". It is located at location 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GrainYield_Graminor_2019_all': 6,\n",
       " 'Name_Graminor_2019_all': 7,\n",
       " 'Pedigree_Graminor_2019_all': 8,\n",
       " 'GrainYield_Graminor_2020_all': 6,\n",
       " 'Name_Graminor_2020_all': 7,\n",
       " 'Pedigree_Graminor_2020_all': 8,\n",
       " 'GrainYield_Masbasis_2019_all': 6,\n",
       " 'Name_Masbasis_2019_all': 7,\n",
       " 'Line_Masbasis_2019_all': 8,\n",
       " 'Days2Heading_Masbasis_2019_all': 9,\n",
       " 'Days2Maturity_Masbasis_2019_all': 10,\n",
       " 'GrainYield_Masbasis_2020_all_lodg': 6,\n",
       " 'Name_Masbasis_2020_all_lodg': 7,\n",
       " 'Line_Masbasis_2020_all_lodg': 8,\n",
       " 'Maturity_Date_Masbasis_2020_all_lodg': 9,\n",
       " 'Days2Heading_Masbasis_2020_all_lodg': 10,\n",
       " 'Days2Maturity_Masbasis_2020_all_lodg': 11,\n",
       " 'Lodging_Masbasis_2020_all_lodg': 12,\n",
       " 'GrainYield_Robot_2020_all': 6,\n",
       " 'Name_Robot_2020_all': 7,\n",
       " 'CodeName_Robot_2020_all': 8,\n",
       " 'Heading_Date_Robot_2020_all': 9,\n",
       " 'Maturity_Date_Robot_2020_all': 10,\n",
       " 'Days2Heading_Robot_2020_all': 11,\n",
       " 'Days2Maturity_Robot_2020_all': 12,\n",
       " 'GrainYield_Staur_2019_all': 6,\n",
       " 'Name_Staur_2019_all': 7,\n",
       " 'Line_Staur_2019_all': 8,\n",
       " 'Days2Heading_Staur_2019_all': 9,\n",
       " 'Days2Maturity_Staur_2019_all': 10,\n",
       " 'GrainYield_Staur_2020_all_lodg': 6,\n",
       " 'Name_Staur_2020_all_lodg': 7,\n",
       " 'Pedigree_Staur_2020_all_lodg': 8,\n",
       " 'Lodging_Staur_2020_all_lodg': 9}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToDo: Add check for duplicate columns in the df\n",
    "\n",
    "general_col_names = ['Plot_ID', 'Blue', 'Green', 'Red', 'RedEdge', 'NIR']\n",
    "\n",
    "base_indices = ['Blue', 'Green', 'Red', 'RedEdge', 'NIR']\n",
    "\n",
    "spectral_indices = ['NDVI', 'MTCI', 'DVI', 'GDVI', 'MTCI_CI', 'EXG', 'EXGR', 'RDVI',\n",
    "                    'TDVI', 'GNDVI', 'NDRE', 'SCCI', 'EVI', 'TVI', 'VARI', 'GARI',\n",
    "                    'GCI', 'GLI', 'NLI', 'MNLI', 'SAVI', 'GSAVI', 'OSAVI', 'GOSAVI',\n",
    "                    'MSAVI2', 'MSR', 'GRVI', 'WDRVI', 'SR']\n",
    "# list_agg_df\n",
    "yield_cols = ['GrainYield', 'Name', 'CodeName', 'Pedigree', 'Line', 'Heading_Date',\n",
    "              'Maturity_Date', 'Days2Heading', 'Days2Maturity', 'Lodging']\n",
    "\n",
    "id_cols_new = ['Plot_ID']\n",
    "\n",
    "# Counter for location of column in columns list\n",
    "\n",
    "# Dict for saving the name and location of the yield column/s\n",
    "loc_yield_cols = {}\n",
    "for df in all_df:\n",
    "    loc = 0\n",
    "    for cols in locals()[df].columns.tolist():\n",
    "        for y_col in yield_cols:\n",
    "            if not cols.find(y_col):\n",
    "                loc_yield_cols[cols+'_'+df] = loc\n",
    "                print(f'\\\"{cols}\\\" column in {df} is the yield column\\n as it contains the text \\\"{y_col}\\\". It is located at location {loc}')\n",
    "        loc += 1\n",
    "\n",
    "    yield_cols_found = list(loc_yield_cols.keys())\n",
    "    target_cols=yield_cols_found[0]\n",
    "loc_yield_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding dates between heading and maturity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.751197Z",
     "start_time": "2021-10-03T02:54:42.738205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GrainYield',\n",
       " 'Name',\n",
       " 'CodeName',\n",
       " 'Pedigree',\n",
       " 'Line',\n",
       " 'Heading_Date',\n",
       " 'Maturity_Date',\n",
       " 'Days2Heading',\n",
       " 'Days2Maturity',\n",
       " 'Lodging']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.767129Z",
     "start_time": "2021-10-03T02:54:42.753166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_all\n",
      "Masbasis_2020_all_lodg\n",
      "Robot_2020_all\n",
      "Staur_2019_all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all',\n",
       " 'Graminor_2020_all',\n",
       " 'Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all',\n",
       " 'Staur_2020_all_lodg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    if 'Days2Maturity' in temp_df.columns:\n",
    "        print(df)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring the important dates for each field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.783085Z",
     "start_time": "2021-10-03T02:54:42.768127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dates listed in dict in order; sowing, heading, maturity\n",
    "# The order of fields must be the same as in all_df list\n",
    "# sowing_dict = {\n",
    "#     'Graminor_2019': ['240419', 'XX', 'XX'],\n",
    "#     'Graminor_2020': ['150420', 'XX', 'XX'],\n",
    "#     'Masbasis_2019': ['190519', 'XX', 'XX'],\n",
    "#     'Masbasis_2020': ['150520', 'XX', 'XX'],\n",
    "#     'Robot_2020': ['200420', '170620', '310720'],\n",
    "#     'Staur_2019': ['040619', 'XX', 'XX'],\n",
    "#     'Staur_2020': ['210420', 'XX', 'XX'],\n",
    "# }\n",
    "\n",
    "sowing_dict = {\n",
    "    'Graminor_2019': '240419',\n",
    "    'Graminor_2020': '150420',\n",
    "    'Masbasis_2019': '190519',\n",
    "    'Masbasis_2020': '150520',\n",
    "    'Robot_2020': '200420',\n",
    "    'Staur_2019': '040619',\n",
    "    'Staur_2020': '210420',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the df based on imp_dates dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.799042Z",
     "start_time": "2021-10-03T02:54:42.785080Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Creating a list to add the names of new filtered df\n",
    "# all_df_dates_filtered = {}\n",
    "\n",
    "# for field, key in zip_longest(all_df, imp_dates):\n",
    "#     # Checking if the field df and key in the dict are for the same field\n",
    "#     print(field, key)\n",
    "#     assert field.split('_')[0] == key.split('_')[0]\n",
    "    \n",
    "#     # Getting dates from imp_dates dict\n",
    "#     sowing, maturity, heading = imp_dates[key]\n",
    "   \n",
    "#     sowing_date = datetime.datetime.strptime(sowing, '%d%m%y').date()\n",
    "#     heading_date = datetime.datetime.strptime(maturity, '%d%m%y').date()\n",
    "#     maturity_date =datetime.datetime.strptime(heading, '%d%m%y').date()\n",
    "    \n",
    "#     # Iterating through all base indices column names\n",
    "#     for col in general_col_names[1:]:\n",
    "\n",
    "#         cols_current = [x for x in locals()[field].columns if col+'_' in x]\n",
    "#         dates = [x.split('_')[1] for x in cols_current]\n",
    "#         date_fmt = [datetime.datetime.strptime(x, '%d%m%y').date() for x in dates]\n",
    "#         # Listing the dates in between(and including) heading and maturity dates\n",
    "#         in_between_dates = [x.strftime(\"%d%m%y\") for x in date_fmt\\\n",
    "#                             if x >= heading_date and x <= maturity_date]\n",
    "                        \n",
    "#         dates_not_usable = [x.strftime(\"%d%m%y\") for x in date_fmt\\\n",
    "#                              if not x.strftime(\"%d%m%y\") in in_between_dates]\n",
    "\n",
    "#     # Filter the datasets with date between heading and maturity\n",
    "#     select_cols = [x for x in locals()[field].columns if x[-6:] not in dates_not_usable]\n",
    "#     temp_df = locals()[field][select_cols].copy()\n",
    "\n",
    "#     # Adding the names of new df into all_df_dates_filtered list\n",
    "#     filtered_df = key+'_dates_filtered'\n",
    "#     all_df_dates_filtered[filtered_df] = imp_dates[key]\n",
    "#     locals()[filtered_df] = temp_df\n",
    "# all_df_dates_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering df which have Days2Maturity and Days2Heading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.814002Z",
     "start_time": "2021-10-03T02:54:42.800040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_all\n",
      "Masbasis_2020_all_lodg\n",
      "Robot_2020_all\n",
      "Staur_2019_all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Masbasis_2019_all': '190519',\n",
       " 'Masbasis_2020_all_lodg': '150520',\n",
       " 'Robot_2020_all': '200420',\n",
       " 'Staur_2019_all': '040619'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the dataset had Days 2 heading and days to maturity columns then create the\n",
    "# following dictionary with the respective sowing dates of each field as value\n",
    "all_df_dates_filtered = {}\n",
    "\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    field_temp = df.split('_')[0]+'_'+df.split('_')[1]\n",
    "    if 'Days2Heading' in temp_df.columns and 'Days2Maturity' in temp_df.columns:\n",
    "        print(df)\n",
    "        all_df_dates_filtered[df] = sowing_dict[field_temp]\n",
    "all_df_dates_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T02:54:42.828962Z",
     "start_time": "2021-10-03T02:54:42.814999Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "from numpy import trapz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating df with Plot_ID and Grain_Yield only\n",
    "## Calculating AUC and creating new df with calculated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T03:13:58.713668Z",
     "start_time": "2021-10-03T03:13:46.731394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Plot_ID', 'GrainYield', 'Name', 'Line', 'Days2Heading', 'Days2Maturity']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>GrainYield</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Days2Heading</th>\n",
       "      <th>Days2Maturity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>522.666667</td>\n",
       "      <td>GN12687</td>\n",
       "      <td>1574</td>\n",
       "      <td>66</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>Avocet YrA</td>\n",
       "      <td>28</td>\n",
       "      <td>69</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>541.333333</td>\n",
       "      <td>GN08557</td>\n",
       "      <td>1313</td>\n",
       "      <td>70</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>GN08541</td>\n",
       "      <td>1311</td>\n",
       "      <td>69</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>542.666667</td>\n",
       "      <td>SW44431</td>\n",
       "      <td>1324</td>\n",
       "      <td>67</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Plot_ID  GrainYield        Name  Line  Days2Heading  Days2Maturity\n",
       "0     1101  522.666667     GN12687  1574            66            107\n",
       "1     1102  388.000000  Avocet YrA    28            69            110\n",
       "2     1103  541.333333     GN08557  1313            70            108\n",
       "3     1104  572.000000     GN08541  1311            69            109\n",
       "4     1105  542.666667     SW44431  1324            67            106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Plot_ID', 'GrainYield', 'Name', 'Line', 'Maturity_Date', 'Days2Heading', 'Days2Maturity', 'Lodging']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>GrainYield</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Maturity_Date</th>\n",
       "      <th>Days2Heading</th>\n",
       "      <th>Days2Maturity</th>\n",
       "      <th>Lodging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MS 273-150</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sabin</td>\n",
       "      <td>1322.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T2038</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bastian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>713.333333</td>\n",
       "      <td>T9040</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>66</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Plot_ID  GrainYield        Name    Line Maturity_Date  Days2Heading  \\\n",
       "0     1101         NaN  MS 273-150    26.0           NaN            67   \n",
       "1     1102         NaN       Sabin  1322.0           NaN            65   \n",
       "2     1103         NaN       T2038    25.0           NaN            65   \n",
       "3     1104         NaN     Bastian     NaN           NaN            65   \n",
       "4     1105  713.333333       T9040     6.0    2020-08-11            66   \n",
       "\n",
       "   Days2Maturity  Lodging  \n",
       "0            NaN      1.0  \n",
       "1            NaN      1.0  \n",
       "2            NaN      1.0  \n",
       "3            NaN      1.0  \n",
       "4           88.0      0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Plot_ID', 'GrainYield', 'Name', 'CodeName', 'Heading_Date', 'Maturity_Date', 'Days2Heading', 'Days2Maturity']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>GrainYield</th>\n",
       "      <th>Name</th>\n",
       "      <th>CodeName</th>\n",
       "      <th>Heading_Date</th>\n",
       "      <th>Maturity_Date</th>\n",
       "      <th>Days2Heading</th>\n",
       "      <th>Days2Maturity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>453.658537</td>\n",
       "      <td>Avle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>2020-08-07</td>\n",
       "      <td>62</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>439.024390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GN10637</td>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>62</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>409.756098</td>\n",
       "      <td>Runar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>60</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>474.796748</td>\n",
       "      <td>Betong</td>\n",
       "      <td>GN13618</td>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>2020-08-08</td>\n",
       "      <td>61</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>411.382114</td>\n",
       "      <td>Reno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>61</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Plot_ID  GrainYield    Name CodeName Heading_Date Maturity_Date  \\\n",
       "0     1101  453.658537    Avle      NaN   2020-06-21    2020-08-07   \n",
       "1     1102  439.024390     NaN  GN10637   2020-06-21    2020-08-11   \n",
       "2     1103  409.756098   Runar      NaN   2020-06-19    2020-08-04   \n",
       "3     1104  474.796748  Betong  GN13618   2020-06-20    2020-08-08   \n",
       "4     1105  411.382114    Reno      NaN   2020-06-20    2020-08-04   \n",
       "\n",
       "   Days2Heading  Days2Maturity  \n",
       "0            62            109  \n",
       "1            62            113  \n",
       "2            60            106  \n",
       "3            61            110  \n",
       "4            61            106  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Plot_ID', 'GrainYield', 'Name', 'Line', 'Days2Heading', 'Days2Maturity']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>GrainYield</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Days2Heading</th>\n",
       "      <th>Days2Maturity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>357.239871</td>\n",
       "      <td>512-21</td>\n",
       "      <td>76.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>634.385088</td>\n",
       "      <td>GN11634</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>730.274361</td>\n",
       "      <td>SW51114 (Amulett)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>217.024221</td>\n",
       "      <td>Sumai 3 (18.)</td>\n",
       "      <td>71.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>598.191762</td>\n",
       "      <td>GN14516</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Plot_ID  GrainYield               Name    Line  Days2Heading  Days2Maturity\n",
       "0      101  357.239871             512-21    76.0          45.0          100.0\n",
       "1      102  634.385088            GN11634  1515.0          51.0          114.0\n",
       "2      103  730.274361  SW51114 (Amulett)    60.0          50.0          114.0\n",
       "3      104  217.024221      Sumai 3 (18.)    71.0          60.0          120.0\n",
       "4      105  598.191762            GN14516  1625.0          49.0          112.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Masbasis_2019_Simps',\n",
       " 'Masbasis_2020_Simps',\n",
       " 'Robot_2020_Simps',\n",
       " 'Staur_2019_Simps']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp_df_all = []\n",
    "samples_record_simps = {}\n",
    "for df, sowing in all_df_dates_filtered.items():\n",
    "\n",
    "    temp_df = locals()[df].copy()\n",
    "    cols = temp_df.columns\n",
    "    \n",
    "    # Creating a list of columns which other than the indices (ID and yield columns)\n",
    "    # Making a temp list of yield columns since all entries from yield cols are not present in every df\n",
    "    temp_yield_cols = [x for x in temp_df.columns if x in yield_cols]\n",
    "    non_indices_cols = id_cols_new+temp_yield_cols\n",
    "    print(non_indices_cols)\n",
    "    df_auc = temp_df[non_indices_cols]\n",
    "    display(df_auc.head())\n",
    "\n",
    "    # Calculating AUC and creating new df with calculated values\n",
    "    for col_name in base_indices+spectral_indices:\n",
    "        df_simp = []\n",
    "        # Making temp_cols list avoids problems finding and differentiating 'OSAVI' and 'GOSAVI'\n",
    "        temp_cols = [x for x in cols if col_name.split('_') == x.split('_')[:-1]]\n",
    "        temp_dates = [datetime.datetime.strptime(date.split('_')[-1], '%d%m%y').date() for date in temp_cols]\n",
    "\n",
    "        # Calculating the days from sowing,i.e. age of the crop in days\n",
    "        sowing_date = datetime.datetime.strptime(sowing, '%d%m%y').date() \n",
    "        \n",
    "        temp_samples = []\n",
    "        for sample in range(temp_df.shape[0]):\n",
    "            # Number of days since sowing for each entry\n",
    "            days_sow = [(x-sowing_date).days for x in temp_dates]\n",
    "            # The respective value of the index in question \n",
    "            temp_entries= [temp_df[x][sample] for x in temp_cols]\n",
    "\n",
    "            #### DROPPING DATES OUTSIDE HEADING AND MATURITY DATES ####\n",
    "            # Days to heading for current sample \n",
    "            DH = temp_df.Days2Heading[sample]\n",
    "            # Days to maturity for current sample \n",
    "            DM = temp_df.Days2Maturity[sample]\n",
    "            \n",
    "            # Skip the entry if wither DH or DM is Nan\n",
    "            if str(DH)=='nan' or str(DM)=='nan':\n",
    "#                 print(DH, DM, 'NAN')\n",
    "                df_simp.append(np.nan)\n",
    "                continue\n",
    "\n",
    "            DH = int(DH)\n",
    "            DM = int(DM)\n",
    "            # Making sure that the maturity comes after heading\n",
    "            if DM < DH:\n",
    "                print(DM, DH)\n",
    "            assert DM > DH\n",
    "#             print(DM, DH)\n",
    "            heading_date = sowing_date + datetime.timedelta(days=DH)\n",
    "            maturity_date = sowing_date + datetime.timedelta(days=DM)\n",
    "            \n",
    "            # Replacing the respective values of items in temp_entries with np.nan which correspond \n",
    "            # to dates not in between heading and maturity for that specific sub-plot\n",
    "            temp_entries = [y if heading_date <= x <= maturity_date else np.nan for x,y in zip(temp_dates, temp_entries)]\n",
    "            \n",
    "            # Dropping missing(nan) values from the entries\n",
    "            temp_entries_dropna = [x for x in temp_entries if str(x) != 'nan']\n",
    "\n",
    "            # Checking if the number of items in temp_entries and days_sow is the same\n",
    "            # If not, i.e., there are missing values(nan) in temp_entries then drop the\n",
    "            # respective entries from days_sow list\n",
    "            if not len(temp_entries_dropna) == len(days_sow):\n",
    "                # Dictionary comprehension\n",
    "                # Creating dictionary(dict comprehension) where temp_entries are not nan\n",
    "                dict_dropna = {i: [temp_entries[i], days_sow[i]] for i in range(len(temp_entries))\\\n",
    "                       if not str(temp_entries[i]) == 'nan' }\n",
    "                \n",
    "                # Checking if the previously created temp_entries_dropna is the same as the new that will\n",
    "                # be created from dict_dropna (Unnecessary check but curious to check if any problems arise)\n",
    "                assert temp_entries_dropna == [dict_dropna[i][0] for i in dict_dropna.keys()]\n",
    "                \n",
    "                # Creating new temp_entries and days_sow after dropping nan and respective entries in days_sow\n",
    "                temp_entries_dropna = [dict_dropna[i][0] for i in dict_dropna.keys()]\n",
    "                days_sow = [dict_dropna[i][1] for i in dict_dropna.keys()]\n",
    "\n",
    "#             Checking if the lists have the same number of entries\n",
    "            assert len(temp_entries_dropna) == len(days_sow)\n",
    "\n",
    "            df_simp.append(simps(temp_entries_dropna, days_sow))\n",
    "            temp_samples.append([simps(temp_entries_dropna, days_sow), temp_entries_dropna, days_sow])\n",
    "        samples_record_simps[df+'_'+col_name] = temp_samples\n",
    "        \n",
    "        # Insert the new column at the end, but before GrainYield\n",
    "        df_auc.insert(len(df_auc.columns)-1, col_name, df_simp)\n",
    "\n",
    "    # Adding the new name of the df to a list named simp_df_all\n",
    "    simp_df = df.split('_')[0]+'_'+df.split('_')[1]+'_Simps'\n",
    "    simp_df_all.append(simp_df)\n",
    "    locals()[simp_df] = df_auc.copy()\n",
    "simp_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T03:18:36.913645Z",
     "start_time": "2021-10-03T03:18:36.892310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_Simps Dropped entried 0 : 528 528\n",
      "Masbasis_2020_Simps Dropped entried 112 : 659 547\n",
      "Robot_2020_Simps Dropped entried 0 : 96 96\n",
      "Staur_2019_Simps Dropped entried 1166 : 1328 162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Masbasis_2019_Simps_dropna',\n",
       " 'Masbasis_2020_Simps_dropna',\n",
       " 'Robot_2020_Simps_dropna',\n",
       " 'Staur_2019_Simps_dropna']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp_df_all_dropna = []\n",
    "for df in simp_df_all:\n",
    "    temp_df = locals()[df].copy()\n",
    "    rows = temp_df.shape[0]\n",
    "#     print(temp_df.shape)\n",
    "    temp_df.dropna(subset=['Blue'],inplace = True)\n",
    "    print(df, 'Dropped entried', rows- temp_df.shape[0],':', rows, temp_df.shape[0])\n",
    "    new_df = df+'_dropna'\n",
    "    locals()[new_df] = temp_df.copy()\n",
    "    simp_df_all_dropna.append(new_df)\n",
    "simp_df_all_dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T03:19:09.162327Z",
     "start_time": "2021-10-03T03:19:09.123505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>GrainYield</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Days2Heading</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>RedEdge</th>\n",
       "      <th>NIR</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>MTCI</th>\n",
       "      <th>DVI</th>\n",
       "      <th>GDVI</th>\n",
       "      <th>MTCI_CI</th>\n",
       "      <th>EXG</th>\n",
       "      <th>EXGR</th>\n",
       "      <th>RDVI</th>\n",
       "      <th>TDVI</th>\n",
       "      <th>GNDVI</th>\n",
       "      <th>NDRE</th>\n",
       "      <th>SCCI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>TVI</th>\n",
       "      <th>VARI</th>\n",
       "      <th>GARI</th>\n",
       "      <th>GCI</th>\n",
       "      <th>GLI</th>\n",
       "      <th>NLI</th>\n",
       "      <th>MNLI</th>\n",
       "      <th>SAVI</th>\n",
       "      <th>GSAVI</th>\n",
       "      <th>OSAVI</th>\n",
       "      <th>GOSAVI</th>\n",
       "      <th>MSAVI2</th>\n",
       "      <th>MSR</th>\n",
       "      <th>GRVI</th>\n",
       "      <th>WDRVI</th>\n",
       "      <th>SR</th>\n",
       "      <th>Days2Maturity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>357.239871</td>\n",
       "      <td>512-21</td>\n",
       "      <td>76.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.891441</td>\n",
       "      <td>2.496192</td>\n",
       "      <td>1.575735</td>\n",
       "      <td>5.080712</td>\n",
       "      <td>18.959833</td>\n",
       "      <td>31.524212</td>\n",
       "      <td>155.743364</td>\n",
       "      <td>17.384098</td>\n",
       "      <td>16.463641</td>\n",
       "      <td>155.743364</td>\n",
       "      <td>2.525209</td>\n",
       "      <td>2.815372</td>\n",
       "      <td>23.393197</td>\n",
       "      <td>29.084631</td>\n",
       "      <td>28.485757</td>\n",
       "      <td>21.693060</td>\n",
       "      <td>25.228202</td>\n",
       "      <td>-49.498249</td>\n",
       "      <td>1079.864163</td>\n",
       "      <td>13.474818</td>\n",
       "      <td>19.525651</td>\n",
       "      <td>264.543523</td>\n",
       "      <td>0.821819</td>\n",
       "      <td>27.224074</td>\n",
       "      <td>15.248713</td>\n",
       "      <td>24.765070</td>\n",
       "      <td>22.886253</td>\n",
       "      <td>24.410953</td>\n",
       "      <td>22.294432</td>\n",
       "      <td>64.510195</td>\n",
       "      <td>558.125548</td>\n",
       "      <td>301.543523</td>\n",
       "      <td>6.089392</td>\n",
       "      <td>568.335371</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>634.385088</td>\n",
       "      <td>GN11634</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.454023</td>\n",
       "      <td>1.307849</td>\n",
       "      <td>0.751860</td>\n",
       "      <td>2.720009</td>\n",
       "      <td>10.658808</td>\n",
       "      <td>20.076644</td>\n",
       "      <td>101.513738</td>\n",
       "      <td>9.906949</td>\n",
       "      <td>9.350960</td>\n",
       "      <td>101.513738</td>\n",
       "      <td>1.409815</td>\n",
       "      <td>1.665061</td>\n",
       "      <td>14.088110</td>\n",
       "      <td>17.181887</td>\n",
       "      <td>18.065563</td>\n",
       "      <td>13.911963</td>\n",
       "      <td>15.852559</td>\n",
       "      <td>-28.347421</td>\n",
       "      <td>616.656489</td>\n",
       "      <td>8.919082</td>\n",
       "      <td>10.760771</td>\n",
       "      <td>175.623412</td>\n",
       "      <td>0.783027</td>\n",
       "      <td>17.248032</td>\n",
       "      <td>8.431690</td>\n",
       "      <td>14.926473</td>\n",
       "      <td>13.755619</td>\n",
       "      <td>15.137620</td>\n",
       "      <td>13.780119</td>\n",
       "      <td>38.467212</td>\n",
       "      <td>373.172348</td>\n",
       "      <td>198.623412</td>\n",
       "      <td>4.947035</td>\n",
       "      <td>379.087118</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>730.274361</td>\n",
       "      <td>SW51114 (Amulett)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.806496</td>\n",
       "      <td>2.120763</td>\n",
       "      <td>1.268243</td>\n",
       "      <td>4.318234</td>\n",
       "      <td>19.073734</td>\n",
       "      <td>32.396645</td>\n",
       "      <td>186.533126</td>\n",
       "      <td>17.805491</td>\n",
       "      <td>16.952971</td>\n",
       "      <td>186.533126</td>\n",
       "      <td>2.166787</td>\n",
       "      <td>2.512010</td>\n",
       "      <td>23.986655</td>\n",
       "      <td>29.755699</td>\n",
       "      <td>29.566846</td>\n",
       "      <td>23.426494</td>\n",
       "      <td>26.625393</td>\n",
       "      <td>-54.186812</td>\n",
       "      <td>1102.430259</td>\n",
       "      <td>14.024517</td>\n",
       "      <td>19.105437</td>\n",
       "      <td>308.708247</td>\n",
       "      <td>0.625270</td>\n",
       "      <td>28.516598</td>\n",
       "      <td>16.033038</td>\n",
       "      <td>25.380869</td>\n",
       "      <td>23.635102</td>\n",
       "      <td>25.047162</td>\n",
       "      <td>23.079023</td>\n",
       "      <td>65.449259</td>\n",
       "      <td>640.120100</td>\n",
       "      <td>345.708247</td>\n",
       "      <td>8.724839</td>\n",
       "      <td>649.475629</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>217.024221</td>\n",
       "      <td>Sumai 3 (18.)</td>\n",
       "      <td>71.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.490968</td>\n",
       "      <td>1.467358</td>\n",
       "      <td>1.088434</td>\n",
       "      <td>3.058573</td>\n",
       "      <td>9.778403</td>\n",
       "      <td>18.514131</td>\n",
       "      <td>80.384626</td>\n",
       "      <td>8.689969</td>\n",
       "      <td>8.311045</td>\n",
       "      <td>80.384626</td>\n",
       "      <td>1.355312</td>\n",
       "      <td>1.298862</td>\n",
       "      <td>12.678980</td>\n",
       "      <td>15.299158</td>\n",
       "      <td>17.015703</td>\n",
       "      <td>12.176331</td>\n",
       "      <td>15.001603</td>\n",
       "      <td>-22.261099</td>\n",
       "      <td>536.555038</td>\n",
       "      <td>5.834481</td>\n",
       "      <td>11.367351</td>\n",
       "      <td>134.614566</td>\n",
       "      <td>-0.087690</td>\n",
       "      <td>13.890034</td>\n",
       "      <td>6.375298</td>\n",
       "      <td>13.435915</td>\n",
       "      <td>12.608908</td>\n",
       "      <td>13.799072</td>\n",
       "      <td>12.814489</td>\n",
       "      <td>35.484995</td>\n",
       "      <td>249.294871</td>\n",
       "      <td>157.614566</td>\n",
       "      <td>0.317268</td>\n",
       "      <td>256.718244</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>598.191762</td>\n",
       "      <td>GN14516</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.153968</td>\n",
       "      <td>3.003463</td>\n",
       "      <td>1.714870</td>\n",
       "      <td>5.741359</td>\n",
       "      <td>20.686545</td>\n",
       "      <td>31.415006</td>\n",
       "      <td>147.870205</td>\n",
       "      <td>18.971675</td>\n",
       "      <td>17.683082</td>\n",
       "      <td>147.870205</td>\n",
       "      <td>3.138088</td>\n",
       "      <td>3.740733</td>\n",
       "      <td>24.410540</td>\n",
       "      <td>30.727245</td>\n",
       "      <td>27.689786</td>\n",
       "      <td>21.151252</td>\n",
       "      <td>24.691254</td>\n",
       "      <td>-52.009138</td>\n",
       "      <td>1189.844229</td>\n",
       "      <td>15.002430</td>\n",
       "      <td>20.082992</td>\n",
       "      <td>239.521081</td>\n",
       "      <td>0.796924</td>\n",
       "      <td>27.650799</td>\n",
       "      <td>17.250383</td>\n",
       "      <td>25.773786</td>\n",
       "      <td>23.290973</td>\n",
       "      <td>24.831837</td>\n",
       "      <td>22.139405</td>\n",
       "      <td>67.170173</td>\n",
       "      <td>522.156729</td>\n",
       "      <td>276.521081</td>\n",
       "      <td>5.190130</td>\n",
       "      <td>532.542099</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>326</td>\n",
       "      <td>443.478067</td>\n",
       "      <td>GN12650</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.729238</td>\n",
       "      <td>2.072085</td>\n",
       "      <td>1.231619</td>\n",
       "      <td>4.296052</td>\n",
       "      <td>18.341864</td>\n",
       "      <td>32.117191</td>\n",
       "      <td>170.968478</td>\n",
       "      <td>17.110245</td>\n",
       "      <td>16.269779</td>\n",
       "      <td>170.968478</td>\n",
       "      <td>2.183312</td>\n",
       "      <td>2.531130</td>\n",
       "      <td>23.359551</td>\n",
       "      <td>28.707676</td>\n",
       "      <td>29.279533</td>\n",
       "      <td>22.691420</td>\n",
       "      <td>25.976173</td>\n",
       "      <td>-54.052238</td>\n",
       "      <td>1060.233322</td>\n",
       "      <td>13.570207</td>\n",
       "      <td>18.838420</td>\n",
       "      <td>297.021355</td>\n",
       "      <td>1.024821</td>\n",
       "      <td>27.278347</td>\n",
       "      <td>15.002476</td>\n",
       "      <td>24.677466</td>\n",
       "      <td>22.951156</td>\n",
       "      <td>24.576354</td>\n",
       "      <td>22.619913</td>\n",
       "      <td>63.700406</td>\n",
       "      <td>629.759773</td>\n",
       "      <td>334.021355</td>\n",
       "      <td>8.002199</td>\n",
       "      <td>639.369282</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>327</td>\n",
       "      <td>521.343900</td>\n",
       "      <td>SW51114 (Amulett)</td>\n",
       "      <td>60.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.774273</td>\n",
       "      <td>2.187079</td>\n",
       "      <td>1.479116</td>\n",
       "      <td>4.404733</td>\n",
       "      <td>15.878395</td>\n",
       "      <td>30.352915</td>\n",
       "      <td>142.732910</td>\n",
       "      <td>14.399279</td>\n",
       "      <td>13.691316</td>\n",
       "      <td>142.732910</td>\n",
       "      <td>2.120769</td>\n",
       "      <td>2.237086</td>\n",
       "      <td>20.830763</td>\n",
       "      <td>25.060464</td>\n",
       "      <td>27.795799</td>\n",
       "      <td>20.563757</td>\n",
       "      <td>24.949805</td>\n",
       "      <td>-39.428246</td>\n",
       "      <td>892.275276</td>\n",
       "      <td>10.017306</td>\n",
       "      <td>17.615663</td>\n",
       "      <td>231.744897</td>\n",
       "      <td>-0.156361</td>\n",
       "      <td>22.540597</td>\n",
       "      <td>11.043946</td>\n",
       "      <td>22.007716</td>\n",
       "      <td>20.522764</td>\n",
       "      <td>22.573069</td>\n",
       "      <td>20.852797</td>\n",
       "      <td>57.687127</td>\n",
       "      <td>431.439516</td>\n",
       "      <td>268.744897</td>\n",
       "      <td>1.751372</td>\n",
       "      <td>442.881540</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>328</td>\n",
       "      <td>477.973623</td>\n",
       "      <td>Paros</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.725017</td>\n",
       "      <td>2.022605</td>\n",
       "      <td>1.397897</td>\n",
       "      <td>4.272810</td>\n",
       "      <td>16.483497</td>\n",
       "      <td>31.076720</td>\n",
       "      <td>162.185444</td>\n",
       "      <td>15.085600</td>\n",
       "      <td>14.460892</td>\n",
       "      <td>162.185444</td>\n",
       "      <td>1.922296</td>\n",
       "      <td>1.987845</td>\n",
       "      <td>21.595316</td>\n",
       "      <td>26.153974</td>\n",
       "      <td>28.704206</td>\n",
       "      <td>21.565294</td>\n",
       "      <td>25.382842</td>\n",
       "      <td>-44.188648</td>\n",
       "      <td>930.124355</td>\n",
       "      <td>11.077394</td>\n",
       "      <td>18.024138</td>\n",
       "      <td>281.652495</td>\n",
       "      <td>0.109567</td>\n",
       "      <td>24.607294</td>\n",
       "      <td>12.136921</td>\n",
       "      <td>22.843019</td>\n",
       "      <td>21.499109</td>\n",
       "      <td>23.280119</td>\n",
       "      <td>21.702623</td>\n",
       "      <td>59.621812</td>\n",
       "      <td>544.188805</td>\n",
       "      <td>318.652495</td>\n",
       "      <td>5.008174</td>\n",
       "      <td>554.799046</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>329</td>\n",
       "      <td>464.364326</td>\n",
       "      <td>GN13626</td>\n",
       "      <td>1615.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.574082</td>\n",
       "      <td>1.736141</td>\n",
       "      <td>0.897789</td>\n",
       "      <td>3.791359</td>\n",
       "      <td>18.034478</td>\n",
       "      <td>33.431710</td>\n",
       "      <td>183.522653</td>\n",
       "      <td>17.136689</td>\n",
       "      <td>16.298337</td>\n",
       "      <td>183.522653</td>\n",
       "      <td>2.000411</td>\n",
       "      <td>2.479647</td>\n",
       "      <td>23.893056</td>\n",
       "      <td>29.289601</td>\n",
       "      <td>30.453397</td>\n",
       "      <td>24.075199</td>\n",
       "      <td>26.611263</td>\n",
       "      <td>-56.663329</td>\n",
       "      <td>1061.735412</td>\n",
       "      <td>15.418630</td>\n",
       "      <td>17.916079</td>\n",
       "      <td>350.552765</td>\n",
       "      <td>2.055216</td>\n",
       "      <td>29.858499</td>\n",
       "      <td>15.488562</td>\n",
       "      <td>25.295600</td>\n",
       "      <td>23.531304</td>\n",
       "      <td>25.413143</td>\n",
       "      <td>23.384359</td>\n",
       "      <td>64.640221</td>\n",
       "      <td>771.893337</td>\n",
       "      <td>387.552765</td>\n",
       "      <td>12.502904</td>\n",
       "      <td>780.156593</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>330</td>\n",
       "      <td>424.961714</td>\n",
       "      <td>GN08588</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.335050</td>\n",
       "      <td>3.746807</td>\n",
       "      <td>2.310398</td>\n",
       "      <td>7.097665</td>\n",
       "      <td>21.422347</td>\n",
       "      <td>29.861593</td>\n",
       "      <td>113.648601</td>\n",
       "      <td>19.111949</td>\n",
       "      <td>17.675540</td>\n",
       "      <td>113.648601</td>\n",
       "      <td>3.848166</td>\n",
       "      <td>4.360415</td>\n",
       "      <td>23.880875</td>\n",
       "      <td>30.226276</td>\n",
       "      <td>25.930454</td>\n",
       "      <td>18.624240</td>\n",
       "      <td>22.830588</td>\n",
       "      <td>-49.728031</td>\n",
       "      <td>1204.173304</td>\n",
       "      <td>13.764594</td>\n",
       "      <td>21.782961</td>\n",
       "      <td>189.342789</td>\n",
       "      <td>1.014113</td>\n",
       "      <td>25.450829</td>\n",
       "      <td>16.915601</td>\n",
       "      <td>25.128813</td>\n",
       "      <td>22.427777</td>\n",
       "      <td>23.878217</td>\n",
       "      <td>20.995213</td>\n",
       "      <td>66.732684</td>\n",
       "      <td>430.224439</td>\n",
       "      <td>226.342789</td>\n",
       "      <td>1.161213</td>\n",
       "      <td>442.044775</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows  40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Plot_ID  GrainYield               Name    Line  Days2Heading      Blue  \\\n",
       "0        101  357.239871             512-21    76.0          45.0  0.891441   \n",
       "1        102  634.385088            GN11634  1515.0          51.0  0.454023   \n",
       "2        103  730.274361  SW51114 (Amulett)    60.0          50.0  0.806496   \n",
       "3        104  217.024221      Sumai 3 (18.)    71.0          60.0  0.490968   \n",
       "4        105  598.191762            GN14516  1625.0          49.0  1.153968   \n",
       "..       ...         ...                ...     ...           ...       ...   \n",
       "157      326  443.478067            GN12650  1621.0          49.0  0.729238   \n",
       "158      327  521.343900  SW51114 (Amulett)    60.0          48.0  0.774273   \n",
       "159      328  477.973623              Paros    10.0          48.0  0.725017   \n",
       "160      329  464.364326            GN13626  1615.0          47.0  0.574082   \n",
       "161      330  424.961714            GN08588  1316.0          48.0  1.335050   \n",
       "\n",
       "        Green       Red   RedEdge        NIR       NDVI        MTCI  \\\n",
       "0    2.496192  1.575735  5.080712  18.959833  31.524212  155.743364   \n",
       "1    1.307849  0.751860  2.720009  10.658808  20.076644  101.513738   \n",
       "2    2.120763  1.268243  4.318234  19.073734  32.396645  186.533126   \n",
       "3    1.467358  1.088434  3.058573   9.778403  18.514131   80.384626   \n",
       "4    3.003463  1.714870  5.741359  20.686545  31.415006  147.870205   \n",
       "..        ...       ...       ...        ...        ...         ...   \n",
       "157  2.072085  1.231619  4.296052  18.341864  32.117191  170.968478   \n",
       "158  2.187079  1.479116  4.404733  15.878395  30.352915  142.732910   \n",
       "159  2.022605  1.397897  4.272810  16.483497  31.076720  162.185444   \n",
       "160  1.736141  0.897789  3.791359  18.034478  33.431710  183.522653   \n",
       "161  3.746807  2.310398  7.097665  21.422347  29.861593  113.648601   \n",
       "\n",
       "           DVI       GDVI     MTCI_CI       EXG      EXGR       RDVI  \\\n",
       "0    17.384098  16.463641  155.743364  2.525209  2.815372  23.393197   \n",
       "1     9.906949   9.350960  101.513738  1.409815  1.665061  14.088110   \n",
       "2    17.805491  16.952971  186.533126  2.166787  2.512010  23.986655   \n",
       "3     8.689969   8.311045   80.384626  1.355312  1.298862  12.678980   \n",
       "4    18.971675  17.683082  147.870205  3.138088  3.740733  24.410540   \n",
       "..         ...        ...         ...       ...       ...        ...   \n",
       "157  17.110245  16.269779  170.968478  2.183312  2.531130  23.359551   \n",
       "158  14.399279  13.691316  142.732910  2.120769  2.237086  20.830763   \n",
       "159  15.085600  14.460892  162.185444  1.922296  1.987845  21.595316   \n",
       "160  17.136689  16.298337  183.522653  2.000411  2.479647  23.893056   \n",
       "161  19.111949  17.675540  113.648601  3.848166  4.360415  23.880875   \n",
       "\n",
       "          TDVI      GNDVI       NDRE       SCCI        EVI          TVI  \\\n",
       "0    29.084631  28.485757  21.693060  25.228202 -49.498249  1079.864163   \n",
       "1    17.181887  18.065563  13.911963  15.852559 -28.347421   616.656489   \n",
       "2    29.755699  29.566846  23.426494  26.625393 -54.186812  1102.430259   \n",
       "3    15.299158  17.015703  12.176331  15.001603 -22.261099   536.555038   \n",
       "4    30.727245  27.689786  21.151252  24.691254 -52.009138  1189.844229   \n",
       "..         ...        ...        ...        ...        ...          ...   \n",
       "157  28.707676  29.279533  22.691420  25.976173 -54.052238  1060.233322   \n",
       "158  25.060464  27.795799  20.563757  24.949805 -39.428246   892.275276   \n",
       "159  26.153974  28.704206  21.565294  25.382842 -44.188648   930.124355   \n",
       "160  29.289601  30.453397  24.075199  26.611263 -56.663329  1061.735412   \n",
       "161  30.226276  25.930454  18.624240  22.830588 -49.728031  1204.173304   \n",
       "\n",
       "          VARI       GARI         GCI       GLI        NLI       MNLI  \\\n",
       "0    13.474818  19.525651  264.543523  0.821819  27.224074  15.248713   \n",
       "1     8.919082  10.760771  175.623412  0.783027  17.248032   8.431690   \n",
       "2    14.024517  19.105437  308.708247  0.625270  28.516598  16.033038   \n",
       "3     5.834481  11.367351  134.614566 -0.087690  13.890034   6.375298   \n",
       "4    15.002430  20.082992  239.521081  0.796924  27.650799  17.250383   \n",
       "..         ...        ...         ...       ...        ...        ...   \n",
       "157  13.570207  18.838420  297.021355  1.024821  27.278347  15.002476   \n",
       "158  10.017306  17.615663  231.744897 -0.156361  22.540597  11.043946   \n",
       "159  11.077394  18.024138  281.652495  0.109567  24.607294  12.136921   \n",
       "160  15.418630  17.916079  350.552765  2.055216  29.858499  15.488562   \n",
       "161  13.764594  21.782961  189.342789  1.014113  25.450829  16.915601   \n",
       "\n",
       "          SAVI      GSAVI      OSAVI     GOSAVI     MSAVI2         MSR  \\\n",
       "0    24.765070  22.886253  24.410953  22.294432  64.510195  558.125548   \n",
       "1    14.926473  13.755619  15.137620  13.780119  38.467212  373.172348   \n",
       "2    25.380869  23.635102  25.047162  23.079023  65.449259  640.120100   \n",
       "3    13.435915  12.608908  13.799072  12.814489  35.484995  249.294871   \n",
       "4    25.773786  23.290973  24.831837  22.139405  67.170173  522.156729   \n",
       "..         ...        ...        ...        ...        ...         ...   \n",
       "157  24.677466  22.951156  24.576354  22.619913  63.700406  629.759773   \n",
       "158  22.007716  20.522764  22.573069  20.852797  57.687127  431.439516   \n",
       "159  22.843019  21.499109  23.280119  21.702623  59.621812  544.188805   \n",
       "160  25.295600  23.531304  25.413143  23.384359  64.640221  771.893337   \n",
       "161  25.128813  22.427777  23.878217  20.995213  66.732684  430.224439   \n",
       "\n",
       "           GRVI      WDRVI          SR  Days2Maturity  \n",
       "0    301.543523   6.089392  568.335371          100.0  \n",
       "1    198.623412   4.947035  379.087118          114.0  \n",
       "2    345.708247   8.724839  649.475629          114.0  \n",
       "3    157.614566   0.317268  256.718244          120.0  \n",
       "4    276.521081   5.190130  532.542099          112.0  \n",
       "..          ...        ...         ...            ...  \n",
       "157  334.021355   8.002199  639.369282           97.0  \n",
       "158  268.744897   1.751372  442.881540          100.0  \n",
       "159  318.652495   5.008174  554.799046           96.0  \n",
       "160  387.552765  12.502904  780.156593           92.0  \n",
       "161  226.342789   1.161213  442.044775           88.0  \n",
       "\n",
       "[162 rows x 40 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Staur_2019_Simps_dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp: Exporting data to be used for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = export_path+'Temp_Data/'\n",
    "os.makedirs(temp_data, exist_ok=True)\n",
    "# for df in simp_df_all:\n",
    "#     locals()[df].to_csv(temp_data+df+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Genomics Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Genomics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Yield data with line information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:56:14.818870Z",
     "start_time": "2021-09-08T17:56:14.815434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vollebekk 2019: Graminor_2019_x_19TvPhenores_x_Vollebekk_res\n",
    "# Masbasis 2020: Masbasis_x_20BMLGI1_2020_tm_x_data\n",
    "# Robot 2020: Robot_x_ROBOT_2020_x_raw\n",
    "# Masbasis 2019: Masbasis_2019_x_Field_data_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:56:14.833002Z",
     "start_time": "2021-09-08T17:56:14.824218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Graminor 2019': ['Graminor_2019_x_19TvPhenores_x_Vollebekk_res',\n",
      "                   '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                   'Thesis\\\\Data\\\\Feb2021\\\\Graminor_2019\\\\19TvPhenores.xlsx'],\n",
      " 'Masbasis 2019': ['Masbasis_2019_x_Field_data_2019',\n",
      "                   '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                   'Thesis\\\\Data\\\\Feb2021\\\\Masbasis_2019\\\\Field_data_2019.xlsx'],\n",
      " 'Masbasis 2020': ['Masbasis_x_20BMLGI1_2020_tm_x_data',\n",
      "                   '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                   'Thesis\\\\Data\\\\Feb2021\\\\Vollebekke-total_2020\\\\Masbasis\\\\20BMLGI1_2020_tm.xlsx'],\n",
      " 'Robot 2020': ['Robot_x_ROBOT_2020_x_raw',\n",
      "                '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                'Thesis\\\\Data\\\\Feb2021\\\\Vollebekke-total_2020\\\\Robot\\\\ROBOT_2020.xlsx'],\n",
      " 'Staur 2019': ['Graminor_2019_x_19TvPhenores_x_Staur_res',\n",
      "                '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                'Thesis\\\\Data\\\\Feb2021\\\\Graminor_2019\\\\19TvPhenores.xlsx']}\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+'yield_df.json', \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "\n",
    "# Converting it to dictionary\n",
    "output_dict = json.loads(output_str)\n",
    "a_file.close()\n",
    "\n",
    "pprint(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking number of unique cultivars in the field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:56:14.839834Z",
     "start_time": "2021-09-08T17:56:14.835929Z"
    }
   },
   "outputs": [],
   "source": [
    "# plots_data = pd.read_excel(files_with_address[0],engine='openpyxl')\n",
    "# # Pandas converts 'NA' string to NaN. Need to change those to \n",
    "# # some string to get a count as NaNs are not counted as unique values\n",
    "\n",
    "# plots_data.Name.fillna('-', inplace=True)\n",
    "# plots_data.CodeName.fillna('-', inplace=True)\n",
    "\n",
    "# # Creating a new column as multiple plots were named 'NA' but the \n",
    "# # CodeName was different for each one of them\n",
    "# plots_data['NameCode'] = plots_data.Name+plots_data.CodeName\n",
    "\n",
    "# plots_data\n",
    "# len(plots_data.NameCode.unique())\n",
    "# plots_data.NameCode.value_counts()\n",
    "# # plots_data.NameCode.value_counts().sum()\n",
    "# # plots_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo: Dropping NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding NAN values\n",
    "### ToDo: Test: Raise error if missing values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.599254Z",
     "start_time": "2021-09-08T17:16:55.592423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing value found in any dataframe\n"
     ]
    }
   ],
   "source": [
    "# Finding number of missing values in each dataframe\n",
    "df_with_nan = []\n",
    "missing_values = False\n",
    "for df in all_df:\n",
    "    if locals()[df].isna().sum().sum() > 0:\n",
    "        print(f'Total missing values in {df} are {locals()[df].isna().sum().sum()}')\n",
    "        missing_values = True\n",
    "        df_with_nan.append(df)\n",
    "#     if len(df_with_nan) > 0:\n",
    "#         raise ValueError\n",
    "if not missing_values:\n",
    "    print('No missing value found in any dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.623191Z",
     "start_time": "2021-09-08T17:16:55.601230Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Graminor_2019_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-92e745b63b43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGraminor_2019_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Graminor_2019_all' is not defined"
     ]
    }
   ],
   "source": [
    "Graminor_2019_all.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.632951Z",
     "start_time": "2021-09-08T17:16:55.626119Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.640759Z",
     "start_time": "2021-09-08T17:16:55.635878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding which column has NAN values\n",
    "for df in df_with_nan:\n",
    "    print(f'{df}:\\n {locals()[df].shape[1]-locals()[df].dropna(axis=1).shape[1]} columns or {locals()[df].shape[0]-locals()[df].dropna().shape[0]} rows to be dropped,')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Automate: Drop rows with missing values in df_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.936906Z",
     "start_time": "2021-09-08T17:16:55.923195Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Graminor_eastwest_020719_NIR_half_missing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-bd632eb495de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{Graminor_eastwest_020719_NIR_half_missing.shape} Before dropping'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Graminor_eastwest_020719_NIR_half_missing.dropna(inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{Graminor_eastwest_020719_NIR_half_missing.shape} After dropping'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Graminor_eastwest_020719_NIR_half_missing' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'{Graminor_eastwest_020719_NIR_half_missing.shape} Before dropping')\n",
    "# Graminor_eastwest_020719_NIR_half_missing.dropna(inplace=True)\n",
    "print(f'{Graminor_eastwest_020719_NIR_half_missing.shape} After dropping')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Droppping df with Nan from the all_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:56.595993Z",
     "start_time": "2021-09-08T17:16:56.591114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in all_df is 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of items in all_df is {len(all_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:56.602824Z",
     "start_time": "2021-09-08T17:16:56.598923Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for df in df_with_nan:\n",
    "#     all_df.remove(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ToDo: Update field_year_dict and sorted_field_year_dict after dropping the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:56.943290Z",
     "start_time": "2021-09-08T17:16:56.938408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in all_df now is 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of items in all_df now is {len(all_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo:  \n",
    "see the distribution of data if it is normal  \n",
    "else make transpose to make it normal  \n",
    "dist in Gausion function   \n",
    "in each field  \n",
    "what if the data is normal dist?  \n",
    "the use some transpose to box pox   \n",
    "try diff funct to see which one iis able to make data normal  \n",
    "make heat map of whole if not normal  \n",
    "see which parts are not normal and exculde them  \n",
    "ls_means in R to make the normalisation/transpose  \n",
    "pearson corr bw yield and indices for diff dates  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:57.911154Z",
     "start_time": "2021-09-08T17:16:57.898466Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1ae58ac70b7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_labels' is not defined"
     ]
    }
   ],
   "source": [
    "x_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yeo-Johnson Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:59.631522Z",
     "start_time": "2021-09-08T17:16:58.258599Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'field_year_dict_yield' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-bf2287054a1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_agg_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcol_for_plotting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_year_dict_yield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'field_year_dict_yield' is not defined"
     ]
    }
   ],
   "source": [
    "col_for_plotting = ['Blue', 'Green', 'Red', 'RedEdge', 'NIR', 'NDVI', 'MTCI', 'EVI']\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, normalize, StandardScaler\n",
    "data_agg_list = ['_median_indices']\n",
    "\n",
    "# col_for_plotting = ['Blue']\n",
    "# col_for_plotting = ['Green']\n",
    "# col_for_plotting = ['Red']\n",
    "\n",
    "for d_type in data_agg_list:\n",
    "    for col in col_for_plotting:\n",
    "        fields = len(field_year_dict_yield.keys())\n",
    "        rows = math.ceil(fields/2)\n",
    "        \n",
    "        fig, ax = plt.subplots(rows,2, figsize=(15,10))\n",
    "        plots = ax.flatten()\n",
    "        n = 0\n",
    "        # TODO: Fix the x ticks\n",
    "        \n",
    "\n",
    "        for field_sample, dates in sorted_field_year_dict_yield.items():\n",
    "            x_labels = []\n",
    "            # Adding required data to a temp dataframe\n",
    "            temp_df = pd.DataFrame()\n",
    "            for date in dates:\n",
    "                date_str = date.strftime('%d%m%y')\n",
    "                field_df = field_sample[:-5]+'_'+date_str+d_type\n",
    "                temp_df[date] = locals()[field_df][col]\n",
    "                x_label = date.strftime('%d-%m-%y')+':'+str(len(locals()[field_df][col]))\n",
    "                \n",
    "                x_labels.append(x_label)\n",
    "                x_labels= list(set(x_labels))\n",
    "            # Transform the df\n",
    "#             pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "            pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "\n",
    "            temp_arr = pt.fit_transform(temp_df)\n",
    "            temp_df = pd.DataFrame(temp_arr)\n",
    "            \n",
    "            # Adding field plot to the subplots\n",
    "            num_of_fields = len(field_year_dict_yield.keys())\n",
    "            \n",
    "            text = \"Grain Yield\"\n",
    "            ax_n = plots[n]\n",
    "            \n",
    "            temp_df.boxplot(ax=ax_n)\n",
    "            ax_n.set_xticklabels(x_labels, rotation=-35)\n",
    "            ax_n.set_title(field_sample+'_'+col+d_type[:-5]+'_yeo-johnson')\n",
    "            \n",
    "#             # Printing the grain yield in plot of the fiels_sample for reference\n",
    "#             ax_n.text(0.85, 1.05, text, ha='center', va='top', weight='bold', color='blue', transform=ax_n.transAxes)\n",
    "            n+=1\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-Cox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:59.656899Z",
     "start_time": "2021-09-08T17:16:59.633474Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'field_year_dict_yield' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-8b39c1ee47a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_agg_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcol_for_plotting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_year_dict_yield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'field_year_dict_yield' is not defined"
     ]
    }
   ],
   "source": [
    "col_for_plotting = ['Blue', 'Green', 'Red', 'RedEdge', 'NIR', 'NDVI', 'MTCI', 'EVI']\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, normalize, StandardScaler\n",
    "data_agg_list = ['_median_indices']\n",
    "\n",
    "# col_for_plotting = ['Blue']\n",
    "# col_for_plotting = ['Green']\n",
    "# col_for_plotting = ['Red']\n",
    "\n",
    "for d_type in data_agg_list:\n",
    "    for col in col_for_plotting:\n",
    "        fields = len(field_year_dict_yield.keys())\n",
    "        rows = math.ceil(fields/2)\n",
    "        \n",
    "        fig, ax = plt.subplots(rows,2, figsize=(15,10))\n",
    "        plots = ax.flatten()\n",
    "        n = 0\n",
    "        # TODO: Fix the x ticks\n",
    "        for field_sample, dates in sorted_field_year_dict_yield.items():\n",
    "            \n",
    "            # Adding required data to a temp dataframe\n",
    "            temp_df = pd.DataFrame()\n",
    "            for date in dates:\n",
    "                date_str = date.strftime('%d%m%y')\n",
    "                field_df = field_sample[:-5]+'_'+date_str+d_type\n",
    "                temp_df[date] = locals()[field_df][col]\n",
    "            x_labels = temp_df.columns.tolist()\n",
    "\n",
    "            # Transform the df\n",
    "#             pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "            pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "\n",
    "            # Taking absolute values of the dataframe(avoiding negative values)\n",
    "            temp_arr = pt.fit_transform(temp_df.abs())\n",
    "            temp_df = pd.DataFrame(temp_arr)\n",
    "            \n",
    "            # Adding field plot to the subplots\n",
    "            num_of_fields = len(field_year_dict_yield.keys())\n",
    "            \n",
    "            text = \"Grain Yield\"\n",
    "            ax_n = plots[n]\n",
    "\n",
    "            temp_df.boxplot(ax=ax_n)\n",
    "            ax_n.set_xticklabels(x_labels, rotation=90)\n",
    "            ax_n.set_title(field_sample+'_'+col+d_type[:-5]+'_box-cox')\n",
    "            \n",
    "#             # Printing the grain yield in plot of the fiels_sample for reference\n",
    "#             ax_n.text(0.85, 1.05, text, ha='center', va='top', weight='bold', color='blue', transform=ax_n.transAxes)\n",
    "            n+=1\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo: Identify Dates and index with problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecxclude the problematic data/dates\n",
    "or\n",
    "### Take average values where the problematic data is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take average of data for date 20200708 and 20200624  \n",
    "Masbasis  \n",
    "Cleanup  \n",
    "Remove dates which have drop  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find AUC for all dates of one field\n",
    "See if it covers tha gaps under the dates,i.e.\n",
    "\n",
    "Since data points are different  \n",
    "Flying time is different  \n",
    "Cover the gaps between the dates  \n",
    "\n",
    "Since the data collection is not uniform throughout the year so AUC will give a single value instead of multiple values for one field year which will be representative of all the dates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Use Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.226553Z",
     "start_time": "2021-09-08T17:17:01.218744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.241194Z",
     "start_time": "2021-09-08T17:17:01.235336Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "from scipy.integrate import simps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.254854Z",
     "start_time": "2021-09-08T17:17:01.248025Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import simpson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.280233Z",
     "start_time": "2021-09-08T17:17:01.274374Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(0, 10)\n",
    "y = np.arange(0, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.306584Z",
     "start_time": "2021-09-08T17:17:01.296829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integrate.simpson(y, x)\n",
    "integrate.simps(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.333910Z",
     "start_time": "2021-09-08T17:17:01.323176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   8,  27,  64, 125, 216, 343, 512, 729], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.power(x, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.356360Z",
     "start_time": "2021-09-08T17:17:01.347576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrate.simpson(y, x)\n",
    "# integrate.simps(y, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.372949Z",
     "start_time": "2021-09-08T17:17:01.364165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640.25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrate.quad(lambda x: x**3, 0, 9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.392469Z",
     "start_time": "2021-09-08T17:17:01.380762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrate.simpson(y, x, even='first')\n",
    "# integrate.simps(y, x, even='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.969977Z",
     "start_time": "2021-09-08T17:17:01.954361Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-5c4058e7910f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# plot: Plot ID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# x: Number of days after sowing or actual date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# y: Value of the index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data\n",
    "# plot: Plot ID\n",
    "# x: Number of days after sowing or actual date\n",
    "# y: Value of the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.991449Z",
     "start_time": "2021-09-08T17:17:01.973882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8500000000000001\n",
      "1.5\n",
      "1.95\n"
     ]
    }
   ],
   "source": [
    "# x: Days from sowing to data collection\n",
    "# May 5 2019 Masbasis and Graminor\n",
    "# Robot: \n",
    "\n",
    "data={'plot':['1','1','2','2','3','3'],'x':['5','6','7','8','9','10'],'y':['0.9','0.8','0.7','0.6','0.5','0.4'] }\n",
    "\n",
    "ACC=[]\n",
    "A=pd.DataFrame(data, columns=['plot','x','y'])\n",
    "AA=0\n",
    "\n",
    "for item in range(len(A)-1):\n",
    "    if A['plot'][item]== A['plot'][item+1]:\n",
    "        Ans=(float((A['y'][item]))+float((A['y'][item+1])))*((float((A['x'][item+1]))-float((A['x'][item]))))/2\n",
    "        AA+=Ans\n",
    "        print(AA)\n",
    "        ACC.append(AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:02.434915Z",
     "start_time": "2021-09-08T17:17:02.414078Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-508f0f07663b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Plot'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mACC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mNumbers_final\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Data' is not defined"
     ]
    }
   ],
   "source": [
    "df1=Data.set_index(['Plot'])\n",
    "ACC=[]\n",
    "\n",
    "for item in Numbers_final:\n",
    "    df2=df1[df1.index==item]\n",
    "    df2=df2.filter(['Blue', 'Green', 'Red', 'RedEdge', 'NIR','NDVI', 'MTCI', 'EVI', 'DVI', 'RVI', 'VARI', 'EXG', 'EXGR', 'GLI', 'GNDVI', 'GVI','Time','timepoint'], axis=1)\n",
    "    df2=df2.sort_values(by='timepoint')\n",
    "    df3=df2.reset_index()\n",
    "\n",
    "AA=0\n",
    "for j in range(0,3):\n",
    "    Ans=(float((df3['GVI'][j]))+float((df3['GVI'][j+1])))*((float((df3['timepoint'][j+1]))-float((df3['timepoint'][j]))))/2\n",
    "    AA+=Ans\n",
    "\n",
    "    print(AA)\n",
    "    ACC.append(AA)\n",
    "\n",
    "\n",
    "\n",
    "DA=pd.DataFrame(ACC)\n",
    "DD=pd.DataFrame(Numbers_final)\n",
    "DDA=pd.concat([DD, DA], axis=1)\n",
    "DDA.to_excel('Staur_Accumulative_GVI_2019.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series data vs the AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Make model for one year at a time and try to predict yield of another field  \n",
    "\n",
    "TODO: Train on Masbasis 2019 an 2020  \n",
    "Test on Staur  \n",
    "\n",
    "Use data until august for yield prediction since it is most relavant  \n",
    "Use all data for predicting date to maturity  \n",
    "\n",
    "Data Collection:  \n",
    "Data collection usually starts after heading  \n",
    "2019 has the data before hading as well. To use that, dont use dates before heading  \n",
    "\n",
    "NDVI is resistant to shadows  \n",
    "\n",
    "DAT390 Report: Do the report with Robot Data only  \n",
    "\n",
    "TODO: Use AUC for each index for prediction  \n",
    "\n",
    "TODO:   \n",
    "Time series data vs the AUC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "391.441px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
