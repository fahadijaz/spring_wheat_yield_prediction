{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather and Genomics Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Half datasets, with separate files for east and west subplots have been merged manually in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:54.855760Z",
     "start_time": "2021-10-11T02:38:53.550728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "\n",
    "# Dictionaries\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Iterate in loops\n",
    "from itertools import zip_longest\n",
    "\n",
    "# Simpsons integration\n",
    "from numpy import trapz\n",
    "from scipy.integrate import simps\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To display df nicely in loops\n",
    "from IPython.display import display \n",
    "# display(df1.head()) \n",
    "# display(df2.head())\n",
    "\n",
    "# Display rows and columns Pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:54.871213Z",
     "start_time": "2021-10-11T02:38:54.856756Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fahad\\\\MegaSync\\\\NMBU\\\\GitHub\\\\vPheno'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the current working directory\n",
    "os.getcwd()\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Username folder to make general path for multi PC use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:54.886226Z",
     "start_time": "2021-10-11T02:38:54.873208Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fahad', 'C:/Users/fahad/')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = str(os.getcwd()).split('\\\\')[2]\n",
    "user_path = r'C:/Users/'+username+'/'\n",
    "username, user_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:54.901695Z",
     "start_time": "2021-10-11T02:38:54.887750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all.csv',\n",
       " 'Graminor_2020_all.csv',\n",
       " 'Masbasis_2019_all.csv',\n",
       " 'Masbasis_2020_all_lodg.csv',\n",
       " 'Robot_2020_all.csv',\n",
       " 'Staur_2019_all.csv',\n",
       " 'Staur_2020_all_lodg.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = r'./Data/'\n",
    "path = r'./Data/2. renamed_merged/'\n",
    "export_path = r'./Data/3. merged data/'\n",
    "# temp_export_path = r'./Data/3. Temp_Data/'\n",
    "weather_data = user_path+r'\\\\MegaSync\\NMBU\\Master Thesis\\Data\\Weather\\Weather_Data.csv'\n",
    "genomics_data = user_path+r'\\\\MegaSync\\NMBU\\Master Thesis\\Data\\Genomics\\\\'\n",
    "\n",
    "# Create export_path folder if not exists already\n",
    "os.makedirs(path, exist_ok=True)\n",
    "os.makedirs(export_path, exist_ok=True)\n",
    "# os.makedirs(temp_export_path, exist_ok=True)\n",
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Creating list of complete files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:54.917651Z",
     "start_time": "2021-10-11T02:38:54.903703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 files found in the directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all.csv',\n",
       " 'Graminor_2020_all.csv',\n",
       " 'Masbasis_2019_all.csv',\n",
       " 'Masbasis_2020_all_lodg.csv',\n",
       " 'Robot_2020_all.csv',\n",
       " 'Staur_2019_all.csv',\n",
       " 'Staur_2020_all_lodg.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of all files in directory tree at given path\n",
    "\n",
    "files_with_address = []\n",
    "files_list = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "    files_with_address += [os.path.join(dirpath, file) for file in filenames]\n",
    "    files_list.extend(filenames)\n",
    "    \n",
    "print(len(files_with_address), 'files found in the directory')\n",
    "# files_with_address\n",
    "files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Checking/control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Check for duplicate filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:54.933613Z",
     "start_time": "2021-10-11T02:38:54.918648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files are : 7\n",
      "Number of unique file names are: 7\n",
      "There is/are 0 duplicate file name/names.\n"
     ]
    }
   ],
   "source": [
    "print('Total number of files are :', len(files_list))\n",
    "\n",
    "print('Number of unique file names are:', len(set(files_list)))\n",
    "\n",
    "print('There is/are', len(files_list) - len(set(files_list)),'duplicate file name/names.')\n",
    "if len(files_list) - len(set(files_list)) > 0:\n",
    "    raise NameError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data files to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:55.406371Z",
     "start_time": "2021-10-11T02:38:54.934606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_all ===== (600, 378)\n",
      "Graminor_2020_all ===== (800, 378)\n",
      "Masbasis_2019_all ===== (528, 278)\n",
      "Masbasis_2020_all_lodg ===== (659, 416)\n",
      "Robot_2020_all ===== (96, 484)\n",
      "Staur_2019_all ===== (1328, 175)\n",
      "Staur_2020_all_lodg ===== (1504, 209)\n",
      "Wall time: 465 ms\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "%%time\n",
    "\n",
    "all_df = []\n",
    "for data in files_with_address:\n",
    "    file_name = os.path.splitext(os.path.basename(data))[0]\n",
    "\n",
    "    # Replce all invalid characters in the name\n",
    "    file_name = file_name.replace(\" \", \"_\")\n",
    "    file_name = file_name.replace(\"-\", \"_\")\n",
    "    file_name = file_name.replace(\")\", \"\")\n",
    "    file_name = file_name.replace(\"(\", \"\")\n",
    "    df_name = file_name.replace(\".\", \"\")\n",
    "    # Test: Check if the same date is already present in the current dict key\n",
    "    if df_name in all_df:\n",
    "        print(f'A file with the same name {df_name} has already been imported. \\n Please check if there is duplication of data.')\n",
    "        raise NameError\n",
    "    all_df.append(df_name)\n",
    "\n",
    "    locals()[df_name] = pd.read_csv(data, index_col=False)\n",
    "    print(df_name, '=====', locals()[df_name].shape)\n",
    "# all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:55.422319Z",
     "start_time": "2021-10-11T02:38:55.408364Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imported 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all',\n",
       " 'Graminor_2020_all',\n",
       " 'Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all',\n",
       " 'Staur_2020_all_lodg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total imported {len(all_df)}')\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:55.438304Z",
     "start_time": "2021-10-11T02:38:55.424314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_all (600, 378)\n",
      "Graminor_2020_all (800, 378)\n",
      "Masbasis_2019_all (528, 278)\n",
      "Masbasis_2020_all_lodg (659, 416)\n",
      "Robot_2020_all (96, 484)\n",
      "Staur_2019_all (1328, 175)\n",
      "Staur_2020_all_lodg (1504, 209)\n"
     ]
    }
   ],
   "source": [
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    print(df, temp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GrainYield data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:55.469193Z",
     "start_time": "2021-10-11T02:38:55.439273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_all\n",
      "Grain Yield data missing for  1 out of  600\n",
      "Graminor_2020_all\n",
      "Grain Yield data missing for  1 out of  800\n",
      "Masbasis_2019_all\n",
      "Grain Yield data missing for  6 out of  528\n",
      "Masbasis_2020_all_lodg\n",
      "Grain Yield data missing for  116 out of  659\n",
      "Robot_2020_all\n",
      "Grain Yield data missing for  0 out of  96\n",
      "Staur_2019_all\n",
      "Grain Yield data missing for  0 out of  1328\n",
      "Staur_2020_all_lodg\n",
      "Grain Yield data missing for  568 out of  1504\n"
     ]
    }
   ],
   "source": [
    "# Masbasis_2019_Simps.info(null_counts=True)\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "#     print('*************', df, '**************')\n",
    "#     print(locals()[df].info())\n",
    "\n",
    "    print (df)\n",
    "    print('Grain Yield data missing for ', temp_df['GrainYield'].isna().sum(), 'out of ', temp_df.shape[0])\n",
    "# Graminor_2019_Simps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for zero values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.015539Z",
     "start_time": "2021-10-11T02:38:55.470191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2020_all_lodg Lodging 502\n",
      "Staur_2020_all_lodg Lodging 157\n"
     ]
    }
   ],
   "source": [
    "# Masbasis_2019_Simps.info(null_counts=True)\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    for col in temp_df.columns.to_list():\n",
    "        if (temp_df[col]==0).sum() >0:\n",
    "#             print(temp_df.columns.to_list())\n",
    "            print(df, col, (temp_df[col]==0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeros only present in Lodging columns where present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding yield columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.046520Z",
     "start_time": "2021-10-11T02:38:56.017533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"GrainYield\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Pedigree\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 8\n",
      "\"GrainYield\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Pedigree\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 8\n",
      "\"GrainYield\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Line\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Line\". It is located at location 8\n",
      "\"Days2Heading\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 9\n",
      "\"Days2Maturity\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 10\n",
      "\"GrainYield\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Line\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Line\". It is located at location 8\n",
      "\"Maturity_Date\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Maturity_Date\". It is located at location 9\n",
      "\"Days2Heading\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 10\n",
      "\"Days2Maturity\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 11\n",
      "\"Lodging\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Lodging\". It is located at location 12\n",
      "\"GrainYield\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"CodeName\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"CodeName\". It is located at location 8\n",
      "\"Heading_Date\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Heading_Date\". It is located at location 9\n",
      "\"Maturity_Date\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Maturity_Date\". It is located at location 10\n",
      "\"Days2Heading\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 11\n",
      "\"Days2Maturity\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 12\n",
      "\"GrainYield\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Line\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Line\". It is located at location 7\n",
      "\"Days2Heading\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 8\n",
      "\"Days2Maturity\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 9\n",
      "\"GrainYield\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Name\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Name\". It is located at location 7\n",
      "\"Pedigree\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 8\n",
      "\"Lodging\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Lodging\". It is located at location 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GrainYield_Graminor_2019_all': 6,\n",
       " 'Name_Graminor_2019_all': 7,\n",
       " 'Pedigree_Graminor_2019_all': 8,\n",
       " 'GrainYield_Graminor_2020_all': 6,\n",
       " 'Name_Graminor_2020_all': 7,\n",
       " 'Pedigree_Graminor_2020_all': 8,\n",
       " 'GrainYield_Masbasis_2019_all': 6,\n",
       " 'Name_Masbasis_2019_all': 7,\n",
       " 'Line_Masbasis_2019_all': 8,\n",
       " 'Days2Heading_Masbasis_2019_all': 9,\n",
       " 'Days2Maturity_Masbasis_2019_all': 10,\n",
       " 'GrainYield_Masbasis_2020_all_lodg': 6,\n",
       " 'Name_Masbasis_2020_all_lodg': 7,\n",
       " 'Line_Masbasis_2020_all_lodg': 8,\n",
       " 'Maturity_Date_Masbasis_2020_all_lodg': 9,\n",
       " 'Days2Heading_Masbasis_2020_all_lodg': 10,\n",
       " 'Days2Maturity_Masbasis_2020_all_lodg': 11,\n",
       " 'Lodging_Masbasis_2020_all_lodg': 12,\n",
       " 'GrainYield_Robot_2020_all': 6,\n",
       " 'Name_Robot_2020_all': 7,\n",
       " 'CodeName_Robot_2020_all': 8,\n",
       " 'Heading_Date_Robot_2020_all': 9,\n",
       " 'Maturity_Date_Robot_2020_all': 10,\n",
       " 'Days2Heading_Robot_2020_all': 11,\n",
       " 'Days2Maturity_Robot_2020_all': 12,\n",
       " 'GrainYield_Staur_2019_all': 6,\n",
       " 'Line_Staur_2019_all': 7,\n",
       " 'Days2Heading_Staur_2019_all': 8,\n",
       " 'Days2Maturity_Staur_2019_all': 9,\n",
       " 'GrainYield_Staur_2020_all_lodg': 6,\n",
       " 'Name_Staur_2020_all_lodg': 7,\n",
       " 'Pedigree_Staur_2020_all_lodg': 8,\n",
       " 'Lodging_Staur_2020_all_lodg': 9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToDo: Add check for duplicate columns in the df\n",
    "\n",
    "general_col_names = ['Plot_ID', 'Blue', 'Green', 'Red', 'RedEdge', 'NIR']\n",
    "\n",
    "base_indices = ['Blue', 'Green', 'Red', 'RedEdge', 'NIR']\n",
    "\n",
    "spectral_indices = ['NDVI', 'MTCI', 'DVI', 'GDVI', 'MTCI_CI', 'EXG', 'EXGR', 'RDVI',\n",
    "                    'TDVI', 'GNDVI', 'NDRE', 'SCCI', 'EVI', 'TVI', 'VARI', 'GARI',\n",
    "                    'GCI', 'GLI', 'NLI', 'MNLI', 'SAVI', 'GSAVI', 'OSAVI', 'GOSAVI',\n",
    "                    'MSAVI2', 'MSR', 'GRVI', 'WDRVI', 'SR']\n",
    "# list_agg_df\n",
    "yield_cols = ['GrainYield', 'Name', 'CodeName', 'Pedigree', 'Line', 'Heading_Date',\n",
    "              'Maturity_Date', 'Days2Heading', 'Days2Maturity', 'Lodging']\n",
    "\n",
    "id_cols_new = ['Plot_ID']\n",
    "\n",
    "# Counter for location of column in columns list\n",
    "\n",
    "# Dict for saving the name and location of the yield column/s\n",
    "loc_yield_cols = {}\n",
    "for df in all_df:\n",
    "    loc = 0\n",
    "    for cols in locals()[df].columns.tolist():\n",
    "        for y_col in yield_cols:\n",
    "            if not cols.find(y_col):\n",
    "                loc_yield_cols[cols+'_'+df] = loc\n",
    "                print(f'\\\"{cols}\\\" column in {df} is the yield column\\n as it contains the text \\\"{y_col}\\\". It is located at location {loc}')\n",
    "        loc += 1\n",
    "\n",
    "    yield_cols_found = list(loc_yield_cols.keys())\n",
    "    target_cols=yield_cols_found[0]\n",
    "loc_yield_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding dates between heading and maturity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.062464Z",
     "start_time": "2021-10-11T02:38:56.047504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GrainYield',\n",
       " 'Name',\n",
       " 'CodeName',\n",
       " 'Pedigree',\n",
       " 'Line',\n",
       " 'Heading_Date',\n",
       " 'Maturity_Date',\n",
       " 'Days2Heading',\n",
       " 'Days2Maturity',\n",
       " 'Lodging']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.078422Z",
     "start_time": "2021-10-11T02:38:56.064458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_all\n",
      "Masbasis_2020_all_lodg\n",
      "Robot_2020_all\n",
      "Staur_2019_all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all',\n",
       " 'Graminor_2020_all',\n",
       " 'Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all',\n",
       " 'Staur_2020_all_lodg']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    if 'Days2Maturity' in temp_df.columns:\n",
    "        print(df)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring the important dates for each field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.093413Z",
     "start_time": "2021-10-11T02:38:56.079418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dates listed in dict in order; sowing, heading, maturity\n",
    "# The order of fields must be the same as in all_df list\n",
    "# sowing_dict = {\n",
    "#     'Graminor_2019': ['240419', 'XX', 'XX'],\n",
    "#     'Graminor_2020': ['150420', 'XX', 'XX'],\n",
    "#     'Masbasis_2019': ['190519', 'XX', 'XX'],\n",
    "#     'Masbasis_2020': ['150520', 'XX', 'XX'],\n",
    "#     'Robot_2020': ['200420', '170620', '310720'],\n",
    "#     'Staur_2019': ['040619', 'XX', 'XX'],\n",
    "#     'Staur_2020': ['210420', 'XX', 'XX'],\n",
    "# }\n",
    "\n",
    "sowing_dict = {\n",
    "    'Graminor_2019': '240419',\n",
    "    'Graminor_2020': '150420',\n",
    "    'Masbasis_2019': '190519',\n",
    "    'Masbasis_2020': '150520',\n",
    "    'Robot_2020': '200420',\n",
    "    'Staur_2019': '040619',\n",
    "    'Staur_2020': '210420',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering df which have Days2Maturity and Days2Heading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.108341Z",
     "start_time": "2021-10-11T02:38:56.094378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Graminor_2019_all': '240419',\n",
       " 'Graminor_2020_all': '150420',\n",
       " 'Masbasis_2019_all': '190519',\n",
       " 'Masbasis_2020_all_lodg': '150520',\n",
       " 'Robot_2020_all': '200420',\n",
       " 'Staur_2019_all': '040619',\n",
       " 'Staur_2020_all_lodg': '210420'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the dataset had Days 2 heading and days to maturity columns then create the\n",
    "# following dictionary with the respective sowing dates of each field as value\n",
    "all_df_sowing = {}\n",
    "\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    field_temp = df.split('_')[0]+'_'+df.split('_')[1]\n",
    "#     if 'Days2Heading' in temp_df.columns and 'Days2Maturity' in temp_df.columns:\n",
    "#         print(df)\n",
    "#         all_df_sowing[df] = sowing_dict[field_temp]\n",
    "    all_df_sowing[df] = sowing_dict[field_temp]\n",
    "\n",
    "all_df_sowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average DH and DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.124314Z",
     "start_time": "2021-10-11T02:38:56.109338Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Masbasis_2019_all': [68.18939393939394, 108.64393939393939],\n",
       " 'Masbasis_2020_all_lodg': [66.28983308042488, 87.94881170018282],\n",
       " 'Robot_2020_all': [61.09375, 110.84375],\n",
       " 'Staur_2019_all': [48.53333333333333, 101.25757575757575]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary with average Days2Heading and Days2Maturity for fields whose data is available\n",
    "dict_avg_dh_dm = {}\n",
    "df_dh_dm = []\n",
    "for df in all_df_sowing.keys():\n",
    "    temp_df = locals()[df].copy()\n",
    "\n",
    "#     print('Days2Heading')\n",
    "#     print(locals()[df].Days2Heading.min(), ':      ', locals()[df].Days2Heading.max(), ':     ', locals()[df].Days2Heading.mean())\n",
    "#     print('Days2Maturity')\n",
    "#     print(locals()[df].Days2Maturity.min(), ':      ', locals()[df].Days2Maturity.max(), ':     ', locals()[df].Days2Maturity.mean())\n",
    "\n",
    "    if 'Days2Heading' in temp_df.columns and 'Days2Maturity' in temp_df.columns:\n",
    "        df_dh_dm.append(df)\n",
    "        dict_avg_dh_dm[df] = [locals()[df].Days2Heading.mean(), locals()[df].Days2Maturity.mean()]\n",
    "dict_avg_dh_dm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.140255Z",
     "start_time": "2021-10-11T02:38:56.125296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Days2Heading is 61.026577588288035\n",
      "Average Days2Maturity is 102.17351921292449\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "list_dh = []\n",
    "list_dm = []\n",
    "for field, dhdm in dict_avg_dh_dm.items():\n",
    "    list_dh.append(dhdm[0])\n",
    "    list_dm.append(dhdm[1])\n",
    "mean_dh = mean(list_dh)\n",
    "mean_dm = mean(list_dm)\n",
    "print(f'Average Days2Heading is {mean_dh}')\n",
    "print(f'Average Days2Maturity is {mean_dm}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.156213Z",
     "start_time": "2021-10-11T02:38:56.142250Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "from numpy import trapz\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from scipy.integrate import romb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.172191Z",
     "start_time": "2021-10-11T02:38:56.158211Z"
    }
   },
   "outputs": [],
   "source": [
    "# simps(temp_entries_dropna, days_sow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.188136Z",
     "start_time": "2021-10-11T02:38:56.173168Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# days_sow\n",
    "\n",
    "# days = [50, 64, 72, ((72 + 87) / 2), 87]\n",
    "# band = [21, 14, 9, ((9 + 2) / 2), 2]\n",
    "\n",
    "# days2 = [50, 64, 72, 87]\n",
    "# band2 = [21, 14, 9, 2]\n",
    "\n",
    "# simps(band, days), simps(band2, days2), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.204086Z",
     "start_time": "2021-10-11T02:38:56.190122Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp_entries_dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sahameh's Method of integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.219046Z",
     "start_time": "2021-10-11T02:38:56.207076Z"
    }
   },
   "outputs": [],
   "source": [
    "# data\n",
    "# # plot: Plot ID\n",
    "# # x: Number of days after sowing or actual date\n",
    "# # y: Value of the index\n",
    "# temp_entries, days_sow\n",
    "# # x: Days from sowing to data collection\n",
    "# # May 5 2019 Masbasis and Graminor\n",
    "# # Robot: \n",
    "\n",
    "# data={'plot':['1','1','2','2','5'],'x':temp_entries,'y':days_sow }\n",
    "\n",
    "# ACC=[]\n",
    "# A=pd.DataFrame(data, columns=['plot','x','y'])\n",
    "# AA=0\n",
    "\n",
    "# for item in range(len(A)-1):\n",
    "#     if A['plot'][item]!= A['plot'][item+1]:\n",
    "#         Ans=(float((A['y'][item]))+float((A['y'][item+1])))*((float((A['x'][item+1]))-float((A['x'][item]))))/2\n",
    "#         AA+=Ans\n",
    "#         print(AA)\n",
    "#         ACC.append(AA)\n",
    "# ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.234008Z",
     "start_time": "2021-10-11T02:38:56.221039Z"
    }
   },
   "outputs": [],
   "source": [
    "# df1=A.set_index(['Plot'])\n",
    "# ACC=[]\n",
    "\n",
    "# for item in Numbers_final:\n",
    "#     df2=df1[df1.index==item]\n",
    "#     df2=df2.filter(['X', 'Green', 'Red', 'RedEdge', 'NIR','NDVI', 'MTCI', 'EVI', 'DVI', 'RVI', 'VARI', 'EXG', 'EXGR', 'GLI', 'GNDVI', 'GVI','Time','timepoint'], axis=1)\n",
    "#     df2=df2.sort_values(by='timepoint')\n",
    "#     df3=df2.reset_index()\n",
    "\n",
    "# AA=0\n",
    "# for j in range(0,3):\n",
    "#     Ans=(float((df3['GVI'][j]))+float((df3['GVI'][j+1])))*((float((df3['timepoint'][j+1]))-float((df3['timepoint'][j]))))/2\n",
    "#     AA+=Ans\n",
    "\n",
    "#     print(AA)\n",
    "#     ACC.append(AA)\n",
    "\n",
    "\n",
    "\n",
    "# DA=pd.DataFrame(ACC)\n",
    "# DD=pd.DataFrame(Numbers_final)\n",
    "# DDA=pd.concat([DD, DA], axis=1)\n",
    "# DDA.to_excel('Staur_Accumulative_GVI_2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.249962Z",
     "start_time": "2021-10-11T02:38:56.236000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all',\n",
       " 'Graminor_2020_all',\n",
       " 'Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all',\n",
       " 'Staur_2020_all_lodg']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:38:56.265922Z",
     "start_time": "2021-10-11T02:38:56.250959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Graminor_2019_all': '240419',\n",
       " 'Graminor_2020_all': '150420',\n",
       " 'Masbasis_2019_all': '190519',\n",
       " 'Masbasis_2020_all_lodg': '150520',\n",
       " 'Robot_2020_all': '200420',\n",
       " 'Staur_2019_all': '040619',\n",
       " 'Staur_2020_all_lodg': '210420'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_sowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T03:08:05.320783Z",
     "start_time": "2021-10-11T03:08:05.302830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Masbasis_2019_all': '190519', 'Masbasis_2020_all_lodg': '150520'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_sowing_test = {\n",
    "    'Masbasis_2019_all': '190519',\n",
    "    'Masbasis_2020_all_lodg': '150520'\n",
    "}\n",
    "all_df_sowing_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating df with Plot_ID and Grain_Yield only\n",
    "## Calculating AUC and creating new df with calculated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T03:14:30.436119Z",
     "start_time": "2021-10-11T03:14:21.604602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_Simps (528, 40) Masbasis_2019_Trapz (528, 40)\n",
      "Masbasis_2020_Simps (659, 42) Masbasis_2020_Trapz (659, 42)\n"
     ]
    }
   ],
   "source": [
    "simp_df_all = []\n",
    "trapz_df_all = []\n",
    "samples_record_simps = {}\n",
    "for df, sowing in all_df_sowing_test.items():\n",
    "\n",
    "    temp_df = locals()[df].copy()\n",
    "    cols = temp_df.columns\n",
    "    \n",
    "    # Creating a list of columns which other than the indices (ID and yield columns)\n",
    "    # Making a temp list of yield columns since all entries from yield cols are not present in every df\n",
    "    temp_yield_cols = [x for x in temp_df.columns if x in yield_cols]\n",
    "    non_indices_cols = id_cols_new+temp_yield_cols\n",
    "#     print(non_indices_cols)\n",
    "    \n",
    "    df_auc_simps = temp_df[non_indices_cols].copy()\n",
    "    df_auc_trapz = temp_df[non_indices_cols].copy()\n",
    "#     display(df_auc.head())\n",
    "\n",
    "    # Calculating AUC and creating new df with calculated values\n",
    "    temp_samples = {}\n",
    "    for col_name in base_indices+spectral_indices:\n",
    "        df_simp = []\n",
    "        df_trapz = []\n",
    "        # Making temp_cols list avoids problems finding and differentiating 'OSAVI' and 'GOSAVI'\n",
    "        temp_cols = [x for x in cols if col_name.split('_') == x.split('_')[:-1]]\n",
    "        temp_dates = [datetime.datetime.strptime(date.split('_')[-1], '%d%m%y').date() for date in temp_cols]\n",
    "\n",
    "        # Calculating the days from sowing,i.e. age of the crop in days\n",
    "        sowing_date = datetime.datetime.strptime(sowing, '%d%m%y').date() \n",
    "        \n",
    "        temp_samples_list = []\n",
    "        for sample in range(temp_df.shape[0]):\n",
    "            # Number of days since sowing for each entry\n",
    "            days_sow = [(x-sowing_date).days for x in temp_dates]\n",
    "            # The respective value of the index in question \n",
    "            temp_entries = [temp_df[x][sample] for x in temp_cols]\n",
    "\n",
    "            #### DROPPING DATES OUTSIDE HEADING AND MATURITY DATES ####\n",
    "            \n",
    "            # Determining Days2Heading values\n",
    "            if 'Days2Heading' in temp_df.columns:\n",
    "                # Days to heading for current sample \n",
    "                DH = temp_df.Days2Heading[sample]\n",
    "                # If DH is missing then use the smallest of Mean DH from fields whose DH is available\n",
    "                if str(DH)=='nan':\n",
    "                    DH = round(min(list_dh))\n",
    "            else:\n",
    "                DH = round(min(list_dh))\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            if 'Days2Maturity' in temp_df.columns:\n",
    "                # Days to maturity for current sample \n",
    "                DM = temp_df.Days2Maturity[sample]\n",
    "                # If DM is missing then use the largest of Mean DM from fields whose DM is available\n",
    "                if str(DM)=='nan':\n",
    "                    DM = round(max(list_dm))\n",
    "            else:\n",
    "                DM = round(max(list_dm))  \n",
    "                    \n",
    "            DH = int(DH)\n",
    "            DM = int(DM)\n",
    "            # Making sure that the maturity comes after heading\n",
    "            if DM < DH:\n",
    "                print(DM, DH)\n",
    "            assert DM > DH\n",
    "#             print(DM, DH)\n",
    "            heading_date = sowing_date + datetime.timedelta(days=DH)\n",
    "            maturity_date = sowing_date + datetime.timedelta(days=DM)\n",
    "            \n",
    "            # Replacing the respective values of items in temp_entries with np.nan which correspond \n",
    "            # to dates not in between heading and maturity for that specific sub-plot\n",
    "            temp_entries_filtered = [y if heading_date <= x <= maturity_date else np.nan for x,y in zip(temp_dates, temp_entries)]\n",
    "            \n",
    "            # Dropping missing(nan) values from the entries\n",
    "            temp_entries_dropna = [x for x in temp_entries_filtered if str(x) != 'nan']\n",
    "            days_before = days_sow.copy()\n",
    "            # Checking if the number of items in temp_entries_filtered and days_sow is the same\n",
    "            # If not, i.e., there are missing values(nan) in temp_entries_filtered then drop the\n",
    "            # respective entries from days_sow list\n",
    "            if not len(temp_entries_dropna) == len(days_sow):\n",
    "                # Dictionary comprehension\n",
    "                # Creating dictionary(dict comprehension) where temp_entries_filtered are not nan\n",
    "                dict_dropna = {i: [temp_entries_filtered[i], days_sow[i]] for i in range(len(temp_entries_filtered))\\\n",
    "                       if not str(temp_entries_filtered[i]) == 'nan' }\n",
    "                \n",
    "                # Checking if the previously created temp_entries_dropna is the same as the new that will\n",
    "                # be created from dict_dropna (Unnecessary check but curious to check if any problems arise)\n",
    "                assert temp_entries_dropna == [dict_dropna[i][0] for i in dict_dropna.keys()]\n",
    "                \n",
    "                # Creating new temp entries and days_sow after dropping nan and respective entries in days_sow\n",
    "                temp_entries_dropna = [dict_dropna[i][0] for i in dict_dropna.keys()]\n",
    "                days_sow = [dict_dropna[i][1] for i in dict_dropna.keys()]\n",
    "\n",
    "            # Checking if the lists have the same number of entries\n",
    "            if len(temp_entries_dropna) != len(days_sow):\n",
    "                print(df, col_name, temp_entries, days_before, temp_entries_dropna, days_sow, dict_dropna)\n",
    "            assert len(temp_entries_dropna) == len(days_sow)\n",
    "            \n",
    "            simps_value = simps(temp_entries_dropna, days_sow)\n",
    "            trapz_value = trapz(temp_entries_dropna, days_sow)\n",
    "            \n",
    "            df_simp.append(simps_value)\n",
    "            df_trapz.append(trapz_value)\n",
    "            \n",
    "#             if simps_value == 0:\n",
    "#                 print(temp_entries_filtered, days_before, temp_entries_dropna, days_sow)\n",
    "            # Adding values to a list for reference and record to verify the results and identify problems later\n",
    "            temp_samples_list.append([temp_df['Plot_ID'][sample], simps_value, trapz_value, temp_cols, temp_dates, sowing_date, DH, DM, heading_date, maturity_date, temp_entries, days_before, temp_entries_dropna, days_sow])\n",
    "        temp_samples[col_name] = temp_samples_list\n",
    "\n",
    "        # Insert the new column at the end, but before GrainYield\n",
    "        df_auc_simps.insert(len(df_auc_simps.columns)-1, col_name, df_simp)\n",
    "        df_auc_trapz.insert(len(df_auc_trapz.columns)-1, col_name, df_trapz)\n",
    "        \n",
    "    samples_record_simps[df.split('_')[0]+'_'+df.split('_')[1]] = temp_samples\n",
    "\n",
    "    # Adding the new name of the df to a list named simp_df_all\n",
    "    simp_df = df.split('_')[0]+'_'+df.split('_')[1]+'_Simps'\n",
    "    trapz_df = df.split('_')[0]+'_'+df.split('_')[1]+'_Trapz'\n",
    "\n",
    "    simp_df_all.append(simp_df)\n",
    "    trapz_df_all.append(trapz_df)\n",
    "    print(simp_df, df_auc_simps.shape, trapz_df, df_auc_trapz.shape)\n",
    "    locals()[simp_df] = df_auc_simps.copy()\n",
    "    locals()[trapz_df] = df_auc_trapz.copy()\n",
    "# simp_df_all, trapz_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for Zero values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T03:14:34.614039Z",
     "start_time": "2021-10-11T03:14:34.491941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_Simps Blue 19\n",
      "Masbasis_2019_Simps Green 19\n",
      "Masbasis_2019_Simps Red 19\n",
      "Masbasis_2019_Simps RedEdge 19\n",
      "Masbasis_2019_Simps NIR 19\n",
      "Masbasis_2019_Simps NDVI 19\n",
      "Masbasis_2019_Simps MTCI 19\n",
      "Masbasis_2019_Simps DVI 19\n",
      "Masbasis_2019_Simps GDVI 19\n",
      "Masbasis_2019_Simps MTCI_CI 19\n",
      "Masbasis_2019_Simps EXG 19\n",
      "Masbasis_2019_Simps EXGR 19\n",
      "Masbasis_2019_Simps RDVI 19\n",
      "Masbasis_2019_Simps TDVI 19\n",
      "Masbasis_2019_Simps GNDVI 19\n",
      "Masbasis_2019_Simps NDRE 19\n",
      "Masbasis_2019_Simps SCCI 19\n",
      "Masbasis_2019_Simps EVI 19\n",
      "Masbasis_2019_Simps TVI 19\n",
      "Masbasis_2019_Simps VARI 19\n",
      "Masbasis_2019_Simps GARI 19\n",
      "Masbasis_2019_Simps GCI 19\n",
      "Masbasis_2019_Simps GLI 19\n",
      "Masbasis_2019_Simps NLI 19\n",
      "Masbasis_2019_Simps MNLI 19\n",
      "Masbasis_2019_Simps SAVI 19\n",
      "Masbasis_2019_Simps GSAVI 19\n",
      "Masbasis_2019_Simps OSAVI 19\n",
      "Masbasis_2019_Simps GOSAVI 19\n",
      "Masbasis_2019_Simps MSAVI2 19\n",
      "Masbasis_2019_Simps MSR 19\n",
      "Masbasis_2019_Simps GRVI 19\n",
      "Masbasis_2019_Simps WDRVI 19\n",
      "Masbasis_2019_Simps SR 19\n",
      "Masbasis_2020_Simps Blue 1\n",
      "Masbasis_2020_Simps Green 1\n",
      "Masbasis_2020_Simps Red 1\n",
      "Masbasis_2020_Simps RedEdge 1\n",
      "Masbasis_2020_Simps NIR 1\n",
      "Masbasis_2020_Simps NDVI 1\n",
      "Masbasis_2020_Simps MTCI 1\n",
      "Masbasis_2020_Simps DVI 1\n",
      "Masbasis_2020_Simps GDVI 1\n",
      "Masbasis_2020_Simps MTCI_CI 1\n",
      "Masbasis_2020_Simps EXG 1\n",
      "Masbasis_2020_Simps EXGR 1\n",
      "Masbasis_2020_Simps RDVI 1\n",
      "Masbasis_2020_Simps TDVI 1\n",
      "Masbasis_2020_Simps GNDVI 1\n",
      "Masbasis_2020_Simps NDRE 1\n",
      "Masbasis_2020_Simps SCCI 1\n",
      "Masbasis_2020_Simps EVI 1\n",
      "Masbasis_2020_Simps TVI 1\n",
      "Masbasis_2020_Simps VARI 1\n",
      "Masbasis_2020_Simps GARI 1\n",
      "Masbasis_2020_Simps GCI 1\n",
      "Masbasis_2020_Simps GLI 1\n",
      "Masbasis_2020_Simps NLI 1\n",
      "Masbasis_2020_Simps MNLI 1\n",
      "Masbasis_2020_Simps SAVI 1\n",
      "Masbasis_2020_Simps GSAVI 1\n",
      "Masbasis_2020_Simps OSAVI 1\n",
      "Masbasis_2020_Simps GOSAVI 1\n",
      "Masbasis_2020_Simps MSAVI2 1\n",
      "Masbasis_2020_Simps MSR 1\n",
      "Masbasis_2020_Simps GRVI 1\n",
      "Masbasis_2020_Simps WDRVI 1\n",
      "Masbasis_2020_Simps SR 1\n",
      "Masbasis_2019_Trapz Blue 19\n",
      "Masbasis_2019_Trapz Green 19\n",
      "Masbasis_2019_Trapz Red 19\n",
      "Masbasis_2019_Trapz RedEdge 19\n",
      "Masbasis_2019_Trapz NIR 19\n",
      "Masbasis_2019_Trapz NDVI 19\n",
      "Masbasis_2019_Trapz MTCI 19\n",
      "Masbasis_2019_Trapz DVI 19\n",
      "Masbasis_2019_Trapz GDVI 19\n",
      "Masbasis_2019_Trapz MTCI_CI 19\n",
      "Masbasis_2019_Trapz EXG 19\n",
      "Masbasis_2019_Trapz EXGR 19\n",
      "Masbasis_2019_Trapz RDVI 19\n",
      "Masbasis_2019_Trapz TDVI 19\n",
      "Masbasis_2019_Trapz GNDVI 19\n",
      "Masbasis_2019_Trapz NDRE 19\n",
      "Masbasis_2019_Trapz SCCI 19\n",
      "Masbasis_2019_Trapz EVI 19\n",
      "Masbasis_2019_Trapz TVI 19\n",
      "Masbasis_2019_Trapz VARI 19\n",
      "Masbasis_2019_Trapz GARI 19\n",
      "Masbasis_2019_Trapz GCI 19\n",
      "Masbasis_2019_Trapz GLI 19\n",
      "Masbasis_2019_Trapz NLI 19\n",
      "Masbasis_2019_Trapz MNLI 19\n",
      "Masbasis_2019_Trapz SAVI 19\n",
      "Masbasis_2019_Trapz GSAVI 19\n",
      "Masbasis_2019_Trapz OSAVI 19\n",
      "Masbasis_2019_Trapz GOSAVI 19\n",
      "Masbasis_2019_Trapz MSAVI2 19\n",
      "Masbasis_2019_Trapz MSR 19\n",
      "Masbasis_2019_Trapz GRVI 19\n",
      "Masbasis_2019_Trapz WDRVI 19\n",
      "Masbasis_2019_Trapz SR 19\n",
      "Masbasis_2020_Trapz Blue 1\n",
      "Masbasis_2020_Trapz Green 1\n",
      "Masbasis_2020_Trapz Red 1\n",
      "Masbasis_2020_Trapz RedEdge 1\n",
      "Masbasis_2020_Trapz NIR 1\n",
      "Masbasis_2020_Trapz NDVI 1\n",
      "Masbasis_2020_Trapz MTCI 1\n",
      "Masbasis_2020_Trapz DVI 1\n",
      "Masbasis_2020_Trapz GDVI 1\n",
      "Masbasis_2020_Trapz MTCI_CI 1\n",
      "Masbasis_2020_Trapz EXG 1\n",
      "Masbasis_2020_Trapz EXGR 1\n",
      "Masbasis_2020_Trapz RDVI 1\n",
      "Masbasis_2020_Trapz TDVI 1\n",
      "Masbasis_2020_Trapz GNDVI 1\n",
      "Masbasis_2020_Trapz NDRE 1\n",
      "Masbasis_2020_Trapz SCCI 1\n",
      "Masbasis_2020_Trapz EVI 1\n",
      "Masbasis_2020_Trapz TVI 1\n",
      "Masbasis_2020_Trapz VARI 1\n",
      "Masbasis_2020_Trapz GARI 1\n",
      "Masbasis_2020_Trapz GCI 1\n",
      "Masbasis_2020_Trapz GLI 1\n",
      "Masbasis_2020_Trapz NLI 1\n",
      "Masbasis_2020_Trapz MNLI 1\n",
      "Masbasis_2020_Trapz SAVI 1\n",
      "Masbasis_2020_Trapz GSAVI 1\n",
      "Masbasis_2020_Trapz OSAVI 1\n",
      "Masbasis_2020_Trapz GOSAVI 1\n",
      "Masbasis_2020_Trapz MSAVI2 1\n",
      "Masbasis_2020_Trapz MSR 1\n",
      "Masbasis_2020_Trapz GRVI 1\n",
      "Masbasis_2020_Trapz WDRVI 1\n",
      "Masbasis_2020_Trapz SR 1\n"
     ]
    }
   ],
   "source": [
    "# Masbasis_2019_Simps.info(null_counts=True)\n",
    "for df in simp_df_all+trapz_df_all:\n",
    "    temp_df = locals()[df][base_indices+spectral_indices].copy()\n",
    "    for col in temp_df.columns.to_list():\n",
    "        if (temp_df[col]==0).sum() >0:\n",
    "#             print(temp_df.columns.to_list())\n",
    "            print(df, col, (temp_df[col]==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T03:27:23.027349Z",
     "start_time": "2021-10-11T03:27:22.921621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Blue', 'Green', 'Red', 'RedEdge', 'NIR', 'NDVI', 'MTCI', 'DVI', 'GDVI', 'MTCI_CI', 'EXG', 'EXGR', 'RDVI', 'TDVI', 'GNDVI', 'NDRE', 'SCCI', 'EVI', 'TVI', 'VARI', 'GARI', 'GCI', 'GLI', 'NLI', 'MNLI', 'SAVI', 'GSAVI', 'OSAVI', 'GOSAVI', 'MSAVI2', 'MSR', 'GRVI', 'WDRVI', 'SR'])\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n",
      "1230 2019-05-19\n",
      "1239 2019-05-19\n",
      "1263 2019-05-19\n",
      "1327 2019-05-19\n",
      "1358 2019-05-19\n",
      "1365 2019-05-19\n",
      "1427 2019-05-19\n",
      "1515 2019-05-19\n",
      "1611 2019-05-19\n",
      "1650 2019-05-19\n",
      "1651 2019-05-19\n",
      "1655 2019-05-19\n",
      "1656 2019-05-19\n",
      "1658 2019-05-19\n",
      "1708 2019-05-19\n",
      "1759 2019-05-19\n",
      "1810 2019-05-19\n",
      "1827 2019-05-19\n",
      "1847 2019-05-19\n"
     ]
    }
   ],
   "source": [
    "# Plot_ID, simps_value, trapz_value, temp_cols, temp_dates, sowing_date, DH, DM, heading_date, maturity_date, temp_entries, days_before, temp_entries_dropna, days_sow])\n",
    "\n",
    "list_problem = []\n",
    "pprint(samples_record_simps['Masbasis_2019'].keys())\n",
    "for keya, data in samples_record_simps['Masbasis_2019'].items():\n",
    "    for x in data:\n",
    "        if x [1]==0:\n",
    "            print(x[0], x[5])\n",
    "#             print(x)\n",
    "            list_problem.append(x[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T03:29:19.122441Z",
     "start_time": "2021-10-11T03:29:19.111470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2019, 5, 19),\n",
       " 69,\n",
       " 112,\n",
       " datetime.date(2019, 7, 27),\n",
       " datetime.date(2019, 9, 8),\n",
       " [datetime.date(2019, 8, 7),\n",
       "  datetime.date(2019, 7, 29),\n",
       "  datetime.date(2019, 7, 22),\n",
       "  datetime.date(2019, 7, 15),\n",
       "  datetime.date(2019, 7, 5),\n",
       "  datetime.date(2019, 6, 28),\n",
       "  datetime.date(2019, 6, 26),\n",
       "  datetime.date(2019, 6, 6)])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_entries = x[10]\n",
    "days_sow = x[11]\n",
    "simps(xx,dd)\n",
    "sowing_date = x[5]\n",
    "DH = x[6]\n",
    "DM = x[7]\n",
    "# temp_cols = x[10]\n",
    "\n",
    "temp_dates = x[4]\n",
    "heading_date= x[8]\n",
    "maturity_date = x[9]\n",
    "temp_entries_filtered = [y if heading_date <= x <= maturity_date else np.nan for x,y in zip(temp_dates, temp_entries)]\n",
    "temp_entries_filtered\n",
    "# \n",
    "sowing_date, DH, DM, heading_date, maturity_date, temp_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T03:28:44.435601Z",
     "start_time": "2021-10-11T03:28:44.424627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.888522761915658,\n",
       " 12.669300691123034,\n",
       " 24.855834054335432,\n",
       " 15.733699946397245,\n",
       " 39.894317188245374,\n",
       " 25.613389954447552,\n",
       " 22.69891356388166,\n",
       " 6.156171509754077]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T03:14:40.433295Z",
     "start_time": "2021-10-11T03:14:40.411354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_070819</th>\n",
       "      <th>Blue_290719</th>\n",
       "      <th>Blue_220719</th>\n",
       "      <th>Blue_150719</th>\n",
       "      <th>Blue_050719</th>\n",
       "      <th>Blue_280619</th>\n",
       "      <th>Blue_260619</th>\n",
       "      <th>Blue_060619</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.027306</td>\n",
       "      <td>0.016146</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.023842</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.024337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Blue_070819  Blue_290719  Blue_220719  Blue_150719  Blue_050719  \\\n",
       "95     0.027306     0.016146     0.014434     0.023842     0.009863   \n",
       "\n",
       "    Blue_280619  Blue_260619  Blue_060619  \n",
       "95     0.015405     0.021012     0.024337  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blu_cols = [x for x in Masbasis_2019_all.columns if 'Blue' in x]\n",
    "\n",
    "Masbasis_2019_all['Plot_ID']\n",
    "Masbasis_2019_all.iloc[95:96,:][blu_cols]\n",
    "\n",
    "# list_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T03:14:41.466407Z",
     "start_time": "2021-10-11T03:14:41.221090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>Blue_070819</th>\n",
       "      <th>Blue_290719</th>\n",
       "      <th>Blue_220719</th>\n",
       "      <th>Blue_150719</th>\n",
       "      <th>Blue_050719</th>\n",
       "      <th>Blue_280619</th>\n",
       "      <th>Blue_260619</th>\n",
       "      <th>Blue_060619</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1230</td>\n",
       "      <td>0.027306</td>\n",
       "      <td>0.016146</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.023842</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.024337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1239</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>0.028146</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.019248</td>\n",
       "      <td>0.025816</td>\n",
       "      <td>0.028921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1263</td>\n",
       "      <td>0.023095</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>0.032513</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>0.030060</td>\n",
       "      <td>0.034576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1327</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.015360</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>0.024240</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>0.017926</td>\n",
       "      <td>0.024122</td>\n",
       "      <td>0.024535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1358</td>\n",
       "      <td>0.021469</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.013210</td>\n",
       "      <td>0.035064</td>\n",
       "      <td>0.018151</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>0.030716</td>\n",
       "      <td>0.040643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1708</td>\n",
       "      <td>0.026613</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>0.025384</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>0.016434</td>\n",
       "      <td>0.025196</td>\n",
       "      <td>0.025509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1759</td>\n",
       "      <td>0.025247</td>\n",
       "      <td>0.018615</td>\n",
       "      <td>0.014826</td>\n",
       "      <td>0.034066</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>0.039553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1810</td>\n",
       "      <td>0.027780</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>0.016675</td>\n",
       "      <td>0.028434</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>0.021508</td>\n",
       "      <td>0.030092</td>\n",
       "      <td>0.029373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1827</td>\n",
       "      <td>0.022435</td>\n",
       "      <td>0.018452</td>\n",
       "      <td>0.014112</td>\n",
       "      <td>0.026933</td>\n",
       "      <td>0.016467</td>\n",
       "      <td>0.023138</td>\n",
       "      <td>0.031967</td>\n",
       "      <td>0.027474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1847</td>\n",
       "      <td>0.025904</td>\n",
       "      <td>0.018947</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.031060</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.025564</td>\n",
       "      <td>0.036066</td>\n",
       "      <td>0.033788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>646 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Plot_ID  Blue_070819  Blue_290719  Blue_220719  Blue_150719  Blue_050719  \\\n",
       "95      1230     0.027306     0.016146     0.014434     0.023842     0.009863   \n",
       "104     1239     0.025600     0.015743     0.014608     0.028146     0.013328   \n",
       "128     1263     0.023095     0.018011     0.015735     0.032513     0.016847   \n",
       "158     1327     0.021836     0.015360     0.012360     0.024240     0.016347   \n",
       "189     1358     0.021469     0.014657     0.013210     0.035064     0.018151   \n",
       "..       ...          ...          ...          ...          ...          ...   \n",
       "403     1708     0.026613     0.020416     0.014928     0.025384     0.012373   \n",
       "454     1759     0.025247     0.018615     0.014826     0.034066     0.014901   \n",
       "471     1810     0.027780     0.022841     0.016675     0.028434     0.014408   \n",
       "488     1827     0.022435     0.018452     0.014112     0.026933     0.016467   \n",
       "508     1847     0.025904     0.018947     0.014390     0.031060     0.014940   \n",
       "\n",
       "     Blue_280619  Blue_260619  Blue_060619  \n",
       "95      0.015405     0.021012     0.024337  \n",
       "104     0.019248     0.025816     0.028921  \n",
       "128     0.021034     0.030060     0.034576  \n",
       "158     0.017926     0.024122     0.024535  \n",
       "189     0.022021     0.030716     0.040643  \n",
       "..           ...          ...          ...  \n",
       "403     0.016434     0.025196     0.025509  \n",
       "454     0.023356     0.033556     0.039553  \n",
       "471     0.021508     0.030092     0.029373  \n",
       "488     0.023138     0.031967     0.027474  \n",
       "508     0.025564     0.036066     0.033788  \n",
       "\n",
       "[646 rows x 9 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_found = []\n",
    "for x in list_problem:\n",
    "    idx_found.append(int(Masbasis_2019_all[Masbasis_2019_all['Plot_ID']==x].index.values))\n",
    "#     print()\n",
    "Masbasis_2019_all.iloc[idx_found,:][['Plot_ID']+blu_cols]\n",
    "# idx_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T03:04:04.822072Z",
     "start_time": "2021-10-11T03:04:04.803613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['Plot_ID']==x\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:41:59.810129Z",
     "start_time": "2021-10-11T00:41:59.796167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dh_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:41:59.841046Z",
     "start_time": "2021-10-11T00:41:59.811129Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps\n",
      "Grain Yield data missing for  1 out of  600\n",
      "Graminor_2020_Simps\n",
      "Grain Yield data missing for  1 out of  800\n",
      "Masbasis_2019_Simps\n",
      "Grain Yield data missing for  6 out of  528\n",
      "Masbasis_2020_Simps\n",
      "Grain Yield data missing for  116 out of  659\n",
      "Robot_2020_Simps\n",
      "Grain Yield data missing for  0 out of  96\n",
      "Staur_2019_Simps\n",
      "Grain Yield data missing for  0 out of  1328\n",
      "Staur_2020_Simps\n",
      "Grain Yield data missing for  568 out of  1504\n"
     ]
    }
   ],
   "source": [
    "# Masbasis_2019_Simps.info(null_counts=True)\n",
    "for df in simp_df_all:\n",
    "    temp_df = locals()[df].copy()\n",
    "#     print('*************', df, '**************')\n",
    "#     print(locals()[df].info())\n",
    "\n",
    "    print (df)\n",
    "    print('Grain Yield data missing for ', temp_df['GrainYield'].isna().sum(), 'out of ', temp_df.shape[0])\n",
    "# Graminor_2019_Simps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T23:35:44.442995Z",
     "start_time": "2021-10-10T23:35:44.424577Z"
    }
   },
   "source": [
    "Yield data of Staur 2020 is disjoint with the banda data. There are 568 subplots whose yield is not available in the yield file and there are 10 subplots in the yield data which are not in the bands data sheets.\n",
    "\n",
    "\n",
    "There are atleast 116 missing grain yield values in Msbasis 2020 yield dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:41:59.902880Z",
     "start_time": "2021-10-11T00:41:59.842043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps Dropped entries 0 : 600 600\n",
      "Graminor_2020_Simps Dropped entries 0 : 800 800\n",
      "Masbasis_2019_Simps Dropped entries 0 : 528 528\n",
      "Masbasis_2020_Simps Dropped entries 0 : 659 659\n",
      "Robot_2020_Simps Dropped entries 0 : 96 96\n",
      "Staur_2019_Simps Dropped entries 0 : 1328 1328\n",
      "Staur_2020_Simps Dropped entries 0 : 1504 1504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Simps_dropna',\n",
       " 'Graminor_2020_Simps_dropna',\n",
       " 'Masbasis_2019_Simps_dropna',\n",
       " 'Masbasis_2020_Simps_dropna',\n",
       " 'Robot_2020_Simps_dropna',\n",
       " 'Staur_2019_Simps_dropna',\n",
       " 'Staur_2020_Simps_dropna']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp_df_all_dropna = []\n",
    "for df in simp_df_all:\n",
    "    temp_df = locals()[df].copy()\n",
    "    rows = temp_df.shape[0]\n",
    "#     print(temp_df.shape)\n",
    "    temp_df.dropna(subset=['Blue'],inplace = True)\n",
    "    print(df, 'Dropped entries', rows- temp_df.shape[0],':', rows, temp_df.shape[0])\n",
    "    new_df = df+'_dropna'\n",
    "    locals()[new_df] = temp_df.copy()\n",
    "    simp_df_all_dropna.append(new_df)\n",
    "simp_df_all_dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:41:59.950753Z",
     "start_time": "2021-10-11T00:41:59.903878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Trapz Dropped entries 0 : 600 600\n",
      "Graminor_2020_Trapz Dropped entries 0 : 800 800\n",
      "Masbasis_2019_Trapz Dropped entries 0 : 528 528\n",
      "Masbasis_2020_Trapz Dropped entries 0 : 659 659\n",
      "Robot_2020_Trapz Dropped entries 0 : 96 96\n",
      "Staur_2019_Trapz Dropped entries 0 : 1328 1328\n",
      "Staur_2020_Trapz Dropped entries 0 : 1504 1504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Trapz_dropna',\n",
       " 'Graminor_2020_Trapz_dropna',\n",
       " 'Masbasis_2019_Trapz_dropna',\n",
       " 'Masbasis_2020_Trapz_dropna',\n",
       " 'Robot_2020_Trapz_dropna',\n",
       " 'Staur_2019_Trapz_dropna',\n",
       " 'Staur_2020_Trapz_dropna']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trapz_df_all_dropna = []\n",
    "for df in trapz_df_all:\n",
    "    temp_df = locals()[df].copy()\n",
    "    rows = temp_df.shape[0]\n",
    "#     print(temp_df.shape)\n",
    "    temp_df.dropna(subset=['Blue'],inplace = True)\n",
    "    print(df, 'Dropped entries', rows- temp_df.shape[0],':', rows, temp_df.shape[0])\n",
    "    new_df = df+'_dropna'\n",
    "    locals()[new_df] = temp_df.copy()\n",
    "    trapz_df_all_dropna.append(new_df)\n",
    "trapz_df_all_dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old:  \n",
    "Masbasis_2019_Trapz Dropped entries 0 : 528 528  \n",
    "Masbasis_2020_Trapz Dropped entries 112 : 659 547  \n",
    "Robot_2020_Trapz Dropped entries 0 : 96 96  \n",
    "Staur_2019_Trapz Dropped entries 1166 : 1328 162  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:00.357663Z",
     "start_time": "2021-10-11T00:41:59.951750Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2020_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2020_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot_2020_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_2019_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_2020_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2020_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2020_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot_2020_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_2019_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_2020_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def describe_nan(df):\n",
    "    return pd.DataFrame([(i, df[df[i].isna()].shape[0],df[df[i].isna()].shape[0]/df.shape[0]) for i in df.columns], columns=['column', 'nan_counts', 'nan_rate'])\n",
    "for df in simp_df_all_dropna+trapz_df_all_dropna:\n",
    "    print(df)\n",
    "    display(describe_nan(locals()[df][base_indices+spectral_indices+['GrainYield']]).nan_counts.sum())\n",
    "#     display(describe_nan(locals()[df][base_indices+spectral_indices+['GrainYield']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp: Exporting data to be used for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:00.482813Z",
     "start_time": "2021-10-11T00:42:00.360655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time measured', 'Middeltemperatur i 2m hyde (TM)',\n",
       "       'Maksimum lufttemperatur i 2m hyde (TX)',\n",
       "       'Minimums lufttemperatur i 2m hyde (TN)', 'Nedbr (RR)',\n",
       "       'Relativ luftfuktighet i 2m', 'Relativ luftfuktighet i 2m.1',\n",
       "       ' siste minuttverdi (UU)', 'Bladfuktighet i 2m hyde (BT)',\n",
       "       ' 10 min glidende middel (FF2)', ' 5 sek middel', ' vindkast (FG2)',\n",
       "       'Vindhastighet i 2m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = pd.read_csv(weather_data)\n",
    "\n",
    "# Converting date time to python datetime\n",
    "weather['Time measured'] = pd.to_datetime(weather['Time measured'], infer_datetime_format=True)\n",
    "# weather['Time measured'] = weather['Time measured'].dt.normalize()\n",
    "\n",
    "# Removing timezone info from datetime sice other date data is without timezone info\n",
    "weather['Time measured'] = pd.Series(x.replace(tzinfo=None) for x in weather['Time measured'])\n",
    "\n",
    "weather.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:00.498768Z",
     "start_time": "2021-10-11T00:42:00.485804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Translated the column heading using google translate\n",
    "\n",
    "weather.columns = ['Time measured', 'Average temperature at 2m altitude (TM)',\n",
    " 'Maximum air temperature at 2m altitude (TX)',\n",
    " 'Minimum air temperature at 2m altitude (TN)', 'Precipitation (RR)',\n",
    " 'Relative humidity in 2m', 'Relative humidity in 2m.1',\n",
    " 'last minute value (UU)', 'Leaf moisture at 2m height (BT)',\n",
    " '10 min lubricant (FF2)', '5 sec medium', 'gusts of wind (FG2)',\n",
    " 'Wind speed in 2m']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:00.514094Z",
     "start_time": "2021-10-11T00:42:00.501129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2019-04-01\n",
       "1     2019-04-02\n",
       "2     2019-04-03\n",
       "3     2019-04-04\n",
       "4     2019-04-05\n",
       "         ...    \n",
       "540   2020-09-26\n",
       "541   2020-09-27\n",
       "542   2020-09-28\n",
       "543   2020-09-29\n",
       "544   2020-09-30\n",
       "Name: Time measured, Length: 545, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['Time measured']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Craeting a list of min and max date in every field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:00.545016Z",
     "start_time": "2021-10-11T00:42:00.516089Z"
    }
   },
   "outputs": [],
   "source": [
    "max_min_dates = {}\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    dates = [x.split('_')[1] for x in temp_df.columns if 'Blue' in x]\n",
    "    df_name_temp = df.split('_')[0]+'_'+df.split('_')[1]\n",
    "    sowing_date_temp = datetime.datetime.strptime(sowing_dict[df_name_temp], '%d%m%y')\n",
    "    min_date_temp = min([datetime.datetime.strptime(x, '%d%m%y') for x in dates ])\n",
    "    max_date_temp = max([datetime.datetime.strptime(x, '%d%m%y') for x in dates ])\n",
    "    max_min_dates[df] = [sowing_date_temp, min_date_temp, max_date_temp]\n",
    "# max_min_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T23:34:52.239619Z",
     "start_time": "2021-10-06T23:34:52.233535Z"
    }
   },
   "source": [
    "## Calculating average DH and DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:00.559972Z",
     "start_time": "2021-10-11T00:42:00.548006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Masbasis_2019_all': [68.18939393939394, 108.64393939393939],\n",
       " 'Masbasis_2020_all_lodg': [66.28983308042488, 87.94881170018282],\n",
       " 'Robot_2020_all': [61.09375, 110.84375],\n",
       " 'Staur_2019_all': [48.53333333333333, 101.25757575757575]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_avg_dh_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:00.574903Z",
     "start_time": "2021-10-11T00:42:00.564962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Days2Heading is 61.026577588288035\n",
      "Average Days2Maturity is 102.17351921292449\n"
     ]
    }
   ],
   "source": [
    "print(f'Average Days2Heading is {mean_dh}')\n",
    "print(f'Average Days2Maturity is {mean_dm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:00.918489Z",
     "start_time": "2021-10-11T00:42:00.578370Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_weather_agg',\n",
       " 'Graminor_2020_weather_agg',\n",
       " 'Masbasis_2019_weather_agg',\n",
       " 'Masbasis_2020_weather_agg',\n",
       " 'Robot_2020_weather_agg',\n",
       " 'Staur_2019_weather_agg',\n",
       " 'Staur_2020_weather_agg']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weather data for days from sowing date. Largerst of the average number of Days2Maturity \n",
    "# is a good measaure to use\n",
    "# Could have used max_date(last date availabel for the field) but that date does not \n",
    "# correspond to the actual crop maturity.\n",
    "# So using approxipame maturity time is a better measure of the affect of weather on yield\n",
    "days_delta = max(list_dm)\n",
    "\n",
    "weather_dfs = []\n",
    "weathers_processed_df = []\n",
    "for df, dates in max_min_dates.items():\n",
    "    df_weather_temp = pd.DataFrame()\n",
    "\n",
    "    sowing_date_temp = dates[0]\n",
    "    min_date_temp = dates[1]\n",
    "    max_date_temp = dates[2]\n",
    "    \n",
    "    # Filtering the weather date from sowing_date to max_date the data is available for\n",
    "    temp_weather = weather.loc[(weather['Time measured'] >= sowing_date_temp) &\\\n",
    "                          (weather['Time measured'] <= sowing_date_temp + datetime.timedelta(days=days_delta))]\n",
    "\n",
    "#     print(df, sowing_date_temp.date(), min_date_temp.date(), max_date_temp.date())\n",
    "#     print(temp_weather.shape)\n",
    "\n",
    "#     # See info to find hoe many missing values and in which column\n",
    "#     display(temp_weather.info())\n",
    "\n",
    "    # Filling themissing values with the average of the column\n",
    "    # Applying Only on columns with NaN values\n",
    "    for i in temp_weather.columns[temp_weather.isnull().any(axis=0)]:\n",
    "        temp_weather[i].fillna(temp_weather[i].mean(),inplace=True)\n",
    "    # Drop the time measures column\n",
    "    temp_weather.drop(['Time measured'], axis=1, inplace=True)\n",
    "    \n",
    "    df_weat_temp = df.split('_')[0]+'_'+df.split('_')[1]+'_weather_all'\n",
    "    locals()[df_name_temp] = temp_weather.copy()\n",
    "    weather_dfs.append(df_name_temp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Aggregating the weather data using several statistical methods\n",
    "    mean_df = temp_weather.mean().to_frame().transpose().add_prefix('MEAN ')\n",
    "    median_df = temp_weather.median().to_frame().transpose().add_prefix('MEDIAN ')\n",
    "    # Different for mode since mode returns a df, instead of series object\n",
    "    mode_df = temp_weather.mode().transpose().iloc[:,0].to_frame().transpose().add_prefix('MODE ')\n",
    "    sum_df = temp_weather.sum().to_frame().transpose().add_prefix('SUM ')\n",
    "    min_df = temp_weather.min().to_frame().transpose().add_prefix('MIN ')\n",
    "    max_df = temp_weather.max().to_frame().transpose().add_prefix('MAX ')\n",
    "    std_df = temp_weather.std().to_frame().transpose().add_prefix('STD_DEV ')\n",
    "    # Reset index in quantile since it takes quantile of index as well\n",
    "    quantile_25 = temp_weather.quantile(q=0.25).to_frame().transpose().add_prefix('QUANTILE_25 ').reset_index(drop=True)\n",
    "    quantile_50 = temp_weather.quantile(q=0.5).to_frame().transpose().add_prefix('QUANTILE_50 ').reset_index(drop=True)\n",
    "    quantile_75 = temp_weather.quantile(q=0.75).to_frame().transpose().add_prefix('QUANTILE_75 ').reset_index(drop=True)\n",
    "\n",
    "    single_row_df = pd.concat([mean_df, median_df, mode_df, sum_df, min_df, max_df, std_df, quantile_25, quantile_50, quantile_75], axis=1)\n",
    "        \n",
    "#     display(single_row_df)\n",
    "\n",
    "    df_processed_temp = df.split('_')[0]+'_'+df.split('_')[1]+'_weather_agg'\n",
    "    locals()[df_processed_temp] = single_row_df.copy()\n",
    "    weathers_processed_df.append(df_processed_temp)\n",
    "weathers_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:00.964837Z",
     "start_time": "2021-10-11T00:42:00.920473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average temperature at 2m altitude (TM)</th>\n",
       "      <th>Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>Precipitation (RR)</th>\n",
       "      <th>Relative humidity in 2m</th>\n",
       "      <th>Relative humidity in 2m.1</th>\n",
       "      <th>last minute value (UU)</th>\n",
       "      <th>Leaf moisture at 2m height (BT)</th>\n",
       "      <th>10 min lubricant (FF2)</th>\n",
       "      <th>5 sec medium</th>\n",
       "      <th>gusts of wind (FG2)</th>\n",
       "      <th>Wind speed in 2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>11.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>83.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>12.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>84.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>11.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>88.9</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>8.9</td>\n",
       "      <td>13.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>8.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>72.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>13.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>93.7</td>\n",
       "      <td>97.8</td>\n",
       "      <td>830</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>15.1</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>17.4</td>\n",
       "      <td>22.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.4</td>\n",
       "      <td>98.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2.2</td>\n",
       "      <td>12.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>18.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.3</td>\n",
       "      <td>99.8</td>\n",
       "      <td>508</td>\n",
       "      <td>1.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>19.2</td>\n",
       "      <td>25.7</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.4</td>\n",
       "      <td>99.6</td>\n",
       "      <td>383</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>18.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.9</td>\n",
       "      <td>99.8</td>\n",
       "      <td>441</td>\n",
       "      <td>1.7</td>\n",
       "      <td>20.5</td>\n",
       "      <td>17.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Average temperature at 2m altitude (TM)  \\\n",
       "382                                     11.9   \n",
       "383                                     12.3   \n",
       "384                                     11.2   \n",
       "385                                      8.9   \n",
       "386                                      8.6   \n",
       "..                                       ...   \n",
       "488                                     13.4   \n",
       "489                                     17.4   \n",
       "490                                     18.4   \n",
       "491                                     19.2   \n",
       "492                                     18.2   \n",
       "\n",
       "     Maximum air temperature at 2m altitude (TX)  \\\n",
       "382                                         21.9   \n",
       "383                                         22.0   \n",
       "384                                         20.0   \n",
       "385                                         13.1   \n",
       "386                                         15.5   \n",
       "..                                           ...   \n",
       "488                                         15.6   \n",
       "489                                         22.8   \n",
       "490                                         24.9   \n",
       "491                                         25.7   \n",
       "492                                         24.4   \n",
       "\n",
       "     Minimum air temperature at 2m altitude (TN)  Precipitation (RR)  \\\n",
       "382                                         -0.2                 0.0   \n",
       "383                                          0.7                 0.0   \n",
       "384                                          0.6                 0.0   \n",
       "385                                          3.2                 0.0   \n",
       "386                                          0.8                 0.0   \n",
       "..                                           ...                 ...   \n",
       "488                                         11.0                15.4   \n",
       "489                                         12.8                 0.0   \n",
       "490                                         11.5                 0.0   \n",
       "491                                         11.9                 0.0   \n",
       "492                                         11.6                 0.0   \n",
       "\n",
       "     Relative humidity in 2m  Relative humidity in 2m.1  \\\n",
       "382                     48.9                       83.8   \n",
       "383                     46.5                       84.4   \n",
       "384                     48.9                       88.9   \n",
       "385                     46.5                       76.0   \n",
       "386                     46.9                       72.7   \n",
       "..                       ...                        ...   \n",
       "488                     93.7                       97.8   \n",
       "489                     85.4                       98.5   \n",
       "490                     79.3                       99.8   \n",
       "491                     77.4                       99.6   \n",
       "492                     72.9                       99.8   \n",
       "\n",
       "     last minute value (UU)  Leaf moisture at 2m height (BT)  \\\n",
       "382                       0                              0.8   \n",
       "383                       0                              1.3   \n",
       "384                      50                              1.0   \n",
       "385                       1                              3.3   \n",
       "386                       0                              2.1   \n",
       "..                      ...                              ...   \n",
       "488                     830                              3.2   \n",
       "489                     108                              2.2   \n",
       "490                     508                              1.2   \n",
       "491                     383                              1.5   \n",
       "492                     441                              1.7   \n",
       "\n",
       "     10 min lubricant (FF2)  5 sec medium  gusts of wind (FG2)  \\\n",
       "382                    21.6           7.7                  6.5   \n",
       "383                    22.0           8.3                  7.2   \n",
       "384                    20.8           8.5                  7.5   \n",
       "385                    15.5           7.9                  7.2   \n",
       "386                    20.7           7.6                  6.8   \n",
       "..                      ...           ...                  ...   \n",
       "488                     2.2          15.9                 15.1   \n",
       "489                    12.7          16.7                 15.4   \n",
       "490                    20.1          17.5                 16.1   \n",
       "491                    18.8          18.2                 16.8   \n",
       "492                    20.5          17.9                 16.7   \n",
       "\n",
       "     Wind speed in 2m  \n",
       "382               6.4  \n",
       "383               7.1  \n",
       "384               7.5  \n",
       "385               7.6  \n",
       "386               7.2  \n",
       "..                ...  \n",
       "488              16.6  \n",
       "489              16.5  \n",
       "490              17.1  \n",
       "491              17.8  \n",
       "492              17.9  \n",
       "\n",
       "[111 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Staur_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:01.088490Z",
     "start_time": "2021-10-11T00:42:00.967831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN Average temperature at 2m altitude (TM)</th>\n",
       "      <th>MEAN Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>MEAN Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>MEAN Precipitation (RR)</th>\n",
       "      <th>MEAN Relative humidity in 2m</th>\n",
       "      <th>MEAN Relative humidity in 2m.1</th>\n",
       "      <th>MEAN last minute value (UU)</th>\n",
       "      <th>MEAN Leaf moisture at 2m height (BT)</th>\n",
       "      <th>MEAN 10 min lubricant (FF2)</th>\n",
       "      <th>MEAN 5 sec medium</th>\n",
       "      <th>MEAN gusts of wind (FG2)</th>\n",
       "      <th>MEAN Wind speed in 2m</th>\n",
       "      <th>MEDIAN Average temperature at 2m altitude (TM)</th>\n",
       "      <th>MEDIAN Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>MEDIAN Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>MEDIAN Precipitation (RR)</th>\n",
       "      <th>MEDIAN Relative humidity in 2m</th>\n",
       "      <th>MEDIAN Relative humidity in 2m.1</th>\n",
       "      <th>MEDIAN last minute value (UU)</th>\n",
       "      <th>MEDIAN Leaf moisture at 2m height (BT)</th>\n",
       "      <th>MEDIAN 10 min lubricant (FF2)</th>\n",
       "      <th>MEDIAN 5 sec medium</th>\n",
       "      <th>MEDIAN gusts of wind (FG2)</th>\n",
       "      <th>MEDIAN Wind speed in 2m</th>\n",
       "      <th>MODE Average temperature at 2m altitude (TM)</th>\n",
       "      <th>MODE Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>MODE Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>MODE Precipitation (RR)</th>\n",
       "      <th>MODE Relative humidity in 2m</th>\n",
       "      <th>MODE Relative humidity in 2m.1</th>\n",
       "      <th>MODE last minute value (UU)</th>\n",
       "      <th>MODE Leaf moisture at 2m height (BT)</th>\n",
       "      <th>MODE 10 min lubricant (FF2)</th>\n",
       "      <th>MODE 5 sec medium</th>\n",
       "      <th>MODE gusts of wind (FG2)</th>\n",
       "      <th>MODE Wind speed in 2m</th>\n",
       "      <th>SUM Average temperature at 2m altitude (TM)</th>\n",
       "      <th>SUM Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>SUM Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>SUM Precipitation (RR)</th>\n",
       "      <th>SUM Relative humidity in 2m</th>\n",
       "      <th>SUM Relative humidity in 2m.1</th>\n",
       "      <th>SUM last minute value (UU)</th>\n",
       "      <th>SUM Leaf moisture at 2m height (BT)</th>\n",
       "      <th>SUM 10 min lubricant (FF2)</th>\n",
       "      <th>SUM 5 sec medium</th>\n",
       "      <th>SUM gusts of wind (FG2)</th>\n",
       "      <th>SUM Wind speed in 2m</th>\n",
       "      <th>MIN Average temperature at 2m altitude (TM)</th>\n",
       "      <th>MIN Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>...</th>\n",
       "      <th>MAX gusts of wind (FG2)</th>\n",
       "      <th>MAX Wind speed in 2m</th>\n",
       "      <th>STD_DEV Average temperature at 2m altitude (TM)</th>\n",
       "      <th>STD_DEV Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>STD_DEV Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>STD_DEV Precipitation (RR)</th>\n",
       "      <th>STD_DEV Relative humidity in 2m</th>\n",
       "      <th>STD_DEV Relative humidity in 2m.1</th>\n",
       "      <th>STD_DEV last minute value (UU)</th>\n",
       "      <th>STD_DEV Leaf moisture at 2m height (BT)</th>\n",
       "      <th>STD_DEV 10 min lubricant (FF2)</th>\n",
       "      <th>STD_DEV 5 sec medium</th>\n",
       "      <th>STD_DEV gusts of wind (FG2)</th>\n",
       "      <th>STD_DEV Wind speed in 2m</th>\n",
       "      <th>QUANTILE_25 Average temperature at 2m altitude (TM)</th>\n",
       "      <th>QUANTILE_25 Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>QUANTILE_25 Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>QUANTILE_25 Precipitation (RR)</th>\n",
       "      <th>QUANTILE_25 Relative humidity in 2m</th>\n",
       "      <th>QUANTILE_25 Relative humidity in 2m.1</th>\n",
       "      <th>QUANTILE_25 last minute value (UU)</th>\n",
       "      <th>QUANTILE_25 Leaf moisture at 2m height (BT)</th>\n",
       "      <th>QUANTILE_25 10 min lubricant (FF2)</th>\n",
       "      <th>QUANTILE_25 5 sec medium</th>\n",
       "      <th>QUANTILE_25 gusts of wind (FG2)</th>\n",
       "      <th>QUANTILE_25 Wind speed in 2m</th>\n",
       "      <th>QUANTILE_50 Average temperature at 2m altitude (TM)</th>\n",
       "      <th>QUANTILE_50 Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>QUANTILE_50 Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>QUANTILE_50 Precipitation (RR)</th>\n",
       "      <th>QUANTILE_50 Relative humidity in 2m</th>\n",
       "      <th>QUANTILE_50 Relative humidity in 2m.1</th>\n",
       "      <th>QUANTILE_50 last minute value (UU)</th>\n",
       "      <th>QUANTILE_50 Leaf moisture at 2m height (BT)</th>\n",
       "      <th>QUANTILE_50 10 min lubricant (FF2)</th>\n",
       "      <th>QUANTILE_50 5 sec medium</th>\n",
       "      <th>QUANTILE_50 gusts of wind (FG2)</th>\n",
       "      <th>QUANTILE_50 Wind speed in 2m</th>\n",
       "      <th>QUANTILE_75 Average temperature at 2m altitude (TM)</th>\n",
       "      <th>QUANTILE_75 Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>QUANTILE_75 Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>QUANTILE_75 Precipitation (RR)</th>\n",
       "      <th>QUANTILE_75 Relative humidity in 2m</th>\n",
       "      <th>QUANTILE_75 Relative humidity in 2m.1</th>\n",
       "      <th>QUANTILE_75 last minute value (UU)</th>\n",
       "      <th>QUANTILE_75 Leaf moisture at 2m height (BT)</th>\n",
       "      <th>QUANTILE_75 10 min lubricant (FF2)</th>\n",
       "      <th>QUANTILE_75 5 sec medium</th>\n",
       "      <th>QUANTILE_75 gusts of wind (FG2)</th>\n",
       "      <th>QUANTILE_75 Wind speed in 2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.468468</td>\n",
       "      <td>19.534234</td>\n",
       "      <td>6.936937</td>\n",
       "      <td>2.936036</td>\n",
       "      <td>66.053153</td>\n",
       "      <td>91.625225</td>\n",
       "      <td>307.702703</td>\n",
       "      <td>1.825225</td>\n",
       "      <td>19.46036</td>\n",
       "      <td>14.003604</td>\n",
       "      <td>12.82973</td>\n",
       "      <td>13.593694</td>\n",
       "      <td>13.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.8</td>\n",
       "      <td>94.4</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.8</td>\n",
       "      <td>13.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.4</td>\n",
       "      <td>94.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>22.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>2168.3</td>\n",
       "      <td>770.0</td>\n",
       "      <td>325.9</td>\n",
       "      <td>7331.9</td>\n",
       "      <td>10170.4</td>\n",
       "      <td>34155.0</td>\n",
       "      <td>202.6</td>\n",
       "      <td>2160.1</td>\n",
       "      <td>1554.4</td>\n",
       "      <td>1424.1</td>\n",
       "      <td>1508.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.2</td>\n",
       "      <td>4.703422</td>\n",
       "      <td>5.397819</td>\n",
       "      <td>5.047374</td>\n",
       "      <td>6.72885</td>\n",
       "      <td>14.666969</td>\n",
       "      <td>8.180036</td>\n",
       "      <td>307.821453</td>\n",
       "      <td>0.720791</td>\n",
       "      <td>7.106479</td>\n",
       "      <td>4.032908</td>\n",
       "      <td>3.786065</td>\n",
       "      <td>4.057032</td>\n",
       "      <td>10.25</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>89.15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>14.75</td>\n",
       "      <td>9.9</td>\n",
       "      <td>8.75</td>\n",
       "      <td>9.15</td>\n",
       "      <td>13.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.8</td>\n",
       "      <td>94.4</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>15.8</td>\n",
       "      <td>16.4</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>76.7</td>\n",
       "      <td>97.5</td>\n",
       "      <td>467.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>24.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MEAN Average temperature at 2m altitude (TM)  \\\n",
       "0                                     13.468468   \n",
       "\n",
       "   MEAN Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                         19.534234   \n",
       "\n",
       "   MEAN Minimum air temperature at 2m altitude (TN)  MEAN Precipitation (RR)  \\\n",
       "0                                          6.936937                 2.936036   \n",
       "\n",
       "   MEAN Relative humidity in 2m  MEAN Relative humidity in 2m.1  \\\n",
       "0                     66.053153                       91.625225   \n",
       "\n",
       "   MEAN last minute value (UU)  MEAN Leaf moisture at 2m height (BT)  \\\n",
       "0                   307.702703                              1.825225   \n",
       "\n",
       "   MEAN 10 min lubricant (FF2)  MEAN 5 sec medium  MEAN gusts of wind (FG2)  \\\n",
       "0                     19.46036          14.003604                  12.82973   \n",
       "\n",
       "   MEAN Wind speed in 2m  MEDIAN Average temperature at 2m altitude (TM)  \\\n",
       "0              13.593694                                            13.6   \n",
       "\n",
       "   MEDIAN Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                               19.6    \n",
       "\n",
       "   MEDIAN Minimum air temperature at 2m altitude (TN)  \\\n",
       "0                                                7.6    \n",
       "\n",
       "   MEDIAN Precipitation (RR)  MEDIAN Relative humidity in 2m  \\\n",
       "0                        0.0                            65.8   \n",
       "\n",
       "   MEDIAN Relative humidity in 2m.1  MEDIAN last minute value (UU)  \\\n",
       "0                              94.4                          244.0   \n",
       "\n",
       "   MEDIAN Leaf moisture at 2m height (BT)  MEDIAN 10 min lubricant (FF2)  \\\n",
       "0                                     1.7                           21.4   \n",
       "\n",
       "   MEDIAN 5 sec medium  MEDIAN gusts of wind (FG2)  MEDIAN Wind speed in 2m  \\\n",
       "0                 15.7                        14.7                     15.8   \n",
       "\n",
       "   MODE Average temperature at 2m altitude (TM)  \\\n",
       "0                                          13.2   \n",
       "\n",
       "   MODE Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                              15.2   \n",
       "\n",
       "   MODE Minimum air temperature at 2m altitude (TN)  MODE Precipitation (RR)  \\\n",
       "0                                               9.1                      0.0   \n",
       "\n",
       "   MODE Relative humidity in 2m  MODE Relative humidity in 2m.1  \\\n",
       "0                          77.4                            94.4   \n",
       "\n",
       "   MODE last minute value (UU)  MODE Leaf moisture at 2m height (BT)  \\\n",
       "0                          0.0                                   1.5   \n",
       "\n",
       "   MODE 10 min lubricant (FF2)  MODE 5 sec medium  MODE gusts of wind (FG2)  \\\n",
       "0                         22.1               15.6                      14.7   \n",
       "\n",
       "   MODE Wind speed in 2m  SUM Average temperature at 2m altitude (TM)  \\\n",
       "0                   16.5                                       1495.0   \n",
       "\n",
       "   SUM Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                           2168.3   \n",
       "\n",
       "   SUM Minimum air temperature at 2m altitude (TN)  SUM Precipitation (RR)  \\\n",
       "0                                            770.0                   325.9   \n",
       "\n",
       "   SUM Relative humidity in 2m  SUM Relative humidity in 2m.1  \\\n",
       "0                       7331.9                        10170.4   \n",
       "\n",
       "   SUM last minute value (UU)  SUM Leaf moisture at 2m height (BT)  \\\n",
       "0                     34155.0                                202.6   \n",
       "\n",
       "   SUM 10 min lubricant (FF2)  SUM 5 sec medium  SUM gusts of wind (FG2)  \\\n",
       "0                      2160.1            1554.4                   1424.1   \n",
       "\n",
       "   SUM Wind speed in 2m  MIN Average temperature at 2m altitude (TM)  \\\n",
       "0                1508.9                                          3.3   \n",
       "\n",
       "   MIN Maximum air temperature at 2m altitude (TX)  ...  \\\n",
       "0                                              7.4  ...   \n",
       "\n",
       "   MAX gusts of wind (FG2)  MAX Wind speed in 2m  \\\n",
       "0                     18.3                  19.2   \n",
       "\n",
       "   STD_DEV Average temperature at 2m altitude (TM)  \\\n",
       "0                                         4.703422   \n",
       "\n",
       "   STD_DEV Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                           5.397819     \n",
       "\n",
       "   STD_DEV Minimum air temperature at 2m altitude (TN)  \\\n",
       "0                                           5.047374     \n",
       "\n",
       "   STD_DEV Precipitation (RR)  STD_DEV Relative humidity in 2m  \\\n",
       "0                     6.72885                        14.666969   \n",
       "\n",
       "   STD_DEV Relative humidity in 2m.1  STD_DEV last minute value (UU)  \\\n",
       "0                           8.180036                      307.821453   \n",
       "\n",
       "   STD_DEV Leaf moisture at 2m height (BT)  STD_DEV 10 min lubricant (FF2)  \\\n",
       "0                                 0.720791                        7.106479   \n",
       "\n",
       "   STD_DEV 5 sec medium  STD_DEV gusts of wind (FG2)  \\\n",
       "0              4.032908                     3.786065   \n",
       "\n",
       "   STD_DEV Wind speed in 2m  \\\n",
       "0                  4.057032   \n",
       "\n",
       "   QUANTILE_25 Average temperature at 2m altitude (TM)  \\\n",
       "0                                              10.25     \n",
       "\n",
       "   QUANTILE_25 Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                               15.9         \n",
       "\n",
       "   QUANTILE_25 Minimum air temperature at 2m altitude (TN)  \\\n",
       "0                                               2.55         \n",
       "\n",
       "   QUANTILE_25 Precipitation (RR)  QUANTILE_25 Relative humidity in 2m  \\\n",
       "0                             0.0                                 52.6   \n",
       "\n",
       "   QUANTILE_25 Relative humidity in 2m.1  QUANTILE_25 last minute value (UU)  \\\n",
       "0                                  89.15                                 3.0   \n",
       "\n",
       "   QUANTILE_25 Leaf moisture at 2m height (BT)  \\\n",
       "0                                         1.35   \n",
       "\n",
       "   QUANTILE_25 10 min lubricant (FF2)  QUANTILE_25 5 sec medium  \\\n",
       "0                               14.75                       9.9   \n",
       "\n",
       "   QUANTILE_25 gusts of wind (FG2)  QUANTILE_25 Wind speed in 2m  \\\n",
       "0                             8.75                          9.15   \n",
       "\n",
       "   QUANTILE_50 Average temperature at 2m altitude (TM)  \\\n",
       "0                                               13.6     \n",
       "\n",
       "   QUANTILE_50 Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                               19.6         \n",
       "\n",
       "   QUANTILE_50 Minimum air temperature at 2m altitude (TN)  \\\n",
       "0                                                7.6         \n",
       "\n",
       "   QUANTILE_50 Precipitation (RR)  QUANTILE_50 Relative humidity in 2m  \\\n",
       "0                             0.0                                 65.8   \n",
       "\n",
       "   QUANTILE_50 Relative humidity in 2m.1  QUANTILE_50 last minute value (UU)  \\\n",
       "0                                   94.4                               244.0   \n",
       "\n",
       "   QUANTILE_50 Leaf moisture at 2m height (BT)  \\\n",
       "0                                          1.7   \n",
       "\n",
       "   QUANTILE_50 10 min lubricant (FF2)  QUANTILE_50 5 sec medium  \\\n",
       "0                                21.4                      15.7   \n",
       "\n",
       "   QUANTILE_50 gusts of wind (FG2)  QUANTILE_50 Wind speed in 2m  \\\n",
       "0                             14.7                          15.8   \n",
       "\n",
       "   QUANTILE_75 Average temperature at 2m altitude (TM)  \\\n",
       "0                                               16.4     \n",
       "\n",
       "   QUANTILE_75 Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                              22.95         \n",
       "\n",
       "   QUANTILE_75 Minimum air temperature at 2m altitude (TN)  \\\n",
       "0                                               11.3         \n",
       "\n",
       "   QUANTILE_75 Precipitation (RR)  QUANTILE_75 Relative humidity in 2m  \\\n",
       "0                             1.9                                 76.7   \n",
       "\n",
       "   QUANTILE_75 Relative humidity in 2m.1  QUANTILE_75 last minute value (UU)  \\\n",
       "0                                   97.5                               467.5   \n",
       "\n",
       "   QUANTILE_75 Leaf moisture at 2m height (BT)  \\\n",
       "0                                          2.2   \n",
       "\n",
       "   QUANTILE_75 10 min lubricant (FF2)  QUANTILE_75 5 sec medium  \\\n",
       "0                                24.5                      16.7   \n",
       "\n",
       "   QUANTILE_75 gusts of wind (FG2)  QUANTILE_75 Wind speed in 2m  \n",
       "0                             15.5                          16.7  \n",
       "\n",
       "[1 rows x 120 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Staur_2020_weather_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:01.103447Z",
     "start_time": "2021-10-11T00:42:01.091481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MEAN Average temperature at 2m altitude (TM)',\n",
       " 'MEAN Maximum air temperature at 2m altitude (TX)',\n",
       " 'MEAN Minimum air temperature at 2m altitude (TN)',\n",
       " 'MEAN Precipitation (RR)',\n",
       " 'MEAN Relative humidity in 2m',\n",
       " 'MEAN Relative humidity in 2m.1',\n",
       " 'MEAN last minute value (UU)',\n",
       " 'MEAN Leaf moisture at 2m height (BT)',\n",
       " 'MEAN 10 min lubricant (FF2)',\n",
       " 'MEAN 5 sec medium',\n",
       " 'MEAN gusts of wind (FG2)',\n",
       " 'MEAN Wind speed in 2m',\n",
       " 'MEDIAN Average temperature at 2m altitude (TM)',\n",
       " 'MEDIAN Maximum air temperature at 2m altitude (TX)',\n",
       " 'MEDIAN Minimum air temperature at 2m altitude (TN)',\n",
       " 'MEDIAN Precipitation (RR)',\n",
       " 'MEDIAN Relative humidity in 2m',\n",
       " 'MEDIAN Relative humidity in 2m.1',\n",
       " 'MEDIAN last minute value (UU)',\n",
       " 'MEDIAN Leaf moisture at 2m height (BT)',\n",
       " 'MEDIAN 10 min lubricant (FF2)',\n",
       " 'MEDIAN 5 sec medium',\n",
       " 'MEDIAN gusts of wind (FG2)',\n",
       " 'MEDIAN Wind speed in 2m',\n",
       " 'MODE Average temperature at 2m altitude (TM)',\n",
       " 'MODE Maximum air temperature at 2m altitude (TX)',\n",
       " 'MODE Minimum air temperature at 2m altitude (TN)',\n",
       " 'MODE Precipitation (RR)',\n",
       " 'MODE Relative humidity in 2m',\n",
       " 'MODE Relative humidity in 2m.1',\n",
       " 'MODE last minute value (UU)',\n",
       " 'MODE Leaf moisture at 2m height (BT)',\n",
       " 'MODE 10 min lubricant (FF2)',\n",
       " 'MODE 5 sec medium',\n",
       " 'MODE gusts of wind (FG2)',\n",
       " 'MODE Wind speed in 2m',\n",
       " 'SUM Average temperature at 2m altitude (TM)',\n",
       " 'SUM Maximum air temperature at 2m altitude (TX)',\n",
       " 'SUM Minimum air temperature at 2m altitude (TN)',\n",
       " 'SUM Precipitation (RR)',\n",
       " 'SUM Relative humidity in 2m',\n",
       " 'SUM Relative humidity in 2m.1',\n",
       " 'SUM last minute value (UU)',\n",
       " 'SUM Leaf moisture at 2m height (BT)',\n",
       " 'SUM 10 min lubricant (FF2)',\n",
       " 'SUM 5 sec medium',\n",
       " 'SUM gusts of wind (FG2)',\n",
       " 'SUM Wind speed in 2m',\n",
       " 'MIN Average temperature at 2m altitude (TM)',\n",
       " 'MIN Maximum air temperature at 2m altitude (TX)',\n",
       " 'MIN Minimum air temperature at 2m altitude (TN)',\n",
       " 'MIN Precipitation (RR)',\n",
       " 'MIN Relative humidity in 2m',\n",
       " 'MIN Relative humidity in 2m.1',\n",
       " 'MIN last minute value (UU)',\n",
       " 'MIN Leaf moisture at 2m height (BT)',\n",
       " 'MIN 10 min lubricant (FF2)',\n",
       " 'MIN 5 sec medium',\n",
       " 'MIN gusts of wind (FG2)',\n",
       " 'MIN Wind speed in 2m',\n",
       " 'MAX Average temperature at 2m altitude (TM)',\n",
       " 'MAX Maximum air temperature at 2m altitude (TX)',\n",
       " 'MAX Minimum air temperature at 2m altitude (TN)',\n",
       " 'MAX Precipitation (RR)',\n",
       " 'MAX Relative humidity in 2m',\n",
       " 'MAX Relative humidity in 2m.1',\n",
       " 'MAX last minute value (UU)',\n",
       " 'MAX Leaf moisture at 2m height (BT)',\n",
       " 'MAX 10 min lubricant (FF2)',\n",
       " 'MAX 5 sec medium',\n",
       " 'MAX gusts of wind (FG2)',\n",
       " 'MAX Wind speed in 2m',\n",
       " 'STD_DEV Average temperature at 2m altitude (TM)',\n",
       " 'STD_DEV Maximum air temperature at 2m altitude (TX)',\n",
       " 'STD_DEV Minimum air temperature at 2m altitude (TN)',\n",
       " 'STD_DEV Precipitation (RR)',\n",
       " 'STD_DEV Relative humidity in 2m',\n",
       " 'STD_DEV Relative humidity in 2m.1',\n",
       " 'STD_DEV last minute value (UU)',\n",
       " 'STD_DEV Leaf moisture at 2m height (BT)',\n",
       " 'STD_DEV 10 min lubricant (FF2)',\n",
       " 'STD_DEV 5 sec medium',\n",
       " 'STD_DEV gusts of wind (FG2)',\n",
       " 'STD_DEV Wind speed in 2m',\n",
       " 'QUANTILE_25 Average temperature at 2m altitude (TM)',\n",
       " 'QUANTILE_25 Maximum air temperature at 2m altitude (TX)',\n",
       " 'QUANTILE_25 Minimum air temperature at 2m altitude (TN)',\n",
       " 'QUANTILE_25 Precipitation (RR)',\n",
       " 'QUANTILE_25 Relative humidity in 2m',\n",
       " 'QUANTILE_25 Relative humidity in 2m.1',\n",
       " 'QUANTILE_25 last minute value (UU)',\n",
       " 'QUANTILE_25 Leaf moisture at 2m height (BT)',\n",
       " 'QUANTILE_25 10 min lubricant (FF2)',\n",
       " 'QUANTILE_25 5 sec medium',\n",
       " 'QUANTILE_25 gusts of wind (FG2)',\n",
       " 'QUANTILE_25 Wind speed in 2m',\n",
       " 'QUANTILE_50 Average temperature at 2m altitude (TM)',\n",
       " 'QUANTILE_50 Maximum air temperature at 2m altitude (TX)',\n",
       " 'QUANTILE_50 Minimum air temperature at 2m altitude (TN)',\n",
       " 'QUANTILE_50 Precipitation (RR)',\n",
       " 'QUANTILE_50 Relative humidity in 2m',\n",
       " 'QUANTILE_50 Relative humidity in 2m.1',\n",
       " 'QUANTILE_50 last minute value (UU)',\n",
       " 'QUANTILE_50 Leaf moisture at 2m height (BT)',\n",
       " 'QUANTILE_50 10 min lubricant (FF2)',\n",
       " 'QUANTILE_50 5 sec medium',\n",
       " 'QUANTILE_50 gusts of wind (FG2)',\n",
       " 'QUANTILE_50 Wind speed in 2m',\n",
       " 'QUANTILE_75 Average temperature at 2m altitude (TM)',\n",
       " 'QUANTILE_75 Maximum air temperature at 2m altitude (TX)',\n",
       " 'QUANTILE_75 Minimum air temperature at 2m altitude (TN)',\n",
       " 'QUANTILE_75 Precipitation (RR)',\n",
       " 'QUANTILE_75 Relative humidity in 2m',\n",
       " 'QUANTILE_75 Relative humidity in 2m.1',\n",
       " 'QUANTILE_75 last minute value (UU)',\n",
       " 'QUANTILE_75 Leaf moisture at 2m height (BT)',\n",
       " 'QUANTILE_75 10 min lubricant (FF2)',\n",
       " 'QUANTILE_75 5 sec medium',\n",
       " 'QUANTILE_75 gusts of wind (FG2)',\n",
       " 'QUANTILE_75 Wind speed in 2m']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_cols = locals()[weathers_processed_df[0]].columns.tolist()\n",
    "weather_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T01:50:44.637743Z",
     "start_time": "2021-10-11T01:50:44.625775Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure the folder/dir is there. If not, create one\n",
    "os.makedirs(main_path, exist_ok=True)\n",
    "import json\n",
    "a_file = open(main_path+'weather_columns.json', \"w\")\n",
    "json.dump(weather_cols, a_file)\n",
    "a_file.close()\n",
    "\n",
    "# a_file = open(\"Data\\weather_columns.json\", \"r\")\n",
    "# output = a_file.read()\n",
    "# a_file.close()\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding weather data to the simps integrated df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:01.286502Z",
     "start_time": "2021-10-11T00:42:01.136359Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_export = []\n",
    "for df in simp_df_all_dropna+trapz_df_all_dropna:\n",
    "    temp_df = locals()[df].copy()\n",
    "    \n",
    "    field_name = df.split('_')[0]+'_'+df.split('_')[1]\n",
    "    integration_type = df.split('_')[2]\n",
    "    \n",
    "    single_row_name = field_name+'_weather_agg'\n",
    "    single_row_df = locals()[single_row_name]\n",
    "    # Replicating the single_row data multiple times to make the df equal to the number of rows in the original df\n",
    "    rows_df = temp_df.shape[0] \n",
    "    new_df = pd.DataFrame(np.repeat(single_row_df.values, rows_df, axis=0), columns=single_row_df.columns)\n",
    "    \n",
    "    pd.concat([temp_df, new_df], axis=1)\n",
    "    merged_df = pd.concat([temp_df, new_df], axis=1)\n",
    "    \n",
    "    locals()[field_name+'_'+integration_type] = merged_df.copy()\n",
    "    df_to_export.append(field_name+'_'+integration_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:01.301564Z",
     "start_time": "2021-10-11T00:42:01.289428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Simps',\n",
       " 'Graminor_2020_Simps',\n",
       " 'Masbasis_2019_Simps',\n",
       " 'Masbasis_2020_Simps',\n",
       " 'Robot_2020_Simps',\n",
       " 'Staur_2019_Simps',\n",
       " 'Staur_2020_Simps',\n",
       " 'Graminor_2019_Trapz',\n",
       " 'Graminor_2020_Trapz',\n",
       " 'Masbasis_2019_Trapz',\n",
       " 'Masbasis_2020_Trapz',\n",
       " 'Robot_2020_Trapz',\n",
       " 'Staur_2019_Trapz',\n",
       " 'Staur_2020_Trapz']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:01.333479Z",
     "start_time": "2021-10-11T00:42:01.305560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Plot_ID', 'GrainYield', 'Name', 'Blue', 'Green', 'Red', 'RedEdge',\n",
       "       'NIR', 'NDVI', 'MTCI',\n",
       "       ...\n",
       "       'QUANTILE_75 Minimum air temperature at 2m altitude (TN)',\n",
       "       'QUANTILE_75 Precipitation (RR)', 'QUANTILE_75 Relative humidity in 2m',\n",
       "       'QUANTILE_75 Relative humidity in 2m.1',\n",
       "       'QUANTILE_75 last minute value (UU)',\n",
       "       'QUANTILE_75 Leaf moisture at 2m height (BT)',\n",
       "       'QUANTILE_75 10 min lubricant (FF2)', 'QUANTILE_75 5 sec medium',\n",
       "       'QUANTILE_75 gusts of wind (FG2)', 'QUANTILE_75 Wind speed in 2m'],\n",
       "      dtype='object', length=158)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graminor_2019_Simps.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:23:07.734119Z",
     "start_time": "2021-10-11T00:23:07.721143Z"
    }
   },
   "source": [
    "## Summary of processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:01.533942Z",
     "start_time": "2021-10-11T00:42:01.335474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps : GrainYield : 1\n",
      "*************************\n",
      "Graminor_2020_Simps : GrainYield : 1\n",
      "*************************\n",
      "Masbasis_2019_Simps : GrainYield : 6\n",
      "*************************\n",
      "Masbasis_2020_Simps : GrainYield : 116\n",
      "*************************\n",
      "No nan values found in any column in Robot_2020_Simps\n",
      "*************************\n",
      "No nan values found in any column in Staur_2019_Simps\n",
      "*************************\n",
      "Staur_2020_Simps : GrainYield : 568\n",
      "*************************\n",
      "Graminor_2019_Trapz : GrainYield : 1\n",
      "*************************\n",
      "Graminor_2020_Trapz : GrainYield : 1\n",
      "*************************\n",
      "Masbasis_2019_Trapz : GrainYield : 6\n",
      "*************************\n",
      "Masbasis_2020_Trapz : GrainYield : 116\n",
      "*************************\n",
      "No nan values found in any column in Robot_2020_Trapz\n",
      "*************************\n",
      "No nan values found in any column in Staur_2019_Trapz\n",
      "*************************\n",
      "Staur_2020_Trapz : GrainYield : 568\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "for df in df_to_export:\n",
    "    temp_df = locals()[df].copy()\n",
    "    temp_cols = temp_df.columns.tolist()\n",
    "    # Bands, Indices, Plot_ID and GrainYield columns only\n",
    "    chk_cols = [x for x in temp_cols if x not in weather_cols if x not in yield_cols]+['Plot_ID', 'GrainYield']\n",
    "    nan_found = False\n",
    "    for col in chk_cols:\n",
    "        if temp_df[col].isna().sum() > 0:\n",
    "            nan_found = True\n",
    "            print(df,':', col,':', temp_df[col].isna().sum())\n",
    "    if not nan_found:\n",
    "        print(f'No nan values found in any column in {df}')\n",
    "    \n",
    "    print('*************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:01.548904Z",
     "start_time": "2021-10-11T00:42:01.534939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Simps',\n",
       " 'Graminor_2020_Simps',\n",
       " 'Masbasis_2019_Simps',\n",
       " 'Masbasis_2020_Simps',\n",
       " 'Robot_2020_Simps',\n",
       " 'Staur_2019_Simps',\n",
       " 'Staur_2020_Simps',\n",
       " 'Graminor_2019_Trapz',\n",
       " 'Graminor_2020_Trapz',\n",
       " 'Masbasis_2019_Trapz',\n",
       " 'Masbasis_2020_Trapz',\n",
       " 'Robot_2020_Trapz',\n",
       " 'Staur_2019_Trapz',\n",
       " 'Staur_2020_Trapz']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp: Exporting data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:42:03.951074Z",
     "start_time": "2021-10-11T00:42:01.550897Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(export_path, exist_ok=True)\n",
    "for df in df_to_export:\n",
    "    locals()[df].to_csv(export_path+df+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Genomics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T14:37:23.547182Z",
     "start_time": "2021-10-03T14:37:23.524537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Muhammad Fahad Ijaz/\\\\\\\\MegaSync\\\\NMBU\\\\Master Thesis\\\\Data\\\\Genomics\\\\\\\\'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genomics_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Genomics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-03T14:30:08.248569Z",
     "start_time": "2021-10-03T14:30:08.214709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_all\n",
      "Masbasis_2020_all_lodg\n",
      "Staur_2019_all\n"
     ]
    }
   ],
   "source": [
    "# If the dataset had Days 2 heading and days to maturity columns then create the\n",
    "# following dictionary with the respective sowing dates of each field as value\n",
    "\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    field_temp = df.split('_')[0]+'_'+df.split('_')[1]\n",
    "    if 'Line' in temp_df.columns:\n",
    "        print(df)\n",
    "#         all_df_dates_filtered[df] = sowing_dict[field_temp]\n",
    "# all_df_dates_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Yield data with line information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:56:14.818870Z",
     "start_time": "2021-09-08T17:56:14.815434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vollebekk 2019: Graminor_2019_x_19TvPhenores_x_Vollebekk_res\n",
    "# Masbasis 2020: Masbasis_x_20BMLGI1_2020_tm_x_data\n",
    "# Robot 2020: Robot_x_ROBOT_2020_x_raw\n",
    "# Masbasis 2019: Masbasis_2019_x_Field_data_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:56:14.833002Z",
     "start_time": "2021-09-08T17:56:14.824218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Graminor 2019': ['Graminor_2019_x_19TvPhenores_x_Vollebekk_res',\n",
      "                   '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                   'Thesis\\\\Data\\\\Feb2021\\\\Graminor_2019\\\\19TvPhenores.xlsx'],\n",
      " 'Masbasis 2019': ['Masbasis_2019_x_Field_data_2019',\n",
      "                   '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                   'Thesis\\\\Data\\\\Feb2021\\\\Masbasis_2019\\\\Field_data_2019.xlsx'],\n",
      " 'Masbasis 2020': ['Masbasis_x_20BMLGI1_2020_tm_x_data',\n",
      "                   '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                   'Thesis\\\\Data\\\\Feb2021\\\\Vollebekke-total_2020\\\\Masbasis\\\\20BMLGI1_2020_tm.xlsx'],\n",
      " 'Robot 2020': ['Robot_x_ROBOT_2020_x_raw',\n",
      "                '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                'Thesis\\\\Data\\\\Feb2021\\\\Vollebekke-total_2020\\\\Robot\\\\ROBOT_2020.xlsx'],\n",
      " 'Staur 2019': ['Graminor_2019_x_19TvPhenores_x_Staur_res',\n",
      "                '\\\\MegaSync\\\\NMBU\\\\Master '\n",
      "                'Thesis\\\\Data\\\\Feb2021\\\\Graminor_2019\\\\19TvPhenores.xlsx']}\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+'yield_df.json', \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "\n",
    "# Converting it to dictionary\n",
    "output_dict = json.loads(output_str)\n",
    "a_file.close()\n",
    "\n",
    "pprint(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking number of unique cultivars in the field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:56:14.839834Z",
     "start_time": "2021-09-08T17:56:14.835929Z"
    }
   },
   "outputs": [],
   "source": [
    "# plots_data = pd.read_excel(files_with_address[0],engine='openpyxl')\n",
    "# # Pandas converts 'NA' string to NaN. Need to change those to \n",
    "# # some string to get a count as NaNs are not counted as unique values\n",
    "\n",
    "# plots_data.Name.fillna('-', inplace=True)\n",
    "# plots_data.CodeName.fillna('-', inplace=True)\n",
    "\n",
    "# # Creating a new column as multiple plots were named 'NA' but the \n",
    "# # CodeName was different for each one of them\n",
    "# plots_data['NameCode'] = plots_data.Name+plots_data.CodeName\n",
    "\n",
    "# plots_data\n",
    "# len(plots_data.NameCode.unique())\n",
    "# plots_data.NameCode.value_counts()\n",
    "# # plots_data.NameCode.value_counts().sum()\n",
    "# # plots_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo: Dropping NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding NAN values\n",
    "### ToDo: Test: Raise error if missing values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.599254Z",
     "start_time": "2021-09-08T17:16:55.592423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing value found in any dataframe\n"
     ]
    }
   ],
   "source": [
    "# Finding number of missing values in each dataframe\n",
    "df_with_nan = []\n",
    "missing_values = False\n",
    "for df in all_df:\n",
    "    if locals()[df].isna().sum().sum() > 0:\n",
    "        print(f'Total missing values in {df} are {locals()[df].isna().sum().sum()}')\n",
    "        missing_values = True\n",
    "        df_with_nan.append(df)\n",
    "#     if len(df_with_nan) > 0:\n",
    "#         raise ValueError\n",
    "if not missing_values:\n",
    "    print('No missing value found in any dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.623191Z",
     "start_time": "2021-09-08T17:16:55.601230Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Graminor_2019_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-92e745b63b43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mGraminor_2019_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Graminor_2019_all' is not defined"
     ]
    }
   ],
   "source": [
    "Graminor_2019_all.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.632951Z",
     "start_time": "2021-09-08T17:16:55.626119Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.640759Z",
     "start_time": "2021-09-08T17:16:55.635878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding which column has NAN values\n",
    "for df in df_with_nan:\n",
    "    print(f'{df}:\\n {locals()[df].shape[1]-locals()[df].dropna(axis=1).shape[1]} columns or {locals()[df].shape[0]-locals()[df].dropna().shape[0]} rows to be dropped,')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Automate: Drop rows with missing values in df_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:55.936906Z",
     "start_time": "2021-09-08T17:16:55.923195Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Graminor_eastwest_020719_NIR_half_missing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-bd632eb495de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{Graminor_eastwest_020719_NIR_half_missing.shape} Before dropping'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Graminor_eastwest_020719_NIR_half_missing.dropna(inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{Graminor_eastwest_020719_NIR_half_missing.shape} After dropping'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Graminor_eastwest_020719_NIR_half_missing' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'{Graminor_eastwest_020719_NIR_half_missing.shape} Before dropping')\n",
    "# Graminor_eastwest_020719_NIR_half_missing.dropna(inplace=True)\n",
    "print(f'{Graminor_eastwest_020719_NIR_half_missing.shape} After dropping')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Droppping df with Nan from the all_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:56.595993Z",
     "start_time": "2021-09-08T17:16:56.591114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in all_df is 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of items in all_df is {len(all_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:56.602824Z",
     "start_time": "2021-09-08T17:16:56.598923Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for df in df_with_nan:\n",
    "#     all_df.remove(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ToDo: Update field_year_dict and sorted_field_year_dict after dropping the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:56.943290Z",
     "start_time": "2021-09-08T17:16:56.938408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items in all_df now is 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of items in all_df now is {len(all_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo:  \n",
    "see the distribution of data if it is normal  \n",
    "else make transpose to make it normal  \n",
    "dist in Gausion function   \n",
    "in each field  \n",
    "what if the data is normal dist?  \n",
    "the use some transpose to box pox   \n",
    "try diff funct to see which one iis able to make data normal  \n",
    "make heat map of whole if not normal  \n",
    "see which parts are not normal and exculde them  \n",
    "ls_means in R to make the normalisation/transpose  \n",
    "pearson corr bw yield and indices for diff dates  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:57.911154Z",
     "start_time": "2021-09-08T17:16:57.898466Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1ae58ac70b7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_labels' is not defined"
     ]
    }
   ],
   "source": [
    "x_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yeo-Johnson Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:59.631522Z",
     "start_time": "2021-09-08T17:16:58.258599Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'field_year_dict_yield' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-bf2287054a1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_agg_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcol_for_plotting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_year_dict_yield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'field_year_dict_yield' is not defined"
     ]
    }
   ],
   "source": [
    "col_for_plotting = ['Blue', 'Green', 'Red', 'RedEdge', 'NIR', 'NDVI', 'MTCI', 'EVI']\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, normalize, StandardScaler\n",
    "data_agg_list = ['_median_indices']\n",
    "\n",
    "# col_for_plotting = ['Blue']\n",
    "# col_for_plotting = ['Green']\n",
    "# col_for_plotting = ['Red']\n",
    "\n",
    "for d_type in data_agg_list:\n",
    "    for col in col_for_plotting:\n",
    "        fields = len(field_year_dict_yield.keys())\n",
    "        rows = math.ceil(fields/2)\n",
    "        \n",
    "        fig, ax = plt.subplots(rows,2, figsize=(15,10))\n",
    "        plots = ax.flatten()\n",
    "        n = 0\n",
    "        # TODO: Fix the x ticks\n",
    "        \n",
    "\n",
    "        for field_sample, dates in sorted_field_year_dict_yield.items():\n",
    "            x_labels = []\n",
    "            # Adding required data to a temp dataframe\n",
    "            temp_df = pd.DataFrame()\n",
    "            for date in dates:\n",
    "                date_str = date.strftime('%d%m%y')\n",
    "                field_df = field_sample[:-5]+'_'+date_str+d_type\n",
    "                temp_df[date] = locals()[field_df][col]\n",
    "                x_label = date.strftime('%d-%m-%y')+':'+str(len(locals()[field_df][col]))\n",
    "                \n",
    "                x_labels.append(x_label)\n",
    "                x_labels= list(set(x_labels))\n",
    "            # Transform the df\n",
    "#             pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "            pt = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "\n",
    "            temp_arr = pt.fit_transform(temp_df)\n",
    "            temp_df = pd.DataFrame(temp_arr)\n",
    "            \n",
    "            # Adding field plot to the subplots\n",
    "            num_of_fields = len(field_year_dict_yield.keys())\n",
    "            \n",
    "            text = \"Grain Yield\"\n",
    "            ax_n = plots[n]\n",
    "            \n",
    "            temp_df.boxplot(ax=ax_n)\n",
    "            ax_n.set_xticklabels(x_labels, rotation=-35)\n",
    "            ax_n.set_title(field_sample+'_'+col+d_type[:-5]+'_yeo-johnson')\n",
    "            \n",
    "#             # Printing the grain yield in plot of the fiels_sample for reference\n",
    "#             ax_n.text(0.85, 1.05, text, ha='center', va='top', weight='bold', color='blue', transform=ax_n.transAxes)\n",
    "            n+=1\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box-Cox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:16:59.656899Z",
     "start_time": "2021-09-08T17:16:59.633474Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'field_year_dict_yield' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-8b39c1ee47a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_agg_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcol_for_plotting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mfields\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfield_year_dict_yield\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'field_year_dict_yield' is not defined"
     ]
    }
   ],
   "source": [
    "col_for_plotting = ['Blue', 'Green', 'Red', 'RedEdge', 'NIR', 'NDVI', 'MTCI', 'EVI']\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, normalize, StandardScaler\n",
    "data_agg_list = ['_median_indices']\n",
    "\n",
    "# col_for_plotting = ['Blue']\n",
    "# col_for_plotting = ['Green']\n",
    "# col_for_plotting = ['Red']\n",
    "\n",
    "for d_type in data_agg_list:\n",
    "    for col in col_for_plotting:\n",
    "        fields = len(field_year_dict_yield.keys())\n",
    "        rows = math.ceil(fields/2)\n",
    "        \n",
    "        fig, ax = plt.subplots(rows,2, figsize=(15,10))\n",
    "        plots = ax.flatten()\n",
    "        n = 0\n",
    "        # TODO: Fix the x ticks\n",
    "        for field_sample, dates in sorted_field_year_dict_yield.items():\n",
    "            \n",
    "            # Adding required data to a temp dataframe\n",
    "            temp_df = pd.DataFrame()\n",
    "            for date in dates:\n",
    "                date_str = date.strftime('%d%m%y')\n",
    "                field_df = field_sample[:-5]+'_'+date_str+d_type\n",
    "                temp_df[date] = locals()[field_df][col]\n",
    "            x_labels = temp_df.columns.tolist()\n",
    "\n",
    "            # Transform the df\n",
    "#             pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "            pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "\n",
    "            # Taking absolute values of the dataframe(avoiding negative values)\n",
    "            temp_arr = pt.fit_transform(temp_df.abs())\n",
    "            temp_df = pd.DataFrame(temp_arr)\n",
    "            \n",
    "            # Adding field plot to the subplots\n",
    "            num_of_fields = len(field_year_dict_yield.keys())\n",
    "            \n",
    "            text = \"Grain Yield\"\n",
    "            ax_n = plots[n]\n",
    "\n",
    "            temp_df.boxplot(ax=ax_n)\n",
    "            ax_n.set_xticklabels(x_labels, rotation=90)\n",
    "            ax_n.set_title(field_sample+'_'+col+d_type[:-5]+'_box-cox')\n",
    "            \n",
    "#             # Printing the grain yield in plot of the fiels_sample for reference\n",
    "#             ax_n.text(0.85, 1.05, text, ha='center', va='top', weight='bold', color='blue', transform=ax_n.transAxes)\n",
    "            n+=1\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo: Identify Dates and index with problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecxclude the problematic data/dates\n",
    "or\n",
    "### Take average values where the problematic data is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take average of data for date 20200708 and 20200624  \n",
    "Masbasis  \n",
    "Cleanup  \n",
    "Remove dates which have drop  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find AUC for all dates of one field\n",
    "See if it covers tha gaps under the dates,i.e.\n",
    "\n",
    "Since data points are different  \n",
    "Flying time is different  \n",
    "Cover the gaps between the dates  \n",
    "\n",
    "Since the data collection is not uniform throughout the year so AUC will give a single value instead of multiple values for one field year which will be representative of all the dates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Use Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.226553Z",
     "start_time": "2021-09-08T17:17:01.218744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.241194Z",
     "start_time": "2021-09-08T17:17:01.235336Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "from scipy.integrate import simps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.254854Z",
     "start_time": "2021-09-08T17:17:01.248025Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import simpson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.280233Z",
     "start_time": "2021-09-08T17:17:01.274374Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(0, 10)\n",
    "y = np.arange(0, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.306584Z",
     "start_time": "2021-09-08T17:17:01.296829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integrate.simpson(y, x)\n",
    "integrate.simps(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.333910Z",
     "start_time": "2021-09-08T17:17:01.323176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   8,  27,  64, 125, 216, 343, 512, 729], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.power(x, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.356360Z",
     "start_time": "2021-09-08T17:17:01.347576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrate.simpson(y, x)\n",
    "# integrate.simps(y, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.372949Z",
     "start_time": "2021-09-08T17:17:01.364165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640.25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrate.quad(lambda x: x**3, 0, 9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.392469Z",
     "start_time": "2021-09-08T17:17:01.380762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644.5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrate.simpson(y, x, even='first')\n",
    "# integrate.simps(y, x, even='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.969977Z",
     "start_time": "2021-09-08T17:17:01.954361Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-5c4058e7910f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# plot: Plot ID\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# x: Number of days after sowing or actual date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# y: Value of the index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data\n",
    "# plot: Plot ID\n",
    "# x: Number of days after sowing or actual date\n",
    "# y: Value of the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:01.991449Z",
     "start_time": "2021-09-08T17:17:01.973882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8500000000000001\n",
      "1.5\n",
      "1.95\n"
     ]
    }
   ],
   "source": [
    "# x: Days from sowing to data collection\n",
    "# May 5 2019 Masbasis and Graminor\n",
    "# Robot: \n",
    "\n",
    "data={'plot':['1','1','2','2','3','3'],'x':['5','6','7','8','9','10'],'y':['0.9','0.8','0.7','0.6','0.5','0.4'] }\n",
    "\n",
    "ACC=[]\n",
    "A=pd.DataFrame(data, columns=['plot','x','y'])\n",
    "AA=0\n",
    "\n",
    "for item in range(len(A)-1):\n",
    "    if A['plot'][item]== A['plot'][item+1]:\n",
    "        Ans=(float((A['y'][item]))+float((A['y'][item+1])))*((float((A['x'][item+1]))-float((A['x'][item]))))/2\n",
    "        AA+=Ans\n",
    "        print(AA)\n",
    "        ACC.append(AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T17:17:02.434915Z",
     "start_time": "2021-09-08T17:17:02.414078Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-508f0f07663b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Plot'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mACC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mNumbers_final\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Data' is not defined"
     ]
    }
   ],
   "source": [
    "df1=Data.set_index(['Plot'])\n",
    "ACC=[]\n",
    "\n",
    "for item in Numbers_final:\n",
    "    df2=df1[df1.index==item]\n",
    "    df2=df2.filter(['Blue', 'Green', 'Red', 'RedEdge', 'NIR','NDVI', 'MTCI', 'EVI', 'DVI', 'RVI', 'VARI', 'EXG', 'EXGR', 'GLI', 'GNDVI', 'GVI','Time','timepoint'], axis=1)\n",
    "    df2=df2.sort_values(by='timepoint')\n",
    "    df3=df2.reset_index()\n",
    "\n",
    "AA=0\n",
    "for j in range(0,3):\n",
    "    Ans=(float((df3['GVI'][j]))+float((df3['GVI'][j+1])))*((float((df3['timepoint'][j+1]))-float((df3['timepoint'][j]))))/2\n",
    "    AA+=Ans\n",
    "\n",
    "    print(AA)\n",
    "    ACC.append(AA)\n",
    "\n",
    "\n",
    "\n",
    "DA=pd.DataFrame(ACC)\n",
    "DD=pd.DataFrame(Numbers_final)\n",
    "DDA=pd.concat([DD, DA], axis=1)\n",
    "DDA.to_excel('Staur_Accumulative_GVI_2019.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series data vs the AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Make model for one year at a time and try to predict yield of another field  \n",
    "\n",
    "TODO: Train on Masbasis 2019 an 2020  \n",
    "Test on Staur  \n",
    "\n",
    "Use data until august for yield prediction since it is most relavant  \n",
    "Use all data for predicting date to maturity  \n",
    "\n",
    "Data Collection:  \n",
    "Data collection usually starts after heading  \n",
    "2019 has the data before hading as well. To use that, dont use dates before heading  \n",
    "\n",
    "NDVI is resistant to shadows  \n",
    "\n",
    "DAT390 Report: Do the report with Robot Data only  \n",
    "\n",
    "TODO: Use AUC for each index for prediction  \n",
    "\n",
    "TODO:   \n",
    "Time series data vs the AUC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
