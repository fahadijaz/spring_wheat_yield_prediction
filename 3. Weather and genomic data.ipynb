{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather and Genomics Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Half datasets, with separate files for east and west subplots have been merged manually in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:45.224758Z",
     "start_time": "2021-10-28T09:03:45.217775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "\n",
    "# Dictionaries\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Iterate in loops\n",
    "from itertools import zip_longest\n",
    "\n",
    "# Simpsons integration\n",
    "from numpy import trapz\n",
    "from scipy.integrate import simps\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To display df nicely in loops\n",
    "from IPython.display import display \n",
    "# display(df1.head()) \n",
    "# display(df2.head())\n",
    "\n",
    "# Display rows and columns Pandas\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# # For displaying max rows in series\n",
    "# pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:45.240007Z",
     "start_time": "2021-10-28T09:03:45.226759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fahad\\\\MegaSync\\\\NMBU\\\\GitHub\\\\vPheno'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the current working directory\n",
    "os.getcwd()\n",
    "# os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Username folder to make general path for multi PC use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:45.334970Z",
     "start_time": "2021-10-28T09:03:45.329445Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fahad', 'C:/Users/fahad/')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username = str(os.getcwd()).split('\\\\')[2]\n",
    "user_path = r'C:/Users/'+username+'/'\n",
    "username, user_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:45.441199Z",
     "start_time": "2021-10-28T09:03:45.433220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all.csv',\n",
       " 'Graminor_2020_all.csv',\n",
       " 'Masbasis_2019_all.csv',\n",
       " 'Masbasis_2020_all_lodg.csv',\n",
       " 'Robot_2020_all.csv',\n",
       " 'Staur_2019_all.csv',\n",
       " 'Staur_2020_all_lodg.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_path = r'./Data/'\n",
    "path = r'./Data/2,2. renamed_merged/'\n",
    "export_path = r'./Data/3. merged data/'\n",
    "# temp_export_path = r'./Data/3. Temp_Data/'\n",
    "weather_data_vollebekk = user_path+r'\\\\MegaSync\\NMBU\\Master Thesis\\Data\\Weather\\Weather_Data_Ã…s-Vollebekk.csv'\n",
    "weather_data_staur = user_path+r'\\\\MegaSync\\NMBU\\Master Thesis\\Data\\Weather\\Weather_Data_Ilseng-Staur.csv'\n",
    "genomics_data = user_path+r'\\\\MegaSync\\NMBU\\Master Thesis\\Data\\Genomics\\\\'\n",
    "\n",
    "# Create export_path folder if not exists already\n",
    "os.makedirs(path, exist_ok=True)\n",
    "os.makedirs(export_path, exist_ok=True)\n",
    "# os.makedirs(temp_export_path, exist_ok=True)\n",
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Creating list of complete files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:45.557843Z",
     "start_time": "2021-10-28T09:03:45.547871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 files found in the directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all.csv',\n",
       " 'Graminor_2020_all.csv',\n",
       " 'Masbasis_2019_all.csv',\n",
       " 'Masbasis_2020_all_lodg.csv',\n",
       " 'Robot_2020_all.csv',\n",
       " 'Staur_2019_all.csv',\n",
       " 'Staur_2020_all_lodg.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of all files in directory tree at given path\n",
    "\n",
    "files_with_address = []\n",
    "files_list = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "    files_with_address += [os.path.join(dirpath, file) for file in filenames]\n",
    "    files_list.extend(filenames)\n",
    "    \n",
    "print(len(files_with_address), 'files found in the directory')\n",
    "# files_with_address\n",
    "files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Checking/control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Check for duplicate filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:45.862781Z",
     "start_time": "2021-10-28T09:03:45.857794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files are : 7\n",
      "Number of unique file names are: 7\n",
      "There is/are 0 duplicate file name/names.\n"
     ]
    }
   ],
   "source": [
    "print('Total number of files are :', len(files_list))\n",
    "\n",
    "print('Number of unique file names are:', len(set(files_list)))\n",
    "\n",
    "print('There is/are', len(files_list) - len(set(files_list)),'duplicate file name/names.')\n",
    "if len(files_list) - len(set(files_list)) > 0:\n",
    "    raise NameError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data files to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:46.589334Z",
     "start_time": "2021-10-28T09:03:45.965088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_all ===== (600, 381)\n",
      "Graminor_2020_all ===== (800, 381)\n",
      "Masbasis_2019_all ===== (528, 280)\n",
      "Masbasis_2020_all_lodg ===== (624, 418)\n",
      "Robot_2020_all ===== (96, 485)\n",
      "Staur_2019_all ===== (1328, 181)\n",
      "Staur_2020_all_lodg ===== (1488, 212)\n",
      "Wall time: 499 ms\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "%%time\n",
    "\n",
    "all_df = []\n",
    "for data in files_with_address:\n",
    "    file_name = os.path.splitext(os.path.basename(data))[0]\n",
    "\n",
    "    # Replce all invalid characters in the name\n",
    "    file_name = file_name.replace(\" \", \"_\")\n",
    "    file_name = file_name.replace(\"-\", \"_\")\n",
    "    file_name = file_name.replace(\")\", \"\")\n",
    "    file_name = file_name.replace(\"(\", \"\")\n",
    "    df_name = file_name.replace(\".\", \"\")\n",
    "    # Test: Check if the same date is already present in the current dict key\n",
    "    if df_name in all_df:\n",
    "        print(f'A file with the same name {df_name} has already been imported. \\n Please check if there is duplication of data.')\n",
    "        raise NameError\n",
    "    all_df.append(df_name)\n",
    "\n",
    "    locals()[df_name] = pd.read_csv(data, index_col=False)\n",
    "    print(df_name, '=====', locals()[df_name].shape)\n",
    "# all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:46.598314Z",
     "start_time": "2021-10-28T09:03:46.591313Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total imported 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all',\n",
       " 'Graminor_2020_all',\n",
       " 'Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all',\n",
       " 'Staur_2020_all_lodg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Total imported {len(all_df)}')\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of imported data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:46.614253Z",
     "start_time": "2021-10-28T09:03:46.601287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_all (600, 381)\n",
      "Graminor_2020_all (800, 381)\n",
      "Masbasis_2019_all (528, 280)\n",
      "Masbasis_2020_all_lodg (624, 418)\n",
      "Robot_2020_all (96, 485)\n",
      "Staur_2019_all (1328, 181)\n",
      "Staur_2020_all_lodg (1488, 212)\n"
     ]
    }
   ],
   "source": [
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    print(df, temp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GrainYield data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:46.636193Z",
     "start_time": "2021-10-28T09:03:46.616248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_all\n",
      "Grain Yield data missing for  1 out of  600\n",
      "Graminor_2020_all\n",
      "Grain Yield data missing for  1 out of  800\n",
      "Masbasis_2019_all\n",
      "Grain Yield data missing for  6 out of  528\n",
      "Masbasis_2020_all_lodg\n",
      "Grain Yield data missing for  116 out of  624\n",
      "Robot_2020_all\n",
      "Grain Yield data missing for  0 out of  96\n",
      "Staur_2019_all\n",
      "Grain Yield data missing for  0 out of  1328\n",
      "Staur_2020_all_lodg\n",
      "Grain Yield data missing for  568 out of  1488\n"
     ]
    }
   ],
   "source": [
    "# Masbasis_2019_Simps.info(null_counts=True)\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "#     print('*************', df, '**************')\n",
    "#     print(locals()[df].info())\n",
    "\n",
    "    print (df)\n",
    "    print('Grain Yield data missing for ', temp_df['GrainYield'].isna().sum(), 'out of ', temp_df.shape[0])\n",
    "# Graminor_2019_Simps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking for zero values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.344816Z",
     "start_time": "2021-10-28T09:03:46.638188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2020_all_lodg Lodging 502\n",
      "Staur_2020_all_lodg Lodging 157\n"
     ]
    }
   ],
   "source": [
    "# Masbasis_2019_Simps.info(null_counts=True)\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    for col in temp_df.columns.to_list():\n",
    "        if (temp_df[col]==0).sum() >0:\n",
    "#             print(temp_df.columns.to_list())\n",
    "            print(df, col, (temp_df[col]==0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Yield columns and Spectral Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.355787Z",
     "start_time": "2021-10-28T09:03:47.347809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Days2Maturity', 'CodeName', 'Heading_Date', 'Pedigree', 'Lodging', 'GrainYield', 'Entry', 'Line', 'Name', 'Days2Heading', 'iBlock', 'Replicates', 'Maturity_Date', 'Block']\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+\"yield_columns.json\", \"r\")\n",
    "output_str = a_file.read()\n",
    "\n",
    "# The file is imported as string\n",
    "# Converting it to dictionary\n",
    "yield_cols = json.loads(output_str)\n",
    "a_file.close()\n",
    "print(yield_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.365761Z",
     "start_time": "2021-10-28T09:03:47.357784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NDVI', 'MTCI', 'DVI', 'GDVI', 'MTCI_CI', 'EXG', 'EXGR', 'RDVI', 'TDVI', 'GNDVI', 'NDRE', 'SCCI', 'EVI', 'TVI', 'VARI', 'GARI', 'GCI', 'GLI', 'NLI', 'MNLI', 'SAVI', 'GSAVI', 'OSAVI', 'GOSAVI', 'MSAVI2', 'MSR', 'GRVI', 'WDRVI', 'SR']\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+\"spectral_indices_columns.json\", \"r\")\n",
    "output_str = a_file.read()\n",
    "\n",
    "# The file is imported as string\n",
    "# Converting it to dictionary\n",
    "spectral_indices = json.loads(output_str)\n",
    "a_file.close()\n",
    "print(spectral_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.378728Z",
     "start_time": "2021-10-28T09:03:47.370747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blue', 'Green', 'Red', 'RedEdge', 'NIR']\n"
     ]
    }
   ],
   "source": [
    "a_file = open(main_path+\"base_indices_columns.json\", \"r\")\n",
    "output_str = a_file.read()\n",
    "\n",
    "# The file is imported as string\n",
    "# Converting it to dictionary\n",
    "base_indices = json.loads(output_str)\n",
    "a_file.close()\n",
    "print(base_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeros only present in Lodging columns where present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding yield columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.411644Z",
     "start_time": "2021-10-28T09:03:47.382716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"GrainYield\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Block\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"Block\". It is located at location 7\n",
      "\"iBlock\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"iBlock\". It is located at location 8\n",
      "\"Entry\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"Entry\". It is located at location 9\n",
      "\"Name\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 10\n",
      "\"Pedigree\" column in Graminor_2019_all is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 11\n",
      "\"GrainYield\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Block\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"Block\". It is located at location 7\n",
      "\"iBlock\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"iBlock\". It is located at location 8\n",
      "\"Entry\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"Entry\". It is located at location 9\n",
      "\"Name\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 10\n",
      "\"Pedigree\" column in Graminor_2020_all is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 11\n",
      "\"GrainYield\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Replicates\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Replicates\". It is located at location 7\n",
      "\"Block\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Block\". It is located at location 8\n",
      "\"Name\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 9\n",
      "\"Line\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Line\". It is located at location 10\n",
      "\"Days2Heading\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 11\n",
      "\"Days2Maturity\" column in Masbasis_2019_all is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 12\n",
      "\"GrainYield\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Replicates\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Replicates\". It is located at location 7\n",
      "\"Block\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Block\". It is located at location 8\n",
      "\"Name\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Name\". It is located at location 9\n",
      "\"Line\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Line\". It is located at location 10\n",
      "\"Maturity_Date\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Maturity_Date\". It is located at location 11\n",
      "\"Days2Heading\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 12\n",
      "\"Days2Maturity\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 13\n",
      "\"Lodging\" column in Masbasis_2020_all_lodg is the yield column\n",
      " as it contains the text \"Lodging\". It is located at location 14\n",
      "\"GrainYield\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Block\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Block\". It is located at location 7\n",
      "\"Name\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 8\n",
      "\"CodeName\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"CodeName\". It is located at location 9\n",
      "\"Heading_Date\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Heading_Date\". It is located at location 10\n",
      "\"Maturity_Date\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Maturity_Date\". It is located at location 11\n",
      "\"Days2Heading\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 12\n",
      "\"Days2Maturity\" column in Robot_2020_all is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 13\n",
      "\"GrainYield\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"iBlock\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"iBlock\". It is located at location 7\n",
      "\"Entry\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Entry\". It is located at location 8\n",
      "\"Pedigree\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 9\n",
      "\"Replicates\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Replicates\". It is located at location 10\n",
      "\"Line\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Line\". It is located at location 11\n",
      "\"Days2Heading\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Days2Heading\". It is located at location 12\n",
      "\"Days2Maturity\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Days2Maturity\". It is located at location 13\n",
      "\"Name\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Name\". It is located at location 14\n",
      "\"Block\" column in Staur_2019_all is the yield column\n",
      " as it contains the text \"Block\". It is located at location 15\n",
      "\"GrainYield\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"GrainYield\". It is located at location 6\n",
      "\"Block\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Block\". It is located at location 7\n",
      "\"iBlock\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"iBlock\". It is located at location 8\n",
      "\"Entry\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Entry\". It is located at location 9\n",
      "\"Name\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Name\". It is located at location 10\n",
      "\"Pedigree\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Pedigree\". It is located at location 11\n",
      "\"Lodging\" column in Staur_2020_all_lodg is the yield column\n",
      " as it contains the text \"Lodging\". It is located at location 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GrainYield_Graminor_2019_all': 6,\n",
       " 'Block_Graminor_2019_all': 7,\n",
       " 'iBlock_Graminor_2019_all': 8,\n",
       " 'Entry_Graminor_2019_all': 9,\n",
       " 'Name_Graminor_2019_all': 10,\n",
       " 'Pedigree_Graminor_2019_all': 11,\n",
       " 'GrainYield_Graminor_2020_all': 6,\n",
       " 'Block_Graminor_2020_all': 7,\n",
       " 'iBlock_Graminor_2020_all': 8,\n",
       " 'Entry_Graminor_2020_all': 9,\n",
       " 'Name_Graminor_2020_all': 10,\n",
       " 'Pedigree_Graminor_2020_all': 11,\n",
       " 'GrainYield_Masbasis_2019_all': 6,\n",
       " 'Replicates_Masbasis_2019_all': 7,\n",
       " 'Block_Masbasis_2019_all': 8,\n",
       " 'Name_Masbasis_2019_all': 9,\n",
       " 'Line_Masbasis_2019_all': 10,\n",
       " 'Days2Heading_Masbasis_2019_all': 11,\n",
       " 'Days2Maturity_Masbasis_2019_all': 12,\n",
       " 'GrainYield_Masbasis_2020_all_lodg': 6,\n",
       " 'Replicates_Masbasis_2020_all_lodg': 7,\n",
       " 'Block_Masbasis_2020_all_lodg': 8,\n",
       " 'Name_Masbasis_2020_all_lodg': 9,\n",
       " 'Line_Masbasis_2020_all_lodg': 10,\n",
       " 'Maturity_Date_Masbasis_2020_all_lodg': 11,\n",
       " 'Days2Heading_Masbasis_2020_all_lodg': 12,\n",
       " 'Days2Maturity_Masbasis_2020_all_lodg': 13,\n",
       " 'Lodging_Masbasis_2020_all_lodg': 14,\n",
       " 'GrainYield_Robot_2020_all': 6,\n",
       " 'Block_Robot_2020_all': 7,\n",
       " 'Name_Robot_2020_all': 8,\n",
       " 'CodeName_Robot_2020_all': 9,\n",
       " 'Heading_Date_Robot_2020_all': 10,\n",
       " 'Maturity_Date_Robot_2020_all': 11,\n",
       " 'Days2Heading_Robot_2020_all': 12,\n",
       " 'Days2Maturity_Robot_2020_all': 13,\n",
       " 'GrainYield_Staur_2019_all': 6,\n",
       " 'iBlock_Staur_2019_all': 7,\n",
       " 'Entry_Staur_2019_all': 8,\n",
       " 'Pedigree_Staur_2019_all': 9,\n",
       " 'Replicates_Staur_2019_all': 10,\n",
       " 'Line_Staur_2019_all': 11,\n",
       " 'Days2Heading_Staur_2019_all': 12,\n",
       " 'Days2Maturity_Staur_2019_all': 13,\n",
       " 'Name_Staur_2019_all': 14,\n",
       " 'Block_Staur_2019_all': 15,\n",
       " 'GrainYield_Staur_2020_all_lodg': 6,\n",
       " 'Block_Staur_2020_all_lodg': 7,\n",
       " 'iBlock_Staur_2020_all_lodg': 8,\n",
       " 'Entry_Staur_2020_all_lodg': 9,\n",
       " 'Name_Staur_2020_all_lodg': 10,\n",
       " 'Pedigree_Staur_2020_all_lodg': 11,\n",
       " 'Lodging_Staur_2020_all_lodg': 12}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToDo: Add check for duplicate columns in the df\n",
    "\n",
    "base_indices\n",
    "\n",
    "spectral_indices\n",
    "\n",
    "yield_cols\n",
    "\n",
    "id_cols_new = ['Plot_ID']\n",
    "\n",
    "# Counter for location of column in columns list\n",
    "\n",
    "# Dict for saving the name and location of the yield column/s\n",
    "loc_yield_cols = {}\n",
    "for df in all_df:\n",
    "    loc = 0\n",
    "    for cols in locals()[df].columns.tolist():\n",
    "        for y_col in yield_cols:\n",
    "            if not cols.find(y_col):\n",
    "                loc_yield_cols[cols+'_'+df] = loc\n",
    "                print(f'\\\"{cols}\\\" column in {df} is the yield column\\n as it contains the text \\\"{y_col}\\\". It is located at location {loc}')\n",
    "        loc += 1\n",
    "\n",
    "    yield_cols_found = list(loc_yield_cols.keys())\n",
    "    target_cols=yield_cols_found[0]\n",
    "loc_yield_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding dates between heading and maturity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.419621Z",
     "start_time": "2021-10-28T09:03:47.413639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Days2Maturity',\n",
       " 'CodeName',\n",
       " 'Heading_Date',\n",
       " 'Pedigree',\n",
       " 'Lodging',\n",
       " 'GrainYield',\n",
       " 'Entry',\n",
       " 'Line',\n",
       " 'Name',\n",
       " 'Days2Heading',\n",
       " 'iBlock',\n",
       " 'Replicates',\n",
       " 'Maturity_Date',\n",
       " 'Block']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yield_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.436210Z",
     "start_time": "2021-10-28T09:03:47.421616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_all\n",
      "Masbasis_2020_all_lodg\n",
      "Robot_2020_all\n",
      "Staur_2019_all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all',\n",
       " 'Graminor_2020_all',\n",
       " 'Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all',\n",
       " 'Staur_2020_all_lodg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    if 'Days2Maturity' in temp_df.columns:\n",
    "        print(df)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring the important dates for each field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.442195Z",
     "start_time": "2021-10-28T09:03:47.437206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dates listed in dict in order; sowing, heading, maturity\n",
    "# The order of fields must be the same as in all_df list\n",
    "# sowing_dict = {\n",
    "#     'Graminor_2019': ['240419', 'XX', 'XX'],\n",
    "#     'Graminor_2020': ['150420', 'XX', 'XX'],\n",
    "#     'Masbasis_2019': ['190519', 'XX', 'XX'],\n",
    "#     'Masbasis_2020': ['150520', 'XX', 'XX'],\n",
    "#     'Robot_2020': ['200420', '170620', '310720'],\n",
    "#     'Staur_2019': ['040619', 'XX', 'XX'],\n",
    "#     'Staur_2020': ['210420', 'XX', 'XX'],\n",
    "# }\n",
    "\n",
    "sowing_dict = {\n",
    "    'Graminor_2019': '240419',\n",
    "    'Graminor_2020': '150420',\n",
    "    'Masbasis_2019': '190519',\n",
    "    'Masbasis_2020': '150520',\n",
    "    'Robot_2020': '200420',\n",
    "    'Staur_2019': '040619',\n",
    "    'Staur_2020': '210420',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering df which have Days2Maturity and Days2Heading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.462141Z",
     "start_time": "2021-10-28T09:03:47.449177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Graminor_2019_all': '240419',\n",
       " 'Graminor_2020_all': '150420',\n",
       " 'Masbasis_2019_all': '190519',\n",
       " 'Masbasis_2020_all_lodg': '150520',\n",
       " 'Robot_2020_all': '200420',\n",
       " 'Staur_2019_all': '040619',\n",
       " 'Staur_2020_all_lodg': '210420'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the dataset had Days 2 heading and days to maturity columns then create the\n",
    "# following dictionary with the respective sowing dates of each field as value\n",
    "all_df_sowing = {}\n",
    "\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    field_temp = df.split('_')[0]+'_'+df.split('_')[1]\n",
    "#     if 'Days2Heading' in temp_df.columns and 'Days2Maturity' in temp_df.columns:\n",
    "#         print(df)\n",
    "#         all_df_sowing[df] = sowing_dict[field_temp]\n",
    "    all_df_sowing[df] = sowing_dict[field_temp]\n",
    "\n",
    "all_df_sowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average DH and DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.611839Z",
     "start_time": "2021-10-28T09:03:47.593884Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Masbasis_2019_all': [68.18939393939394, 108.64393939393939],\n",
       " 'Masbasis_2020_all_lodg': [66.24839743589743, 87.794921875],\n",
       " 'Robot_2020_all': [61.09375, 110.84375],\n",
       " 'Staur_2019_all': [48.53333333333333, 101.25757575757575]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dictionary with average Days2Heading and Days2Maturity for fields whose data is available\n",
    "dict_avg_dh_dm = {}\n",
    "df_dh_dm = []\n",
    "for df in all_df_sowing.keys():\n",
    "    temp_df = locals()[df].copy()\n",
    "\n",
    "#     print('Days2Heading')\n",
    "#     print(locals()[df].Days2Heading.min(), ':      ', locals()[df].Days2Heading.max(), ':     ', locals()[df].Days2Heading.mean())\n",
    "#     print('Days2Maturity')\n",
    "#     print(locals()[df].Days2Maturity.min(), ':      ', locals()[df].Days2Maturity.max(), ':     ', locals()[df].Days2Maturity.mean())\n",
    "\n",
    "    if 'Days2Heading' in temp_df.columns and 'Days2Maturity' in temp_df.columns:\n",
    "        df_dh_dm.append(df)\n",
    "        dict_avg_dh_dm[df] = [locals()[df].Days2Heading.mean(), locals()[df].Days2Maturity.mean()]\n",
    "dict_avg_dh_dm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.620812Z",
     "start_time": "2021-10-28T09:03:47.613833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Days2Heading is 61.016218677156175\n",
      "Average Days2Maturity is 102.13504675662878\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "list_dh = []\n",
    "list_dm = []\n",
    "for field, dhdm in dict_avg_dh_dm.items():\n",
    "    list_dh.append(dhdm[0])\n",
    "    list_dm.append(dhdm[1])\n",
    "mean_dh = mean(list_dh)\n",
    "mean_dm = mean(list_dm)\n",
    "print(f'Average Days2Heading is {mean_dh}')\n",
    "print(f'Average Days2Maturity is {mean_dm}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.768802Z",
     "start_time": "2021-10-28T09:03:47.754830Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "from numpy import trapz\n",
    "# from scipy.integrate import cumulative_trapezoid\n",
    "\n",
    "from scipy.integrate import romb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.903943Z",
     "start_time": "2021-10-28T09:03:47.899953Z"
    }
   },
   "outputs": [],
   "source": [
    "# simps(temp_entries_dropna, days_sow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.913917Z",
     "start_time": "2021-10-28T09:03:47.908931Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# days_sow\n",
    "\n",
    "# days = [50, 64, 72, ((72 + 87) / 2), 87]\n",
    "# band = [21, 14, 9, ((9 + 2) / 2), 2]\n",
    "\n",
    "# days2 = [50, 64, 72, 87]\n",
    "# band2 = [21, 14, 9, 2]\n",
    "\n",
    "# simps(band, days), simps(band2, days2), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.920897Z",
     "start_time": "2021-10-28T09:03:47.915910Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp_entries_dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:47.928876Z",
     "start_time": "2021-10-28T09:03:47.922892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_all',\n",
       " 'Graminor_2020_all',\n",
       " 'Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all',\n",
       " 'Staur_2020_all_lodg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating df with Plot_ID and Grain_Yield only\n",
    "## Calculating AUC and creating new df with calculated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:04:50.156116Z",
     "start_time": "2021-10-28T09:03:48.073490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps (600, 41) Graminor_2019_Trapz (600, 41)\n",
      "Graminor_2020_Simps (800, 41) Graminor_2020_Trapz (800, 41)\n",
      "Masbasis_2019_Simps (528, 42) Masbasis_2019_Trapz (528, 42)\n",
      "Masbasis_2020_Simps (624, 44) Masbasis_2020_Trapz (624, 44)\n",
      "Robot_2020_Simps (96, 43) Robot_2020_Trapz (96, 43)\n",
      "Staur_2019_Simps (1328, 45) Staur_2019_Trapz (1328, 45)\n",
      "Staur_2020_Simps (1488, 42) Staur_2020_Trapz (1488, 42)\n"
     ]
    }
   ],
   "source": [
    "simp_df_all = []\n",
    "trapz_df_all = []\n",
    "samples_record_simps = {}\n",
    "for df, sowing in all_df_sowing.items():\n",
    "\n",
    "    temp_df = locals()[df].copy()\n",
    "    cols = temp_df.columns\n",
    "    \n",
    "    # Creating a list of columns which other than the indices (ID and yield columns)\n",
    "    # Making a temp list of yield columns since all entries from yield cols are not present in every df\n",
    "    temp_yield_cols = [x for x in temp_df.columns if x in yield_cols]\n",
    "    non_indices_cols = id_cols_new+temp_yield_cols\n",
    "#     print(non_indices_cols)\n",
    "    \n",
    "    df_auc_simps = temp_df[non_indices_cols].copy()\n",
    "    df_auc_trapz = temp_df[non_indices_cols].copy()\n",
    "#     display(df_auc.head())\n",
    "\n",
    "    # Calculating AUC and creating new df with calculated values\n",
    "    temp_samples = {}\n",
    "    for col_name in base_indices+spectral_indices:\n",
    "        df_simp = []\n",
    "        df_trapz = []\n",
    "        # Making temp_cols list avoids problems finding and differentiating 'OSAVI' and 'GOSAVI'\n",
    "        temp_cols = [x for x in cols if col_name.split('_') == x.split('_')[:-1]]\n",
    "        temp_dates = [dt.strptime(date.split('_')[-1], '%d%m%y').date() for date in temp_cols]\n",
    "\n",
    "        # Calculating the days from sowing,i.e. age of the crop in days\n",
    "        sowing_date = dt.strptime(sowing, '%d%m%y').date() \n",
    "        \n",
    "        temp_samples_list = []\n",
    "        for sample in range(temp_df.shape[0]):\n",
    "            # Number of days since sowing for each entry\n",
    "            days_sow = [(x-sowing_date).days for x in temp_dates]\n",
    "            # The respective value of the index in question \n",
    "            temp_entries = [temp_df[x][sample] for x in temp_cols]\n",
    "\n",
    "            #### DROPPING DATES OUTSIDE HEADING AND MATURITY DATES ####\n",
    "            \n",
    "            # Determining Days2Heading values\n",
    "            if 'Days2Heading' in temp_df.columns:\n",
    "                # Days to heading for current sample \n",
    "                DH = temp_df.Days2Heading[sample]\n",
    "                # If DH is missing then use the smallest of Mean DH from fields whose DH is available\n",
    "                if str(DH)=='nan':\n",
    "                    DH = round(min(list_dh))\n",
    "            else:\n",
    "                DH = round(min(list_dh))\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            if 'Days2Maturity' in temp_df.columns:\n",
    "                # Days to maturity for current sample \n",
    "                DM = temp_df.Days2Maturity[sample]\n",
    "                # If DM is missing then use the largest of Mean DM from fields whose DM is available\n",
    "                if str(DM)=='nan':\n",
    "                    DM = round(max(list_dm))\n",
    "            else:\n",
    "                DM = round(max(list_dm))  \n",
    "                    \n",
    "            DH = int(DH)\n",
    "            DM = int(DM)\n",
    "            # Making sure that the maturity comes after heading\n",
    "            if DM < DH:\n",
    "                print(DM, DH)\n",
    "            assert DM > DH\n",
    "#             print(DM, DH)\n",
    "            heading_date = sowing_date + timedelta(days=DH)\n",
    "            maturity_date = sowing_date + timedelta(days=DM)\n",
    "            \n",
    "            # Replacing the respective values of items in temp_entries with np.nan which correspond \n",
    "            # to dates not in between heading and maturity for that specific sub-plot\n",
    "#             temp_entries_filtered = [y if heading_date <= x <= maturity_date else np.nan for x,y in zip(temp_dates, temp_entries)]\n",
    "            \n",
    "            ## CHANGE: REMOVING LIMIT FOR HEADING DATE. USING ALL DATA BEFORE MATURITY\n",
    "            temp_entries_filtered = [y if x <= maturity_date else np.nan for x,y in zip(temp_dates, temp_entries)]\n",
    "\n",
    "            # Dropping missing(nan) values from the entries\n",
    "            temp_entries_dropna = [x for x in temp_entries_filtered if str(x) != 'nan']\n",
    "            days_before_dropping = days_sow.copy()\n",
    "            # Checking if the number of items in temp_entries_filtered and days_sow is the same\n",
    "            # If not, i.e., there are missing values(nan) in temp_entries_filtered then drop the\n",
    "            # respective entries from days_sow list\n",
    "            if not len(temp_entries_dropna) == len(days_sow):\n",
    "                # Dictionary comprehension\n",
    "                # Creating dictionary(dict comprehension) where temp_entries_filtered are not nan\n",
    "                dict_dropna = {i: [temp_entries_filtered[i], days_sow[i]] for i in range(len(temp_entries_filtered))\\\n",
    "                       if not str(temp_entries_filtered[i]) == 'nan' }\n",
    "                \n",
    "                # Checking if the previously created temp_entries_dropna is the same as the new that will\n",
    "                # be created from dict_dropna (Unnecessary check but curious to check if any problems arise)\n",
    "                assert temp_entries_dropna == [dict_dropna[i][0] for i in dict_dropna.keys()]\n",
    "                \n",
    "                # Creating new temp entries and days_sow after dropping nan and respective entries in days_sow\n",
    "                temp_entries_dropna = [dict_dropna[i][0] for i in dict_dropna.keys()]\n",
    "                days_sow = [dict_dropna[i][1] for i in dict_dropna.keys()]\n",
    "\n",
    "            # Checking if the lists have the same number of entries\n",
    "            if len(temp_entries_dropna) != len(days_sow):\n",
    "                print(df, col_name, temp_entries, days_before_dropping, temp_entries_dropna, days_sow, dict_dropna)\n",
    "            assert len(temp_entries_dropna) == len(days_sow)\n",
    "            \n",
    "            # Sorting both lists with dates in ascending order\n",
    "            days_sow, temp_entries_dropna = zip(*sorted(zip(days_sow, temp_entries_dropna)))\n",
    "            \n",
    "            simps_value = simps(temp_entries_dropna, days_sow)\n",
    "            trapz_value = trapz(temp_entries_dropna, days_sow)\n",
    "            \n",
    "            df_simp.append(simps_value)\n",
    "            df_trapz.append(trapz_value)\n",
    "            \n",
    "#             if simps_value == 0:\n",
    "#                 print(temp_entries_filtered, days_before_dropping, temp_entries_dropna, days_sow)\n",
    "            # Adding values to a list for reference and record to verify the results and identify problems later\n",
    "            temp_samples_list.append([df, col_name, temp_df['Plot_ID'][sample], simps_value, temp_entries_dropna, days_sow])\n",
    "        temp_samples[col_name] = temp_samples_list\n",
    "\n",
    "        # Insert the new column at the end, but before GrainYield\n",
    "        df_auc_simps.insert(len(df_auc_simps.columns)-1, col_name, df_simp)\n",
    "        df_auc_trapz.insert(len(df_auc_trapz.columns)-1, col_name, df_trapz)\n",
    "        \n",
    "    samples_record_simps[df.split('_')[0]+'_'+df.split('_')[1]] = temp_samples\n",
    "\n",
    "    # Adding the new name of the df to a list named simp_df_all\n",
    "    simp_df = df.split('_')[0]+'_'+df.split('_')[1]+'_Simps'\n",
    "    trapz_df = df.split('_')[0]+'_'+df.split('_')[1]+'_Trapz'\n",
    "\n",
    "    simp_df_all.append(simp_df)\n",
    "    trapz_df_all.append(trapz_df)\n",
    "    print(simp_df, df_auc_simps.shape, trapz_df, df_auc_trapz.shape)\n",
    "    locals()[simp_df] = df_auc_simps.copy()\n",
    "    locals()[trapz_df] = df_auc_trapz.copy()\n",
    "# simp_df_all, trapz_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:04:50.161704Z",
     "start_time": "2021-10-28T09:04:50.159111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Masbasis_2020_all_lodg[[x for x in Masbasis_2020_all_lodg.columns if 'EVI' in x]+['Plot_ID']].head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:04:50.180485Z",
     "start_time": "2021-10-28T09:04:50.165093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Graminor_2019', 'Graminor_2020', 'Masbasis_2019', 'Masbasis_2020', 'Robot_2020', 'Staur_2019', 'Staur_2020'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_record_simps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:04:50.189851Z",
     "start_time": "2021-10-28T09:04:50.182870Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp_entries_dropna, days_sow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:04:50.196833Z",
     "start_time": "2021-10-28T09:04:50.191846Z"
    }
   },
   "outputs": [],
   "source": [
    "# samples_record_simps['Masbasis_2020']['EVI'][149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T00:26:15.372830Z",
     "start_time": "2021-10-28T00:26:15.353429Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:38.145203Z",
     "start_time": "2021-10-28T00:26:19.258399Z"
    }
   },
   "outputs": [],
   "source": [
    "# from pycaret.anomaly import *\n",
    "# s = setup(Robot_2020_all, session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T09:03:38.147198Z",
     "start_time": "2021-10-28T00:26:27.603Z"
    }
   },
   "outputs": [],
   "source": [
    "# iforest = create_model('iforest', fraction = 0.1)\n",
    "# iforest_results = assign_model(iforest)\n",
    "# iforest_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iforest_results[iforest_results['Anomaly'] == 1].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# # plot value on y-axis and date on x-axis\n",
    "# fig = px.line(iforest_results, x=iforest_results.index, y=\"value\", title='NYC TAXI TRIPS - UNSUPERVISED ANOMALY DETECTION', template = 'plotly_dark')\n",
    "# # create list of outlier_dates\n",
    "# outlier_dates = iforest_results[iforest_results['Anomaly'] == 1].index\n",
    "# # obtain y value of anomalies to plot\n",
    "# y_values = [iforest_results.loc[i]['value'] for i in outlier_dates]\n",
    "# fig.add_trace(go.Scatter(x=outlier_dates, y=y_values, mode = 'markers', \n",
    "#                 name = 'Anomaly', \n",
    "#                 marker=dict(color='red',size=10)))\n",
    "        \n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T00:08:38.223304Z",
     "start_time": "2021-10-28T00:08:38.114733Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(days_sow, temp_entries_dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-28T00:08:49.006144Z",
     "start_time": "2021-10-28T00:08:48.987167Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp_entries_dropna, days_sow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for Zero values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.663787Z",
     "start_time": "2021-10-27T22:35:49.478748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Masbasis_2019_Simps.info(null_counts=True)\n",
    "for df in simp_df_all+trapz_df_all:\n",
    "    temp_df = locals()[df][base_indices+spectral_indices].copy()\n",
    "    for col in temp_df.columns.to_list():\n",
    "        if (temp_df[col]==0).sum() >0:\n",
    "#             print(temp_df.columns.to_list())\n",
    "            print(df, col, (temp_df[col]==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.678747Z",
     "start_time": "2021-10-27T22:35:49.665782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Blue', 'Green', 'Red', 'RedEdge', 'NIR', 'NDVI', 'MTCI', 'DVI', 'GDVI', 'MTCI_CI', 'EXG', 'EXGR', 'RDVI', 'TDVI', 'GNDVI', 'NDRE', 'SCCI', 'EVI', 'TVI', 'VARI', 'GARI', 'GCI', 'GLI', 'NLI', 'MNLI', 'SAVI', 'GSAVI', 'OSAVI', 'GOSAVI', 'MSAVI2', 'MSR', 'GRVI', 'WDRVI', 'SR'])\n"
     ]
    }
   ],
   "source": [
    "# Plot_ID, simps_value, trapz_value, temp_cols, temp_dates, sowing_date, DH, DM, heading_date, maturity_date, temp_entries, days_before, temp_entries_dropna, days_sow])\n",
    "\n",
    "list_problem = []\n",
    "pprint(samples_record_simps['Masbasis_2019'].keys())\n",
    "for keya, data in samples_record_simps['Masbasis_2019'].items():\n",
    "    for x in data:\n",
    "        if x [1]==0:\n",
    "            temp_entries = x[10]\n",
    "            days_sow = x[11]\n",
    "#             simps(xx,dd)\n",
    "            sowing_date = x[5]\n",
    "            DH = x[6]\n",
    "            DM = x[7]\n",
    "            temp_dates = x[4]\n",
    "            heading_date= x[8]\n",
    "            maturity_date = x[9]\n",
    "#             print(x[0], x[5])\n",
    "#             print(x)\n",
    "            list_problem.append(x[0])\n",
    "            temp_entries_filtered = [x if heading_date <= x <= maturity_date else np.nan for x,y in zip(temp_dates, temp_entries)]\n",
    "            print(heading_date.strftime('%d%m%y'),[x.strftime('%d%m%y') for x in temp_dates],  maturity_date.strftime('%d%m%y'))\n",
    "            print('************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.694705Z",
     "start_time": "2021-10-27T22:35:49.680742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.date(2020, 4, 21),\n",
       " 49,\n",
       " 111,\n",
       " datetime.date(2020, 6, 9),\n",
       " datetime.date(2020, 8, 10),\n",
       " [datetime.date(2020, 7, 31),\n",
       "  datetime.date(2020, 7, 24),\n",
       "  datetime.date(2020, 7, 16),\n",
       "  datetime.date(2020, 7, 9),\n",
       "  datetime.date(2020, 6, 25),\n",
       "  datetime.date(2020, 6, 20)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "temp_entries_filtered = [y if heading_date <= x <= maturity_date else np.nan for x,y in zip(temp_dates, temp_entries)]\n",
    "temp_entries_filtered\n",
    "# \n",
    "sowing_date, DH, DM, heading_date, maturity_date, temp_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.710662Z",
     "start_time": "2021-10-27T22:35:49.696699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.284922487860852,\n",
       " 6.443754326877634,\n",
       " 8.757489999068145,\n",
       " 12.97462438907558,\n",
       " 13.55026739342454,\n",
       " 3.991561550234324]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.742672Z",
     "start_time": "2021-10-27T22:35:49.712657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue_070819</th>\n",
       "      <th>Blue_290719</th>\n",
       "      <th>Blue_220719</th>\n",
       "      <th>Blue_150719</th>\n",
       "      <th>Blue_050719</th>\n",
       "      <th>Blue_280619</th>\n",
       "      <th>Blue_260619</th>\n",
       "      <th>Blue_060619</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.027306</td>\n",
       "      <td>0.016146</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.023842</td>\n",
       "      <td>0.009863</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.024337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Blue_070819  Blue_290719  Blue_220719  Blue_150719  Blue_050719  \\\n",
       "95     0.027306     0.016146     0.014434     0.023842     0.009863   \n",
       "\n",
       "    Blue_280619  Blue_260619  Blue_060619  \n",
       "95     0.015405     0.021012     0.024337  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blu_cols = [x for x in Masbasis_2019_all.columns if 'Blue' in x]\n",
    "\n",
    "Masbasis_2019_all['Plot_ID']\n",
    "Masbasis_2019_all.iloc[95:96,:][blu_cols]\n",
    "\n",
    "# list_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.758141Z",
     "start_time": "2021-10-27T22:35:49.744178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>Blue_070819</th>\n",
       "      <th>Blue_290719</th>\n",
       "      <th>Blue_220719</th>\n",
       "      <th>Blue_150719</th>\n",
       "      <th>Blue_050719</th>\n",
       "      <th>Blue_280619</th>\n",
       "      <th>Blue_260619</th>\n",
       "      <th>Blue_060619</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Plot_ID, Blue_070819, Blue_290719, Blue_220719, Blue_150719, Blue_050719, Blue_280619, Blue_260619, Blue_060619]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_found = []\n",
    "for x in list_problem:\n",
    "    idx_found.append(int(Masbasis_2019_all[Masbasis_2019_all['Plot_ID']==x].index.values))\n",
    "#     print()\n",
    "Masbasis_2019_all.iloc[idx_found,:][['Plot_ID']+blu_cols]\n",
    "# idx_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.774099Z",
     "start_time": "2021-10-27T22:35:49.759137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['Plot_ID']==x\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.790055Z",
     "start_time": "2021-10-27T22:35:49.775095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Masbasis_2019_all',\n",
       " 'Masbasis_2020_all_lodg',\n",
       " 'Robot_2020_all',\n",
       " 'Staur_2019_all']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dh_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.806014Z",
     "start_time": "2021-10-27T22:35:49.791054Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps\n",
      "Grain Yield data missing for  1 out of  600\n",
      "Graminor_2020_Simps\n",
      "Grain Yield data missing for  1 out of  800\n",
      "Masbasis_2019_Simps\n",
      "Grain Yield data missing for  6 out of  528\n",
      "Masbasis_2020_Simps\n",
      "Grain Yield data missing for  116 out of  624\n",
      "Robot_2020_Simps\n",
      "Grain Yield data missing for  0 out of  96\n",
      "Staur_2019_Simps\n",
      "Grain Yield data missing for  0 out of  1328\n",
      "Staur_2020_Simps\n",
      "Grain Yield data missing for  568 out of  1488\n"
     ]
    }
   ],
   "source": [
    "# Masbasis_2019_Simps.info(null_counts=True)\n",
    "for df in simp_df_all:\n",
    "    temp_df = locals()[df].copy()\n",
    "#     print('*************', df, '**************')\n",
    "#     print(locals()[df].info())\n",
    "\n",
    "    print (df)\n",
    "    print('Grain Yield data missing for ', temp_df['GrainYield'].isna().sum(), 'out of ', temp_df.shape[0])\n",
    "# Graminor_2019_Simps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T23:35:44.442995Z",
     "start_time": "2021-10-10T23:35:44.424577Z"
    }
   },
   "source": [
    "Yield data of Staur 2020 is disjoint with the bands data. There are 568 subplots whose yield is not available in the yield file and there are 10 subplots in the yield data which are not in the bands data sheets.\n",
    "\n",
    "\n",
    "There are atleast 116 missing grain yield values in Masbasis 2020 yield dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.852887Z",
     "start_time": "2021-10-27T22:35:49.807010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps Dropped entries 0 : 600 600\n",
      "Graminor_2020_Simps Dropped entries 0 : 800 800\n",
      "Masbasis_2019_Simps Dropped entries 0 : 528 528\n",
      "Masbasis_2020_Simps Dropped entries 0 : 624 624\n",
      "Robot_2020_Simps Dropped entries 0 : 96 96\n",
      "Staur_2019_Simps Dropped entries 0 : 1328 1328\n",
      "Staur_2020_Simps Dropped entries 0 : 1488 1488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Simps_dropna',\n",
       " 'Graminor_2020_Simps_dropna',\n",
       " 'Masbasis_2019_Simps_dropna',\n",
       " 'Masbasis_2020_Simps_dropna',\n",
       " 'Robot_2020_Simps_dropna',\n",
       " 'Staur_2019_Simps_dropna',\n",
       " 'Staur_2020_Simps_dropna']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simp_df_all_dropna = []\n",
    "for df in simp_df_all:\n",
    "    temp_df = locals()[df].copy()\n",
    "    rows = temp_df.shape[0]\n",
    "#     print(temp_df.shape)\n",
    "    temp_df.dropna(subset=['Blue'],inplace = True)\n",
    "    print(df, 'Dropped entries', rows- temp_df.shape[0],':', rows, temp_df.shape[0])\n",
    "    new_df = df+'_dropna'\n",
    "    locals()[new_df] = temp_df.copy()\n",
    "    simp_df_all_dropna.append(new_df)\n",
    "simp_df_all_dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:49.883805Z",
     "start_time": "2021-10-27T22:35:49.853885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Trapz Dropped entries 0 : 600 600\n",
      "Graminor_2020_Trapz Dropped entries 0 : 800 800\n",
      "Masbasis_2019_Trapz Dropped entries 0 : 528 528\n",
      "Masbasis_2020_Trapz Dropped entries 0 : 624 624\n",
      "Robot_2020_Trapz Dropped entries 0 : 96 96\n",
      "Staur_2019_Trapz Dropped entries 0 : 1328 1328\n",
      "Staur_2020_Trapz Dropped entries 0 : 1488 1488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Trapz_dropna',\n",
       " 'Graminor_2020_Trapz_dropna',\n",
       " 'Masbasis_2019_Trapz_dropna',\n",
       " 'Masbasis_2020_Trapz_dropna',\n",
       " 'Robot_2020_Trapz_dropna',\n",
       " 'Staur_2019_Trapz_dropna',\n",
       " 'Staur_2020_Trapz_dropna']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trapz_df_all_dropna = []\n",
    "for df in trapz_df_all:\n",
    "    temp_df = locals()[df].copy()\n",
    "    rows = temp_df.shape[0]\n",
    "#     print(temp_df.shape)\n",
    "    temp_df.dropna(subset=['Blue'],inplace = True)\n",
    "    print(df, 'Dropped entries', rows- temp_df.shape[0],':', rows, temp_df.shape[0])\n",
    "    new_df = df+'_dropna'\n",
    "    locals()[new_df] = temp_df.copy()\n",
    "    trapz_df_all_dropna.append(new_df)\n",
    "trapz_df_all_dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old:  \n",
    "Masbasis_2019_Trapz Dropped entries 0 : 528 528  \n",
    "Masbasis_2020_Trapz Dropped entries 112 : 659 547  \n",
    "Robot_2020_Trapz Dropped entries 0 : 96 96  \n",
    "Staur_2019_Trapz Dropped entries 1166 : 1328 162  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.232425Z",
     "start_time": "2021-10-27T22:35:49.885801Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2020_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2020_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot_2020_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_2019_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_2020_Simps_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2020_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2019_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masbasis_2020_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot_2020_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_2019_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staur_2020_Trapz_dropna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def describe_nan(df):\n",
    "    return pd.DataFrame([(i, df[df[i].isna()].shape[0],df[df[i].isna()].shape[0]/df.shape[0]) for i in df.columns], columns=['column', 'nan_counts', 'nan_rate'])\n",
    "for df in simp_df_all_dropna+trapz_df_all_dropna:\n",
    "    print(df)\n",
    "    display(describe_nan(locals()[df][base_indices+spectral_indices+['GrainYield']]).nan_counts.sum())\n",
    "#     display(describe_nan(locals()[df][base_indices+spectral_indices+['GrainYield']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vollebekk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.388009Z",
     "start_time": "2021-10-27T22:35:50.233422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time measured', 'Middeltemperatur i 2m hÃ¸yde (TM)',\n",
       "       'Maksimum lufttemperatur i 2m hÃ¸yde (TX)',\n",
       "       'Minimums lufttemperatur i 2m hÃ¸yde (TN)', 'NedbÃ¸r (RR)',\n",
       "       'Relativ luftfuktighet i 2m', 'Relativ luftfuktighet i 2m.1',\n",
       "       'Bladfuktighet i 2m hÃ¸yde (BT)', ' 10 min glidende middel (FF2)',\n",
       "       ' vindkast (FG2)', 'Vindhastighet i 2m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_vollebekk = pd.read_csv(weather_data_vollebekk)\n",
    "\n",
    "# Converting date time to python datetime\n",
    "weather_vollebekk['Time measured'] = pd.to_datetime(weather_vollebekk['Time measured'], infer_datetime_format=True)\n",
    "# weather_vollebekk['Time measured'] = weather_vollebekk['Time measured'].dt.normalize()\n",
    "\n",
    "# Removing timezone info from datetime sice other date data is without timezone info\n",
    "weather_vollebekk['Time measured'] = pd.Series(x.replace(tzinfo=None) for x in weather_vollebekk['Time measured'])\n",
    "\n",
    "weather_vollebekk.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vollebekk: Dropping the two xolumns whixh are not in staur weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.402969Z",
     "start_time": "2021-10-27T22:35:50.389006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time measured', 'Middeltemperatur i 2m hÃ¸yde (TM)',\n",
       "       'Maksimum lufttemperatur i 2m hÃ¸yde (TX)',\n",
       "       'Minimums lufttemperatur i 2m hÃ¸yde (TN)', 'NedbÃ¸r (RR)',\n",
       "       'Relativ luftfuktighet i 2m', 'Relativ luftfuktighet i 2m.1',\n",
       "       ' vindkast (FG2)', 'Vindhastighet i 2m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_vollebekk.drop(['Bladfuktighet i 2m hÃ¸yde (BT)', ' 10 min glidende middel (FF2)'], axis='columns', inplace=True)\n",
    "weather_vollebekk.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.588983Z",
     "start_time": "2021-10-27T22:35:50.404971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time measured', 'Middeltemperatur i 2m hÃ¸yde (TM)',\n",
       "       'Maksimum lufttemperatur i 2m hÃ¸yde (TX)',\n",
       "       'Minimums lufttemperatur i 2m hÃ¸yde (TN)', 'NedbÃ¸r (RR)',\n",
       "       'Relativ luftfuktighet i 2m', 'Relativ luftfuktighet i 2m.1',\n",
       "       ' vindkast (FG2)', 'Vindhastighet i 2m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_staur = pd.read_csv(weather_data_staur)\n",
    "\n",
    "# Converting date time to python datetime\n",
    "weather_staur['Time measured'] = pd.to_datetime(weather_staur['Time measured'], infer_datetime_format=True)\n",
    "# weather_staur['Time measured'] = weather_staur['Time measured'].dt.normalize()\n",
    "\n",
    "# Removing timezone info from datetime sice other date data is without timezone info\n",
    "weather_staur['Time measured'] = pd.Series(x.replace(tzinfo=None) for x in weather_staur['Time measured'])\n",
    "\n",
    "weather_staur.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if both weather datas have same colummns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.604168Z",
     "start_time": "2021-10-27T22:35:50.589980Z"
    }
   },
   "outputs": [],
   "source": [
    "assert weather_vollebekk.columns.tolist() == weather_staur.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.620125Z",
     "start_time": "2021-10-27T22:35:50.605165Z"
    }
   },
   "outputs": [],
   "source": [
    "# Translated the column heading using google translate\n",
    "\n",
    "\n",
    "weather_vollebekk.columns = ['Time measured', 'Average temperature at 2m altitude (TM)',\n",
    "        'Maximum air temperature at 2m altitude (TX)',\n",
    "        'Minimum air temperature at 2m altitude (TN)', 'Precipitation (RR)',\n",
    "        'Relative humidity in 2m', 'Relative humidity in 2m.1',\n",
    "        'Wind gust (FG2)', 'Wind speed in 2m']\n",
    "\n",
    "\n",
    "# Translated the column heading using google translate\n",
    "\n",
    "weather_staur.columns = ['Time measured', 'Average temperature at 2m altitude (TM)',\n",
    "        'Maximum air temperature at 2m altitude (TX)',\n",
    "        'Minimum air temperature at 2m altitude (TN)', 'Precipitation (RR)',\n",
    "        'Relative humidity in 2m', 'Relative humidity in 2m.1',\n",
    "        'Wind gust (FG2)', 'Wind speed in 2m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Craeting a list of min and max date in every field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.636083Z",
     "start_time": "2021-10-27T22:35:50.621125Z"
    }
   },
   "outputs": [],
   "source": [
    "max_min_dates = {}\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    dates = [x.split('_')[1] for x in temp_df.columns if 'Blue' in x]\n",
    "    df_name_temp = df.split('_')[0]+'_'+df.split('_')[1]\n",
    "    sowing_date_temp = dt.strptime(sowing_dict[df_name_temp], '%d%m%y')\n",
    "    min_date_temp = min([dt.strptime(x, '%d%m%y') for x in dates ])\n",
    "    max_date_temp = max([dt.strptime(x, '%d%m%y') for x in dates ])\n",
    "    max_min_dates[df] = [sowing_date_temp, min_date_temp, max_date_temp]\n",
    "# max_min_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T23:34:52.239619Z",
     "start_time": "2021-10-06T23:34:52.233535Z"
    }
   },
   "source": [
    "## Calculating average DH and DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.652040Z",
     "start_time": "2021-10-27T22:35:50.640086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Masbasis_2019_all': [68.18939393939394, 108.64393939393939],\n",
       " 'Masbasis_2020_all_lodg': [66.24839743589743, 87.794921875],\n",
       " 'Robot_2020_all': [61.09375, 110.84375],\n",
       " 'Staur_2019_all': [48.53333333333333, 101.25757575757575]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_avg_dh_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.667998Z",
     "start_time": "2021-10-27T22:35:50.654036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Days2Heading is 61.016218677156175\n",
      "Average Days2Maturity is 102.13504675662878\n"
     ]
    }
   ],
   "source": [
    "print(f'Average Days2Heading is {mean_dh}')\n",
    "print(f'Average Days2Maturity is {mean_dm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.856648Z",
     "start_time": "2021-10-27T22:35:50.668995Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_weather_agg',\n",
       " 'Graminor_2020_weather_agg',\n",
       " 'Masbasis_2019_weather_agg',\n",
       " 'Masbasis_2020_weather_agg',\n",
       " 'Robot_2020_weather_agg',\n",
       " 'Staur_2019_weather_agg',\n",
       " 'Staur_2020_weather_agg']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weather data for days from sowing date. Largerst of the average number of Days2Maturity \n",
    "# is a good measaure to use\n",
    "# Could have used max_date(last date availabel for the field) but that date does not \n",
    "# correspond to the actual crop maturity.\n",
    "# So using approxipame maturity time is a better measure of the affect of weather on yield\n",
    "days_delta = max(list_dm)\n",
    "\n",
    "weather_dfs = []\n",
    "weathers_processed_df = []\n",
    "for df, dates in max_min_dates.items():\n",
    "    df_weather_temp = pd.DataFrame()\n",
    "\n",
    "    sowing_date_temp = dates[0]\n",
    "    min_date_temp = dates[1]\n",
    "    max_date_temp = dates[2]\n",
    "    \n",
    "    if 'Staur' in df:\n",
    "        # Filtering the weather date from sowing_date to max_date the data is available for\n",
    "        temp_weather = weather_staur.loc[(weather_staur['Time measured'] >= sowing_date_temp) &\\\n",
    "                              (weather_staur['Time measured'] <= sowing_date_temp + timedelta(days=days_delta))]\n",
    "        # Filling the missing values with the average value of the area for the given complete weather data\n",
    "        temp_weather.fillna(weather_staur.mean(), inplace = True)\n",
    "\n",
    "    else:\n",
    "        # Filtering the weather date from sowing_date to max_date the data is available for\n",
    "        temp_weather = weather_vollebekk.loc[(weather_vollebekk['Time measured'] >= sowing_date_temp) &\\\n",
    "                              (weather_vollebekk['Time measured'] <= sowing_date_temp + timedelta(days=days_delta))]\n",
    "        # Filling the missing values with the average value of the area for the given complete weather data\n",
    "        temp_weather.fillna(weather_vollebekk.mean(), inplace = True)\n",
    "\n",
    "#     print(df, sowing_date_temp.date(), min_date_temp.date(), max_date_temp.date())\n",
    "#     print(temp_weather.shape)\n",
    "\n",
    "#     # See info to find hoe many missing values and in which column\n",
    "#     display(temp_weather.info())\n",
    "\n",
    "    # Filling themissing values with the average of the column\n",
    "    # Applying Only on columns with NaN values\n",
    "    for i in temp_weather.columns[temp_weather.isnull().any(axis=0)]:\n",
    "        temp_weather[i].fillna(temp_weather[i].mean(),inplace=True)\n",
    "    # Drop the time measures column\n",
    "    temp_weather.drop(['Time measured'], axis=1, inplace=True)\n",
    "    \n",
    "    df_weat_temp = df.split('_')[0]+'_'+df.split('_')[1]+'_weather_all'\n",
    "    locals()[df_name_temp] = temp_weather.copy()\n",
    "    weather_dfs.append(df_name_temp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Aggregating the weather data using several statistical methods\n",
    "    mean_df = temp_weather.mean().to_frame().transpose().add_prefix('MEAN ')\n",
    "    median_df = temp_weather.median().to_frame().transpose().add_prefix('MEDIAN ')\n",
    "    # Different for mode since mode returns a df, instead of series object\n",
    "    mode_df = temp_weather.mode().transpose().iloc[:,0].to_frame().transpose().add_prefix('MODE ')\n",
    "    sum_df = temp_weather.sum().to_frame().transpose().add_prefix('SUM ')\n",
    "    min_df = temp_weather.min().to_frame().transpose().add_prefix('MIN ')\n",
    "    max_df = temp_weather.max().to_frame().transpose().add_prefix('MAX ')\n",
    "    std_df = temp_weather.std().to_frame().transpose().add_prefix('STD_DEV ')\n",
    "    # Reset index in quantile since it takes quantile of index as well\n",
    "    quantile_25 = temp_weather.quantile(q=0.25).to_frame().transpose().add_prefix('QUANTILE_25 ').reset_index(drop=True)\n",
    "    quantile_50 = temp_weather.quantile(q=0.5).to_frame().transpose().add_prefix('QUANTILE_50 ').reset_index(drop=True)\n",
    "    quantile_75 = temp_weather.quantile(q=0.75).to_frame().transpose().add_prefix('QUANTILE_75 ').reset_index(drop=True)\n",
    "\n",
    "    single_row_df = pd.concat([mean_df, median_df, mode_df, sum_df, min_df, max_df, std_df, quantile_25, quantile_50, quantile_75], axis=1)\n",
    "    \n",
    "    if single_row_df.isna().sum().sum() > 1:\n",
    "        print(df)\n",
    "        print(single_row_df.isna().sum())\n",
    "        raise ValueError\n",
    "#     display(single_row_df)\n",
    "\n",
    "    df_processed_temp = df.split('_')[0]+'_'+df.split('_')[1]+'_weather_agg'\n",
    "    locals()[df_processed_temp] = single_row_df.copy()\n",
    "    weathers_processed_df.append(df_processed_temp)\n",
    "weathers_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.872607Z",
     "start_time": "2021-10-27T22:35:50.857646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 80)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Masbasis_2019_weather_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.888564Z",
     "start_time": "2021-10-27T22:35:50.873604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Staur_2020_weather_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.904522Z",
     "start_time": "2021-10-27T22:35:50.889561Z"
    }
   },
   "outputs": [],
   "source": [
    "vollebekk_fields_weather = [x for x in weathers_processed_df if 'Staur' not  in x]\n",
    "staur_fields_weather = [x for x in weathers_processed_df if 'Staur' in x]\n",
    "\n",
    "weather_cols_vollebekk = locals()[vollebekk_fields_weather[0]].columns.tolist()\n",
    "weather_cols_staur = locals()[staur_fields_weather[0]].columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Weather Indices for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.920480Z",
     "start_time": "2021-10-27T22:35:50.905519Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure the folder/dir is there. If not, create one\n",
    "os.makedirs(main_path, exist_ok=True)\n",
    "import json\n",
    "a_file = open(main_path+'vollebekk_weather_columns.json', \"w\")\n",
    "json.dump(weather_cols_vollebekk, a_file)\n",
    "a_file.close()\n",
    "\n",
    "# a_file = open(\"Data\\vollebekk_weather_columns.json\", \"r\")\n",
    "# output_str = a_file.read()\n",
    "\n",
    "# # The file is imported as string\n",
    "# # Converting it to python format\n",
    "# weather_cols_vollebekk = json.loads(output_str)\n",
    "# a_file.close()\n",
    "# print(weather_cols_vollebekk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:50.936437Z",
     "start_time": "2021-10-27T22:35:50.921477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure the folder/dir is there. If not, create one\n",
    "os.makedirs(main_path, exist_ok=True)\n",
    "import json\n",
    "a_file = open(main_path+'staur_weather_columns.json', \"w\")\n",
    "json.dump(weather_cols_staur, a_file)\n",
    "a_file.close()\n",
    "\n",
    "# a_file = open(\"Data\\staur_weather_columns.json\", \"r\")\n",
    "# output_str = a_file.read()\n",
    "\n",
    "# # The file is imported as string\n",
    "# # Converting it to python format\n",
    "# weather_cols_staur = json.loads(output_str)\n",
    "# a_file.close()\n",
    "# print(weather_cols_staur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding weather data to the simps integrated df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:51.015665Z",
     "start_time": "2021-10-27T22:35:50.937434Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_export = []\n",
    "for df in simp_df_all_dropna+trapz_df_all_dropna:\n",
    "    temp_df = locals()[df].copy()\n",
    "    \n",
    "    field_name = df.split('_')[0]+'_'+df.split('_')[1]\n",
    "    integration_type = df.split('_')[2]\n",
    "    \n",
    "    single_row_name = field_name+'_weather_agg'\n",
    "    single_row_df = locals()[single_row_name]\n",
    "    # Replicating the single_row data multiple times to make the df equal to the number of rows in the original df\n",
    "    rows_df = temp_df.shape[0] \n",
    "    new_df = pd.DataFrame(np.repeat(single_row_df.values, rows_df, axis=0), columns=single_row_df.columns)\n",
    "    \n",
    "    pd.concat([temp_df, new_df], axis=1)\n",
    "    merged_df = pd.concat([temp_df, new_df], axis=1)\n",
    "    \n",
    "    locals()[field_name+'_'+integration_type] = merged_df.copy()\n",
    "    df_to_export.append(field_name+'_'+integration_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:51.031623Z",
     "start_time": "2021-10-27T22:35:51.017660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Plot_ID', 'GrainYield', 'Block', 'iBlock', 'Entry', 'Name', 'Blue',\n",
       "       'Green', 'Red', 'RedEdge',\n",
       "       ...\n",
       "       'QUANTILE_50 Wind gust (FG2)', 'QUANTILE_50 Wind speed in 2m',\n",
       "       'QUANTILE_75 Average temperature at 2m altitude (TM)',\n",
       "       'QUANTILE_75 Maximum air temperature at 2m altitude (TX)',\n",
       "       'QUANTILE_75 Minimum air temperature at 2m altitude (TN)',\n",
       "       'QUANTILE_75 Precipitation (RR)', 'QUANTILE_75 Relative humidity in 2m',\n",
       "       'QUANTILE_75 Relative humidity in 2m.1', 'QUANTILE_75 Wind gust (FG2)',\n",
       "       'QUANTILE_75 Wind speed in 2m'],\n",
       "      dtype='object', length=121)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graminor_2019_Simps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:51.157288Z",
     "start_time": "2021-10-27T22:35:51.033618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>GrainYield</th>\n",
       "      <th>Block</th>\n",
       "      <th>iBlock</th>\n",
       "      <th>Entry</th>\n",
       "      <th>Name</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>RedEdge</th>\n",
       "      <th>...</th>\n",
       "      <th>QUANTILE_50 Wind gust (FG2)</th>\n",
       "      <th>QUANTILE_50 Wind speed in 2m</th>\n",
       "      <th>QUANTILE_75 Average temperature at 2m altitude (TM)</th>\n",
       "      <th>QUANTILE_75 Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>QUANTILE_75 Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>QUANTILE_75 Precipitation (RR)</th>\n",
       "      <th>QUANTILE_75 Relative humidity in 2m</th>\n",
       "      <th>QUANTILE_75 Relative humidity in 2m.1</th>\n",
       "      <th>QUANTILE_75 Wind gust (FG2)</th>\n",
       "      <th>QUANTILE_75 Wind speed in 2m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>499.624440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Zebra</td>\n",
       "      <td>2.730156</td>\n",
       "      <td>6.636563</td>\n",
       "      <td>5.810611</td>\n",
       "      <td>12.271557</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>515.532751</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>GN14547</td>\n",
       "      <td>2.592873</td>\n",
       "      <td>6.884701</td>\n",
       "      <td>5.349383</td>\n",
       "      <td>12.983170</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>529.501025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Tarrafal</td>\n",
       "      <td>2.501096</td>\n",
       "      <td>6.534736</td>\n",
       "      <td>5.489296</td>\n",
       "      <td>12.598181</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>544.503985</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>GN12760</td>\n",
       "      <td>2.435992</td>\n",
       "      <td>6.382933</td>\n",
       "      <td>5.114914</td>\n",
       "      <td>12.268243</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>529.501025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Bjarne</td>\n",
       "      <td>2.443793</td>\n",
       "      <td>6.538687</td>\n",
       "      <td>5.222022</td>\n",
       "      <td>12.900846</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>872</td>\n",
       "      <td>469.682277</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>GN19602</td>\n",
       "      <td>1.603014</td>\n",
       "      <td>5.170059</td>\n",
       "      <td>2.366899</td>\n",
       "      <td>11.045714</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>873</td>\n",
       "      <td>594.682657</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>GN19587</td>\n",
       "      <td>1.761630</td>\n",
       "      <td>5.725813</td>\n",
       "      <td>2.633292</td>\n",
       "      <td>12.048401</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>874</td>\n",
       "      <td>528.060114</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>GN19599</td>\n",
       "      <td>1.669110</td>\n",
       "      <td>5.587970</td>\n",
       "      <td>2.539977</td>\n",
       "      <td>12.098062</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>875</td>\n",
       "      <td>489.629146</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>GN19590</td>\n",
       "      <td>2.471685</td>\n",
       "      <td>6.540378</td>\n",
       "      <td>4.632317</td>\n",
       "      <td>12.512835</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>801</td>\n",
       "      <td>591.977989</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>GN17621</td>\n",
       "      <td>1.692110</td>\n",
       "      <td>5.326152</td>\n",
       "      <td>2.587565</td>\n",
       "      <td>12.170790</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>22.95</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.838274</td>\n",
       "      <td>84.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>15.95</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Plot_ID  GrainYield  Block  iBlock  Entry      Name      Blue     Green  \\\n",
       "0        101  499.624440      1       1      1     Zebra  2.730156  6.636563   \n",
       "1        102  515.532751      1       1     11   GN14547  2.592873  6.884701   \n",
       "2        103  529.501025      1       1     13  Tarrafal  2.501096  6.534736   \n",
       "3        104  544.503985      1       1     14   GN12760  2.435992  6.382933   \n",
       "4        105  529.501025      1       1      4    Bjarne  2.443793  6.538687   \n",
       "..       ...         ...    ...     ...    ...       ...       ...       ...   \n",
       "595      872  469.682277      4      20     24   GN19602  1.603014  5.170059   \n",
       "596      873  594.682657      4      20      9   GN19587  1.761630  5.725813   \n",
       "597      874  528.060114      4      20     21   GN19599  1.669110  5.587970   \n",
       "598      875  489.629146      4      20     12   GN19590  2.471685  6.540378   \n",
       "599      801  591.977989      2       6     12   GN17621  1.692110  5.326152   \n",
       "\n",
       "          Red    RedEdge  ...  QUANTILE_50 Wind gust (FG2)  \\\n",
       "0    5.810611  12.271557  ...                         14.5   \n",
       "1    5.349383  12.983170  ...                         14.5   \n",
       "2    5.489296  12.598181  ...                         14.5   \n",
       "3    5.114914  12.268243  ...                         14.5   \n",
       "4    5.222022  12.900846  ...                         14.5   \n",
       "..        ...        ...  ...                          ...   \n",
       "595  2.366899  11.045714  ...                         14.5   \n",
       "596  2.633292  12.048401  ...                         14.5   \n",
       "597  2.539977  12.098062  ...                         14.5   \n",
       "598  4.632317  12.512835  ...                         14.5   \n",
       "599  2.587565  12.170790  ...                         14.5   \n",
       "\n",
       "     QUANTILE_50 Wind speed in 2m  \\\n",
       "0                            15.2   \n",
       "1                            15.2   \n",
       "2                            15.2   \n",
       "3                            15.2   \n",
       "4                            15.2   \n",
       "..                            ...   \n",
       "595                          15.2   \n",
       "596                          15.2   \n",
       "597                          15.2   \n",
       "598                          15.2   \n",
       "599                          15.2   \n",
       "\n",
       "     QUANTILE_75 Average temperature at 2m altitude (TM)  \\\n",
       "0                                                 16.8     \n",
       "1                                                 16.8     \n",
       "2                                                 16.8     \n",
       "3                                                 16.8     \n",
       "4                                                 16.8     \n",
       "..                                                 ...     \n",
       "595                                               16.8     \n",
       "596                                               16.8     \n",
       "597                                               16.8     \n",
       "598                                               16.8     \n",
       "599                                               16.8     \n",
       "\n",
       "     QUANTILE_75 Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                                22.95         \n",
       "1                                                22.95         \n",
       "2                                                22.95         \n",
       "3                                                22.95         \n",
       "4                                                22.95         \n",
       "..                                                 ...         \n",
       "595                                              22.95         \n",
       "596                                              22.95         \n",
       "597                                              22.95         \n",
       "598                                              22.95         \n",
       "599                                              22.95         \n",
       "\n",
       "     QUANTILE_75 Minimum air temperature at 2m altitude (TN)  \\\n",
       "0                                                 11.5         \n",
       "1                                                 11.5         \n",
       "2                                                 11.5         \n",
       "3                                                 11.5         \n",
       "4                                                 11.5         \n",
       "..                                                 ...         \n",
       "595                                               11.5         \n",
       "596                                               11.5         \n",
       "597                                               11.5         \n",
       "598                                               11.5         \n",
       "599                                               11.5         \n",
       "\n",
       "     QUANTILE_75 Precipitation (RR)  QUANTILE_75 Relative humidity in 2m  \\\n",
       "0                          2.838274                                 84.0   \n",
       "1                          2.838274                                 84.0   \n",
       "2                          2.838274                                 84.0   \n",
       "3                          2.838274                                 84.0   \n",
       "4                          2.838274                                 84.0   \n",
       "..                              ...                                  ...   \n",
       "595                        2.838274                                 84.0   \n",
       "596                        2.838274                                 84.0   \n",
       "597                        2.838274                                 84.0   \n",
       "598                        2.838274                                 84.0   \n",
       "599                        2.838274                                 84.0   \n",
       "\n",
       "     QUANTILE_75 Relative humidity in 2m.1  QUANTILE_75 Wind gust (FG2)  \\\n",
       "0                                     99.9                        15.95   \n",
       "1                                     99.9                        15.95   \n",
       "2                                     99.9                        15.95   \n",
       "3                                     99.9                        15.95   \n",
       "4                                     99.9                        15.95   \n",
       "..                                     ...                          ...   \n",
       "595                                   99.9                        15.95   \n",
       "596                                   99.9                        15.95   \n",
       "597                                   99.9                        15.95   \n",
       "598                                   99.9                        15.95   \n",
       "599                                   99.9                        15.95   \n",
       "\n",
       "     QUANTILE_75 Wind speed in 2m  \n",
       "0                            16.8  \n",
       "1                            16.8  \n",
       "2                            16.8  \n",
       "3                            16.8  \n",
       "4                            16.8  \n",
       "..                            ...  \n",
       "595                          16.8  \n",
       "596                          16.8  \n",
       "597                          16.8  \n",
       "598                          16.8  \n",
       "599                          16.8  \n",
       "\n",
       "[600 rows x 121 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graminor_2019_Simps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T00:23:07.734119Z",
     "start_time": "2021-10-11T00:23:07.721143Z"
    }
   },
   "source": [
    "## Summary of processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:51.280955Z",
     "start_time": "2021-10-27T22:35:51.158283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graminor_2019_Simps : Missing GrainYield : 1\n",
      "*************************\n",
      "Graminor_2020_Simps : Missing GrainYield : 1\n",
      "*************************\n",
      "Masbasis_2019_Simps : Missing GrainYield : 6\n",
      "*************************\n",
      "Masbasis_2020_Simps : Missing GrainYield : 116\n",
      "*************************\n",
      "No nan values found in any column in Robot_2020_Simps\n",
      "*************************\n",
      "No nan values found in any column in Staur_2019_Simps\n",
      "*************************\n",
      "Staur_2020_Simps : Missing GrainYield : 568\n",
      "*************************\n",
      "Graminor_2019_Trapz : Missing GrainYield : 1\n",
      "*************************\n",
      "Graminor_2020_Trapz : Missing GrainYield : 1\n",
      "*************************\n",
      "Masbasis_2019_Trapz : Missing GrainYield : 6\n",
      "*************************\n",
      "Masbasis_2020_Trapz : Missing GrainYield : 116\n",
      "*************************\n",
      "No nan values found in any column in Robot_2020_Trapz\n",
      "*************************\n",
      "No nan values found in any column in Staur_2019_Trapz\n",
      "*************************\n",
      "Staur_2020_Trapz : Missing GrainYield : 568\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "for df in df_to_export:\n",
    "    temp_df = locals()[df].copy()\n",
    "    temp_cols = temp_df.columns.tolist()\n",
    "    # Bands, Indices, Plot_ID and GrainYield columns only\n",
    "    chk_cols = [x for x in temp_cols if x not in weather_cols_staur if x not in yield_cols]+['Plot_ID', 'GrainYield']\n",
    "    nan_found = False\n",
    "    for col in chk_cols:\n",
    "        if temp_df[col].isna().sum() > 0:\n",
    "            nan_found = True\n",
    "            print(df,': Missing', col,':', temp_df[col].isna().sum())\n",
    "    if not nan_found:\n",
    "        print(f'No nan values found in any column in {df}')\n",
    "    \n",
    "    print('*************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:51.296914Z",
     "start_time": "2021-10-27T22:35:51.282953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Graminor_2019_Simps',\n",
       " 'Graminor_2020_Simps',\n",
       " 'Masbasis_2019_Simps',\n",
       " 'Masbasis_2020_Simps',\n",
       " 'Robot_2020_Simps',\n",
       " 'Staur_2019_Simps',\n",
       " 'Staur_2020_Simps',\n",
       " 'Graminor_2019_Trapz',\n",
       " 'Graminor_2020_Trapz',\n",
       " 'Masbasis_2019_Trapz',\n",
       " 'Masbasis_2020_Trapz',\n",
       " 'Robot_2020_Trapz',\n",
       " 'Staur_2019_Trapz',\n",
       " 'Staur_2020_Trapz']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Environment Variable to differentiate Vollebek and Staur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:51.328829Z",
     "start_time": "2021-10-27T22:35:51.298909Z"
    }
   },
   "outputs": [],
   "source": [
    "for df in df_to_export:\n",
    "    temp_df = locals()[df].copy()\n",
    "    if 'Staur' in df:\n",
    "        temp_df['Staur_Env'] = int(1)\n",
    "        temp_df['Vollebekk_Env'] = int(0)\n",
    "    else:\n",
    "        temp_df['Staur_Env'] = int(0)\n",
    "        temp_df['Vollebekk_Env'] = int(1)\n",
    "    locals()[df] = temp_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:51.440531Z",
     "start_time": "2021-10-27T22:35:51.329826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plot_ID</th>\n",
       "      <th>GrainYield</th>\n",
       "      <th>Block</th>\n",
       "      <th>iBlock</th>\n",
       "      <th>Entry</th>\n",
       "      <th>Name</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Red</th>\n",
       "      <th>RedEdge</th>\n",
       "      <th>...</th>\n",
       "      <th>QUANTILE_75 Average temperature at 2m altitude (TM)</th>\n",
       "      <th>QUANTILE_75 Maximum air temperature at 2m altitude (TX)</th>\n",
       "      <th>QUANTILE_75 Minimum air temperature at 2m altitude (TN)</th>\n",
       "      <th>QUANTILE_75 Precipitation (RR)</th>\n",
       "      <th>QUANTILE_75 Relative humidity in 2m</th>\n",
       "      <th>QUANTILE_75 Relative humidity in 2m.1</th>\n",
       "      <th>QUANTILE_75 Wind gust (FG2)</th>\n",
       "      <th>QUANTILE_75 Wind speed in 2m</th>\n",
       "      <th>Staur_Env</th>\n",
       "      <th>Vollebekk_Env</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>654.708159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Zebra</td>\n",
       "      <td>0.721881</td>\n",
       "      <td>1.888871</td>\n",
       "      <td>1.432855</td>\n",
       "      <td>4.223841</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>709.595446</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>GN18666</td>\n",
       "      <td>0.703810</td>\n",
       "      <td>1.796074</td>\n",
       "      <td>1.336747</td>\n",
       "      <td>4.088164</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>707.100569</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>GN15590</td>\n",
       "      <td>0.753506</td>\n",
       "      <td>2.024628</td>\n",
       "      <td>1.461858</td>\n",
       "      <td>4.504250</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>724.958634</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Mirakel</td>\n",
       "      <td>0.712553</td>\n",
       "      <td>1.928361</td>\n",
       "      <td>1.322827</td>\n",
       "      <td>4.351697</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>740.978368</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>GN18751</td>\n",
       "      <td>0.658100</td>\n",
       "      <td>1.743676</td>\n",
       "      <td>1.323602</td>\n",
       "      <td>4.100732</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>896</td>\n",
       "      <td>663.899810</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>GN20696</td>\n",
       "      <td>1.207367</td>\n",
       "      <td>3.129361</td>\n",
       "      <td>1.572211</td>\n",
       "      <td>7.275563</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>897</td>\n",
       "      <td>722.332448</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>GN20693</td>\n",
       "      <td>1.218547</td>\n",
       "      <td>3.029369</td>\n",
       "      <td>1.604616</td>\n",
       "      <td>6.989788</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>898</td>\n",
       "      <td>782.997343</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>GN20679</td>\n",
       "      <td>1.247960</td>\n",
       "      <td>3.080470</td>\n",
       "      <td>1.537271</td>\n",
       "      <td>7.084423</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>899</td>\n",
       "      <td>712.352941</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>GN20682</td>\n",
       "      <td>1.132393</td>\n",
       "      <td>3.076316</td>\n",
       "      <td>1.513926</td>\n",
       "      <td>7.430210</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>900</td>\n",
       "      <td>757.129412</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>GN20686</td>\n",
       "      <td>1.236763</td>\n",
       "      <td>3.118357</td>\n",
       "      <td>1.631101</td>\n",
       "      <td>7.255371</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.05</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>96.9</td>\n",
       "      <td>15.4</td>\n",
       "      <td>16.55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Plot_ID  GrainYield  Block  iBlock  Entry     Name      Blue     Green  \\\n",
       "0        101  654.708159      1       1      1    Zebra  0.721881  1.888871   \n",
       "1        102  709.595446      1       1     19  GN18666  0.703810  1.796074   \n",
       "2        103  707.100569      1       1     11  GN15590  0.753506  2.024628   \n",
       "3        104  724.958634      1       1      5  Mirakel  0.712553  1.928361   \n",
       "4        105  740.978368      1       1     24  GN18751  0.658100  1.743676   \n",
       "..       ...         ...    ...     ...    ...      ...       ...       ...   \n",
       "795      896  663.899810      2      10     23  GN20696  1.207367  3.129361   \n",
       "796      897  722.332448      2      10     20  GN20693  1.218547  3.029369   \n",
       "797      898  782.997343      2      10      6  GN20679  1.247960  3.080470   \n",
       "798      899  712.352941      2      10      9  GN20682  1.132393  3.076316   \n",
       "799      900  757.129412      2      10     13  GN20686  1.236763  3.118357   \n",
       "\n",
       "          Red   RedEdge  ...  \\\n",
       "0    1.432855  4.223841  ...   \n",
       "1    1.336747  4.088164  ...   \n",
       "2    1.461858  4.504250  ...   \n",
       "3    1.322827  4.351697  ...   \n",
       "4    1.323602  4.100732  ...   \n",
       "..        ...       ...  ...   \n",
       "795  1.572211  7.275563  ...   \n",
       "796  1.604616  6.989788  ...   \n",
       "797  1.537271  7.084423  ...   \n",
       "798  1.513926  7.430210  ...   \n",
       "799  1.631101  7.255371  ...   \n",
       "\n",
       "     QUANTILE_75 Average temperature at 2m altitude (TM)  \\\n",
       "0                                                 15.8     \n",
       "1                                                 15.8     \n",
       "2                                                 15.8     \n",
       "3                                                 15.8     \n",
       "4                                                 15.8     \n",
       "..                                                 ...     \n",
       "795                                               15.8     \n",
       "796                                               15.8     \n",
       "797                                               15.8     \n",
       "798                                               15.8     \n",
       "799                                               15.8     \n",
       "\n",
       "     QUANTILE_75 Maximum air temperature at 2m altitude (TX)  \\\n",
       "0                                                22.05         \n",
       "1                                                22.05         \n",
       "2                                                22.05         \n",
       "3                                                22.05         \n",
       "4                                                22.05         \n",
       "..                                                 ...         \n",
       "795                                              22.05         \n",
       "796                                              22.05         \n",
       "797                                              22.05         \n",
       "798                                              22.05         \n",
       "799                                              22.05         \n",
       "\n",
       "     QUANTILE_75 Minimum air temperature at 2m altitude (TN)  \\\n",
       "0                                                 10.8         \n",
       "1                                                 10.8         \n",
       "2                                                 10.8         \n",
       "3                                                 10.8         \n",
       "4                                                 10.8         \n",
       "..                                                 ...         \n",
       "795                                               10.8         \n",
       "796                                               10.8         \n",
       "797                                               10.8         \n",
       "798                                               10.8         \n",
       "799                                               10.8         \n",
       "\n",
       "     QUANTILE_75 Precipitation (RR)  QUANTILE_75 Relative humidity in 2m  \\\n",
       "0                               1.3                                 73.9   \n",
       "1                               1.3                                 73.9   \n",
       "2                               1.3                                 73.9   \n",
       "3                               1.3                                 73.9   \n",
       "4                               1.3                                 73.9   \n",
       "..                              ...                                  ...   \n",
       "795                             1.3                                 73.9   \n",
       "796                             1.3                                 73.9   \n",
       "797                             1.3                                 73.9   \n",
       "798                             1.3                                 73.9   \n",
       "799                             1.3                                 73.9   \n",
       "\n",
       "     QUANTILE_75 Relative humidity in 2m.1  QUANTILE_75 Wind gust (FG2)  \\\n",
       "0                                     96.9                         15.4   \n",
       "1                                     96.9                         15.4   \n",
       "2                                     96.9                         15.4   \n",
       "3                                     96.9                         15.4   \n",
       "4                                     96.9                         15.4   \n",
       "..                                     ...                          ...   \n",
       "795                                   96.9                         15.4   \n",
       "796                                   96.9                         15.4   \n",
       "797                                   96.9                         15.4   \n",
       "798                                   96.9                         15.4   \n",
       "799                                   96.9                         15.4   \n",
       "\n",
       "     QUANTILE_75 Wind speed in 2m  Staur_Env  Vollebekk_Env  \n",
       "0                           16.55          0              1  \n",
       "1                           16.55          0              1  \n",
       "2                           16.55          0              1  \n",
       "3                           16.55          0              1  \n",
       "4                           16.55          0              1  \n",
       "..                            ...        ...            ...  \n",
       "795                         16.55          0              1  \n",
       "796                         16.55          0              1  \n",
       "797                         16.55          0              1  \n",
       "798                         16.55          0              1  \n",
       "799                         16.55          0              1  \n",
       "\n",
       "[800 rows x 123 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graminor_2020_Trapz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T22:35:54.054187Z",
     "start_time": "2021-10-27T22:35:51.441525Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(export_path, exist_ok=True)\n",
    "for df in df_to_export:\n",
    "    locals()[df].to_csv(export_path+df+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.235046Z",
     "start_time": "2021-10-19T23:33:13.135451Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ERROR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-709c7506b170>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mERROR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ERROR' is not defined"
     ]
    }
   ],
   "source": [
    "ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Genomics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.238039Z",
     "start_time": "2021-10-19T23:33:09.686Z"
    }
   },
   "outputs": [],
   "source": [
    "genomics_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Genomics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.239035Z",
     "start_time": "2021-10-19T23:33:10.213Z"
    }
   },
   "outputs": [],
   "source": [
    "# If the dataset had Days 2 heading and days to maturity columns then create the\n",
    "# following dictionary with the respective sowing dates of each field as value\n",
    "\n",
    "for df in all_df:\n",
    "    temp_df = locals()[df].copy()\n",
    "    field_temp = df.split('_')[0]+'_'+df.split('_')[1]\n",
    "    if 'Line' in temp_df.columns:\n",
    "        print(df)\n",
    "#         all_df_dates_filtered[df] = sowing_dict[field_temp]\n",
    "# all_df_dates_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.241030Z",
     "start_time": "2021-10-19T23:33:10.216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Yield data with line information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.242028Z",
     "start_time": "2021-10-19T23:33:10.220Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vollebekk 2019: Graminor_2019_x_19TvPhenores_x_Vollebekk_res\n",
    "# Masbasis 2020: Masbasis_x_20BMLGI1_2020_tm_x_data\n",
    "# Robot 2020: Robot_x_ROBOT_2020_x_raw\n",
    "# Masbasis 2019: Masbasis_2019_x_Field_data_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.244022Z",
     "start_time": "2021-10-19T23:33:10.224Z"
    }
   },
   "outputs": [],
   "source": [
    "a_file = open(main_path+'yield_df.json', \"r\")\n",
    "output_str = a_file.read()\n",
    "# The file is imported as string\n",
    "\n",
    "# Converting it to dictionary\n",
    "output_dict = json.loads(output_str)\n",
    "a_file.close()\n",
    "\n",
    "pprint(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking number of unique cultivars in the field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.246017Z",
     "start_time": "2021-10-19T23:33:10.753Z"
    }
   },
   "outputs": [],
   "source": [
    "# plots_data = pd.read_excel(files_with_address[0],engine='openpyxl')\n",
    "# # Pandas converts 'NA' string to NaN. Need to change those to \n",
    "# # some string to get a count as NaNs are not counted as unique values\n",
    "\n",
    "# plots_data.Name.fillna('-', inplace=True)\n",
    "# plots_data.CodeName.fillna('-', inplace=True)\n",
    "\n",
    "# # Creating a new column as multiple plots were named 'NA' but the \n",
    "# # CodeName was different for each one of them\n",
    "# plots_data['NameCode'] = plots_data.Name+plots_data.CodeName\n",
    "\n",
    "# plots_data\n",
    "# len(plots_data.NameCode.unique())\n",
    "# plots_data.NameCode.value_counts()\n",
    "# # plots_data.NameCode.value_counts().sum()\n",
    "# # plots_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo: Dropping NAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding NAN values\n",
    "### ToDo: Test: Raise error if missing values found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.247015Z",
     "start_time": "2021-10-19T23:33:11.813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding number of missing values in each dataframe\n",
    "df_with_nan = []\n",
    "missing_values = False\n",
    "for df in all_df:\n",
    "    if locals()[df].isna().sum().sum() > 0:\n",
    "        print(f'Total missing values in {df} are {locals()[df].isna().sum().sum()}')\n",
    "        missing_values = True\n",
    "        df_with_nan.append(df)\n",
    "#     if len(df_with_nan) > 0:\n",
    "#         raise ValueError\n",
    "if not missing_values:\n",
    "    print('No missing value found in any dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.249009Z",
     "start_time": "2021-10-19T23:33:11.816Z"
    }
   },
   "outputs": [],
   "source": [
    "Graminor_2019_all.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.250007Z",
     "start_time": "2021-10-19T23:33:11.819Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.252001Z",
     "start_time": "2021-10-19T23:33:11.821Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finding which column has NAN values\n",
    "for df in df_with_nan:\n",
    "    print(f'{df}:\\n {locals()[df].shape[1]-locals()[df].dropna(axis=1).shape[1]} columns or {locals()[df].shape[0]-locals()[df].dropna().shape[0]} rows to be dropped,')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Automate: Drop rows with missing values in df_with_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.253089Z",
     "start_time": "2021-10-19T23:33:12.370Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'{Graminor_eastwest_020719_NIR_half_missing.shape} Before dropping')\n",
    "# Graminor_eastwest_020719_NIR_half_missing.dropna(inplace=True)\n",
    "print(f'{Graminor_eastwest_020719_NIR_half_missing.shape} After dropping')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORRR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo: Droppping df with Nan from the all_df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.497738Z",
     "start_time": "2021-10-19T23:33:13.466468Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Number of items in all_df is {len(all_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.515424Z",
     "start_time": "2021-10-19T23:33:13.499734Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for df in df_with_nan:\n",
    "#     all_df.remove(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ToDo: Update field_year_dict and sorted_field_year_dict after dropping the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T23:33:13.935156Z",
     "start_time": "2021-10-19T23:33:13.923190Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Number of items in all_df now is {len(all_df)}')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325.417px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
